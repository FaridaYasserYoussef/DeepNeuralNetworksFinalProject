{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6575869",
   "metadata": {},
   "source": [
    "# Simple DNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "934847a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Users\\Suzan Hatem\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import  Dense,Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978ceb42",
   "metadata": {},
   "source": [
    "##### 1)Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "272b56c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>preprocessed_abstract</th>\n",
       "      <th>length_after_cleaning</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>2</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>35</td>\n",
       "      <td>what say</td>\n",
       "      <td>8</td>\n",
       "      <td>['what', 'say']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>1</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>72</td>\n",
       "      <td>plus add commercial experience tacky</td>\n",
       "      <td>36</td>\n",
       "      <td>['plus', 'add', 'commercial', 'experience', 't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>2</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>71</td>\n",
       "      <td>i today must mean i need take another trip</td>\n",
       "      <td>42</td>\n",
       "      <td>['i', 'today', 'must', 'mean', 'i', 'need', 't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>126</td>\n",
       "      <td>really aggressive blast obnoxious entertainmen...</td>\n",
       "      <td>78</td>\n",
       "      <td>['really', 'aggressive', 'blast', 'obnoxious',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>55</td>\n",
       "      <td>really big bad thing</td>\n",
       "      <td>20</td>\n",
       "      <td>['really', 'big', 'bad', 'thing']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id  label  \\\n",
       "0  570306133677760513      2   \n",
       "1  570301130888122368      1   \n",
       "2  570301083672813571      2   \n",
       "3  570301031407624196      0   \n",
       "4  570300817074462722      0   \n",
       "\n",
       "                                                text  length  \\\n",
       "0                @VirginAmerica What @dhepburn said.      35   \n",
       "1  @VirginAmerica plus you've added commercials t...      72   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...      71   \n",
       "3  @VirginAmerica it's really aggressive to blast...     126   \n",
       "4  @VirginAmerica and it's a really big bad thing...      55   \n",
       "\n",
       "                               preprocessed_abstract  length_after_cleaning  \\\n",
       "0                                           what say                      8   \n",
       "1               plus add commercial experience tacky                     36   \n",
       "2         i today must mean i need take another trip                     42   \n",
       "3  really aggressive blast obnoxious entertainmen...                     78   \n",
       "4                               really big bad thing                     20   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0                                    ['what', 'say']  \n",
       "1  ['plus', 'add', 'commercial', 'experience', 't...  \n",
       "2  ['i', 'today', 'must', 'mean', 'i', 'need', 't...  \n",
       "3  ['really', 'aggressive', 'blast', 'obnoxious',...  \n",
       "4                  ['really', 'big', 'bad', 'thing']  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"df_Original.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fc2dbfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id                  0\n",
       "label                     0\n",
       "text                      0\n",
       "length                    0\n",
       "preprocessed_abstract    17\n",
       "length_after_cleaning     0\n",
       "tokenized_text            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4ad58fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e03b6a9",
   "metadata": {},
   "source": [
    "#####  2) Split , into Training and Validation Sets (80:20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8741840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: (11698,) (11698,)\n",
      "Test data: (2925,) (2925,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['preprocessed_abstract'], df['label'], test_size=0.2, stratify=df['label'], random_state=42)\n",
    "print(\"Train data:\",  X_train.shape, y_train.shape)\n",
    "print(\"Test data:\",  X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d5b7f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "colors = ['#4285f4', '#ea4335', '#fbbc05', '#34a853']\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.pie([len(y_train), len(y_test)],\n",
    "        labels=['Train','Test'],\n",
    "        colors=colors, autopct='%.1f%%', explode=(0.05,0.05),\n",
    "        startangle=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a556ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_TF-IDF shape:  (11698, 814)\n",
      "X_test_TF-IDF shape:  (2925, 814)\n"
     ]
    }
   ],
   "source": [
    "vect= TfidfVectorizer(min_df=20)\n",
    "X_train_idf = vect.fit_transform(X_train)\n",
    "X_test_idf = vect.transform(X_test)\n",
    "\n",
    "print('X_train_TF-IDF shape: ', X_train_idf.shape)\n",
    "print('X_test_TF-IDF shape: ', X_test_idf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ffb115",
   "metadata": {},
   "source": [
    "##### 4)Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4620a071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Users\\Suzan Hatem\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(8,input_shape=(X_train_idf.shape[1],),kernel_regularizer='l2'),\n",
    "    Dense(16,activation='relu'),\n",
    "    Dense(8,activation='relu'),\n",
    "    Dense(3, activation='softmax')#This is a multi-class Classification problem\n",
    "    \n",
    "])\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=0.00001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abfb9a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 8)                 6520      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                144       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 27        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6827 (26.67 KB)\n",
      "Trainable params: 6827 (26.67 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea9dbdd",
   "metadata": {},
   "source": [
    "##### 5) Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a3407cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "WARNING:tensorflow:From D:\\Users\\Suzan Hatem\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Users\\Suzan Hatem\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "74/74 [==============================] - 2s 5ms/step - loss: 1.2501 - accuracy: 0.3879 - val_loss: 1.2475 - val_accuracy: 0.4013\n",
      "Epoch 2/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.2448 - accuracy: 0.4398 - val_loss: 1.2424 - val_accuracy: 0.4658\n",
      "Epoch 3/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.2397 - accuracy: 0.4878 - val_loss: 1.2372 - val_accuracy: 0.5248\n",
      "Epoch 4/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.2345 - accuracy: 0.5384 - val_loss: 1.2320 - val_accuracy: 0.5679\n",
      "Epoch 5/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.2294 - accuracy: 0.5734 - val_loss: 1.2269 - val_accuracy: 0.5893\n",
      "Epoch 6/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.2243 - accuracy: 0.5959 - val_loss: 1.2217 - val_accuracy: 0.6026\n",
      "Epoch 7/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.2191 - accuracy: 0.6117 - val_loss: 1.2166 - val_accuracy: 0.6145\n",
      "Epoch 8/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.2140 - accuracy: 0.6188 - val_loss: 1.2114 - val_accuracy: 0.6205\n",
      "Epoch 9/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.2088 - accuracy: 0.6234 - val_loss: 1.2062 - val_accuracy: 0.6248\n",
      "Epoch 10/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.2036 - accuracy: 0.6264 - val_loss: 1.2010 - val_accuracy: 0.6252\n",
      "Epoch 11/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.1984 - accuracy: 0.6273 - val_loss: 1.1958 - val_accuracy: 0.6256\n",
      "Epoch 12/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.1932 - accuracy: 0.6276 - val_loss: 1.1906 - val_accuracy: 0.6256\n",
      "Epoch 13/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.1879 - accuracy: 0.6277 - val_loss: 1.1853 - val_accuracy: 0.6256\n",
      "Epoch 14/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.1826 - accuracy: 0.6277 - val_loss: 1.1800 - val_accuracy: 0.6256\n",
      "Epoch 15/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.1773 - accuracy: 0.6277 - val_loss: 1.1747 - val_accuracy: 0.6256\n",
      "Epoch 16/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.1719 - accuracy: 0.6278 - val_loss: 1.1693 - val_accuracy: 0.6256\n",
      "Epoch 17/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.1665 - accuracy: 0.6278 - val_loss: 1.1639 - val_accuracy: 0.6256\n",
      "Epoch 18/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.1611 - accuracy: 0.6278 - val_loss: 1.1585 - val_accuracy: 0.6256\n",
      "Epoch 19/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.1557 - accuracy: 0.6278 - val_loss: 1.1531 - val_accuracy: 0.6256\n",
      "Epoch 20/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.1502 - accuracy: 0.6278 - val_loss: 1.1477 - val_accuracy: 0.6256\n",
      "Epoch 21/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.1448 - accuracy: 0.6278 - val_loss: 1.1423 - val_accuracy: 0.6256\n",
      "Epoch 22/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.1393 - accuracy: 0.6278 - val_loss: 1.1369 - val_accuracy: 0.6256\n",
      "Epoch 23/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.1339 - accuracy: 0.6278 - val_loss: 1.1315 - val_accuracy: 0.6256\n",
      "Epoch 24/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.1285 - accuracy: 0.6278 - val_loss: 1.1261 - val_accuracy: 0.6256\n",
      "Epoch 25/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.1231 - accuracy: 0.6278 - val_loss: 1.1207 - val_accuracy: 0.6256\n",
      "Epoch 26/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.1177 - accuracy: 0.6278 - val_loss: 1.1154 - val_accuracy: 0.6256\n",
      "Epoch 27/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.1123 - accuracy: 0.6278 - val_loss: 1.1101 - val_accuracy: 0.6256\n",
      "Epoch 28/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.1069 - accuracy: 0.6278 - val_loss: 1.1048 - val_accuracy: 0.6256\n",
      "Epoch 29/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.1015 - accuracy: 0.6278 - val_loss: 1.0996 - val_accuracy: 0.6256\n",
      "Epoch 30/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.0962 - accuracy: 0.6278 - val_loss: 1.0943 - val_accuracy: 0.6256\n",
      "Epoch 31/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.0909 - accuracy: 0.6278 - val_loss: 1.0891 - val_accuracy: 0.6256\n",
      "Epoch 32/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.0858 - accuracy: 0.6278 - val_loss: 1.0840 - val_accuracy: 0.6256\n",
      "Epoch 33/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.0805 - accuracy: 0.6278 - val_loss: 1.0789 - val_accuracy: 0.6256\n",
      "Epoch 34/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.0753 - accuracy: 0.6278 - val_loss: 1.0738 - val_accuracy: 0.6256\n",
      "Epoch 35/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.0702 - accuracy: 0.6278 - val_loss: 1.0688 - val_accuracy: 0.6256\n",
      "Epoch 36/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.0651 - accuracy: 0.6278 - val_loss: 1.0638 - val_accuracy: 0.6256\n",
      "Epoch 37/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.0600 - accuracy: 0.6278 - val_loss: 1.0588 - val_accuracy: 0.6256\n",
      "Epoch 38/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.0550 - accuracy: 0.6278 - val_loss: 1.0538 - val_accuracy: 0.6256\n",
      "Epoch 39/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.0500 - accuracy: 0.6278 - val_loss: 1.0490 - val_accuracy: 0.6256\n",
      "Epoch 40/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.0451 - accuracy: 0.6278 - val_loss: 1.0442 - val_accuracy: 0.6256\n",
      "Epoch 41/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.0402 - accuracy: 0.6278 - val_loss: 1.0394 - val_accuracy: 0.6256\n",
      "Epoch 42/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.0353 - accuracy: 0.6278 - val_loss: 1.0347 - val_accuracy: 0.6256\n",
      "Epoch 43/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.0305 - accuracy: 0.6278 - val_loss: 1.0300 - val_accuracy: 0.6256\n",
      "Epoch 44/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.0258 - accuracy: 0.6278 - val_loss: 1.0254 - val_accuracy: 0.6256\n",
      "Epoch 45/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.0212 - accuracy: 0.6278 - val_loss: 1.0209 - val_accuracy: 0.6256\n",
      "Epoch 46/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.0166 - accuracy: 0.6278 - val_loss: 1.0165 - val_accuracy: 0.6256\n",
      "Epoch 47/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.0120 - accuracy: 0.6278 - val_loss: 1.0121 - val_accuracy: 0.6256\n",
      "Epoch 48/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.0076 - accuracy: 0.6278 - val_loss: 1.0078 - val_accuracy: 0.6256\n",
      "Epoch 49/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.0032 - accuracy: 0.6278 - val_loss: 1.0036 - val_accuracy: 0.6256\n",
      "Epoch 50/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.9989 - accuracy: 0.6278 - val_loss: 0.9994 - val_accuracy: 0.6256\n",
      "Epoch 51/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.9946 - accuracy: 0.6278 - val_loss: 0.9953 - val_accuracy: 0.6256\n",
      "Epoch 52/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.9905 - accuracy: 0.6278 - val_loss: 0.9913 - val_accuracy: 0.6256\n",
      "Epoch 53/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.9864 - accuracy: 0.6278 - val_loss: 0.9874 - val_accuracy: 0.6256\n",
      "Epoch 54/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.9824 - accuracy: 0.6278 - val_loss: 0.9836 - val_accuracy: 0.6256\n",
      "Epoch 55/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 0s 2ms/step - loss: 0.9786 - accuracy: 0.6278 - val_loss: 0.9799 - val_accuracy: 0.6256\n",
      "Epoch 56/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.9748 - accuracy: 0.6278 - val_loss: 0.9762 - val_accuracy: 0.6256\n",
      "Epoch 57/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.9711 - accuracy: 0.6278 - val_loss: 0.9727 - val_accuracy: 0.6256\n",
      "Epoch 58/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.9674 - accuracy: 0.6278 - val_loss: 0.9692 - val_accuracy: 0.6256\n",
      "Epoch 59/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.9639 - accuracy: 0.6278 - val_loss: 0.9658 - val_accuracy: 0.6256\n",
      "Epoch 60/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.9604 - accuracy: 0.6278 - val_loss: 0.9625 - val_accuracy: 0.6256\n",
      "Epoch 61/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.9570 - accuracy: 0.6278 - val_loss: 0.9593 - val_accuracy: 0.6256\n",
      "Epoch 62/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.9537 - accuracy: 0.6278 - val_loss: 0.9562 - val_accuracy: 0.6256\n",
      "Epoch 63/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.9505 - accuracy: 0.6278 - val_loss: 0.9531 - val_accuracy: 0.6256\n",
      "Epoch 64/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.9474 - accuracy: 0.6278 - val_loss: 0.9501 - val_accuracy: 0.6256\n",
      "Epoch 65/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.9443 - accuracy: 0.6278 - val_loss: 0.9473 - val_accuracy: 0.6256\n",
      "Epoch 66/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.9414 - accuracy: 0.6278 - val_loss: 0.9445 - val_accuracy: 0.6256\n",
      "Epoch 67/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.9384 - accuracy: 0.6278 - val_loss: 0.9417 - val_accuracy: 0.6256\n",
      "Epoch 68/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.9357 - accuracy: 0.6278 - val_loss: 0.9391 - val_accuracy: 0.6256\n",
      "Epoch 69/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.9329 - accuracy: 0.6278 - val_loss: 0.9365 - val_accuracy: 0.6256\n",
      "Epoch 70/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.9303 - accuracy: 0.6278 - val_loss: 0.9340 - val_accuracy: 0.6256\n",
      "Epoch 71/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.9277 - accuracy: 0.6278 - val_loss: 0.9317 - val_accuracy: 0.6256\n",
      "Epoch 72/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.9253 - accuracy: 0.6278 - val_loss: 0.9294 - val_accuracy: 0.6256\n",
      "Epoch 73/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.9229 - accuracy: 0.6278 - val_loss: 0.9271 - val_accuracy: 0.6256\n",
      "Epoch 74/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.9205 - accuracy: 0.6278 - val_loss: 0.9249 - val_accuracy: 0.6256\n",
      "Epoch 75/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.9183 - accuracy: 0.6278 - val_loss: 0.9228 - val_accuracy: 0.6256\n",
      "Epoch 76/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.9161 - accuracy: 0.6278 - val_loss: 0.9208 - val_accuracy: 0.6256\n",
      "Epoch 77/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.9140 - accuracy: 0.6278 - val_loss: 0.9189 - val_accuracy: 0.6256\n",
      "Epoch 78/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.9120 - accuracy: 0.6278 - val_loss: 0.9170 - val_accuracy: 0.6256\n",
      "Epoch 79/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.9100 - accuracy: 0.6278 - val_loss: 0.9151 - val_accuracy: 0.6256\n",
      "Epoch 80/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.9081 - accuracy: 0.6278 - val_loss: 0.9134 - val_accuracy: 0.6256\n",
      "Epoch 81/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.9063 - accuracy: 0.6278 - val_loss: 0.9117 - val_accuracy: 0.6256\n",
      "Epoch 82/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.9045 - accuracy: 0.6278 - val_loss: 0.9101 - val_accuracy: 0.6256\n",
      "Epoch 83/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.9028 - accuracy: 0.6278 - val_loss: 0.9085 - val_accuracy: 0.6256\n",
      "Epoch 84/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.9011 - accuracy: 0.6278 - val_loss: 0.9069 - val_accuracy: 0.6256\n",
      "Epoch 85/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8995 - accuracy: 0.6278 - val_loss: 0.9054 - val_accuracy: 0.6256\n",
      "Epoch 86/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8979 - accuracy: 0.6278 - val_loss: 0.9040 - val_accuracy: 0.6256\n",
      "Epoch 87/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8964 - accuracy: 0.6278 - val_loss: 0.9025 - val_accuracy: 0.6256\n",
      "Epoch 88/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8949 - accuracy: 0.6278 - val_loss: 0.9012 - val_accuracy: 0.6256\n",
      "Epoch 89/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8935 - accuracy: 0.6278 - val_loss: 0.8999 - val_accuracy: 0.6256\n",
      "Epoch 90/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8921 - accuracy: 0.6278 - val_loss: 0.8986 - val_accuracy: 0.6256\n",
      "Epoch 91/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8907 - accuracy: 0.6278 - val_loss: 0.8973 - val_accuracy: 0.6256\n",
      "Epoch 92/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8893 - accuracy: 0.6278 - val_loss: 0.8960 - val_accuracy: 0.6256\n",
      "Epoch 93/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8880 - accuracy: 0.6278 - val_loss: 0.8949 - val_accuracy: 0.6256\n",
      "Epoch 94/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8867 - accuracy: 0.6278 - val_loss: 0.8937 - val_accuracy: 0.6256\n",
      "Epoch 95/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8855 - accuracy: 0.6278 - val_loss: 0.8925 - val_accuracy: 0.6256\n",
      "Epoch 96/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8842 - accuracy: 0.6278 - val_loss: 0.8913 - val_accuracy: 0.6256\n",
      "Epoch 97/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8830 - accuracy: 0.6278 - val_loss: 0.8902 - val_accuracy: 0.6256\n",
      "Epoch 98/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8818 - accuracy: 0.6278 - val_loss: 0.8891 - val_accuracy: 0.6256\n",
      "Epoch 99/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8806 - accuracy: 0.6278 - val_loss: 0.8880 - val_accuracy: 0.6256\n",
      "Epoch 100/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8794 - accuracy: 0.6278 - val_loss: 0.8869 - val_accuracy: 0.6256\n",
      "Epoch 101/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8782 - accuracy: 0.6278 - val_loss: 0.8858 - val_accuracy: 0.6256\n",
      "Epoch 102/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8770 - accuracy: 0.6278 - val_loss: 0.8848 - val_accuracy: 0.6256\n",
      "Epoch 103/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8759 - accuracy: 0.6278 - val_loss: 0.8837 - val_accuracy: 0.6256\n",
      "Epoch 104/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8747 - accuracy: 0.6278 - val_loss: 0.8827 - val_accuracy: 0.6256\n",
      "Epoch 105/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8735 - accuracy: 0.6278 - val_loss: 0.8816 - val_accuracy: 0.6256\n",
      "Epoch 106/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8724 - accuracy: 0.6278 - val_loss: 0.8805 - val_accuracy: 0.6256\n",
      "Epoch 107/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8712 - accuracy: 0.6278 - val_loss: 0.8795 - val_accuracy: 0.6256\n",
      "Epoch 108/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8701 - accuracy: 0.6278 - val_loss: 0.8785 - val_accuracy: 0.6256\n",
      "Epoch 109/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8689 - accuracy: 0.6278 - val_loss: 0.8774 - val_accuracy: 0.6256\n",
      "Epoch 110/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8678 - accuracy: 0.6278 - val_loss: 0.8764 - val_accuracy: 0.6256\n",
      "Epoch 111/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8667 - accuracy: 0.6278 - val_loss: 0.8754 - val_accuracy: 0.6256\n",
      "Epoch 112/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8655 - accuracy: 0.6278 - val_loss: 0.8744 - val_accuracy: 0.6256\n",
      "Epoch 113/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8644 - accuracy: 0.6278 - val_loss: 0.8734 - val_accuracy: 0.6256\n",
      "Epoch 114/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8633 - accuracy: 0.6278 - val_loss: 0.8724 - val_accuracy: 0.6256\n",
      "Epoch 115/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8622 - accuracy: 0.6278 - val_loss: 0.8714 - val_accuracy: 0.6256\n",
      "Epoch 116/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8611 - accuracy: 0.6278 - val_loss: 0.8704 - val_accuracy: 0.6256\n",
      "Epoch 117/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8599 - accuracy: 0.6278 - val_loss: 0.8694 - val_accuracy: 0.6256\n",
      "Epoch 118/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8588 - accuracy: 0.6278 - val_loss: 0.8684 - val_accuracy: 0.6256\n",
      "Epoch 119/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8577 - accuracy: 0.6278 - val_loss: 0.8674 - val_accuracy: 0.6256\n",
      "Epoch 120/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8566 - accuracy: 0.6278 - val_loss: 0.8664 - val_accuracy: 0.6256\n",
      "Epoch 121/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8555 - accuracy: 0.6278 - val_loss: 0.8654 - val_accuracy: 0.6256\n",
      "Epoch 122/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8543 - accuracy: 0.6278 - val_loss: 0.8644 - val_accuracy: 0.6256\n",
      "Epoch 123/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8532 - accuracy: 0.6278 - val_loss: 0.8634 - val_accuracy: 0.6256\n",
      "Epoch 124/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8521 - accuracy: 0.6278 - val_loss: 0.8625 - val_accuracy: 0.6256\n",
      "Epoch 125/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8509 - accuracy: 0.6278 - val_loss: 0.8615 - val_accuracy: 0.6256\n",
      "Epoch 126/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8498 - accuracy: 0.6278 - val_loss: 0.8605 - val_accuracy: 0.6256\n",
      "Epoch 127/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8487 - accuracy: 0.6278 - val_loss: 0.8595 - val_accuracy: 0.6256\n",
      "Epoch 128/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8475 - accuracy: 0.6278 - val_loss: 0.8585 - val_accuracy: 0.6256\n",
      "Epoch 129/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8464 - accuracy: 0.6278 - val_loss: 0.8576 - val_accuracy: 0.6256\n",
      "Epoch 130/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8453 - accuracy: 0.6278 - val_loss: 0.8566 - val_accuracy: 0.6256\n",
      "Epoch 131/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8441 - accuracy: 0.6278 - val_loss: 0.8556 - val_accuracy: 0.6256\n",
      "Epoch 132/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8430 - accuracy: 0.6278 - val_loss: 0.8547 - val_accuracy: 0.6256\n",
      "Epoch 133/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8419 - accuracy: 0.6278 - val_loss: 0.8537 - val_accuracy: 0.6256\n",
      "Epoch 134/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8408 - accuracy: 0.6278 - val_loss: 0.8527 - val_accuracy: 0.6256\n",
      "Epoch 135/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8396 - accuracy: 0.6278 - val_loss: 0.8517 - val_accuracy: 0.6256\n",
      "Epoch 136/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8385 - accuracy: 0.6278 - val_loss: 0.8508 - val_accuracy: 0.6256\n",
      "Epoch 137/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8374 - accuracy: 0.6278 - val_loss: 0.8498 - val_accuracy: 0.6256\n",
      "Epoch 138/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8362 - accuracy: 0.6278 - val_loss: 0.8488 - val_accuracy: 0.6256\n",
      "Epoch 139/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8351 - accuracy: 0.6278 - val_loss: 0.8479 - val_accuracy: 0.6256\n",
      "Epoch 140/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8340 - accuracy: 0.6278 - val_loss: 0.8469 - val_accuracy: 0.6256\n",
      "Epoch 141/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8328 - accuracy: 0.6278 - val_loss: 0.8460 - val_accuracy: 0.6256\n",
      "Epoch 142/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8317 - accuracy: 0.6278 - val_loss: 0.8450 - val_accuracy: 0.6256\n",
      "Epoch 143/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8306 - accuracy: 0.6278 - val_loss: 0.8441 - val_accuracy: 0.6256\n",
      "Epoch 144/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8294 - accuracy: 0.6278 - val_loss: 0.8431 - val_accuracy: 0.6256\n",
      "Epoch 145/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8283 - accuracy: 0.6278 - val_loss: 0.8422 - val_accuracy: 0.6256\n",
      "Epoch 146/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8271 - accuracy: 0.6278 - val_loss: 0.8412 - val_accuracy: 0.6256\n",
      "Epoch 147/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8260 - accuracy: 0.6278 - val_loss: 0.8403 - val_accuracy: 0.6256\n",
      "Epoch 148/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8249 - accuracy: 0.6278 - val_loss: 0.8393 - val_accuracy: 0.6256\n",
      "Epoch 149/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8237 - accuracy: 0.6278 - val_loss: 0.8384 - val_accuracy: 0.6256\n",
      "Epoch 150/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8226 - accuracy: 0.6278 - val_loss: 0.8374 - val_accuracy: 0.6256\n",
      "Epoch 151/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8215 - accuracy: 0.6278 - val_loss: 0.8365 - val_accuracy: 0.6256\n",
      "Epoch 152/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8203 - accuracy: 0.6278 - val_loss: 0.8356 - val_accuracy: 0.6256\n",
      "Epoch 153/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8192 - accuracy: 0.6278 - val_loss: 0.8347 - val_accuracy: 0.6256\n",
      "Epoch 154/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8181 - accuracy: 0.6278 - val_loss: 0.8337 - val_accuracy: 0.6256\n",
      "Epoch 155/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8170 - accuracy: 0.6278 - val_loss: 0.8328 - val_accuracy: 0.6256\n",
      "Epoch 156/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8159 - accuracy: 0.6278 - val_loss: 0.8319 - val_accuracy: 0.6256\n",
      "Epoch 157/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8147 - accuracy: 0.6278 - val_loss: 0.8310 - val_accuracy: 0.6256\n",
      "Epoch 158/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8136 - accuracy: 0.6278 - val_loss: 0.8301 - val_accuracy: 0.6256\n",
      "Epoch 159/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8125 - accuracy: 0.6278 - val_loss: 0.8293 - val_accuracy: 0.6256\n",
      "Epoch 160/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8114 - accuracy: 0.6278 - val_loss: 0.8284 - val_accuracy: 0.6256\n",
      "Epoch 161/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8103 - accuracy: 0.6278 - val_loss: 0.8275 - val_accuracy: 0.6256\n",
      "Epoch 162/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8093 - accuracy: 0.6278 - val_loss: 0.8266 - val_accuracy: 0.6256\n",
      "Epoch 163/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8082 - accuracy: 0.6278 - val_loss: 0.8258 - val_accuracy: 0.6256\n",
      "Epoch 164/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8071 - accuracy: 0.6278 - val_loss: 0.8249 - val_accuracy: 0.6256\n",
      "Epoch 165/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8060 - accuracy: 0.6278 - val_loss: 0.8240 - val_accuracy: 0.6256\n",
      "Epoch 166/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8049 - accuracy: 0.6278 - val_loss: 0.8231 - val_accuracy: 0.6256\n",
      "Epoch 167/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8038 - accuracy: 0.6278 - val_loss: 0.8222 - val_accuracy: 0.6256\n",
      "Epoch 168/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8027 - accuracy: 0.6278 - val_loss: 0.8214 - val_accuracy: 0.6256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8016 - accuracy: 0.6278 - val_loss: 0.8205 - val_accuracy: 0.6256\n",
      "Epoch 170/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8005 - accuracy: 0.6278 - val_loss: 0.8197 - val_accuracy: 0.6256\n",
      "Epoch 171/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7995 - accuracy: 0.6278 - val_loss: 0.8188 - val_accuracy: 0.6256\n",
      "Epoch 172/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7984 - accuracy: 0.6278 - val_loss: 0.8180 - val_accuracy: 0.6256\n",
      "Epoch 173/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7973 - accuracy: 0.6278 - val_loss: 0.8171 - val_accuracy: 0.6256\n",
      "Epoch 174/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7963 - accuracy: 0.6278 - val_loss: 0.8163 - val_accuracy: 0.6256\n",
      "Epoch 175/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7953 - accuracy: 0.6278 - val_loss: 0.8155 - val_accuracy: 0.6256\n",
      "Epoch 176/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7942 - accuracy: 0.6278 - val_loss: 0.8147 - val_accuracy: 0.6256\n",
      "Epoch 177/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7932 - accuracy: 0.6278 - val_loss: 0.8139 - val_accuracy: 0.6256\n",
      "Epoch 178/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7921 - accuracy: 0.6278 - val_loss: 0.8130 - val_accuracy: 0.6256\n",
      "Epoch 179/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7911 - accuracy: 0.6278 - val_loss: 0.8122 - val_accuracy: 0.6256\n",
      "Epoch 180/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7901 - accuracy: 0.6278 - val_loss: 0.8114 - val_accuracy: 0.6256\n",
      "Epoch 181/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7891 - accuracy: 0.6278 - val_loss: 0.8106 - val_accuracy: 0.6256\n",
      "Epoch 182/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7880 - accuracy: 0.6278 - val_loss: 0.8098 - val_accuracy: 0.6256\n",
      "Epoch 183/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7870 - accuracy: 0.6278 - val_loss: 0.8090 - val_accuracy: 0.6256\n",
      "Epoch 184/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7860 - accuracy: 0.6278 - val_loss: 0.8082 - val_accuracy: 0.6256\n",
      "Epoch 185/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7850 - accuracy: 0.6278 - val_loss: 0.8074 - val_accuracy: 0.6256\n",
      "Epoch 186/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7840 - accuracy: 0.6278 - val_loss: 0.8066 - val_accuracy: 0.6256\n",
      "Epoch 187/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7830 - accuracy: 0.6278 - val_loss: 0.8058 - val_accuracy: 0.6256\n",
      "Epoch 188/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7820 - accuracy: 0.6278 - val_loss: 0.8050 - val_accuracy: 0.6256\n",
      "Epoch 189/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7810 - accuracy: 0.6278 - val_loss: 0.8042 - val_accuracy: 0.6256\n",
      "Epoch 190/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7800 - accuracy: 0.6278 - val_loss: 0.8034 - val_accuracy: 0.6256\n",
      "Epoch 191/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7790 - accuracy: 0.6278 - val_loss: 0.8026 - val_accuracy: 0.6256\n",
      "Epoch 192/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7779 - accuracy: 0.6278 - val_loss: 0.8018 - val_accuracy: 0.6256\n",
      "Epoch 193/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7770 - accuracy: 0.6278 - val_loss: 0.8011 - val_accuracy: 0.6256\n",
      "Epoch 194/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7759 - accuracy: 0.6278 - val_loss: 0.8003 - val_accuracy: 0.6256\n",
      "Epoch 195/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7750 - accuracy: 0.6278 - val_loss: 0.7995 - val_accuracy: 0.6256\n",
      "Epoch 196/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7739 - accuracy: 0.6278 - val_loss: 0.7988 - val_accuracy: 0.6256\n",
      "Epoch 197/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7730 - accuracy: 0.6278 - val_loss: 0.7980 - val_accuracy: 0.6256\n",
      "Epoch 198/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7720 - accuracy: 0.6278 - val_loss: 0.7972 - val_accuracy: 0.6256\n",
      "Epoch 199/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7710 - accuracy: 0.6278 - val_loss: 0.7965 - val_accuracy: 0.6256\n",
      "Epoch 200/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7700 - accuracy: 0.6278 - val_loss: 0.7958 - val_accuracy: 0.6256\n",
      "Epoch 201/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7690 - accuracy: 0.6278 - val_loss: 0.7950 - val_accuracy: 0.6256\n",
      "Epoch 202/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7681 - accuracy: 0.6278 - val_loss: 0.7943 - val_accuracy: 0.6256\n",
      "Epoch 203/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7671 - accuracy: 0.6278 - val_loss: 0.7935 - val_accuracy: 0.6256\n",
      "Epoch 204/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7662 - accuracy: 0.6278 - val_loss: 0.7928 - val_accuracy: 0.6256\n",
      "Epoch 205/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7652 - accuracy: 0.6278 - val_loss: 0.7920 - val_accuracy: 0.6256\n",
      "Epoch 206/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7643 - accuracy: 0.6278 - val_loss: 0.7914 - val_accuracy: 0.6256\n",
      "Epoch 207/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7634 - accuracy: 0.6278 - val_loss: 0.7907 - val_accuracy: 0.6256\n",
      "Epoch 208/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7625 - accuracy: 0.6278 - val_loss: 0.7900 - val_accuracy: 0.6256\n",
      "Epoch 209/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7616 - accuracy: 0.6278 - val_loss: 0.7893 - val_accuracy: 0.6256\n",
      "Epoch 210/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7607 - accuracy: 0.6278 - val_loss: 0.7886 - val_accuracy: 0.6256\n",
      "Epoch 211/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7598 - accuracy: 0.6278 - val_loss: 0.7880 - val_accuracy: 0.6256\n",
      "Epoch 212/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7590 - accuracy: 0.6278 - val_loss: 0.7873 - val_accuracy: 0.6256\n",
      "Epoch 213/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7581 - accuracy: 0.6278 - val_loss: 0.7867 - val_accuracy: 0.6256\n",
      "Epoch 214/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7573 - accuracy: 0.6278 - val_loss: 0.7860 - val_accuracy: 0.6256\n",
      "Epoch 215/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7564 - accuracy: 0.6280 - val_loss: 0.7854 - val_accuracy: 0.6265\n",
      "Epoch 216/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7556 - accuracy: 0.6283 - val_loss: 0.7847 - val_accuracy: 0.6265\n",
      "Epoch 217/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7547 - accuracy: 0.6330 - val_loss: 0.7841 - val_accuracy: 0.6325\n",
      "Epoch 218/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7539 - accuracy: 0.6351 - val_loss: 0.7835 - val_accuracy: 0.6368\n",
      "Epoch 219/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7531 - accuracy: 0.6366 - val_loss: 0.7829 - val_accuracy: 0.6376\n",
      "Epoch 220/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7523 - accuracy: 0.6371 - val_loss: 0.7822 - val_accuracy: 0.6393\n",
      "Epoch 221/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7515 - accuracy: 0.6387 - val_loss: 0.7816 - val_accuracy: 0.6427\n",
      "Epoch 222/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7507 - accuracy: 0.6395 - val_loss: 0.7810 - val_accuracy: 0.6444\n",
      "Epoch 223/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7499 - accuracy: 0.6414 - val_loss: 0.7804 - val_accuracy: 0.6453\n",
      "Epoch 224/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7491 - accuracy: 0.6446 - val_loss: 0.7798 - val_accuracy: 0.6474\n",
      "Epoch 225/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7483 - accuracy: 0.6490 - val_loss: 0.7793 - val_accuracy: 0.6496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 226/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7476 - accuracy: 0.6537 - val_loss: 0.7787 - val_accuracy: 0.6543\n",
      "Epoch 227/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7468 - accuracy: 0.6585 - val_loss: 0.7781 - val_accuracy: 0.6581\n",
      "Epoch 228/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7460 - accuracy: 0.6736 - val_loss: 0.7776 - val_accuracy: 0.6688\n",
      "Epoch 229/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7453 - accuracy: 0.6748 - val_loss: 0.7770 - val_accuracy: 0.6692\n",
      "Epoch 230/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7446 - accuracy: 0.6764 - val_loss: 0.7764 - val_accuracy: 0.6697\n",
      "Epoch 231/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7438 - accuracy: 0.6777 - val_loss: 0.7759 - val_accuracy: 0.6709\n",
      "Epoch 232/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7431 - accuracy: 0.6788 - val_loss: 0.7753 - val_accuracy: 0.6714\n",
      "Epoch 233/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7423 - accuracy: 0.6801 - val_loss: 0.7748 - val_accuracy: 0.6722\n",
      "Epoch 234/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7416 - accuracy: 0.6813 - val_loss: 0.7742 - val_accuracy: 0.6731\n",
      "Epoch 235/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7409 - accuracy: 0.6823 - val_loss: 0.7737 - val_accuracy: 0.6748\n",
      "Epoch 236/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7402 - accuracy: 0.6833 - val_loss: 0.7732 - val_accuracy: 0.6748\n",
      "Epoch 237/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7395 - accuracy: 0.6842 - val_loss: 0.7727 - val_accuracy: 0.6748\n",
      "Epoch 238/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7388 - accuracy: 0.6852 - val_loss: 0.7721 - val_accuracy: 0.6756\n",
      "Epoch 239/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7381 - accuracy: 0.6855 - val_loss: 0.7717 - val_accuracy: 0.6761\n",
      "Epoch 240/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7374 - accuracy: 0.6862 - val_loss: 0.7712 - val_accuracy: 0.6774\n",
      "Epoch 241/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7367 - accuracy: 0.6867 - val_loss: 0.7706 - val_accuracy: 0.6774\n",
      "Epoch 242/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7361 - accuracy: 0.6871 - val_loss: 0.7701 - val_accuracy: 0.6778\n",
      "Epoch 243/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7354 - accuracy: 0.6873 - val_loss: 0.7697 - val_accuracy: 0.6778\n",
      "Epoch 244/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7347 - accuracy: 0.6874 - val_loss: 0.7692 - val_accuracy: 0.6778\n",
      "Epoch 245/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7341 - accuracy: 0.6880 - val_loss: 0.7687 - val_accuracy: 0.6778\n",
      "Epoch 246/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7334 - accuracy: 0.6881 - val_loss: 0.7682 - val_accuracy: 0.6782\n",
      "Epoch 247/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7328 - accuracy: 0.6881 - val_loss: 0.7677 - val_accuracy: 0.6786\n",
      "Epoch 248/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7321 - accuracy: 0.6884 - val_loss: 0.7672 - val_accuracy: 0.6791\n",
      "Epoch 249/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7315 - accuracy: 0.6889 - val_loss: 0.7668 - val_accuracy: 0.6791\n",
      "Epoch 250/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7308 - accuracy: 0.6891 - val_loss: 0.7663 - val_accuracy: 0.6795\n",
      "Epoch 251/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7302 - accuracy: 0.6899 - val_loss: 0.7658 - val_accuracy: 0.6799\n",
      "Epoch 252/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7295 - accuracy: 0.6903 - val_loss: 0.7653 - val_accuracy: 0.6803\n",
      "Epoch 253/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7289 - accuracy: 0.6906 - val_loss: 0.7649 - val_accuracy: 0.6799\n",
      "Epoch 254/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7283 - accuracy: 0.6911 - val_loss: 0.7644 - val_accuracy: 0.6795\n",
      "Epoch 255/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7277 - accuracy: 0.6917 - val_loss: 0.7640 - val_accuracy: 0.6803\n",
      "Epoch 256/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7270 - accuracy: 0.6918 - val_loss: 0.7635 - val_accuracy: 0.6808\n",
      "Epoch 257/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7264 - accuracy: 0.6921 - val_loss: 0.7631 - val_accuracy: 0.6808\n",
      "Epoch 258/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7258 - accuracy: 0.6923 - val_loss: 0.7626 - val_accuracy: 0.6812\n",
      "Epoch 259/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7252 - accuracy: 0.6926 - val_loss: 0.7622 - val_accuracy: 0.6816\n",
      "Epoch 260/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7246 - accuracy: 0.6927 - val_loss: 0.7617 - val_accuracy: 0.6803\n",
      "Epoch 261/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7240 - accuracy: 0.6929 - val_loss: 0.7613 - val_accuracy: 0.6803\n",
      "Epoch 262/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7234 - accuracy: 0.6933 - val_loss: 0.7609 - val_accuracy: 0.6816\n",
      "Epoch 263/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7228 - accuracy: 0.6936 - val_loss: 0.7604 - val_accuracy: 0.6838\n",
      "Epoch 264/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7222 - accuracy: 0.6942 - val_loss: 0.7600 - val_accuracy: 0.6842\n",
      "Epoch 265/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7216 - accuracy: 0.6943 - val_loss: 0.7596 - val_accuracy: 0.6833\n",
      "Epoch 266/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7210 - accuracy: 0.6946 - val_loss: 0.7592 - val_accuracy: 0.6838\n",
      "Epoch 267/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7205 - accuracy: 0.6949 - val_loss: 0.7587 - val_accuracy: 0.6850\n",
      "Epoch 268/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7199 - accuracy: 0.6950 - val_loss: 0.7583 - val_accuracy: 0.6863\n",
      "Epoch 269/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7193 - accuracy: 0.6957 - val_loss: 0.7579 - val_accuracy: 0.6868\n",
      "Epoch 270/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7188 - accuracy: 0.6971 - val_loss: 0.7575 - val_accuracy: 0.6880\n",
      "Epoch 271/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7182 - accuracy: 0.6978 - val_loss: 0.7570 - val_accuracy: 0.6885\n",
      "Epoch 272/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7176 - accuracy: 0.6988 - val_loss: 0.7567 - val_accuracy: 0.6885\n",
      "Epoch 273/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7171 - accuracy: 0.6999 - val_loss: 0.7562 - val_accuracy: 0.6889\n",
      "Epoch 274/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7165 - accuracy: 0.7030 - val_loss: 0.7558 - val_accuracy: 0.6932\n",
      "Epoch 275/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7160 - accuracy: 0.7060 - val_loss: 0.7554 - val_accuracy: 0.6944\n",
      "Epoch 276/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7154 - accuracy: 0.7069 - val_loss: 0.7550 - val_accuracy: 0.6953\n",
      "Epoch 277/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7148 - accuracy: 0.7075 - val_loss: 0.7546 - val_accuracy: 0.6957\n",
      "Epoch 278/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7143 - accuracy: 0.7082 - val_loss: 0.7542 - val_accuracy: 0.6957\n",
      "Epoch 279/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7138 - accuracy: 0.7086 - val_loss: 0.7538 - val_accuracy: 0.6953\n",
      "Epoch 280/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7132 - accuracy: 0.7090 - val_loss: 0.7534 - val_accuracy: 0.6953\n",
      "Epoch 281/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7127 - accuracy: 0.7096 - val_loss: 0.7530 - val_accuracy: 0.6957\n",
      "Epoch 282/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7121 - accuracy: 0.7103 - val_loss: 0.7526 - val_accuracy: 0.6953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 283/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7116 - accuracy: 0.7110 - val_loss: 0.7522 - val_accuracy: 0.6957\n",
      "Epoch 284/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7111 - accuracy: 0.7108 - val_loss: 0.7519 - val_accuracy: 0.6957\n",
      "Epoch 285/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7106 - accuracy: 0.7113 - val_loss: 0.7515 - val_accuracy: 0.6957\n",
      "Epoch 286/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7100 - accuracy: 0.7113 - val_loss: 0.7511 - val_accuracy: 0.6953\n",
      "Epoch 287/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7095 - accuracy: 0.7115 - val_loss: 0.7508 - val_accuracy: 0.6957\n",
      "Epoch 288/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7090 - accuracy: 0.7115 - val_loss: 0.7504 - val_accuracy: 0.6953\n",
      "Epoch 289/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7085 - accuracy: 0.7119 - val_loss: 0.7500 - val_accuracy: 0.6957\n",
      "Epoch 290/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7080 - accuracy: 0.7119 - val_loss: 0.7497 - val_accuracy: 0.6957\n",
      "Epoch 291/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7074 - accuracy: 0.7120 - val_loss: 0.7493 - val_accuracy: 0.6957\n",
      "Epoch 292/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7069 - accuracy: 0.7125 - val_loss: 0.7489 - val_accuracy: 0.6957\n",
      "Epoch 293/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7064 - accuracy: 0.7132 - val_loss: 0.7485 - val_accuracy: 0.6957\n",
      "Epoch 294/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7059 - accuracy: 0.7132 - val_loss: 0.7482 - val_accuracy: 0.6953\n",
      "Epoch 295/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7054 - accuracy: 0.7140 - val_loss: 0.7478 - val_accuracy: 0.6966\n",
      "Epoch 296/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7049 - accuracy: 0.7146 - val_loss: 0.7474 - val_accuracy: 0.6966\n",
      "Epoch 297/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7044 - accuracy: 0.7153 - val_loss: 0.7471 - val_accuracy: 0.6970\n",
      "Epoch 298/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7039 - accuracy: 0.7153 - val_loss: 0.7467 - val_accuracy: 0.6979\n",
      "Epoch 299/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7034 - accuracy: 0.7164 - val_loss: 0.7463 - val_accuracy: 0.6983\n",
      "Epoch 300/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7029 - accuracy: 0.7164 - val_loss: 0.7460 - val_accuracy: 0.6983\n",
      "Epoch 301/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7024 - accuracy: 0.7167 - val_loss: 0.7457 - val_accuracy: 0.6991\n",
      "Epoch 302/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7019 - accuracy: 0.7178 - val_loss: 0.7453 - val_accuracy: 0.6996\n",
      "Epoch 303/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7014 - accuracy: 0.7182 - val_loss: 0.7450 - val_accuracy: 0.6996\n",
      "Epoch 304/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7009 - accuracy: 0.7195 - val_loss: 0.7446 - val_accuracy: 0.6996\n",
      "Epoch 305/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7004 - accuracy: 0.7200 - val_loss: 0.7443 - val_accuracy: 0.7009\n",
      "Epoch 306/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6999 - accuracy: 0.7209 - val_loss: 0.7439 - val_accuracy: 0.7009\n",
      "Epoch 307/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6994 - accuracy: 0.7221 - val_loss: 0.7435 - val_accuracy: 0.7026\n",
      "Epoch 308/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6990 - accuracy: 0.7228 - val_loss: 0.7432 - val_accuracy: 0.7030\n",
      "Epoch 309/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6985 - accuracy: 0.7232 - val_loss: 0.7429 - val_accuracy: 0.7017\n",
      "Epoch 310/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6980 - accuracy: 0.7237 - val_loss: 0.7426 - val_accuracy: 0.7013\n",
      "Epoch 311/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6975 - accuracy: 0.7249 - val_loss: 0.7422 - val_accuracy: 0.7013\n",
      "Epoch 312/2000\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.6970 - accuracy: 0.7249 - val_loss: 0.7419 - val_accuracy: 0.7017\n",
      "Epoch 313/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6965 - accuracy: 0.7260 - val_loss: 0.7415 - val_accuracy: 0.7021\n",
      "Epoch 314/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6960 - accuracy: 0.7271 - val_loss: 0.7412 - val_accuracy: 0.7021\n",
      "Epoch 315/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6955 - accuracy: 0.7274 - val_loss: 0.7409 - val_accuracy: 0.7021\n",
      "Epoch 316/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6950 - accuracy: 0.7276 - val_loss: 0.7405 - val_accuracy: 0.7030\n",
      "Epoch 317/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6946 - accuracy: 0.7275 - val_loss: 0.7402 - val_accuracy: 0.7030\n",
      "Epoch 318/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.7285 - val_loss: 0.7398 - val_accuracy: 0.7030\n",
      "Epoch 319/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.7289 - val_loss: 0.7395 - val_accuracy: 0.7038\n",
      "Epoch 320/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.7289 - val_loss: 0.7392 - val_accuracy: 0.7043\n",
      "Epoch 321/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.7293 - val_loss: 0.7388 - val_accuracy: 0.7051\n",
      "Epoch 322/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6920 - accuracy: 0.7300 - val_loss: 0.7384 - val_accuracy: 0.7056\n",
      "Epoch 323/2000\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.6915 - accuracy: 0.7307 - val_loss: 0.7381 - val_accuracy: 0.7056\n",
      "Epoch 324/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.7314 - val_loss: 0.7377 - val_accuracy: 0.7068\n",
      "Epoch 325/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.7320 - val_loss: 0.7374 - val_accuracy: 0.7068\n",
      "Epoch 326/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6900 - accuracy: 0.7330 - val_loss: 0.7370 - val_accuracy: 0.7081\n",
      "Epoch 327/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6895 - accuracy: 0.7336 - val_loss: 0.7366 - val_accuracy: 0.7090\n",
      "Epoch 328/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6889 - accuracy: 0.7335 - val_loss: 0.7363 - val_accuracy: 0.7094\n",
      "Epoch 329/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6884 - accuracy: 0.7341 - val_loss: 0.7359 - val_accuracy: 0.7098\n",
      "Epoch 330/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6879 - accuracy: 0.7347 - val_loss: 0.7356 - val_accuracy: 0.7107\n",
      "Epoch 331/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6874 - accuracy: 0.7349 - val_loss: 0.7353 - val_accuracy: 0.7107\n",
      "Epoch 332/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6869 - accuracy: 0.7357 - val_loss: 0.7350 - val_accuracy: 0.7115\n",
      "Epoch 333/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6864 - accuracy: 0.7357 - val_loss: 0.7346 - val_accuracy: 0.7115\n",
      "Epoch 334/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6859 - accuracy: 0.7362 - val_loss: 0.7343 - val_accuracy: 0.7111\n",
      "Epoch 335/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6855 - accuracy: 0.7367 - val_loss: 0.7340 - val_accuracy: 0.7120\n",
      "Epoch 336/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6850 - accuracy: 0.7366 - val_loss: 0.7337 - val_accuracy: 0.7120\n",
      "Epoch 337/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.7367 - val_loss: 0.7334 - val_accuracy: 0.7124\n",
      "Epoch 338/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6840 - accuracy: 0.7364 - val_loss: 0.7331 - val_accuracy: 0.7128\n",
      "Epoch 339/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6836 - accuracy: 0.7366 - val_loss: 0.7328 - val_accuracy: 0.7132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 340/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6831 - accuracy: 0.7368 - val_loss: 0.7324 - val_accuracy: 0.7132\n",
      "Epoch 341/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6826 - accuracy: 0.7370 - val_loss: 0.7321 - val_accuracy: 0.7132\n",
      "Epoch 342/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6822 - accuracy: 0.7379 - val_loss: 0.7318 - val_accuracy: 0.7141\n",
      "Epoch 343/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6817 - accuracy: 0.7380 - val_loss: 0.7315 - val_accuracy: 0.7141\n",
      "Epoch 344/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6813 - accuracy: 0.7380 - val_loss: 0.7312 - val_accuracy: 0.7145\n",
      "Epoch 345/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6808 - accuracy: 0.7387 - val_loss: 0.7309 - val_accuracy: 0.7150\n",
      "Epoch 346/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6804 - accuracy: 0.7387 - val_loss: 0.7306 - val_accuracy: 0.7150\n",
      "Epoch 347/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6799 - accuracy: 0.7401 - val_loss: 0.7302 - val_accuracy: 0.7141\n",
      "Epoch 348/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6795 - accuracy: 0.7400 - val_loss: 0.7299 - val_accuracy: 0.7145\n",
      "Epoch 349/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6790 - accuracy: 0.7405 - val_loss: 0.7297 - val_accuracy: 0.7154\n",
      "Epoch 350/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6786 - accuracy: 0.7408 - val_loss: 0.7294 - val_accuracy: 0.7154\n",
      "Epoch 351/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6782 - accuracy: 0.7405 - val_loss: 0.7291 - val_accuracy: 0.7154\n",
      "Epoch 352/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6778 - accuracy: 0.7412 - val_loss: 0.7288 - val_accuracy: 0.7171\n",
      "Epoch 353/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6773 - accuracy: 0.7417 - val_loss: 0.7284 - val_accuracy: 0.7184\n",
      "Epoch 354/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6769 - accuracy: 0.7424 - val_loss: 0.7282 - val_accuracy: 0.7184\n",
      "Epoch 355/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6765 - accuracy: 0.7424 - val_loss: 0.7279 - val_accuracy: 0.7184\n",
      "Epoch 356/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6761 - accuracy: 0.7425 - val_loss: 0.7277 - val_accuracy: 0.7184\n",
      "Epoch 357/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6756 - accuracy: 0.7428 - val_loss: 0.7273 - val_accuracy: 0.7188\n",
      "Epoch 358/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6752 - accuracy: 0.7429 - val_loss: 0.7271 - val_accuracy: 0.7184\n",
      "Epoch 359/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6748 - accuracy: 0.7431 - val_loss: 0.7268 - val_accuracy: 0.7184\n",
      "Epoch 360/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6744 - accuracy: 0.7439 - val_loss: 0.7265 - val_accuracy: 0.7197\n",
      "Epoch 361/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6740 - accuracy: 0.7441 - val_loss: 0.7263 - val_accuracy: 0.7201\n",
      "Epoch 362/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6736 - accuracy: 0.7451 - val_loss: 0.7260 - val_accuracy: 0.7201\n",
      "Epoch 363/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6732 - accuracy: 0.7451 - val_loss: 0.7258 - val_accuracy: 0.7205\n",
      "Epoch 364/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6728 - accuracy: 0.7458 - val_loss: 0.7255 - val_accuracy: 0.7201\n",
      "Epoch 365/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6723 - accuracy: 0.7459 - val_loss: 0.7252 - val_accuracy: 0.7205\n",
      "Epoch 366/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6719 - accuracy: 0.7459 - val_loss: 0.7250 - val_accuracy: 0.7201\n",
      "Epoch 367/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6715 - accuracy: 0.7471 - val_loss: 0.7247 - val_accuracy: 0.7201\n",
      "Epoch 368/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6711 - accuracy: 0.7468 - val_loss: 0.7245 - val_accuracy: 0.7201\n",
      "Epoch 369/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6707 - accuracy: 0.7474 - val_loss: 0.7242 - val_accuracy: 0.7201\n",
      "Epoch 370/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6703 - accuracy: 0.7472 - val_loss: 0.7240 - val_accuracy: 0.7205\n",
      "Epoch 371/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6699 - accuracy: 0.7472 - val_loss: 0.7237 - val_accuracy: 0.7201\n",
      "Epoch 372/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6695 - accuracy: 0.7479 - val_loss: 0.7234 - val_accuracy: 0.7209\n",
      "Epoch 373/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6691 - accuracy: 0.7482 - val_loss: 0.7231 - val_accuracy: 0.7205\n",
      "Epoch 374/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6687 - accuracy: 0.7481 - val_loss: 0.7229 - val_accuracy: 0.7209\n",
      "Epoch 375/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6683 - accuracy: 0.7482 - val_loss: 0.7227 - val_accuracy: 0.7218\n",
      "Epoch 376/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6679 - accuracy: 0.7489 - val_loss: 0.7224 - val_accuracy: 0.7218\n",
      "Epoch 377/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6675 - accuracy: 0.7491 - val_loss: 0.7221 - val_accuracy: 0.7218\n",
      "Epoch 378/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6671 - accuracy: 0.7489 - val_loss: 0.7220 - val_accuracy: 0.7222\n",
      "Epoch 379/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6667 - accuracy: 0.7493 - val_loss: 0.7216 - val_accuracy: 0.7231\n",
      "Epoch 380/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6663 - accuracy: 0.7493 - val_loss: 0.7214 - val_accuracy: 0.7231\n",
      "Epoch 381/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6659 - accuracy: 0.7497 - val_loss: 0.7211 - val_accuracy: 0.7235\n",
      "Epoch 382/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6655 - accuracy: 0.7499 - val_loss: 0.7208 - val_accuracy: 0.7231\n",
      "Epoch 383/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6651 - accuracy: 0.7506 - val_loss: 0.7206 - val_accuracy: 0.7239\n",
      "Epoch 384/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6648 - accuracy: 0.7505 - val_loss: 0.7203 - val_accuracy: 0.7239\n",
      "Epoch 385/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6644 - accuracy: 0.7511 - val_loss: 0.7201 - val_accuracy: 0.7244\n",
      "Epoch 386/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6640 - accuracy: 0.7514 - val_loss: 0.7199 - val_accuracy: 0.7244\n",
      "Epoch 387/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6636 - accuracy: 0.7514 - val_loss: 0.7197 - val_accuracy: 0.7235\n",
      "Epoch 388/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6632 - accuracy: 0.7522 - val_loss: 0.7194 - val_accuracy: 0.7235\n",
      "Epoch 389/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6628 - accuracy: 0.7528 - val_loss: 0.7191 - val_accuracy: 0.7235\n",
      "Epoch 390/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6624 - accuracy: 0.7535 - val_loss: 0.7188 - val_accuracy: 0.7244\n",
      "Epoch 391/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6620 - accuracy: 0.7536 - val_loss: 0.7186 - val_accuracy: 0.7248\n",
      "Epoch 392/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6616 - accuracy: 0.7538 - val_loss: 0.7184 - val_accuracy: 0.7248\n",
      "Epoch 393/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6612 - accuracy: 0.7539 - val_loss: 0.7182 - val_accuracy: 0.7248\n",
      "Epoch 394/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6609 - accuracy: 0.7541 - val_loss: 0.7178 - val_accuracy: 0.7239\n",
      "Epoch 395/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6605 - accuracy: 0.7556 - val_loss: 0.7175 - val_accuracy: 0.7239\n",
      "Epoch 396/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6601 - accuracy: 0.7559 - val_loss: 0.7174 - val_accuracy: 0.7239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 397/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6597 - accuracy: 0.7559 - val_loss: 0.7171 - val_accuracy: 0.7235\n",
      "Epoch 398/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6593 - accuracy: 0.7566 - val_loss: 0.7169 - val_accuracy: 0.7235\n",
      "Epoch 399/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6590 - accuracy: 0.7575 - val_loss: 0.7166 - val_accuracy: 0.7235\n",
      "Epoch 400/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6586 - accuracy: 0.7574 - val_loss: 0.7164 - val_accuracy: 0.7235\n",
      "Epoch 401/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6582 - accuracy: 0.7580 - val_loss: 0.7162 - val_accuracy: 0.7239\n",
      "Epoch 402/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6578 - accuracy: 0.7581 - val_loss: 0.7160 - val_accuracy: 0.7239\n",
      "Epoch 403/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6575 - accuracy: 0.7580 - val_loss: 0.7158 - val_accuracy: 0.7235\n",
      "Epoch 404/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6571 - accuracy: 0.7582 - val_loss: 0.7156 - val_accuracy: 0.7235\n",
      "Epoch 405/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6567 - accuracy: 0.7585 - val_loss: 0.7153 - val_accuracy: 0.7244\n",
      "Epoch 406/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6564 - accuracy: 0.7586 - val_loss: 0.7151 - val_accuracy: 0.7244\n",
      "Epoch 407/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6560 - accuracy: 0.7590 - val_loss: 0.7148 - val_accuracy: 0.7239\n",
      "Epoch 408/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6556 - accuracy: 0.7589 - val_loss: 0.7146 - val_accuracy: 0.7239\n",
      "Epoch 409/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6552 - accuracy: 0.7594 - val_loss: 0.7144 - val_accuracy: 0.7239\n",
      "Epoch 410/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6549 - accuracy: 0.7592 - val_loss: 0.7142 - val_accuracy: 0.7239\n",
      "Epoch 411/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6545 - accuracy: 0.7592 - val_loss: 0.7139 - val_accuracy: 0.7239\n",
      "Epoch 412/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6541 - accuracy: 0.7601 - val_loss: 0.7137 - val_accuracy: 0.7239\n",
      "Epoch 413/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6538 - accuracy: 0.7591 - val_loss: 0.7135 - val_accuracy: 0.7244\n",
      "Epoch 414/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6534 - accuracy: 0.7601 - val_loss: 0.7133 - val_accuracy: 0.7244\n",
      "Epoch 415/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6530 - accuracy: 0.7602 - val_loss: 0.7131 - val_accuracy: 0.7248\n",
      "Epoch 416/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6527 - accuracy: 0.7603 - val_loss: 0.7129 - val_accuracy: 0.7248\n",
      "Epoch 417/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6523 - accuracy: 0.7604 - val_loss: 0.7126 - val_accuracy: 0.7252\n",
      "Epoch 418/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6519 - accuracy: 0.7605 - val_loss: 0.7124 - val_accuracy: 0.7256\n",
      "Epoch 419/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6515 - accuracy: 0.7612 - val_loss: 0.7121 - val_accuracy: 0.7256\n",
      "Epoch 420/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6512 - accuracy: 0.7613 - val_loss: 0.7119 - val_accuracy: 0.7261\n",
      "Epoch 421/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6508 - accuracy: 0.7617 - val_loss: 0.7117 - val_accuracy: 0.7261\n",
      "Epoch 422/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6505 - accuracy: 0.7617 - val_loss: 0.7115 - val_accuracy: 0.7256\n",
      "Epoch 423/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6501 - accuracy: 0.7621 - val_loss: 0.7113 - val_accuracy: 0.7256\n",
      "Epoch 424/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6497 - accuracy: 0.7628 - val_loss: 0.7111 - val_accuracy: 0.7256\n",
      "Epoch 425/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6494 - accuracy: 0.7628 - val_loss: 0.7108 - val_accuracy: 0.7261\n",
      "Epoch 426/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6490 - accuracy: 0.7642 - val_loss: 0.7105 - val_accuracy: 0.7265\n",
      "Epoch 427/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6487 - accuracy: 0.7633 - val_loss: 0.7103 - val_accuracy: 0.7265\n",
      "Epoch 428/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6483 - accuracy: 0.7638 - val_loss: 0.7101 - val_accuracy: 0.7265\n",
      "Epoch 429/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6479 - accuracy: 0.7645 - val_loss: 0.7099 - val_accuracy: 0.7265\n",
      "Epoch 430/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6476 - accuracy: 0.7645 - val_loss: 0.7097 - val_accuracy: 0.7265\n",
      "Epoch 431/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6472 - accuracy: 0.7645 - val_loss: 0.7095 - val_accuracy: 0.7265\n",
      "Epoch 432/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6468 - accuracy: 0.7648 - val_loss: 0.7092 - val_accuracy: 0.7265\n",
      "Epoch 433/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6465 - accuracy: 0.7644 - val_loss: 0.7091 - val_accuracy: 0.7261\n",
      "Epoch 434/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6461 - accuracy: 0.7649 - val_loss: 0.7088 - val_accuracy: 0.7261\n",
      "Epoch 435/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6458 - accuracy: 0.7650 - val_loss: 0.7086 - val_accuracy: 0.7265\n",
      "Epoch 436/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6454 - accuracy: 0.7651 - val_loss: 0.7084 - val_accuracy: 0.7265\n",
      "Epoch 437/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6451 - accuracy: 0.7654 - val_loss: 0.7081 - val_accuracy: 0.7261\n",
      "Epoch 438/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6447 - accuracy: 0.7651 - val_loss: 0.7080 - val_accuracy: 0.7261\n",
      "Epoch 439/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6443 - accuracy: 0.7655 - val_loss: 0.7077 - val_accuracy: 0.7256\n",
      "Epoch 440/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6440 - accuracy: 0.7661 - val_loss: 0.7075 - val_accuracy: 0.7261\n",
      "Epoch 441/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6436 - accuracy: 0.7665 - val_loss: 0.7073 - val_accuracy: 0.7265\n",
      "Epoch 442/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6433 - accuracy: 0.7674 - val_loss: 0.7070 - val_accuracy: 0.7269\n",
      "Epoch 443/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6429 - accuracy: 0.7680 - val_loss: 0.7068 - val_accuracy: 0.7274\n",
      "Epoch 444/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6426 - accuracy: 0.7676 - val_loss: 0.7067 - val_accuracy: 0.7269\n",
      "Epoch 445/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6422 - accuracy: 0.7679 - val_loss: 0.7064 - val_accuracy: 0.7274\n",
      "Epoch 446/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6419 - accuracy: 0.7691 - val_loss: 0.7062 - val_accuracy: 0.7269\n",
      "Epoch 447/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6415 - accuracy: 0.7689 - val_loss: 0.7060 - val_accuracy: 0.7274\n",
      "Epoch 448/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6412 - accuracy: 0.7689 - val_loss: 0.7058 - val_accuracy: 0.7269\n",
      "Epoch 449/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6408 - accuracy: 0.7693 - val_loss: 0.7057 - val_accuracy: 0.7269\n",
      "Epoch 450/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6405 - accuracy: 0.7690 - val_loss: 0.7054 - val_accuracy: 0.7278\n",
      "Epoch 451/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6401 - accuracy: 0.7690 - val_loss: 0.7052 - val_accuracy: 0.7282\n",
      "Epoch 452/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6398 - accuracy: 0.7692 - val_loss: 0.7049 - val_accuracy: 0.7282\n",
      "Epoch 453/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6394 - accuracy: 0.7701 - val_loss: 0.7047 - val_accuracy: 0.7278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 454/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6391 - accuracy: 0.7700 - val_loss: 0.7045 - val_accuracy: 0.7282\n",
      "Epoch 455/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6387 - accuracy: 0.7705 - val_loss: 0.7043 - val_accuracy: 0.7282\n",
      "Epoch 456/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6384 - accuracy: 0.7704 - val_loss: 0.7041 - val_accuracy: 0.7282\n",
      "Epoch 457/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6380 - accuracy: 0.7705 - val_loss: 0.7040 - val_accuracy: 0.7282\n",
      "Epoch 458/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6377 - accuracy: 0.7708 - val_loss: 0.7038 - val_accuracy: 0.7282\n",
      "Epoch 459/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6374 - accuracy: 0.7711 - val_loss: 0.7035 - val_accuracy: 0.7286\n",
      "Epoch 460/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6370 - accuracy: 0.7708 - val_loss: 0.7033 - val_accuracy: 0.7286\n",
      "Epoch 461/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6367 - accuracy: 0.7714 - val_loss: 0.7032 - val_accuracy: 0.7286\n",
      "Epoch 462/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6363 - accuracy: 0.7712 - val_loss: 0.7029 - val_accuracy: 0.7291\n",
      "Epoch 463/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6360 - accuracy: 0.7721 - val_loss: 0.7027 - val_accuracy: 0.7295\n",
      "Epoch 464/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6356 - accuracy: 0.7722 - val_loss: 0.7025 - val_accuracy: 0.7295\n",
      "Epoch 465/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6353 - accuracy: 0.7726 - val_loss: 0.7023 - val_accuracy: 0.7299\n",
      "Epoch 466/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6350 - accuracy: 0.7726 - val_loss: 0.7021 - val_accuracy: 0.7299\n",
      "Epoch 467/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6346 - accuracy: 0.7727 - val_loss: 0.7019 - val_accuracy: 0.7299\n",
      "Epoch 468/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6343 - accuracy: 0.7730 - val_loss: 0.7017 - val_accuracy: 0.7299\n",
      "Epoch 469/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6339 - accuracy: 0.7730 - val_loss: 0.7015 - val_accuracy: 0.7299\n",
      "Epoch 470/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6336 - accuracy: 0.7742 - val_loss: 0.7012 - val_accuracy: 0.7338\n",
      "Epoch 471/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6333 - accuracy: 0.7756 - val_loss: 0.7011 - val_accuracy: 0.7303\n",
      "Epoch 472/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6329 - accuracy: 0.7743 - val_loss: 0.7010 - val_accuracy: 0.7338\n",
      "Epoch 473/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6326 - accuracy: 0.7758 - val_loss: 0.7008 - val_accuracy: 0.7338\n",
      "Epoch 474/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6323 - accuracy: 0.7764 - val_loss: 0.7005 - val_accuracy: 0.7346\n",
      "Epoch 475/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6319 - accuracy: 0.7767 - val_loss: 0.7004 - val_accuracy: 0.7350\n",
      "Epoch 476/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6316 - accuracy: 0.7767 - val_loss: 0.7002 - val_accuracy: 0.7350\n",
      "Epoch 477/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6312 - accuracy: 0.7774 - val_loss: 0.7000 - val_accuracy: 0.7350\n",
      "Epoch 478/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6309 - accuracy: 0.7772 - val_loss: 0.6997 - val_accuracy: 0.7350\n",
      "Epoch 479/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6306 - accuracy: 0.7778 - val_loss: 0.6994 - val_accuracy: 0.7355\n",
      "Epoch 480/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6302 - accuracy: 0.7779 - val_loss: 0.6992 - val_accuracy: 0.7359\n",
      "Epoch 481/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6299 - accuracy: 0.7782 - val_loss: 0.6991 - val_accuracy: 0.7363\n",
      "Epoch 482/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6296 - accuracy: 0.7779 - val_loss: 0.6989 - val_accuracy: 0.7363\n",
      "Epoch 483/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6292 - accuracy: 0.7782 - val_loss: 0.6987 - val_accuracy: 0.7363\n",
      "Epoch 484/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6289 - accuracy: 0.7786 - val_loss: 0.6986 - val_accuracy: 0.7363\n",
      "Epoch 485/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6285 - accuracy: 0.7787 - val_loss: 0.6984 - val_accuracy: 0.7368\n",
      "Epoch 486/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6282 - accuracy: 0.7787 - val_loss: 0.6981 - val_accuracy: 0.7368\n",
      "Epoch 487/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6279 - accuracy: 0.7788 - val_loss: 0.6980 - val_accuracy: 0.7368\n",
      "Epoch 488/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6275 - accuracy: 0.7786 - val_loss: 0.6977 - val_accuracy: 0.7372\n",
      "Epoch 489/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6272 - accuracy: 0.7790 - val_loss: 0.6976 - val_accuracy: 0.7372\n",
      "Epoch 490/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.7790 - val_loss: 0.6973 - val_accuracy: 0.7376\n",
      "Epoch 491/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6265 - accuracy: 0.7798 - val_loss: 0.6971 - val_accuracy: 0.7380\n",
      "Epoch 492/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6262 - accuracy: 0.7800 - val_loss: 0.6969 - val_accuracy: 0.7376\n",
      "Epoch 493/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6259 - accuracy: 0.7802 - val_loss: 0.6967 - val_accuracy: 0.7380\n",
      "Epoch 494/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6255 - accuracy: 0.7805 - val_loss: 0.6965 - val_accuracy: 0.7380\n",
      "Epoch 495/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6252 - accuracy: 0.7804 - val_loss: 0.6964 - val_accuracy: 0.7380\n",
      "Epoch 496/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6249 - accuracy: 0.7805 - val_loss: 0.6962 - val_accuracy: 0.7385\n",
      "Epoch 497/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6245 - accuracy: 0.7805 - val_loss: 0.6960 - val_accuracy: 0.7385\n",
      "Epoch 498/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6242 - accuracy: 0.7813 - val_loss: 0.6957 - val_accuracy: 0.7380\n",
      "Epoch 499/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6239 - accuracy: 0.7807 - val_loss: 0.6956 - val_accuracy: 0.7389\n",
      "Epoch 500/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6236 - accuracy: 0.7814 - val_loss: 0.6953 - val_accuracy: 0.7385\n",
      "Epoch 501/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6232 - accuracy: 0.7807 - val_loss: 0.6953 - val_accuracy: 0.7389\n",
      "Epoch 502/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6229 - accuracy: 0.7813 - val_loss: 0.6950 - val_accuracy: 0.7393\n",
      "Epoch 503/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6226 - accuracy: 0.7816 - val_loss: 0.6948 - val_accuracy: 0.7393\n",
      "Epoch 504/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6222 - accuracy: 0.7817 - val_loss: 0.6946 - val_accuracy: 0.7397\n",
      "Epoch 505/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6219 - accuracy: 0.7817 - val_loss: 0.6944 - val_accuracy: 0.7397\n",
      "Epoch 506/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6216 - accuracy: 0.7822 - val_loss: 0.6943 - val_accuracy: 0.7402\n",
      "Epoch 507/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6212 - accuracy: 0.7823 - val_loss: 0.6940 - val_accuracy: 0.7393\n",
      "Epoch 508/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6209 - accuracy: 0.7822 - val_loss: 0.6938 - val_accuracy: 0.7402\n",
      "Epoch 509/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6206 - accuracy: 0.7822 - val_loss: 0.6937 - val_accuracy: 0.7406\n",
      "Epoch 510/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6203 - accuracy: 0.7828 - val_loss: 0.6934 - val_accuracy: 0.7397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 511/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6199 - accuracy: 0.7830 - val_loss: 0.6933 - val_accuracy: 0.7397\n",
      "Epoch 512/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6196 - accuracy: 0.7829 - val_loss: 0.6931 - val_accuracy: 0.7406\n",
      "Epoch 513/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6193 - accuracy: 0.7832 - val_loss: 0.6929 - val_accuracy: 0.7397\n",
      "Epoch 514/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6189 - accuracy: 0.7835 - val_loss: 0.6927 - val_accuracy: 0.7397\n",
      "Epoch 515/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6186 - accuracy: 0.7835 - val_loss: 0.6926 - val_accuracy: 0.7397\n",
      "Epoch 516/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6183 - accuracy: 0.7840 - val_loss: 0.6923 - val_accuracy: 0.7393\n",
      "Epoch 517/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6180 - accuracy: 0.7836 - val_loss: 0.6921 - val_accuracy: 0.7385\n",
      "Epoch 518/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6176 - accuracy: 0.7838 - val_loss: 0.6920 - val_accuracy: 0.7389\n",
      "Epoch 519/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6173 - accuracy: 0.7842 - val_loss: 0.6917 - val_accuracy: 0.7389\n",
      "Epoch 520/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6169 - accuracy: 0.7848 - val_loss: 0.6915 - val_accuracy: 0.7389\n",
      "Epoch 521/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6166 - accuracy: 0.7848 - val_loss: 0.6914 - val_accuracy: 0.7389\n",
      "Epoch 522/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6163 - accuracy: 0.7848 - val_loss: 0.6912 - val_accuracy: 0.7389\n",
      "Epoch 523/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6160 - accuracy: 0.7851 - val_loss: 0.6909 - val_accuracy: 0.7397\n",
      "Epoch 524/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6156 - accuracy: 0.7851 - val_loss: 0.6908 - val_accuracy: 0.7397\n",
      "Epoch 525/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6153 - accuracy: 0.7852 - val_loss: 0.6906 - val_accuracy: 0.7402\n",
      "Epoch 526/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6150 - accuracy: 0.7853 - val_loss: 0.6904 - val_accuracy: 0.7402\n",
      "Epoch 527/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6146 - accuracy: 0.7857 - val_loss: 0.6901 - val_accuracy: 0.7397\n",
      "Epoch 528/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6143 - accuracy: 0.7860 - val_loss: 0.6899 - val_accuracy: 0.7402\n",
      "Epoch 529/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6140 - accuracy: 0.7859 - val_loss: 0.6897 - val_accuracy: 0.7415\n",
      "Epoch 530/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6136 - accuracy: 0.7861 - val_loss: 0.6895 - val_accuracy: 0.7415\n",
      "Epoch 531/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6133 - accuracy: 0.7861 - val_loss: 0.6894 - val_accuracy: 0.7415\n",
      "Epoch 532/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6130 - accuracy: 0.7863 - val_loss: 0.6892 - val_accuracy: 0.7423\n",
      "Epoch 533/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6127 - accuracy: 0.7869 - val_loss: 0.6890 - val_accuracy: 0.7419\n",
      "Epoch 534/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6123 - accuracy: 0.7879 - val_loss: 0.6887 - val_accuracy: 0.7415\n",
      "Epoch 535/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6120 - accuracy: 0.7875 - val_loss: 0.6886 - val_accuracy: 0.7410\n",
      "Epoch 536/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6117 - accuracy: 0.7884 - val_loss: 0.6885 - val_accuracy: 0.7415\n",
      "Epoch 537/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6113 - accuracy: 0.7876 - val_loss: 0.6882 - val_accuracy: 0.7410\n",
      "Epoch 538/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6110 - accuracy: 0.7883 - val_loss: 0.6880 - val_accuracy: 0.7415\n",
      "Epoch 539/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6107 - accuracy: 0.7886 - val_loss: 0.6879 - val_accuracy: 0.7410\n",
      "Epoch 540/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6104 - accuracy: 0.7888 - val_loss: 0.6877 - val_accuracy: 0.7410\n",
      "Epoch 541/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6100 - accuracy: 0.7890 - val_loss: 0.6876 - val_accuracy: 0.7419\n",
      "Epoch 542/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6097 - accuracy: 0.7887 - val_loss: 0.6874 - val_accuracy: 0.7419\n",
      "Epoch 543/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6094 - accuracy: 0.7887 - val_loss: 0.6872 - val_accuracy: 0.7419\n",
      "Epoch 544/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6090 - accuracy: 0.7892 - val_loss: 0.6869 - val_accuracy: 0.7415\n",
      "Epoch 545/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6087 - accuracy: 0.7888 - val_loss: 0.6868 - val_accuracy: 0.7415\n",
      "Epoch 546/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6084 - accuracy: 0.7887 - val_loss: 0.6867 - val_accuracy: 0.7427\n",
      "Epoch 547/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6081 - accuracy: 0.7893 - val_loss: 0.6864 - val_accuracy: 0.7415\n",
      "Epoch 548/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6077 - accuracy: 0.7895 - val_loss: 0.6862 - val_accuracy: 0.7419\n",
      "Epoch 549/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6074 - accuracy: 0.7895 - val_loss: 0.6860 - val_accuracy: 0.7419\n",
      "Epoch 550/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6071 - accuracy: 0.7902 - val_loss: 0.6857 - val_accuracy: 0.7410\n",
      "Epoch 551/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6067 - accuracy: 0.7903 - val_loss: 0.6856 - val_accuracy: 0.7415\n",
      "Epoch 552/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6065 - accuracy: 0.7894 - val_loss: 0.6855 - val_accuracy: 0.7423\n",
      "Epoch 553/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6061 - accuracy: 0.7895 - val_loss: 0.6853 - val_accuracy: 0.7423\n",
      "Epoch 554/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6058 - accuracy: 0.7897 - val_loss: 0.6851 - val_accuracy: 0.7419\n",
      "Epoch 555/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6055 - accuracy: 0.7903 - val_loss: 0.6849 - val_accuracy: 0.7415\n",
      "Epoch 556/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6051 - accuracy: 0.7907 - val_loss: 0.6846 - val_accuracy: 0.7397\n",
      "Epoch 557/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6048 - accuracy: 0.7908 - val_loss: 0.6845 - val_accuracy: 0.7402\n",
      "Epoch 558/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6045 - accuracy: 0.7908 - val_loss: 0.6842 - val_accuracy: 0.7410\n",
      "Epoch 559/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6042 - accuracy: 0.7908 - val_loss: 0.6841 - val_accuracy: 0.7406\n",
      "Epoch 560/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6038 - accuracy: 0.7909 - val_loss: 0.6840 - val_accuracy: 0.7415\n",
      "Epoch 561/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6035 - accuracy: 0.7915 - val_loss: 0.6837 - val_accuracy: 0.7419\n",
      "Epoch 562/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6032 - accuracy: 0.7915 - val_loss: 0.6836 - val_accuracy: 0.7419\n",
      "Epoch 563/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6028 - accuracy: 0.7916 - val_loss: 0.6834 - val_accuracy: 0.7419\n",
      "Epoch 564/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6025 - accuracy: 0.7922 - val_loss: 0.6832 - val_accuracy: 0.7423\n",
      "Epoch 565/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6022 - accuracy: 0.7923 - val_loss: 0.6829 - val_accuracy: 0.7427\n",
      "Epoch 566/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6019 - accuracy: 0.7920 - val_loss: 0.6827 - val_accuracy: 0.7427\n",
      "Epoch 567/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6016 - accuracy: 0.7925 - val_loss: 0.6825 - val_accuracy: 0.7427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 568/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6012 - accuracy: 0.7925 - val_loss: 0.6824 - val_accuracy: 0.7427\n",
      "Epoch 569/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6009 - accuracy: 0.7927 - val_loss: 0.6822 - val_accuracy: 0.7427\n",
      "Epoch 570/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6006 - accuracy: 0.7928 - val_loss: 0.6819 - val_accuracy: 0.7427\n",
      "Epoch 571/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6002 - accuracy: 0.7926 - val_loss: 0.6819 - val_accuracy: 0.7436\n",
      "Epoch 572/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5999 - accuracy: 0.7925 - val_loss: 0.6817 - val_accuracy: 0.7440\n",
      "Epoch 573/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5996 - accuracy: 0.7928 - val_loss: 0.6815 - val_accuracy: 0.7440\n",
      "Epoch 574/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5993 - accuracy: 0.7931 - val_loss: 0.6812 - val_accuracy: 0.7432\n",
      "Epoch 575/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5990 - accuracy: 0.7931 - val_loss: 0.6810 - val_accuracy: 0.7432\n",
      "Epoch 576/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5987 - accuracy: 0.7934 - val_loss: 0.6808 - val_accuracy: 0.7432\n",
      "Epoch 577/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5983 - accuracy: 0.7935 - val_loss: 0.6806 - val_accuracy: 0.7432\n",
      "Epoch 578/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5980 - accuracy: 0.7932 - val_loss: 0.6804 - val_accuracy: 0.7436\n",
      "Epoch 579/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5977 - accuracy: 0.7937 - val_loss: 0.6801 - val_accuracy: 0.7436\n",
      "Epoch 580/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5974 - accuracy: 0.7939 - val_loss: 0.6799 - val_accuracy: 0.7440\n",
      "Epoch 581/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5970 - accuracy: 0.7940 - val_loss: 0.6797 - val_accuracy: 0.7432\n",
      "Epoch 582/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5967 - accuracy: 0.7940 - val_loss: 0.6796 - val_accuracy: 0.7436\n",
      "Epoch 583/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5964 - accuracy: 0.7940 - val_loss: 0.6795 - val_accuracy: 0.7444\n",
      "Epoch 584/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5961 - accuracy: 0.7944 - val_loss: 0.6792 - val_accuracy: 0.7432\n",
      "Epoch 585/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5957 - accuracy: 0.7946 - val_loss: 0.6789 - val_accuracy: 0.7440\n",
      "Epoch 586/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5954 - accuracy: 0.7945 - val_loss: 0.6788 - val_accuracy: 0.7444\n",
      "Epoch 587/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5951 - accuracy: 0.7949 - val_loss: 0.6786 - val_accuracy: 0.7444\n",
      "Epoch 588/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5948 - accuracy: 0.7949 - val_loss: 0.6785 - val_accuracy: 0.7449\n",
      "Epoch 589/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5945 - accuracy: 0.7949 - val_loss: 0.6782 - val_accuracy: 0.7449\n",
      "Epoch 590/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5941 - accuracy: 0.7953 - val_loss: 0.6780 - val_accuracy: 0.7449\n",
      "Epoch 591/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5938 - accuracy: 0.7955 - val_loss: 0.6778 - val_accuracy: 0.7453\n",
      "Epoch 592/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5935 - accuracy: 0.7960 - val_loss: 0.6776 - val_accuracy: 0.7453\n",
      "Epoch 593/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5931 - accuracy: 0.7961 - val_loss: 0.6775 - val_accuracy: 0.7453\n",
      "Epoch 594/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5928 - accuracy: 0.7960 - val_loss: 0.6774 - val_accuracy: 0.7457\n",
      "Epoch 595/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5925 - accuracy: 0.7959 - val_loss: 0.6771 - val_accuracy: 0.7462\n",
      "Epoch 596/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5922 - accuracy: 0.7960 - val_loss: 0.6770 - val_accuracy: 0.7457\n",
      "Epoch 597/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5919 - accuracy: 0.7964 - val_loss: 0.6768 - val_accuracy: 0.7466\n",
      "Epoch 598/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5915 - accuracy: 0.7966 - val_loss: 0.6766 - val_accuracy: 0.7462\n",
      "Epoch 599/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5912 - accuracy: 0.7968 - val_loss: 0.6764 - val_accuracy: 0.7466\n",
      "Epoch 600/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5909 - accuracy: 0.7971 - val_loss: 0.6762 - val_accuracy: 0.7470\n",
      "Epoch 601/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5906 - accuracy: 0.7971 - val_loss: 0.6761 - val_accuracy: 0.7470\n",
      "Epoch 602/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5903 - accuracy: 0.7976 - val_loss: 0.6759 - val_accuracy: 0.7474\n",
      "Epoch 603/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5899 - accuracy: 0.7973 - val_loss: 0.6756 - val_accuracy: 0.7470\n",
      "Epoch 604/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5896 - accuracy: 0.7975 - val_loss: 0.6754 - val_accuracy: 0.7479\n",
      "Epoch 605/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5893 - accuracy: 0.7975 - val_loss: 0.6753 - val_accuracy: 0.7479\n",
      "Epoch 606/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5890 - accuracy: 0.7974 - val_loss: 0.6751 - val_accuracy: 0.7487\n",
      "Epoch 607/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5886 - accuracy: 0.7976 - val_loss: 0.6749 - val_accuracy: 0.7487\n",
      "Epoch 608/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5883 - accuracy: 0.7980 - val_loss: 0.6747 - val_accuracy: 0.7479\n",
      "Epoch 609/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5880 - accuracy: 0.7979 - val_loss: 0.6744 - val_accuracy: 0.7479\n",
      "Epoch 610/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5877 - accuracy: 0.7985 - val_loss: 0.6741 - val_accuracy: 0.7487\n",
      "Epoch 611/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5874 - accuracy: 0.7985 - val_loss: 0.6740 - val_accuracy: 0.7491\n",
      "Epoch 612/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5870 - accuracy: 0.7987 - val_loss: 0.6738 - val_accuracy: 0.7487\n",
      "Epoch 613/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5867 - accuracy: 0.7985 - val_loss: 0.6737 - val_accuracy: 0.7491\n",
      "Epoch 614/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5864 - accuracy: 0.7986 - val_loss: 0.6735 - val_accuracy: 0.7487\n",
      "Epoch 615/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5861 - accuracy: 0.7986 - val_loss: 0.6734 - val_accuracy: 0.7491\n",
      "Epoch 616/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5857 - accuracy: 0.7986 - val_loss: 0.6731 - val_accuracy: 0.7496\n",
      "Epoch 617/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5854 - accuracy: 0.7987 - val_loss: 0.6729 - val_accuracy: 0.7496\n",
      "Epoch 618/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5851 - accuracy: 0.7996 - val_loss: 0.6727 - val_accuracy: 0.7496\n",
      "Epoch 619/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5848 - accuracy: 0.7996 - val_loss: 0.6725 - val_accuracy: 0.7496\n",
      "Epoch 620/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5845 - accuracy: 0.7995 - val_loss: 0.6723 - val_accuracy: 0.7496\n",
      "Epoch 621/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5841 - accuracy: 0.7996 - val_loss: 0.6721 - val_accuracy: 0.7496\n",
      "Epoch 622/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5838 - accuracy: 0.8002 - val_loss: 0.6718 - val_accuracy: 0.7491\n",
      "Epoch 623/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5835 - accuracy: 0.8006 - val_loss: 0.6717 - val_accuracy: 0.7496\n",
      "Epoch 624/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5832 - accuracy: 0.8007 - val_loss: 0.6715 - val_accuracy: 0.7496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 625/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5829 - accuracy: 0.8007 - val_loss: 0.6713 - val_accuracy: 0.7504\n",
      "Epoch 626/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5825 - accuracy: 0.8013 - val_loss: 0.6711 - val_accuracy: 0.7500\n",
      "Epoch 627/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5822 - accuracy: 0.8010 - val_loss: 0.6709 - val_accuracy: 0.7504\n",
      "Epoch 628/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5819 - accuracy: 0.8015 - val_loss: 0.6707 - val_accuracy: 0.7500\n",
      "Epoch 629/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5816 - accuracy: 0.8016 - val_loss: 0.6705 - val_accuracy: 0.7504\n",
      "Epoch 630/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5813 - accuracy: 0.8021 - val_loss: 0.6704 - val_accuracy: 0.7504\n",
      "Epoch 631/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5809 - accuracy: 0.8019 - val_loss: 0.6701 - val_accuracy: 0.7500\n",
      "Epoch 632/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5806 - accuracy: 0.8019 - val_loss: 0.6700 - val_accuracy: 0.7504\n",
      "Epoch 633/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5803 - accuracy: 0.8023 - val_loss: 0.6697 - val_accuracy: 0.7504\n",
      "Epoch 634/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5800 - accuracy: 0.8025 - val_loss: 0.6695 - val_accuracy: 0.7509\n",
      "Epoch 635/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5797 - accuracy: 0.8029 - val_loss: 0.6694 - val_accuracy: 0.7509\n",
      "Epoch 636/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5794 - accuracy: 0.8033 - val_loss: 0.6692 - val_accuracy: 0.7504\n",
      "Epoch 637/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5791 - accuracy: 0.8028 - val_loss: 0.6691 - val_accuracy: 0.7513\n",
      "Epoch 638/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5787 - accuracy: 0.8027 - val_loss: 0.6689 - val_accuracy: 0.7504\n",
      "Epoch 639/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5784 - accuracy: 0.8031 - val_loss: 0.6686 - val_accuracy: 0.7504\n",
      "Epoch 640/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5781 - accuracy: 0.8033 - val_loss: 0.6684 - val_accuracy: 0.7509\n",
      "Epoch 641/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5778 - accuracy: 0.8035 - val_loss: 0.6682 - val_accuracy: 0.7500\n",
      "Epoch 642/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5775 - accuracy: 0.8035 - val_loss: 0.6680 - val_accuracy: 0.7504\n",
      "Epoch 643/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5771 - accuracy: 0.8035 - val_loss: 0.6679 - val_accuracy: 0.7509\n",
      "Epoch 644/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5768 - accuracy: 0.8037 - val_loss: 0.6678 - val_accuracy: 0.7509\n",
      "Epoch 645/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5765 - accuracy: 0.8036 - val_loss: 0.6676 - val_accuracy: 0.7509\n",
      "Epoch 646/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5762 - accuracy: 0.8038 - val_loss: 0.6674 - val_accuracy: 0.7513\n",
      "Epoch 647/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5759 - accuracy: 0.8040 - val_loss: 0.6672 - val_accuracy: 0.7509\n",
      "Epoch 648/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5756 - accuracy: 0.8039 - val_loss: 0.6672 - val_accuracy: 0.7513\n",
      "Epoch 649/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5753 - accuracy: 0.8039 - val_loss: 0.6669 - val_accuracy: 0.7509\n",
      "Epoch 650/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5749 - accuracy: 0.8041 - val_loss: 0.6667 - val_accuracy: 0.7509\n",
      "Epoch 651/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5746 - accuracy: 0.8042 - val_loss: 0.6664 - val_accuracy: 0.7513\n",
      "Epoch 652/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5743 - accuracy: 0.8040 - val_loss: 0.6663 - val_accuracy: 0.7509\n",
      "Epoch 653/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5740 - accuracy: 0.8042 - val_loss: 0.6661 - val_accuracy: 0.7513\n",
      "Epoch 654/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5737 - accuracy: 0.8048 - val_loss: 0.6659 - val_accuracy: 0.7517\n",
      "Epoch 655/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5734 - accuracy: 0.8053 - val_loss: 0.6656 - val_accuracy: 0.7517\n",
      "Epoch 656/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5730 - accuracy: 0.8052 - val_loss: 0.6654 - val_accuracy: 0.7521\n",
      "Epoch 657/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5727 - accuracy: 0.8052 - val_loss: 0.6653 - val_accuracy: 0.7521\n",
      "Epoch 658/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5724 - accuracy: 0.8052 - val_loss: 0.6651 - val_accuracy: 0.7521\n",
      "Epoch 659/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5721 - accuracy: 0.8054 - val_loss: 0.6649 - val_accuracy: 0.7517\n",
      "Epoch 660/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5717 - accuracy: 0.8059 - val_loss: 0.6647 - val_accuracy: 0.7526\n",
      "Epoch 661/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5714 - accuracy: 0.8057 - val_loss: 0.6645 - val_accuracy: 0.7526\n",
      "Epoch 662/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5712 - accuracy: 0.8063 - val_loss: 0.6644 - val_accuracy: 0.7521\n",
      "Epoch 663/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5708 - accuracy: 0.8056 - val_loss: 0.6642 - val_accuracy: 0.7513\n",
      "Epoch 664/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5705 - accuracy: 0.8064 - val_loss: 0.6639 - val_accuracy: 0.7526\n",
      "Epoch 665/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5702 - accuracy: 0.8059 - val_loss: 0.6637 - val_accuracy: 0.7530\n",
      "Epoch 666/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5699 - accuracy: 0.8068 - val_loss: 0.6636 - val_accuracy: 0.7517\n",
      "Epoch 667/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5695 - accuracy: 0.8069 - val_loss: 0.6633 - val_accuracy: 0.7530\n",
      "Epoch 668/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5692 - accuracy: 0.8066 - val_loss: 0.6631 - val_accuracy: 0.7526\n",
      "Epoch 669/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5689 - accuracy: 0.8066 - val_loss: 0.6629 - val_accuracy: 0.7530\n",
      "Epoch 670/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5686 - accuracy: 0.8074 - val_loss: 0.6627 - val_accuracy: 0.7526\n",
      "Epoch 671/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5683 - accuracy: 0.8069 - val_loss: 0.6626 - val_accuracy: 0.7526\n",
      "Epoch 672/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5680 - accuracy: 0.8070 - val_loss: 0.6625 - val_accuracy: 0.7521\n",
      "Epoch 673/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5677 - accuracy: 0.8067 - val_loss: 0.6623 - val_accuracy: 0.7526\n",
      "Epoch 674/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5673 - accuracy: 0.8067 - val_loss: 0.6621 - val_accuracy: 0.7530\n",
      "Epoch 675/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5670 - accuracy: 0.8072 - val_loss: 0.6620 - val_accuracy: 0.7530\n",
      "Epoch 676/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5667 - accuracy: 0.8077 - val_loss: 0.6618 - val_accuracy: 0.7526\n",
      "Epoch 677/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5664 - accuracy: 0.8079 - val_loss: 0.6615 - val_accuracy: 0.7530\n",
      "Epoch 678/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5661 - accuracy: 0.8077 - val_loss: 0.6612 - val_accuracy: 0.7551\n",
      "Epoch 679/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5658 - accuracy: 0.8077 - val_loss: 0.6611 - val_accuracy: 0.7547\n",
      "Epoch 680/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5655 - accuracy: 0.8085 - val_loss: 0.6609 - val_accuracy: 0.7551\n",
      "Epoch 681/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5652 - accuracy: 0.8085 - val_loss: 0.6607 - val_accuracy: 0.7556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 682/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5649 - accuracy: 0.8081 - val_loss: 0.6606 - val_accuracy: 0.7551\n",
      "Epoch 683/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5645 - accuracy: 0.8088 - val_loss: 0.6604 - val_accuracy: 0.7556\n",
      "Epoch 684/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5642 - accuracy: 0.8095 - val_loss: 0.6601 - val_accuracy: 0.7560\n",
      "Epoch 685/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5639 - accuracy: 0.8095 - val_loss: 0.6600 - val_accuracy: 0.7560\n",
      "Epoch 686/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5636 - accuracy: 0.8096 - val_loss: 0.6598 - val_accuracy: 0.7556\n",
      "Epoch 687/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5633 - accuracy: 0.8095 - val_loss: 0.6597 - val_accuracy: 0.7556\n",
      "Epoch 688/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5630 - accuracy: 0.8099 - val_loss: 0.6595 - val_accuracy: 0.7556\n",
      "Epoch 689/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5627 - accuracy: 0.8101 - val_loss: 0.6593 - val_accuracy: 0.7556\n",
      "Epoch 690/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5624 - accuracy: 0.8097 - val_loss: 0.6592 - val_accuracy: 0.7551\n",
      "Epoch 691/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5621 - accuracy: 0.8098 - val_loss: 0.6590 - val_accuracy: 0.7556\n",
      "Epoch 692/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5618 - accuracy: 0.8097 - val_loss: 0.6588 - val_accuracy: 0.7551\n",
      "Epoch 693/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5614 - accuracy: 0.8098 - val_loss: 0.6585 - val_accuracy: 0.7560\n",
      "Epoch 694/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5611 - accuracy: 0.8101 - val_loss: 0.6583 - val_accuracy: 0.7564\n",
      "Epoch 695/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5608 - accuracy: 0.8096 - val_loss: 0.6582 - val_accuracy: 0.7560\n",
      "Epoch 696/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5605 - accuracy: 0.8097 - val_loss: 0.6580 - val_accuracy: 0.7564\n",
      "Epoch 697/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5602 - accuracy: 0.8098 - val_loss: 0.6579 - val_accuracy: 0.7564\n",
      "Epoch 698/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5599 - accuracy: 0.8096 - val_loss: 0.6577 - val_accuracy: 0.7573\n",
      "Epoch 699/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5596 - accuracy: 0.8099 - val_loss: 0.6575 - val_accuracy: 0.7573\n",
      "Epoch 700/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5593 - accuracy: 0.8103 - val_loss: 0.6573 - val_accuracy: 0.7573\n",
      "Epoch 701/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5590 - accuracy: 0.8104 - val_loss: 0.6571 - val_accuracy: 0.7573\n",
      "Epoch 702/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5587 - accuracy: 0.8103 - val_loss: 0.6569 - val_accuracy: 0.7573\n",
      "Epoch 703/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5584 - accuracy: 0.8102 - val_loss: 0.6568 - val_accuracy: 0.7577\n",
      "Epoch 704/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5581 - accuracy: 0.8103 - val_loss: 0.6566 - val_accuracy: 0.7573\n",
      "Epoch 705/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5578 - accuracy: 0.8101 - val_loss: 0.6564 - val_accuracy: 0.7577\n",
      "Epoch 706/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5575 - accuracy: 0.8099 - val_loss: 0.6562 - val_accuracy: 0.7577\n",
      "Epoch 707/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5572 - accuracy: 0.8102 - val_loss: 0.6560 - val_accuracy: 0.7585\n",
      "Epoch 708/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5569 - accuracy: 0.8101 - val_loss: 0.6558 - val_accuracy: 0.7585\n",
      "Epoch 709/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5565 - accuracy: 0.8102 - val_loss: 0.6556 - val_accuracy: 0.7590\n",
      "Epoch 710/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5562 - accuracy: 0.8105 - val_loss: 0.6554 - val_accuracy: 0.7581\n",
      "Epoch 711/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5559 - accuracy: 0.8102 - val_loss: 0.6552 - val_accuracy: 0.7590\n",
      "Epoch 712/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5556 - accuracy: 0.8103 - val_loss: 0.6551 - val_accuracy: 0.7590\n",
      "Epoch 713/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5553 - accuracy: 0.8106 - val_loss: 0.6548 - val_accuracy: 0.7577\n",
      "Epoch 714/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5550 - accuracy: 0.8113 - val_loss: 0.6546 - val_accuracy: 0.7577\n",
      "Epoch 715/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5547 - accuracy: 0.8113 - val_loss: 0.6544 - val_accuracy: 0.7577\n",
      "Epoch 716/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5544 - accuracy: 0.8110 - val_loss: 0.6544 - val_accuracy: 0.7585\n",
      "Epoch 717/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5541 - accuracy: 0.8112 - val_loss: 0.6543 - val_accuracy: 0.7585\n",
      "Epoch 718/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5538 - accuracy: 0.8109 - val_loss: 0.6540 - val_accuracy: 0.7585\n",
      "Epoch 719/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5535 - accuracy: 0.8110 - val_loss: 0.6537 - val_accuracy: 0.7598\n",
      "Epoch 720/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5532 - accuracy: 0.8112 - val_loss: 0.6535 - val_accuracy: 0.7603\n",
      "Epoch 721/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5529 - accuracy: 0.8112 - val_loss: 0.6533 - val_accuracy: 0.7603\n",
      "Epoch 722/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5526 - accuracy: 0.8111 - val_loss: 0.6532 - val_accuracy: 0.7603\n",
      "Epoch 723/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5523 - accuracy: 0.8112 - val_loss: 0.6530 - val_accuracy: 0.7603\n",
      "Epoch 724/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5520 - accuracy: 0.8111 - val_loss: 0.6529 - val_accuracy: 0.7598\n",
      "Epoch 725/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5517 - accuracy: 0.8109 - val_loss: 0.6526 - val_accuracy: 0.7607\n",
      "Epoch 726/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5514 - accuracy: 0.8113 - val_loss: 0.6525 - val_accuracy: 0.7607\n",
      "Epoch 727/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5511 - accuracy: 0.8119 - val_loss: 0.6522 - val_accuracy: 0.7603\n",
      "Epoch 728/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5508 - accuracy: 0.8119 - val_loss: 0.6522 - val_accuracy: 0.7607\n",
      "Epoch 729/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.8117 - val_loss: 0.6521 - val_accuracy: 0.7607\n",
      "Epoch 730/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5502 - accuracy: 0.8115 - val_loss: 0.6520 - val_accuracy: 0.7603\n",
      "Epoch 731/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5499 - accuracy: 0.8112 - val_loss: 0.6518 - val_accuracy: 0.7603\n",
      "Epoch 732/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5496 - accuracy: 0.8115 - val_loss: 0.6516 - val_accuracy: 0.7607\n",
      "Epoch 733/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5493 - accuracy: 0.8114 - val_loss: 0.6514 - val_accuracy: 0.7607\n",
      "Epoch 734/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5490 - accuracy: 0.8121 - val_loss: 0.6511 - val_accuracy: 0.7603\n",
      "Epoch 735/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5487 - accuracy: 0.8126 - val_loss: 0.6510 - val_accuracy: 0.7603\n",
      "Epoch 736/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5485 - accuracy: 0.8125 - val_loss: 0.6508 - val_accuracy: 0.7607\n",
      "Epoch 737/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5482 - accuracy: 0.8126 - val_loss: 0.6506 - val_accuracy: 0.7607\n",
      "Epoch 738/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5479 - accuracy: 0.8122 - val_loss: 0.6505 - val_accuracy: 0.7607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 739/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5476 - accuracy: 0.8127 - val_loss: 0.6503 - val_accuracy: 0.7607\n",
      "Epoch 740/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5473 - accuracy: 0.8130 - val_loss: 0.6502 - val_accuracy: 0.7607\n",
      "Epoch 741/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5470 - accuracy: 0.8129 - val_loss: 0.6500 - val_accuracy: 0.7611\n",
      "Epoch 742/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5467 - accuracy: 0.8137 - val_loss: 0.6497 - val_accuracy: 0.7615\n",
      "Epoch 743/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5464 - accuracy: 0.8135 - val_loss: 0.6496 - val_accuracy: 0.7615\n",
      "Epoch 744/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5461 - accuracy: 0.8141 - val_loss: 0.6494 - val_accuracy: 0.7611\n",
      "Epoch 745/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5458 - accuracy: 0.8148 - val_loss: 0.6493 - val_accuracy: 0.7615\n",
      "Epoch 746/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5456 - accuracy: 0.8145 - val_loss: 0.6492 - val_accuracy: 0.7615\n",
      "Epoch 747/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5453 - accuracy: 0.8142 - val_loss: 0.6490 - val_accuracy: 0.7611\n",
      "Epoch 748/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5450 - accuracy: 0.8138 - val_loss: 0.6488 - val_accuracy: 0.7611\n",
      "Epoch 749/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5447 - accuracy: 0.8143 - val_loss: 0.6487 - val_accuracy: 0.7615\n",
      "Epoch 750/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5444 - accuracy: 0.8142 - val_loss: 0.6486 - val_accuracy: 0.7615\n",
      "Epoch 751/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5441 - accuracy: 0.8145 - val_loss: 0.6484 - val_accuracy: 0.7611\n",
      "Epoch 752/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5438 - accuracy: 0.8145 - val_loss: 0.6482 - val_accuracy: 0.7611\n",
      "Epoch 753/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5435 - accuracy: 0.8147 - val_loss: 0.6481 - val_accuracy: 0.7615\n",
      "Epoch 754/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5432 - accuracy: 0.8145 - val_loss: 0.6479 - val_accuracy: 0.7620\n",
      "Epoch 755/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5430 - accuracy: 0.8148 - val_loss: 0.6477 - val_accuracy: 0.7615\n",
      "Epoch 756/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5427 - accuracy: 0.8149 - val_loss: 0.6475 - val_accuracy: 0.7611\n",
      "Epoch 757/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5424 - accuracy: 0.8151 - val_loss: 0.6473 - val_accuracy: 0.7615\n",
      "Epoch 758/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5421 - accuracy: 0.8151 - val_loss: 0.6473 - val_accuracy: 0.7615\n",
      "Epoch 759/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5418 - accuracy: 0.8153 - val_loss: 0.6471 - val_accuracy: 0.7615\n",
      "Epoch 760/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5415 - accuracy: 0.8150 - val_loss: 0.6469 - val_accuracy: 0.7615\n",
      "Epoch 761/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5412 - accuracy: 0.8152 - val_loss: 0.6468 - val_accuracy: 0.7620\n",
      "Epoch 762/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5410 - accuracy: 0.8150 - val_loss: 0.6466 - val_accuracy: 0.7615\n",
      "Epoch 763/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5407 - accuracy: 0.8148 - val_loss: 0.6465 - val_accuracy: 0.7620\n",
      "Epoch 764/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5404 - accuracy: 0.8153 - val_loss: 0.6463 - val_accuracy: 0.7620\n",
      "Epoch 765/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5401 - accuracy: 0.8152 - val_loss: 0.6461 - val_accuracy: 0.7615\n",
      "Epoch 766/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5398 - accuracy: 0.8152 - val_loss: 0.6460 - val_accuracy: 0.7615\n",
      "Epoch 767/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5396 - accuracy: 0.8152 - val_loss: 0.6459 - val_accuracy: 0.7620\n",
      "Epoch 768/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5393 - accuracy: 0.8156 - val_loss: 0.6456 - val_accuracy: 0.7628\n",
      "Epoch 769/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5390 - accuracy: 0.8155 - val_loss: 0.6455 - val_accuracy: 0.7632\n",
      "Epoch 770/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5387 - accuracy: 0.8155 - val_loss: 0.6453 - val_accuracy: 0.7628\n",
      "Epoch 771/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5384 - accuracy: 0.8156 - val_loss: 0.6452 - val_accuracy: 0.7628\n",
      "Epoch 772/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5382 - accuracy: 0.8157 - val_loss: 0.6451 - val_accuracy: 0.7620\n",
      "Epoch 773/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5379 - accuracy: 0.8159 - val_loss: 0.6449 - val_accuracy: 0.7624\n",
      "Epoch 774/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5376 - accuracy: 0.8156 - val_loss: 0.6448 - val_accuracy: 0.7628\n",
      "Epoch 775/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5373 - accuracy: 0.8162 - val_loss: 0.6447 - val_accuracy: 0.7628\n",
      "Epoch 776/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5371 - accuracy: 0.8160 - val_loss: 0.6446 - val_accuracy: 0.7620\n",
      "Epoch 777/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5368 - accuracy: 0.8158 - val_loss: 0.6445 - val_accuracy: 0.7620\n",
      "Epoch 778/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5365 - accuracy: 0.8159 - val_loss: 0.6442 - val_accuracy: 0.7628\n",
      "Epoch 779/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5363 - accuracy: 0.8159 - val_loss: 0.6440 - val_accuracy: 0.7624\n",
      "Epoch 780/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5360 - accuracy: 0.8165 - val_loss: 0.6438 - val_accuracy: 0.7628\n",
      "Epoch 781/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5357 - accuracy: 0.8166 - val_loss: 0.6437 - val_accuracy: 0.7628\n",
      "Epoch 782/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5355 - accuracy: 0.8169 - val_loss: 0.6435 - val_accuracy: 0.7628\n",
      "Epoch 783/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5352 - accuracy: 0.8162 - val_loss: 0.6435 - val_accuracy: 0.7632\n",
      "Epoch 784/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5349 - accuracy: 0.8165 - val_loss: 0.6433 - val_accuracy: 0.7632\n",
      "Epoch 785/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5347 - accuracy: 0.8164 - val_loss: 0.6432 - val_accuracy: 0.7632\n",
      "Epoch 786/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5344 - accuracy: 0.8164 - val_loss: 0.6431 - val_accuracy: 0.7632\n",
      "Epoch 787/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5342 - accuracy: 0.8163 - val_loss: 0.6429 - val_accuracy: 0.7637\n",
      "Epoch 788/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5339 - accuracy: 0.8167 - val_loss: 0.6428 - val_accuracy: 0.7637\n",
      "Epoch 789/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5336 - accuracy: 0.8171 - val_loss: 0.6426 - val_accuracy: 0.7637\n",
      "Epoch 790/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5334 - accuracy: 0.8169 - val_loss: 0.6425 - val_accuracy: 0.7641\n",
      "Epoch 791/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5331 - accuracy: 0.8169 - val_loss: 0.6424 - val_accuracy: 0.7632\n",
      "Epoch 792/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5328 - accuracy: 0.8168 - val_loss: 0.6422 - val_accuracy: 0.7632\n",
      "Epoch 793/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5326 - accuracy: 0.8172 - val_loss: 0.6422 - val_accuracy: 0.7632\n",
      "Epoch 794/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5323 - accuracy: 0.8178 - val_loss: 0.6420 - val_accuracy: 0.7632\n",
      "Epoch 795/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5321 - accuracy: 0.8168 - val_loss: 0.6419 - val_accuracy: 0.7632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 796/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5318 - accuracy: 0.8171 - val_loss: 0.6419 - val_accuracy: 0.7632\n",
      "Epoch 797/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.8173 - val_loss: 0.6417 - val_accuracy: 0.7632\n",
      "Epoch 798/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5313 - accuracy: 0.8171 - val_loss: 0.6416 - val_accuracy: 0.7632\n",
      "Epoch 799/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5310 - accuracy: 0.8174 - val_loss: 0.6414 - val_accuracy: 0.7628\n",
      "Epoch 800/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5308 - accuracy: 0.8174 - val_loss: 0.6413 - val_accuracy: 0.7632\n",
      "Epoch 801/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5305 - accuracy: 0.8176 - val_loss: 0.6412 - val_accuracy: 0.7637\n",
      "Epoch 802/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.8176 - val_loss: 0.6411 - val_accuracy: 0.7632\n",
      "Epoch 803/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5300 - accuracy: 0.8173 - val_loss: 0.6409 - val_accuracy: 0.7632\n",
      "Epoch 804/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5297 - accuracy: 0.8175 - val_loss: 0.6407 - val_accuracy: 0.7632\n",
      "Epoch 805/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5294 - accuracy: 0.8186 - val_loss: 0.6405 - val_accuracy: 0.7624\n",
      "Epoch 806/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5292 - accuracy: 0.8176 - val_loss: 0.6404 - val_accuracy: 0.7628\n",
      "Epoch 807/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5290 - accuracy: 0.8174 - val_loss: 0.6403 - val_accuracy: 0.7628\n",
      "Epoch 808/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5287 - accuracy: 0.8178 - val_loss: 0.6401 - val_accuracy: 0.7624\n",
      "Epoch 809/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5284 - accuracy: 0.8186 - val_loss: 0.6399 - val_accuracy: 0.7620\n",
      "Epoch 810/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5282 - accuracy: 0.8188 - val_loss: 0.6399 - val_accuracy: 0.7628\n",
      "Epoch 811/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5279 - accuracy: 0.8181 - val_loss: 0.6398 - val_accuracy: 0.7628\n",
      "Epoch 812/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.8178 - val_loss: 0.6397 - val_accuracy: 0.7632\n",
      "Epoch 813/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5274 - accuracy: 0.8188 - val_loss: 0.6395 - val_accuracy: 0.7628\n",
      "Epoch 814/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5272 - accuracy: 0.8187 - val_loss: 0.6393 - val_accuracy: 0.7624\n",
      "Epoch 815/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5269 - accuracy: 0.8187 - val_loss: 0.6392 - val_accuracy: 0.7624\n",
      "Epoch 816/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5267 - accuracy: 0.8183 - val_loss: 0.6392 - val_accuracy: 0.7628\n",
      "Epoch 817/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5264 - accuracy: 0.8184 - val_loss: 0.6391 - val_accuracy: 0.7624\n",
      "Epoch 818/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5262 - accuracy: 0.8186 - val_loss: 0.6388 - val_accuracy: 0.7624\n",
      "Epoch 819/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5259 - accuracy: 0.8183 - val_loss: 0.6388 - val_accuracy: 0.7624\n",
      "Epoch 820/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5257 - accuracy: 0.8186 - val_loss: 0.6387 - val_accuracy: 0.7628\n",
      "Epoch 821/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5254 - accuracy: 0.8182 - val_loss: 0.6386 - val_accuracy: 0.7632\n",
      "Epoch 822/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5252 - accuracy: 0.8186 - val_loss: 0.6384 - val_accuracy: 0.7628\n",
      "Epoch 823/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5249 - accuracy: 0.8183 - val_loss: 0.6383 - val_accuracy: 0.7628\n",
      "Epoch 824/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5247 - accuracy: 0.8189 - val_loss: 0.6382 - val_accuracy: 0.7641\n",
      "Epoch 825/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5244 - accuracy: 0.8188 - val_loss: 0.6381 - val_accuracy: 0.7637\n",
      "Epoch 826/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5242 - accuracy: 0.8187 - val_loss: 0.6380 - val_accuracy: 0.7645\n",
      "Epoch 827/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5240 - accuracy: 0.8187 - val_loss: 0.6378 - val_accuracy: 0.7637\n",
      "Epoch 828/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.8188 - val_loss: 0.6377 - val_accuracy: 0.7632\n",
      "Epoch 829/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5235 - accuracy: 0.8187 - val_loss: 0.6376 - val_accuracy: 0.7628\n",
      "Epoch 830/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5232 - accuracy: 0.8190 - val_loss: 0.6375 - val_accuracy: 0.7637\n",
      "Epoch 831/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5230 - accuracy: 0.8188 - val_loss: 0.6374 - val_accuracy: 0.7637\n",
      "Epoch 832/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.8189 - val_loss: 0.6373 - val_accuracy: 0.7637\n",
      "Epoch 833/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.8187 - val_loss: 0.6372 - val_accuracy: 0.7645\n",
      "Epoch 834/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.8188 - val_loss: 0.6370 - val_accuracy: 0.7645\n",
      "Epoch 835/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5220 - accuracy: 0.8188 - val_loss: 0.6370 - val_accuracy: 0.7645\n",
      "Epoch 836/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5217 - accuracy: 0.8190 - val_loss: 0.6368 - val_accuracy: 0.7645\n",
      "Epoch 837/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5215 - accuracy: 0.8189 - val_loss: 0.6367 - val_accuracy: 0.7650\n",
      "Epoch 838/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5213 - accuracy: 0.8190 - val_loss: 0.6366 - val_accuracy: 0.7654\n",
      "Epoch 839/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5211 - accuracy: 0.8189 - val_loss: 0.6365 - val_accuracy: 0.7654\n",
      "Epoch 840/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 0.8194 - val_loss: 0.6363 - val_accuracy: 0.7654\n",
      "Epoch 841/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.8192 - val_loss: 0.6362 - val_accuracy: 0.7641\n",
      "Epoch 842/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.8191 - val_loss: 0.6361 - val_accuracy: 0.7650\n",
      "Epoch 843/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5201 - accuracy: 0.8192 - val_loss: 0.6359 - val_accuracy: 0.7641\n",
      "Epoch 844/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5199 - accuracy: 0.8187 - val_loss: 0.6359 - val_accuracy: 0.7641\n",
      "Epoch 845/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5197 - accuracy: 0.8189 - val_loss: 0.6358 - val_accuracy: 0.7637\n",
      "Epoch 846/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5194 - accuracy: 0.8190 - val_loss: 0.6357 - val_accuracy: 0.7641\n",
      "Epoch 847/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.8184 - val_loss: 0.6356 - val_accuracy: 0.7632\n",
      "Epoch 848/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5190 - accuracy: 0.8186 - val_loss: 0.6355 - val_accuracy: 0.7637\n",
      "Epoch 849/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.8188 - val_loss: 0.6354 - val_accuracy: 0.7624\n",
      "Epoch 850/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.8187 - val_loss: 0.6352 - val_accuracy: 0.7628\n",
      "Epoch 851/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.8188 - val_loss: 0.6351 - val_accuracy: 0.7628\n",
      "Epoch 852/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.8183 - val_loss: 0.6350 - val_accuracy: 0.7628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 853/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 0.8182 - val_loss: 0.6351 - val_accuracy: 0.7637\n",
      "Epoch 854/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.8184 - val_loss: 0.6349 - val_accuracy: 0.7641\n",
      "Epoch 855/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.8187 - val_loss: 0.6348 - val_accuracy: 0.7632\n",
      "Epoch 856/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.8186 - val_loss: 0.6347 - val_accuracy: 0.7628\n",
      "Epoch 857/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.8186 - val_loss: 0.6346 - val_accuracy: 0.7628\n",
      "Epoch 858/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.8186 - val_loss: 0.6345 - val_accuracy: 0.7628\n",
      "Epoch 859/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.8189 - val_loss: 0.6345 - val_accuracy: 0.7624\n",
      "Epoch 860/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.8188 - val_loss: 0.6344 - val_accuracy: 0.7620\n",
      "Epoch 861/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.8191 - val_loss: 0.6344 - val_accuracy: 0.7628\n",
      "Epoch 862/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.8187 - val_loss: 0.6343 - val_accuracy: 0.7620\n",
      "Epoch 863/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.8191 - val_loss: 0.6341 - val_accuracy: 0.7624\n",
      "Epoch 864/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.8188 - val_loss: 0.6341 - val_accuracy: 0.7628\n",
      "Epoch 865/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5152 - accuracy: 0.8190 - val_loss: 0.6339 - val_accuracy: 0.7632\n",
      "Epoch 866/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.8186 - val_loss: 0.6338 - val_accuracy: 0.7628\n",
      "Epoch 867/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.8189 - val_loss: 0.6337 - val_accuracy: 0.7628\n",
      "Epoch 868/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.8189 - val_loss: 0.6337 - val_accuracy: 0.7632\n",
      "Epoch 869/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.8191 - val_loss: 0.6337 - val_accuracy: 0.7641\n",
      "Epoch 870/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.8190 - val_loss: 0.6336 - val_accuracy: 0.7637\n",
      "Epoch 871/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5139 - accuracy: 0.8192 - val_loss: 0.6335 - val_accuracy: 0.7637\n",
      "Epoch 872/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.8193 - val_loss: 0.6333 - val_accuracy: 0.7632\n",
      "Epoch 873/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.8196 - val_loss: 0.6333 - val_accuracy: 0.7632\n",
      "Epoch 874/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.8192 - val_loss: 0.6333 - val_accuracy: 0.7637\n",
      "Epoch 875/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.8197 - val_loss: 0.6331 - val_accuracy: 0.7632\n",
      "Epoch 876/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.8198 - val_loss: 0.6332 - val_accuracy: 0.7637\n",
      "Epoch 877/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.8200 - val_loss: 0.6330 - val_accuracy: 0.7632\n",
      "Epoch 878/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.8199 - val_loss: 0.6329 - val_accuracy: 0.7632\n",
      "Epoch 879/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.8202 - val_loss: 0.6328 - val_accuracy: 0.7628\n",
      "Epoch 880/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.8203 - val_loss: 0.6326 - val_accuracy: 0.7628\n",
      "Epoch 881/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.8203 - val_loss: 0.6325 - val_accuracy: 0.7628\n",
      "Epoch 882/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.8200 - val_loss: 0.6324 - val_accuracy: 0.7628\n",
      "Epoch 883/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.8204 - val_loss: 0.6323 - val_accuracy: 0.7628\n",
      "Epoch 884/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.8200 - val_loss: 0.6323 - val_accuracy: 0.7628\n",
      "Epoch 885/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.8200 - val_loss: 0.6322 - val_accuracy: 0.7628\n",
      "Epoch 886/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.8206 - val_loss: 0.6321 - val_accuracy: 0.7632\n",
      "Epoch 887/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.8204 - val_loss: 0.6320 - val_accuracy: 0.7641\n",
      "Epoch 888/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.8207 - val_loss: 0.6319 - val_accuracy: 0.7628\n",
      "Epoch 889/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.8197 - val_loss: 0.6319 - val_accuracy: 0.7632\n",
      "Epoch 890/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.8202 - val_loss: 0.6318 - val_accuracy: 0.7624\n",
      "Epoch 891/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.8202 - val_loss: 0.6319 - val_accuracy: 0.7637\n",
      "Epoch 892/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.8203 - val_loss: 0.6317 - val_accuracy: 0.7628\n",
      "Epoch 893/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.8203 - val_loss: 0.6316 - val_accuracy: 0.7624\n",
      "Epoch 894/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.8204 - val_loss: 0.6316 - val_accuracy: 0.7624\n",
      "Epoch 895/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.8203 - val_loss: 0.6314 - val_accuracy: 0.7615\n",
      "Epoch 896/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.8206 - val_loss: 0.6314 - val_accuracy: 0.7615\n",
      "Epoch 897/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.8204 - val_loss: 0.6313 - val_accuracy: 0.7624\n",
      "Epoch 898/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.8203 - val_loss: 0.6314 - val_accuracy: 0.7632\n",
      "Epoch 899/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.8207 - val_loss: 0.6313 - val_accuracy: 0.7632\n",
      "Epoch 900/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.8208 - val_loss: 0.6313 - val_accuracy: 0.7632\n",
      "Epoch 901/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.8208 - val_loss: 0.6312 - val_accuracy: 0.7632\n",
      "Epoch 902/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.8208 - val_loss: 0.6310 - val_accuracy: 0.7632\n",
      "Epoch 903/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.8206 - val_loss: 0.6310 - val_accuracy: 0.7632\n",
      "Epoch 904/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.8207 - val_loss: 0.6308 - val_accuracy: 0.7624\n",
      "Epoch 905/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.8207 - val_loss: 0.6308 - val_accuracy: 0.7624\n",
      "Epoch 906/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.8208 - val_loss: 0.6308 - val_accuracy: 0.7628\n",
      "Epoch 907/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.8208 - val_loss: 0.6307 - val_accuracy: 0.7632\n",
      "Epoch 908/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.8206 - val_loss: 0.6308 - val_accuracy: 0.7637\n",
      "Epoch 909/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.8206 - val_loss: 0.6307 - val_accuracy: 0.7632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 910/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.8208 - val_loss: 0.6305 - val_accuracy: 0.7632\n",
      "Epoch 911/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.8203 - val_loss: 0.6305 - val_accuracy: 0.7632\n",
      "Epoch 912/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.8206 - val_loss: 0.6304 - val_accuracy: 0.7628\n",
      "Epoch 913/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.8207 - val_loss: 0.6303 - val_accuracy: 0.7632\n",
      "Epoch 914/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.8205 - val_loss: 0.6304 - val_accuracy: 0.7628\n",
      "Epoch 915/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.8206 - val_loss: 0.6303 - val_accuracy: 0.7632\n",
      "Epoch 916/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.8207 - val_loss: 0.6302 - val_accuracy: 0.7632\n",
      "Epoch 917/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.8209 - val_loss: 0.6301 - val_accuracy: 0.7632\n",
      "Epoch 918/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.8203 - val_loss: 0.6301 - val_accuracy: 0.7632\n",
      "Epoch 919/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.8210 - val_loss: 0.6300 - val_accuracy: 0.7637\n",
      "Epoch 920/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.8208 - val_loss: 0.6299 - val_accuracy: 0.7637\n",
      "Epoch 921/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.8208 - val_loss: 0.6298 - val_accuracy: 0.7637\n",
      "Epoch 922/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.8206 - val_loss: 0.6298 - val_accuracy: 0.7641\n",
      "Epoch 923/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.8208 - val_loss: 0.6296 - val_accuracy: 0.7637\n",
      "Epoch 924/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.8203 - val_loss: 0.6296 - val_accuracy: 0.7637\n",
      "Epoch 925/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.8203 - val_loss: 0.6296 - val_accuracy: 0.7637\n",
      "Epoch 926/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.8204 - val_loss: 0.6295 - val_accuracy: 0.7641\n",
      "Epoch 927/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.8202 - val_loss: 0.6294 - val_accuracy: 0.7632\n",
      "Epoch 928/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.8205 - val_loss: 0.6294 - val_accuracy: 0.7637\n",
      "Epoch 929/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.8205 - val_loss: 0.6294 - val_accuracy: 0.7637\n",
      "Epoch 930/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.8200 - val_loss: 0.6293 - val_accuracy: 0.7641\n",
      "Epoch 931/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.8205 - val_loss: 0.6291 - val_accuracy: 0.7641\n",
      "Epoch 932/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.8204 - val_loss: 0.6291 - val_accuracy: 0.7637\n",
      "Epoch 933/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5019 - accuracy: 0.8205 - val_loss: 0.6290 - val_accuracy: 0.7637\n",
      "Epoch 934/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5017 - accuracy: 0.8199 - val_loss: 0.6291 - val_accuracy: 0.7637\n",
      "Epoch 935/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5015 - accuracy: 0.8200 - val_loss: 0.6289 - val_accuracy: 0.7641\n",
      "Epoch 936/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5014 - accuracy: 0.8200 - val_loss: 0.6289 - val_accuracy: 0.7637\n",
      "Epoch 937/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5012 - accuracy: 0.8202 - val_loss: 0.6289 - val_accuracy: 0.7641\n",
      "Epoch 938/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5010 - accuracy: 0.8203 - val_loss: 0.6289 - val_accuracy: 0.7641\n",
      "Epoch 939/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5009 - accuracy: 0.8200 - val_loss: 0.6288 - val_accuracy: 0.7641\n",
      "Epoch 940/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5007 - accuracy: 0.8203 - val_loss: 0.6287 - val_accuracy: 0.7645\n",
      "Epoch 941/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5005 - accuracy: 0.8202 - val_loss: 0.6287 - val_accuracy: 0.7645\n",
      "Epoch 942/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5003 - accuracy: 0.8199 - val_loss: 0.6286 - val_accuracy: 0.7641\n",
      "Epoch 943/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5002 - accuracy: 0.8206 - val_loss: 0.6285 - val_accuracy: 0.7641\n",
      "Epoch 944/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5000 - accuracy: 0.8202 - val_loss: 0.6285 - val_accuracy: 0.7641\n",
      "Epoch 945/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4998 - accuracy: 0.8207 - val_loss: 0.6285 - val_accuracy: 0.7641\n",
      "Epoch 946/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4996 - accuracy: 0.8204 - val_loss: 0.6285 - val_accuracy: 0.7641\n",
      "Epoch 947/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4995 - accuracy: 0.8203 - val_loss: 0.6284 - val_accuracy: 0.7641\n",
      "Epoch 948/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4993 - accuracy: 0.8207 - val_loss: 0.6283 - val_accuracy: 0.7641\n",
      "Epoch 949/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.8203 - val_loss: 0.6282 - val_accuracy: 0.7632\n",
      "Epoch 950/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4989 - accuracy: 0.8209 - val_loss: 0.6282 - val_accuracy: 0.7632\n",
      "Epoch 951/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4988 - accuracy: 0.8202 - val_loss: 0.6282 - val_accuracy: 0.7641\n",
      "Epoch 952/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4986 - accuracy: 0.8211 - val_loss: 0.6281 - val_accuracy: 0.7628\n",
      "Epoch 953/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.8207 - val_loss: 0.6281 - val_accuracy: 0.7632\n",
      "Epoch 954/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4983 - accuracy: 0.8206 - val_loss: 0.6281 - val_accuracy: 0.7641\n",
      "Epoch 955/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.8206 - val_loss: 0.6281 - val_accuracy: 0.7632\n",
      "Epoch 956/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4979 - accuracy: 0.8209 - val_loss: 0.6280 - val_accuracy: 0.7628\n",
      "Epoch 957/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4978 - accuracy: 0.8210 - val_loss: 0.6278 - val_accuracy: 0.7628\n",
      "Epoch 958/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4976 - accuracy: 0.8212 - val_loss: 0.6278 - val_accuracy: 0.7628\n",
      "Epoch 959/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4975 - accuracy: 0.8210 - val_loss: 0.6279 - val_accuracy: 0.7628\n",
      "Epoch 960/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4973 - accuracy: 0.8207 - val_loss: 0.6278 - val_accuracy: 0.7632\n",
      "Epoch 961/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4971 - accuracy: 0.8211 - val_loss: 0.6277 - val_accuracy: 0.7628\n",
      "Epoch 962/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4970 - accuracy: 0.8210 - val_loss: 0.6278 - val_accuracy: 0.7632\n",
      "Epoch 963/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4968 - accuracy: 0.8208 - val_loss: 0.6276 - val_accuracy: 0.7632\n",
      "Epoch 964/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4967 - accuracy: 0.8209 - val_loss: 0.6275 - val_accuracy: 0.7628\n",
      "Epoch 965/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4965 - accuracy: 0.8206 - val_loss: 0.6275 - val_accuracy: 0.7632\n",
      "Epoch 966/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4963 - accuracy: 0.8203 - val_loss: 0.6274 - val_accuracy: 0.7632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 967/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4962 - accuracy: 0.8210 - val_loss: 0.6274 - val_accuracy: 0.7628\n",
      "Epoch 968/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4960 - accuracy: 0.8210 - val_loss: 0.6275 - val_accuracy: 0.7628\n",
      "Epoch 969/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.8208 - val_loss: 0.6273 - val_accuracy: 0.7624\n",
      "Epoch 970/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4957 - accuracy: 0.8209 - val_loss: 0.6273 - val_accuracy: 0.7628\n",
      "Epoch 971/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4956 - accuracy: 0.8211 - val_loss: 0.6273 - val_accuracy: 0.7637\n",
      "Epoch 972/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.8205 - val_loss: 0.6272 - val_accuracy: 0.7637\n",
      "Epoch 973/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4953 - accuracy: 0.8209 - val_loss: 0.6273 - val_accuracy: 0.7637\n",
      "Epoch 974/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.8211 - val_loss: 0.6271 - val_accuracy: 0.7624\n",
      "Epoch 975/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4950 - accuracy: 0.8213 - val_loss: 0.6270 - val_accuracy: 0.7628\n",
      "Epoch 976/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4948 - accuracy: 0.8208 - val_loss: 0.6271 - val_accuracy: 0.7637\n",
      "Epoch 977/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4947 - accuracy: 0.8208 - val_loss: 0.6271 - val_accuracy: 0.7632\n",
      "Epoch 978/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4945 - accuracy: 0.8212 - val_loss: 0.6271 - val_accuracy: 0.7637\n",
      "Epoch 979/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4944 - accuracy: 0.8212 - val_loss: 0.6270 - val_accuracy: 0.7637\n",
      "Epoch 980/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4942 - accuracy: 0.8212 - val_loss: 0.6270 - val_accuracy: 0.7632\n",
      "Epoch 981/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4941 - accuracy: 0.8214 - val_loss: 0.6269 - val_accuracy: 0.7632\n",
      "Epoch 982/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4939 - accuracy: 0.8215 - val_loss: 0.6269 - val_accuracy: 0.7632\n",
      "Epoch 983/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.8213 - val_loss: 0.6268 - val_accuracy: 0.7632\n",
      "Epoch 984/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4936 - accuracy: 0.8215 - val_loss: 0.6268 - val_accuracy: 0.7637\n",
      "Epoch 985/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4935 - accuracy: 0.8216 - val_loss: 0.6267 - val_accuracy: 0.7641\n",
      "Epoch 986/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4933 - accuracy: 0.8218 - val_loss: 0.6267 - val_accuracy: 0.7641\n",
      "Epoch 987/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4932 - accuracy: 0.8219 - val_loss: 0.6266 - val_accuracy: 0.7641\n",
      "Epoch 988/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.8216 - val_loss: 0.6266 - val_accuracy: 0.7641\n",
      "Epoch 989/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.8214 - val_loss: 0.6266 - val_accuracy: 0.7637\n",
      "Epoch 990/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4928 - accuracy: 0.8214 - val_loss: 0.6266 - val_accuracy: 0.7637\n",
      "Epoch 991/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4926 - accuracy: 0.8220 - val_loss: 0.6265 - val_accuracy: 0.7645\n",
      "Epoch 992/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4925 - accuracy: 0.8216 - val_loss: 0.6265 - val_accuracy: 0.7645\n",
      "Epoch 993/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4924 - accuracy: 0.8220 - val_loss: 0.6265 - val_accuracy: 0.7650\n",
      "Epoch 994/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.8215 - val_loss: 0.6266 - val_accuracy: 0.7641\n",
      "Epoch 995/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4921 - accuracy: 0.8220 - val_loss: 0.6265 - val_accuracy: 0.7645\n",
      "Epoch 996/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4919 - accuracy: 0.8221 - val_loss: 0.6265 - val_accuracy: 0.7645\n",
      "Epoch 997/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4918 - accuracy: 0.8220 - val_loss: 0.6265 - val_accuracy: 0.7645\n",
      "Epoch 998/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4916 - accuracy: 0.8215 - val_loss: 0.6264 - val_accuracy: 0.7650\n",
      "Epoch 999/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4915 - accuracy: 0.8218 - val_loss: 0.6264 - val_accuracy: 0.7650\n",
      "Epoch 1000/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4914 - accuracy: 0.8219 - val_loss: 0.6263 - val_accuracy: 0.7654\n",
      "Epoch 1001/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4912 - accuracy: 0.8221 - val_loss: 0.6264 - val_accuracy: 0.7654\n",
      "Epoch 1002/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4911 - accuracy: 0.8214 - val_loss: 0.6263 - val_accuracy: 0.7650\n",
      "Epoch 1003/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4910 - accuracy: 0.8219 - val_loss: 0.6264 - val_accuracy: 0.7645\n",
      "Epoch 1004/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4908 - accuracy: 0.8220 - val_loss: 0.6263 - val_accuracy: 0.7645\n",
      "Epoch 1005/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4907 - accuracy: 0.8218 - val_loss: 0.6262 - val_accuracy: 0.7658\n",
      "Epoch 1006/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4905 - accuracy: 0.8216 - val_loss: 0.6262 - val_accuracy: 0.7658\n",
      "Epoch 1007/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.8213 - val_loss: 0.6261 - val_accuracy: 0.7654\n",
      "Epoch 1008/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.8215 - val_loss: 0.6261 - val_accuracy: 0.7658\n",
      "Epoch 1009/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4901 - accuracy: 0.8221 - val_loss: 0.6261 - val_accuracy: 0.7658\n",
      "Epoch 1010/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.8216 - val_loss: 0.6261 - val_accuracy: 0.7650\n",
      "Epoch 1011/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4899 - accuracy: 0.8215 - val_loss: 0.6261 - val_accuracy: 0.7658\n",
      "Epoch 1012/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4898 - accuracy: 0.8220 - val_loss: 0.6262 - val_accuracy: 0.7641\n",
      "Epoch 1013/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4896 - accuracy: 0.8216 - val_loss: 0.6262 - val_accuracy: 0.7650\n",
      "Epoch 1014/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4895 - accuracy: 0.8218 - val_loss: 0.6261 - val_accuracy: 0.7650\n",
      "Epoch 1015/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.8216 - val_loss: 0.6260 - val_accuracy: 0.7650\n",
      "Epoch 1016/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4892 - accuracy: 0.8220 - val_loss: 0.6260 - val_accuracy: 0.7650\n",
      "Epoch 1017/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4891 - accuracy: 0.8218 - val_loss: 0.6260 - val_accuracy: 0.7654\n",
      "Epoch 1018/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4890 - accuracy: 0.8221 - val_loss: 0.6260 - val_accuracy: 0.7650\n",
      "Epoch 1019/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.8224 - val_loss: 0.6259 - val_accuracy: 0.7650\n",
      "Epoch 1020/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4887 - accuracy: 0.8225 - val_loss: 0.6258 - val_accuracy: 0.7654\n",
      "Epoch 1021/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4886 - accuracy: 0.8227 - val_loss: 0.6259 - val_accuracy: 0.7650\n",
      "Epoch 1022/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.8223 - val_loss: 0.6259 - val_accuracy: 0.7654\n",
      "Epoch 1023/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.8224 - val_loss: 0.6259 - val_accuracy: 0.7650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1024/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4882 - accuracy: 0.8228 - val_loss: 0.6259 - val_accuracy: 0.7658\n",
      "Epoch 1025/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.8227 - val_loss: 0.6259 - val_accuracy: 0.7650\n",
      "Epoch 1026/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4880 - accuracy: 0.8223 - val_loss: 0.6258 - val_accuracy: 0.7645\n",
      "Epoch 1027/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4879 - accuracy: 0.8227 - val_loss: 0.6258 - val_accuracy: 0.7645\n",
      "Epoch 1028/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4877 - accuracy: 0.8229 - val_loss: 0.6258 - val_accuracy: 0.7645\n",
      "Epoch 1029/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4876 - accuracy: 0.8228 - val_loss: 0.6258 - val_accuracy: 0.7645\n",
      "Epoch 1030/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4875 - accuracy: 0.8227 - val_loss: 0.6258 - val_accuracy: 0.7645\n",
      "Epoch 1031/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4874 - accuracy: 0.8228 - val_loss: 0.6258 - val_accuracy: 0.7645\n",
      "Epoch 1032/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4872 - accuracy: 0.8231 - val_loss: 0.6257 - val_accuracy: 0.7637\n",
      "Epoch 1033/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4871 - accuracy: 0.8230 - val_loss: 0.6257 - val_accuracy: 0.7628\n",
      "Epoch 1034/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4870 - accuracy: 0.8230 - val_loss: 0.6257 - val_accuracy: 0.7637\n",
      "Epoch 1035/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.8230 - val_loss: 0.6258 - val_accuracy: 0.7632\n",
      "Epoch 1036/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.8226 - val_loss: 0.6258 - val_accuracy: 0.7628\n",
      "Epoch 1037/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4866 - accuracy: 0.8227 - val_loss: 0.6258 - val_accuracy: 0.7632\n",
      "Epoch 1038/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.8233 - val_loss: 0.6257 - val_accuracy: 0.7632\n",
      "Epoch 1039/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4864 - accuracy: 0.8230 - val_loss: 0.6258 - val_accuracy: 0.7632\n",
      "Epoch 1040/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4863 - accuracy: 0.8229 - val_loss: 0.6257 - val_accuracy: 0.7628\n",
      "Epoch 1041/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4862 - accuracy: 0.8237 - val_loss: 0.6257 - val_accuracy: 0.7637\n",
      "Epoch 1042/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.8242 - val_loss: 0.6256 - val_accuracy: 0.7628\n",
      "Epoch 1043/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.8237 - val_loss: 0.6256 - val_accuracy: 0.7628\n",
      "Epoch 1044/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4858 - accuracy: 0.8239 - val_loss: 0.6257 - val_accuracy: 0.7624\n",
      "Epoch 1045/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.8239 - val_loss: 0.6257 - val_accuracy: 0.7624\n",
      "Epoch 1046/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.8234 - val_loss: 0.6257 - val_accuracy: 0.7624\n",
      "Epoch 1047/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.8237 - val_loss: 0.6257 - val_accuracy: 0.7620\n",
      "Epoch 1048/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.8245 - val_loss: 0.6257 - val_accuracy: 0.7624\n",
      "Epoch 1049/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4853 - accuracy: 0.8235 - val_loss: 0.6256 - val_accuracy: 0.7624\n",
      "Epoch 1050/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 0.8240 - val_loss: 0.6256 - val_accuracy: 0.7624\n",
      "Epoch 1051/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.8239 - val_loss: 0.6256 - val_accuracy: 0.7620\n",
      "Epoch 1052/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.8239 - val_loss: 0.6255 - val_accuracy: 0.7632\n",
      "Epoch 1053/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.8239 - val_loss: 0.6255 - val_accuracy: 0.7624\n",
      "Epoch 1054/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4847 - accuracy: 0.8239 - val_loss: 0.6255 - val_accuracy: 0.7624\n",
      "Epoch 1055/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4846 - accuracy: 0.8244 - val_loss: 0.6255 - val_accuracy: 0.7628\n",
      "Epoch 1056/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4845 - accuracy: 0.8244 - val_loss: 0.6255 - val_accuracy: 0.7637\n",
      "Epoch 1057/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.8244 - val_loss: 0.6254 - val_accuracy: 0.7632\n",
      "Epoch 1058/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4842 - accuracy: 0.8241 - val_loss: 0.6254 - val_accuracy: 0.7628\n",
      "Epoch 1059/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.8244 - val_loss: 0.6255 - val_accuracy: 0.7632\n",
      "Epoch 1060/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.8243 - val_loss: 0.6255 - val_accuracy: 0.7632\n",
      "Epoch 1061/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4839 - accuracy: 0.8240 - val_loss: 0.6256 - val_accuracy: 0.7632\n",
      "Epoch 1062/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.8242 - val_loss: 0.6255 - val_accuracy: 0.7628\n",
      "Epoch 1063/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.8242 - val_loss: 0.6256 - val_accuracy: 0.7632\n",
      "Epoch 1064/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4836 - accuracy: 0.8242 - val_loss: 0.6255 - val_accuracy: 0.7632\n",
      "Epoch 1065/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.8241 - val_loss: 0.6255 - val_accuracy: 0.7637\n",
      "Epoch 1066/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4834 - accuracy: 0.8237 - val_loss: 0.6255 - val_accuracy: 0.7632\n",
      "Epoch 1067/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.8244 - val_loss: 0.6254 - val_accuracy: 0.7624\n",
      "Epoch 1068/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4832 - accuracy: 0.8250 - val_loss: 0.6255 - val_accuracy: 0.7624\n",
      "Epoch 1069/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 0.8244 - val_loss: 0.6255 - val_accuracy: 0.7624\n",
      "Epoch 1070/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4829 - accuracy: 0.8246 - val_loss: 0.6255 - val_accuracy: 0.7628\n",
      "Epoch 1071/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.8246 - val_loss: 0.6255 - val_accuracy: 0.7620\n",
      "Epoch 1072/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.8253 - val_loss: 0.6254 - val_accuracy: 0.7624\n",
      "Epoch 1073/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.8244 - val_loss: 0.6255 - val_accuracy: 0.7620\n",
      "Epoch 1074/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 0.8250 - val_loss: 0.6255 - val_accuracy: 0.7628\n",
      "Epoch 1075/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4824 - accuracy: 0.8245 - val_loss: 0.6255 - val_accuracy: 0.7628\n",
      "Epoch 1076/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.8250 - val_loss: 0.6255 - val_accuracy: 0.7624\n",
      "Epoch 1077/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.8241 - val_loss: 0.6255 - val_accuracy: 0.7628\n",
      "Epoch 1078/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.8254 - val_loss: 0.6254 - val_accuracy: 0.7624\n",
      "Epoch 1079/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.8246 - val_loss: 0.6255 - val_accuracy: 0.7628\n",
      "Epoch 1080/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.8237 - val_loss: 0.6255 - val_accuracy: 0.7632\n",
      "Epoch 1081/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4818 - accuracy: 0.8239 - val_loss: 0.6255 - val_accuracy: 0.7624\n",
      "Epoch 1082/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.8231 - val_loss: 0.6255 - val_accuracy: 0.7632\n",
      "Epoch 1083/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.8236 - val_loss: 0.6255 - val_accuracy: 0.7624\n",
      "Epoch 1084/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.8239 - val_loss: 0.6254 - val_accuracy: 0.7624\n",
      "Epoch 1085/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.8246 - val_loss: 0.6254 - val_accuracy: 0.7628\n",
      "Epoch 1086/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.8245 - val_loss: 0.6253 - val_accuracy: 0.7624\n",
      "Epoch 1087/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.8245 - val_loss: 0.6253 - val_accuracy: 0.7620\n",
      "Epoch 1088/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4810 - accuracy: 0.8246 - val_loss: 0.6254 - val_accuracy: 0.7624\n",
      "Epoch 1089/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4809 - accuracy: 0.8238 - val_loss: 0.6254 - val_accuracy: 0.7620\n",
      "Epoch 1090/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4809 - accuracy: 0.8241 - val_loss: 0.6254 - val_accuracy: 0.7620\n",
      "Epoch 1091/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4807 - accuracy: 0.8247 - val_loss: 0.6253 - val_accuracy: 0.7615\n",
      "Epoch 1092/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.8246 - val_loss: 0.6254 - val_accuracy: 0.7615\n",
      "Epoch 1093/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.8249 - val_loss: 0.6253 - val_accuracy: 0.7615\n",
      "Epoch 1094/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.8250 - val_loss: 0.6253 - val_accuracy: 0.7624\n",
      "Epoch 1095/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.8243 - val_loss: 0.6254 - val_accuracy: 0.7620\n",
      "Epoch 1096/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.8250 - val_loss: 0.6254 - val_accuracy: 0.7611\n",
      "Epoch 1097/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.8246 - val_loss: 0.6253 - val_accuracy: 0.7611\n",
      "Epoch 1098/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.8246 - val_loss: 0.6253 - val_accuracy: 0.7611\n",
      "Epoch 1099/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.8249 - val_loss: 0.6253 - val_accuracy: 0.7615\n",
      "Epoch 1100/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.8247 - val_loss: 0.6253 - val_accuracy: 0.7611\n",
      "Epoch 1101/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.8250 - val_loss: 0.6254 - val_accuracy: 0.7603\n",
      "Epoch 1102/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.8242 - val_loss: 0.6254 - val_accuracy: 0.7603\n",
      "Epoch 1103/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.8244 - val_loss: 0.6253 - val_accuracy: 0.7611\n",
      "Epoch 1104/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4795 - accuracy: 0.8245 - val_loss: 0.6254 - val_accuracy: 0.7603\n",
      "Epoch 1105/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.8249 - val_loss: 0.6254 - val_accuracy: 0.7603\n",
      "Epoch 1106/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.8247 - val_loss: 0.6253 - val_accuracy: 0.7607\n",
      "Epoch 1107/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.8250 - val_loss: 0.6254 - val_accuracy: 0.7607\n",
      "Epoch 1108/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.8251 - val_loss: 0.6254 - val_accuracy: 0.7603\n",
      "Epoch 1109/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 0.8252 - val_loss: 0.6254 - val_accuracy: 0.7603\n",
      "Epoch 1110/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.8255 - val_loss: 0.6254 - val_accuracy: 0.7598\n",
      "Epoch 1111/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.8255 - val_loss: 0.6254 - val_accuracy: 0.7598\n",
      "Epoch 1112/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.8255 - val_loss: 0.6254 - val_accuracy: 0.7598\n",
      "Epoch 1113/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.8255 - val_loss: 0.6254 - val_accuracy: 0.7598\n",
      "Epoch 1114/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.8253 - val_loss: 0.6254 - val_accuracy: 0.7598\n",
      "Epoch 1115/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.8254 - val_loss: 0.6254 - val_accuracy: 0.7594\n",
      "Epoch 1116/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.8254 - val_loss: 0.6254 - val_accuracy: 0.7594\n",
      "Epoch 1117/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.8253 - val_loss: 0.6255 - val_accuracy: 0.7598\n",
      "Epoch 1118/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.8255 - val_loss: 0.6255 - val_accuracy: 0.7598\n",
      "Epoch 1119/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.8255 - val_loss: 0.6255 - val_accuracy: 0.7594\n",
      "Epoch 1120/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.8256 - val_loss: 0.6254 - val_accuracy: 0.7594\n",
      "Epoch 1121/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.8252 - val_loss: 0.6254 - val_accuracy: 0.7598\n",
      "Epoch 1122/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.8255 - val_loss: 0.6254 - val_accuracy: 0.7594\n",
      "Epoch 1123/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.8253 - val_loss: 0.6255 - val_accuracy: 0.7603\n",
      "Epoch 1124/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.8253 - val_loss: 0.6255 - val_accuracy: 0.7603\n",
      "Epoch 1125/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.8253 - val_loss: 0.6255 - val_accuracy: 0.7594\n",
      "Epoch 1126/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.8251 - val_loss: 0.6255 - val_accuracy: 0.7598\n",
      "Epoch 1127/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.8254 - val_loss: 0.6255 - val_accuracy: 0.7598\n",
      "Epoch 1128/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.8251 - val_loss: 0.6255 - val_accuracy: 0.7594\n",
      "Epoch 1129/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.8257 - val_loss: 0.6255 - val_accuracy: 0.7585\n",
      "Epoch 1130/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.8256 - val_loss: 0.6255 - val_accuracy: 0.7594\n",
      "Epoch 1131/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.8254 - val_loss: 0.6255 - val_accuracy: 0.7598\n",
      "Epoch 1132/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4769 - accuracy: 0.8253 - val_loss: 0.6255 - val_accuracy: 0.7594\n",
      "Epoch 1133/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.8258 - val_loss: 0.6255 - val_accuracy: 0.7594\n",
      "Epoch 1134/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.8261 - val_loss: 0.6254 - val_accuracy: 0.7590\n",
      "Epoch 1135/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.8259 - val_loss: 0.6255 - val_accuracy: 0.7590\n",
      "Epoch 1136/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.8259 - val_loss: 0.6256 - val_accuracy: 0.7590\n",
      "Epoch 1137/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.8261 - val_loss: 0.6256 - val_accuracy: 0.7594\n",
      "Epoch 1138/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.8254 - val_loss: 0.6255 - val_accuracy: 0.7585\n",
      "Epoch 1139/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.8260 - val_loss: 0.6255 - val_accuracy: 0.7590\n",
      "Epoch 1140/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.8264 - val_loss: 0.6255 - val_accuracy: 0.7585\n",
      "Epoch 1141/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.8264 - val_loss: 0.6256 - val_accuracy: 0.7585\n",
      "Epoch 1142/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.8265 - val_loss: 0.6256 - val_accuracy: 0.7585\n",
      "Epoch 1143/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.8262 - val_loss: 0.6256 - val_accuracy: 0.7585\n",
      "Epoch 1144/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.8257 - val_loss: 0.6256 - val_accuracy: 0.7585\n",
      "Epoch 1145/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.8259 - val_loss: 0.6256 - val_accuracy: 0.7581\n",
      "Epoch 1146/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.8255 - val_loss: 0.6256 - val_accuracy: 0.7585\n",
      "Epoch 1147/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.8260 - val_loss: 0.6256 - val_accuracy: 0.7590\n",
      "Epoch 1148/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.8264 - val_loss: 0.6256 - val_accuracy: 0.7590\n",
      "Epoch 1149/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.8265 - val_loss: 0.6256 - val_accuracy: 0.7590\n",
      "Epoch 1150/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.8264 - val_loss: 0.6256 - val_accuracy: 0.7594\n",
      "Epoch 1151/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.8266 - val_loss: 0.6256 - val_accuracy: 0.7590\n",
      "Epoch 1152/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.8264 - val_loss: 0.6257 - val_accuracy: 0.7585\n",
      "Epoch 1153/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.8266 - val_loss: 0.6258 - val_accuracy: 0.7585\n",
      "Epoch 1154/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.8266 - val_loss: 0.6258 - val_accuracy: 0.7585\n",
      "Epoch 1155/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.8264 - val_loss: 0.6258 - val_accuracy: 0.7594\n",
      "Epoch 1156/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.8269 - val_loss: 0.6257 - val_accuracy: 0.7590\n",
      "Epoch 1157/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.8266 - val_loss: 0.6257 - val_accuracy: 0.7590\n",
      "Epoch 1158/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 0.8267 - val_loss: 0.6258 - val_accuracy: 0.7594\n",
      "Epoch 1159/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.8270 - val_loss: 0.6258 - val_accuracy: 0.7590\n",
      "Epoch 1160/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4745 - accuracy: 0.8267 - val_loss: 0.6258 - val_accuracy: 0.7598\n",
      "Epoch 1161/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4745 - accuracy: 0.8267 - val_loss: 0.6258 - val_accuracy: 0.7594\n",
      "Epoch 1162/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.8269 - val_loss: 0.6258 - val_accuracy: 0.7594\n",
      "Epoch 1163/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.8266 - val_loss: 0.6258 - val_accuracy: 0.7594\n",
      "Epoch 1164/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.8268 - val_loss: 0.6258 - val_accuracy: 0.7598\n",
      "Epoch 1165/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.8270 - val_loss: 0.6257 - val_accuracy: 0.7594\n",
      "Epoch 1166/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.8270 - val_loss: 0.6258 - val_accuracy: 0.7598\n",
      "Epoch 1167/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.8270 - val_loss: 0.6258 - val_accuracy: 0.7598\n",
      "Epoch 1168/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.8271 - val_loss: 0.6258 - val_accuracy: 0.7603\n",
      "Epoch 1169/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 0.8268 - val_loss: 0.6258 - val_accuracy: 0.7603\n",
      "Epoch 1170/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.8269 - val_loss: 0.6259 - val_accuracy: 0.7603\n",
      "Epoch 1171/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.8268 - val_loss: 0.6259 - val_accuracy: 0.7598\n",
      "Epoch 1172/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.8272 - val_loss: 0.6259 - val_accuracy: 0.7594\n",
      "Epoch 1173/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.8274 - val_loss: 0.6260 - val_accuracy: 0.7594\n",
      "Epoch 1174/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.8268 - val_loss: 0.6260 - val_accuracy: 0.7603\n",
      "Epoch 1175/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.8268 - val_loss: 0.6260 - val_accuracy: 0.7598\n",
      "Epoch 1176/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.8273 - val_loss: 0.6259 - val_accuracy: 0.7603\n",
      "Epoch 1177/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.8273 - val_loss: 0.6260 - val_accuracy: 0.7598\n",
      "Epoch 1178/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4731 - accuracy: 0.8271 - val_loss: 0.6260 - val_accuracy: 0.7598\n",
      "Epoch 1179/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.8272 - val_loss: 0.6260 - val_accuracy: 0.7590\n",
      "Epoch 1180/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.8271 - val_loss: 0.6260 - val_accuracy: 0.7594\n",
      "Epoch 1181/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.8272 - val_loss: 0.6259 - val_accuracy: 0.7598\n",
      "Epoch 1182/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4728 - accuracy: 0.8271 - val_loss: 0.6261 - val_accuracy: 0.7590\n",
      "Epoch 1183/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.8271 - val_loss: 0.6261 - val_accuracy: 0.7598\n",
      "Epoch 1184/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.8273 - val_loss: 0.6261 - val_accuracy: 0.7594\n",
      "Epoch 1185/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.8272 - val_loss: 0.6261 - val_accuracy: 0.7590\n",
      "Epoch 1186/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.8275 - val_loss: 0.6261 - val_accuracy: 0.7594\n",
      "Epoch 1187/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.8270 - val_loss: 0.6261 - val_accuracy: 0.7594\n",
      "Epoch 1188/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.8270 - val_loss: 0.6262 - val_accuracy: 0.7598\n",
      "Epoch 1189/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.8274 - val_loss: 0.6262 - val_accuracy: 0.7594\n",
      "Epoch 1190/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.8275 - val_loss: 0.6262 - val_accuracy: 0.7594\n",
      "Epoch 1191/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.8272 - val_loss: 0.6263 - val_accuracy: 0.7594\n",
      "Epoch 1192/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.8271 - val_loss: 0.6263 - val_accuracy: 0.7594\n",
      "Epoch 1193/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.8273 - val_loss: 0.6263 - val_accuracy: 0.7594\n",
      "Epoch 1194/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.8272 - val_loss: 0.6263 - val_accuracy: 0.7594\n",
      "Epoch 1195/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.8273 - val_loss: 0.6264 - val_accuracy: 0.7590\n",
      "Epoch 1196/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.8273 - val_loss: 0.6263 - val_accuracy: 0.7590\n",
      "Epoch 1197/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.8276 - val_loss: 0.6264 - val_accuracy: 0.7590\n",
      "Epoch 1198/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.8272 - val_loss: 0.6263 - val_accuracy: 0.7590\n",
      "Epoch 1199/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.8272 - val_loss: 0.6264 - val_accuracy: 0.7590\n",
      "Epoch 1200/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.8276 - val_loss: 0.6263 - val_accuracy: 0.7590\n",
      "Epoch 1201/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.8272 - val_loss: 0.6264 - val_accuracy: 0.7590\n",
      "Epoch 1202/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.8276 - val_loss: 0.6263 - val_accuracy: 0.7590\n",
      "Epoch 1203/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.8275 - val_loss: 0.6264 - val_accuracy: 0.7590\n",
      "Epoch 1204/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.8274 - val_loss: 0.6264 - val_accuracy: 0.7590\n",
      "Epoch 1205/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.8273 - val_loss: 0.6264 - val_accuracy: 0.7603\n",
      "Epoch 1206/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.8275 - val_loss: 0.6264 - val_accuracy: 0.7598\n",
      "Epoch 1207/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.8272 - val_loss: 0.6264 - val_accuracy: 0.7594\n",
      "Epoch 1208/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.8276 - val_loss: 0.6264 - val_accuracy: 0.7603\n",
      "Epoch 1209/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.8273 - val_loss: 0.6264 - val_accuracy: 0.7603\n",
      "Epoch 1210/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4708 - accuracy: 0.8275 - val_loss: 0.6264 - val_accuracy: 0.7603\n",
      "Epoch 1211/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.8274 - val_loss: 0.6266 - val_accuracy: 0.7603\n",
      "Epoch 1212/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.8274 - val_loss: 0.6265 - val_accuracy: 0.7603\n",
      "Epoch 1213/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.8275 - val_loss: 0.6265 - val_accuracy: 0.7603\n",
      "Epoch 1214/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.8275 - val_loss: 0.6266 - val_accuracy: 0.7594\n",
      "Epoch 1215/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.8273 - val_loss: 0.6267 - val_accuracy: 0.7607\n",
      "Epoch 1216/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.8272 - val_loss: 0.6267 - val_accuracy: 0.7598\n",
      "Epoch 1217/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.8274 - val_loss: 0.6267 - val_accuracy: 0.7590\n",
      "Epoch 1218/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.8274 - val_loss: 0.6267 - val_accuracy: 0.7590\n",
      "Epoch 1219/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.8276 - val_loss: 0.6267 - val_accuracy: 0.7594\n",
      "Epoch 1220/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.8277 - val_loss: 0.6267 - val_accuracy: 0.7590\n",
      "Epoch 1221/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.8276 - val_loss: 0.6267 - val_accuracy: 0.7585\n",
      "Epoch 1222/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.8274 - val_loss: 0.6268 - val_accuracy: 0.7590\n",
      "Epoch 1223/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.8275 - val_loss: 0.6268 - val_accuracy: 0.7590\n",
      "Epoch 1224/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.8274 - val_loss: 0.6267 - val_accuracy: 0.7585\n",
      "Epoch 1225/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.8275 - val_loss: 0.6267 - val_accuracy: 0.7590\n",
      "Epoch 1226/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.8276 - val_loss: 0.6268 - val_accuracy: 0.7585\n",
      "Epoch 1227/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.8278 - val_loss: 0.6268 - val_accuracy: 0.7581\n",
      "Epoch 1228/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.8273 - val_loss: 0.6268 - val_accuracy: 0.7590\n",
      "Epoch 1229/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.8281 - val_loss: 0.6268 - val_accuracy: 0.7590\n",
      "Epoch 1230/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.8276 - val_loss: 0.6268 - val_accuracy: 0.7590\n",
      "Epoch 1231/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.8275 - val_loss: 0.6269 - val_accuracy: 0.7585\n",
      "Epoch 1232/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.8276 - val_loss: 0.6269 - val_accuracy: 0.7590\n",
      "Epoch 1233/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.8274 - val_loss: 0.6268 - val_accuracy: 0.7581\n",
      "Epoch 1234/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.8276 - val_loss: 0.6270 - val_accuracy: 0.7585\n",
      "Epoch 1235/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.8275 - val_loss: 0.6270 - val_accuracy: 0.7585\n",
      "Epoch 1236/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.8275 - val_loss: 0.6270 - val_accuracy: 0.7585\n",
      "Epoch 1237/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.8280 - val_loss: 0.6270 - val_accuracy: 0.7585\n",
      "Epoch 1238/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.8271 - val_loss: 0.6270 - val_accuracy: 0.7573\n",
      "Epoch 1239/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.8275 - val_loss: 0.6270 - val_accuracy: 0.7585\n",
      "Epoch 1240/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.8273 - val_loss: 0.6270 - val_accuracy: 0.7577\n",
      "Epoch 1241/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.8271 - val_loss: 0.6271 - val_accuracy: 0.7581\n",
      "Epoch 1242/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.8274 - val_loss: 0.6271 - val_accuracy: 0.7577\n",
      "Epoch 1243/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.8273 - val_loss: 0.6271 - val_accuracy: 0.7568\n",
      "Epoch 1244/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.8277 - val_loss: 0.6271 - val_accuracy: 0.7568\n",
      "Epoch 1245/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.8277 - val_loss: 0.6272 - val_accuracy: 0.7581\n",
      "Epoch 1246/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.8276 - val_loss: 0.6272 - val_accuracy: 0.7585\n",
      "Epoch 1247/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.8274 - val_loss: 0.6272 - val_accuracy: 0.7581\n",
      "Epoch 1248/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.8276 - val_loss: 0.6271 - val_accuracy: 0.7568\n",
      "Epoch 1249/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.8276 - val_loss: 0.6271 - val_accuracy: 0.7573\n",
      "Epoch 1250/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.8276 - val_loss: 0.6272 - val_accuracy: 0.7573\n",
      "Epoch 1251/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.8278 - val_loss: 0.6272 - val_accuracy: 0.7573\n",
      "Epoch 1252/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.8280 - val_loss: 0.6273 - val_accuracy: 0.7581\n",
      "Epoch 1253/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.8277 - val_loss: 0.6273 - val_accuracy: 0.7577\n",
      "Epoch 1254/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.8280 - val_loss: 0.6274 - val_accuracy: 0.7577\n",
      "Epoch 1255/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.8275 - val_loss: 0.6273 - val_accuracy: 0.7577\n",
      "Epoch 1256/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.8280 - val_loss: 0.6273 - val_accuracy: 0.7573\n",
      "Epoch 1257/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.8278 - val_loss: 0.6273 - val_accuracy: 0.7577\n",
      "Epoch 1258/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.8277 - val_loss: 0.6273 - val_accuracy: 0.7581\n",
      "Epoch 1259/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.8281 - val_loss: 0.6274 - val_accuracy: 0.7577\n",
      "Epoch 1260/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.8276 - val_loss: 0.6273 - val_accuracy: 0.7585\n",
      "Epoch 1261/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.8276 - val_loss: 0.6274 - val_accuracy: 0.7573\n",
      "Epoch 1262/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.8281 - val_loss: 0.6274 - val_accuracy: 0.7581\n",
      "Epoch 1263/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.8274 - val_loss: 0.6275 - val_accuracy: 0.7573\n",
      "Epoch 1264/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.8274 - val_loss: 0.6275 - val_accuracy: 0.7577\n",
      "Epoch 1265/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.8274 - val_loss: 0.6275 - val_accuracy: 0.7585\n",
      "Epoch 1266/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.8276 - val_loss: 0.6275 - val_accuracy: 0.7590\n",
      "Epoch 1267/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.8282 - val_loss: 0.6275 - val_accuracy: 0.7585\n",
      "Epoch 1268/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.8275 - val_loss: 0.6276 - val_accuracy: 0.7585\n",
      "Epoch 1269/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.8276 - val_loss: 0.6277 - val_accuracy: 0.7585\n",
      "Epoch 1270/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.8282 - val_loss: 0.6276 - val_accuracy: 0.7585\n",
      "Epoch 1271/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.8284 - val_loss: 0.6276 - val_accuracy: 0.7585\n",
      "Epoch 1272/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.8275 - val_loss: 0.6277 - val_accuracy: 0.7590\n",
      "Epoch 1273/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.8284 - val_loss: 0.6277 - val_accuracy: 0.7585\n",
      "Epoch 1274/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.8275 - val_loss: 0.6278 - val_accuracy: 0.7577\n",
      "Epoch 1275/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.8277 - val_loss: 0.6277 - val_accuracy: 0.7581\n",
      "Epoch 1276/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.8281 - val_loss: 0.6278 - val_accuracy: 0.7577\n",
      "Epoch 1277/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.8282 - val_loss: 0.6277 - val_accuracy: 0.7585\n",
      "Epoch 1278/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.8278 - val_loss: 0.6278 - val_accuracy: 0.7585\n",
      "Epoch 1279/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.8272 - val_loss: 0.6278 - val_accuracy: 0.7585\n",
      "Epoch 1280/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.8280 - val_loss: 0.6279 - val_accuracy: 0.7581\n",
      "Epoch 1281/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.8281 - val_loss: 0.6279 - val_accuracy: 0.7581\n",
      "Epoch 1282/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.8277 - val_loss: 0.6279 - val_accuracy: 0.7581\n",
      "Epoch 1283/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.8280 - val_loss: 0.6279 - val_accuracy: 0.7585\n",
      "Epoch 1284/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.8277 - val_loss: 0.6280 - val_accuracy: 0.7594\n",
      "Epoch 1285/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.8278 - val_loss: 0.6280 - val_accuracy: 0.7581\n",
      "Epoch 1286/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.8277 - val_loss: 0.6280 - val_accuracy: 0.7590\n",
      "Epoch 1287/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.8281 - val_loss: 0.6279 - val_accuracy: 0.7581\n",
      "Epoch 1288/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.8284 - val_loss: 0.6279 - val_accuracy: 0.7585\n",
      "Epoch 1289/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.8285 - val_loss: 0.6279 - val_accuracy: 0.7577\n",
      "Epoch 1290/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.8280 - val_loss: 0.6279 - val_accuracy: 0.7581\n",
      "Epoch 1291/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.8282 - val_loss: 0.6280 - val_accuracy: 0.7585\n",
      "Epoch 1292/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.8273 - val_loss: 0.6281 - val_accuracy: 0.7594\n",
      "Epoch 1293/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.8278 - val_loss: 0.6280 - val_accuracy: 0.7594\n",
      "Epoch 1294/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.8284 - val_loss: 0.6281 - val_accuracy: 0.7585\n",
      "Epoch 1295/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.8277 - val_loss: 0.6281 - val_accuracy: 0.7585\n",
      "Epoch 1296/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.8284 - val_loss: 0.6281 - val_accuracy: 0.7577\n",
      "Epoch 1297/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.8285 - val_loss: 0.6282 - val_accuracy: 0.7594\n",
      "Epoch 1298/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.8277 - val_loss: 0.6281 - val_accuracy: 0.7590\n",
      "Epoch 1299/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.8280 - val_loss: 0.6282 - val_accuracy: 0.7594\n",
      "Epoch 1300/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.8284 - val_loss: 0.6283 - val_accuracy: 0.7594\n",
      "Epoch 1301/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.8277 - val_loss: 0.6282 - val_accuracy: 0.7585\n",
      "Epoch 1302/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.8285 - val_loss: 0.6283 - val_accuracy: 0.7585\n",
      "Epoch 1303/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.8283 - val_loss: 0.6283 - val_accuracy: 0.7585\n",
      "Epoch 1304/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.8283 - val_loss: 0.6283 - val_accuracy: 0.7585\n",
      "Epoch 1305/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.8284 - val_loss: 0.6284 - val_accuracy: 0.7590\n",
      "Epoch 1306/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.8282 - val_loss: 0.6285 - val_accuracy: 0.7590\n",
      "Epoch 1307/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.8286 - val_loss: 0.6285 - val_accuracy: 0.7598\n",
      "Epoch 1308/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.8284 - val_loss: 0.6285 - val_accuracy: 0.7590\n",
      "Epoch 1309/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.8283 - val_loss: 0.6285 - val_accuracy: 0.7585\n",
      "Epoch 1310/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.8285 - val_loss: 0.6286 - val_accuracy: 0.7594\n",
      "Epoch 1311/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.8283 - val_loss: 0.6285 - val_accuracy: 0.7590\n",
      "Epoch 1312/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.8287 - val_loss: 0.6286 - val_accuracy: 0.7594\n",
      "Epoch 1313/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.8288 - val_loss: 0.6285 - val_accuracy: 0.7590\n",
      "Epoch 1314/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.8286 - val_loss: 0.6286 - val_accuracy: 0.7594\n",
      "Epoch 1315/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.8280 - val_loss: 0.6285 - val_accuracy: 0.7585\n",
      "Epoch 1316/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.8285 - val_loss: 0.6286 - val_accuracy: 0.7594\n",
      "Epoch 1317/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.8286 - val_loss: 0.6286 - val_accuracy: 0.7594\n",
      "Epoch 1318/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.8284 - val_loss: 0.6286 - val_accuracy: 0.7590\n",
      "Epoch 1319/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.8286 - val_loss: 0.6287 - val_accuracy: 0.7590\n",
      "Epoch 1320/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.8286 - val_loss: 0.6287 - val_accuracy: 0.7590\n",
      "Epoch 1321/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.8289 - val_loss: 0.6286 - val_accuracy: 0.7590\n",
      "Epoch 1322/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.8287 - val_loss: 0.6287 - val_accuracy: 0.7590\n",
      "Epoch 1323/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.8286 - val_loss: 0.6288 - val_accuracy: 0.7594\n",
      "Epoch 1324/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.8290 - val_loss: 0.6287 - val_accuracy: 0.7590\n",
      "Epoch 1325/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.8287 - val_loss: 0.6288 - val_accuracy: 0.7581\n",
      "Epoch 1326/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.8289 - val_loss: 0.6288 - val_accuracy: 0.7590\n",
      "Epoch 1327/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.8281 - val_loss: 0.6289 - val_accuracy: 0.7594\n",
      "Epoch 1328/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.8282 - val_loss: 0.6289 - val_accuracy: 0.7598\n",
      "Epoch 1329/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.8284 - val_loss: 0.6288 - val_accuracy: 0.7594\n",
      "Epoch 1330/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.8281 - val_loss: 0.6288 - val_accuracy: 0.7590\n",
      "Epoch 1331/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.8283 - val_loss: 0.6288 - val_accuracy: 0.7577\n",
      "Epoch 1332/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.8287 - val_loss: 0.6289 - val_accuracy: 0.7585\n",
      "Epoch 1333/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.8285 - val_loss: 0.6288 - val_accuracy: 0.7577\n",
      "Epoch 1334/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.8287 - val_loss: 0.6289 - val_accuracy: 0.7585\n",
      "Epoch 1335/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.8288 - val_loss: 0.6289 - val_accuracy: 0.7585\n",
      "Epoch 1336/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.8285 - val_loss: 0.6289 - val_accuracy: 0.7581\n",
      "Epoch 1337/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.8280 - val_loss: 0.6290 - val_accuracy: 0.7585\n",
      "Epoch 1338/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.8283 - val_loss: 0.6290 - val_accuracy: 0.7585\n",
      "Epoch 1339/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.8283 - val_loss: 0.6291 - val_accuracy: 0.7598\n",
      "Epoch 1340/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.8285 - val_loss: 0.6291 - val_accuracy: 0.7594\n",
      "Epoch 1341/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.8283 - val_loss: 0.6291 - val_accuracy: 0.7594\n",
      "Epoch 1342/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.8282 - val_loss: 0.6291 - val_accuracy: 0.7594\n",
      "Epoch 1343/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.8285 - val_loss: 0.6292 - val_accuracy: 0.7594\n",
      "Epoch 1344/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.8282 - val_loss: 0.6292 - val_accuracy: 0.7598\n",
      "Epoch 1345/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.8283 - val_loss: 0.6293 - val_accuracy: 0.7598\n",
      "Epoch 1346/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.8282 - val_loss: 0.6293 - val_accuracy: 0.7607\n",
      "Epoch 1347/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.8282 - val_loss: 0.6293 - val_accuracy: 0.7603\n",
      "Epoch 1348/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.8286 - val_loss: 0.6294 - val_accuracy: 0.7603\n",
      "Epoch 1349/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.8286 - val_loss: 0.6294 - val_accuracy: 0.7607\n",
      "Epoch 1350/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.8287 - val_loss: 0.6293 - val_accuracy: 0.7594\n",
      "Epoch 1351/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.8285 - val_loss: 0.6293 - val_accuracy: 0.7603\n",
      "Epoch 1352/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.8288 - val_loss: 0.6293 - val_accuracy: 0.7603\n",
      "Epoch 1353/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.8287 - val_loss: 0.6294 - val_accuracy: 0.7594\n",
      "Epoch 1354/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.8285 - val_loss: 0.6295 - val_accuracy: 0.7598\n",
      "Epoch 1355/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.8286 - val_loss: 0.6295 - val_accuracy: 0.7590\n",
      "Epoch 1356/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.8288 - val_loss: 0.6295 - val_accuracy: 0.7577\n",
      "Epoch 1357/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.8289 - val_loss: 0.6296 - val_accuracy: 0.7594\n",
      "Epoch 1358/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.8288 - val_loss: 0.6296 - val_accuracy: 0.7594\n",
      "Epoch 1359/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.8293 - val_loss: 0.6296 - val_accuracy: 0.7590\n",
      "Epoch 1360/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.8291 - val_loss: 0.6296 - val_accuracy: 0.7590\n",
      "Epoch 1361/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.8287 - val_loss: 0.6297 - val_accuracy: 0.7594\n",
      "Epoch 1362/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.8290 - val_loss: 0.6297 - val_accuracy: 0.7594\n",
      "Epoch 1363/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.8287 - val_loss: 0.6296 - val_accuracy: 0.7594\n",
      "Epoch 1364/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.8289 - val_loss: 0.6297 - val_accuracy: 0.7590\n",
      "Epoch 1365/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.8291 - val_loss: 0.6298 - val_accuracy: 0.7581\n",
      "Epoch 1366/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.8292 - val_loss: 0.6298 - val_accuracy: 0.7581\n",
      "Epoch 1367/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.8287 - val_loss: 0.6298 - val_accuracy: 0.7581\n",
      "Epoch 1368/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.8295 - val_loss: 0.6297 - val_accuracy: 0.7585\n",
      "Epoch 1369/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.8295 - val_loss: 0.6298 - val_accuracy: 0.7585\n",
      "Epoch 1370/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.8292 - val_loss: 0.6298 - val_accuracy: 0.7581\n",
      "Epoch 1371/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.8291 - val_loss: 0.6298 - val_accuracy: 0.7585\n",
      "Epoch 1372/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.8289 - val_loss: 0.6298 - val_accuracy: 0.7594\n",
      "Epoch 1373/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.8292 - val_loss: 0.6298 - val_accuracy: 0.7577\n",
      "Epoch 1374/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.8296 - val_loss: 0.6298 - val_accuracy: 0.7581\n",
      "Epoch 1375/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.8296 - val_loss: 0.6298 - val_accuracy: 0.7581\n",
      "Epoch 1376/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.8295 - val_loss: 0.6298 - val_accuracy: 0.7577\n",
      "Epoch 1377/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.8292 - val_loss: 0.6298 - val_accuracy: 0.7577\n",
      "Epoch 1378/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.8297 - val_loss: 0.6299 - val_accuracy: 0.7581\n",
      "Epoch 1379/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.8296 - val_loss: 0.6299 - val_accuracy: 0.7581\n",
      "Epoch 1380/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.8296 - val_loss: 0.6299 - val_accuracy: 0.7581\n",
      "Epoch 1381/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.8292 - val_loss: 0.6299 - val_accuracy: 0.7581\n",
      "Epoch 1382/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.8293 - val_loss: 0.6300 - val_accuracy: 0.7581\n",
      "Epoch 1383/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.8296 - val_loss: 0.6299 - val_accuracy: 0.7585\n",
      "Epoch 1384/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.8298 - val_loss: 0.6299 - val_accuracy: 0.7577\n",
      "Epoch 1385/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.8292 - val_loss: 0.6300 - val_accuracy: 0.7581\n",
      "Epoch 1386/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.8300 - val_loss: 0.6300 - val_accuracy: 0.7581\n",
      "Epoch 1387/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.8292 - val_loss: 0.6301 - val_accuracy: 0.7581\n",
      "Epoch 1388/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.8296 - val_loss: 0.6301 - val_accuracy: 0.7585\n",
      "Epoch 1389/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.8293 - val_loss: 0.6299 - val_accuracy: 0.7581\n",
      "Epoch 1390/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.8295 - val_loss: 0.6300 - val_accuracy: 0.7581\n",
      "Epoch 1391/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.8297 - val_loss: 0.6300 - val_accuracy: 0.7577\n",
      "Epoch 1392/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.8299 - val_loss: 0.6300 - val_accuracy: 0.7577\n",
      "Epoch 1393/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.8296 - val_loss: 0.6300 - val_accuracy: 0.7577\n",
      "Epoch 1394/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.8298 - val_loss: 0.6300 - val_accuracy: 0.7577\n",
      "Epoch 1395/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.8295 - val_loss: 0.6301 - val_accuracy: 0.7577\n",
      "Epoch 1396/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.8296 - val_loss: 0.6302 - val_accuracy: 0.7577\n",
      "Epoch 1397/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.8295 - val_loss: 0.6302 - val_accuracy: 0.7577\n",
      "Epoch 1398/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.8292 - val_loss: 0.6301 - val_accuracy: 0.7573\n",
      "Epoch 1399/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.8298 - val_loss: 0.6302 - val_accuracy: 0.7577\n",
      "Epoch 1400/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.8290 - val_loss: 0.6302 - val_accuracy: 0.7577\n",
      "Epoch 1401/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.8296 - val_loss: 0.6303 - val_accuracy: 0.7577\n",
      "Epoch 1402/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.8289 - val_loss: 0.6302 - val_accuracy: 0.7568\n",
      "Epoch 1403/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.8293 - val_loss: 0.6302 - val_accuracy: 0.7568\n",
      "Epoch 1404/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.8300 - val_loss: 0.6304 - val_accuracy: 0.7577\n",
      "Epoch 1405/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.8299 - val_loss: 0.6303 - val_accuracy: 0.7568\n",
      "Epoch 1406/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.8299 - val_loss: 0.6304 - val_accuracy: 0.7568\n",
      "Epoch 1407/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.8297 - val_loss: 0.6304 - val_accuracy: 0.7568\n",
      "Epoch 1408/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.8297 - val_loss: 0.6304 - val_accuracy: 0.7568\n",
      "Epoch 1409/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.8295 - val_loss: 0.6304 - val_accuracy: 0.7568\n",
      "Epoch 1410/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.8297 - val_loss: 0.6304 - val_accuracy: 0.7568\n",
      "Epoch 1411/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.8297 - val_loss: 0.6306 - val_accuracy: 0.7568\n",
      "Epoch 1412/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.8298 - val_loss: 0.6305 - val_accuracy: 0.7568\n",
      "Epoch 1413/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.8293 - val_loss: 0.6305 - val_accuracy: 0.7564\n",
      "Epoch 1414/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.8296 - val_loss: 0.6305 - val_accuracy: 0.7564\n",
      "Epoch 1415/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.8301 - val_loss: 0.6306 - val_accuracy: 0.7568\n",
      "Epoch 1416/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.8296 - val_loss: 0.6306 - val_accuracy: 0.7564\n",
      "Epoch 1417/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.8295 - val_loss: 0.6307 - val_accuracy: 0.7564\n",
      "Epoch 1418/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.8299 - val_loss: 0.6307 - val_accuracy: 0.7564\n",
      "Epoch 1419/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.8298 - val_loss: 0.6307 - val_accuracy: 0.7564\n",
      "Epoch 1420/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.8302 - val_loss: 0.6307 - val_accuracy: 0.7564\n",
      "Epoch 1421/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.8304 - val_loss: 0.6308 - val_accuracy: 0.7560\n",
      "Epoch 1422/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.8302 - val_loss: 0.6308 - val_accuracy: 0.7560\n",
      "Epoch 1423/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.8301 - val_loss: 0.6307 - val_accuracy: 0.7560\n",
      "Epoch 1424/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.8302 - val_loss: 0.6307 - val_accuracy: 0.7560\n",
      "Epoch 1425/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.8303 - val_loss: 0.6308 - val_accuracy: 0.7564\n",
      "Epoch 1426/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.8301 - val_loss: 0.6308 - val_accuracy: 0.7560\n",
      "Epoch 1427/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.8301 - val_loss: 0.6309 - val_accuracy: 0.7564\n",
      "Epoch 1428/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.8304 - val_loss: 0.6309 - val_accuracy: 0.7560\n",
      "Epoch 1429/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.8296 - val_loss: 0.6309 - val_accuracy: 0.7560\n",
      "Epoch 1430/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.8300 - val_loss: 0.6310 - val_accuracy: 0.7560\n",
      "Epoch 1431/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.8299 - val_loss: 0.6310 - val_accuracy: 0.7560\n",
      "Epoch 1432/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.8299 - val_loss: 0.6310 - val_accuracy: 0.7560\n",
      "Epoch 1433/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.8306 - val_loss: 0.6310 - val_accuracy: 0.7564\n",
      "Epoch 1434/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.8303 - val_loss: 0.6311 - val_accuracy: 0.7573\n",
      "Epoch 1435/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.8307 - val_loss: 0.6310 - val_accuracy: 0.7568\n",
      "Epoch 1436/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.8304 - val_loss: 0.6311 - val_accuracy: 0.7560\n",
      "Epoch 1437/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.8300 - val_loss: 0.6310 - val_accuracy: 0.7564\n",
      "Epoch 1438/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.8306 - val_loss: 0.6311 - val_accuracy: 0.7560\n",
      "Epoch 1439/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.8298 - val_loss: 0.6311 - val_accuracy: 0.7564\n",
      "Epoch 1440/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.8302 - val_loss: 0.6312 - val_accuracy: 0.7556\n",
      "Epoch 1441/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.8300 - val_loss: 0.6312 - val_accuracy: 0.7564\n",
      "Epoch 1442/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.8300 - val_loss: 0.6312 - val_accuracy: 0.7564\n",
      "Epoch 1443/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.8300 - val_loss: 0.6312 - val_accuracy: 0.7568\n",
      "Epoch 1444/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.8300 - val_loss: 0.6313 - val_accuracy: 0.7568\n",
      "Epoch 1445/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.8309 - val_loss: 0.6313 - val_accuracy: 0.7573\n",
      "Epoch 1446/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.8307 - val_loss: 0.6314 - val_accuracy: 0.7573\n",
      "Epoch 1447/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.8309 - val_loss: 0.6314 - val_accuracy: 0.7577\n",
      "Epoch 1448/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.8309 - val_loss: 0.6314 - val_accuracy: 0.7564\n",
      "Epoch 1449/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.8304 - val_loss: 0.6314 - val_accuracy: 0.7564\n",
      "Epoch 1450/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.8302 - val_loss: 0.6315 - val_accuracy: 0.7564\n",
      "Epoch 1451/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.8301 - val_loss: 0.6315 - val_accuracy: 0.7573\n",
      "Epoch 1452/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.8305 - val_loss: 0.6315 - val_accuracy: 0.7573\n",
      "Epoch 1453/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.8306 - val_loss: 0.6315 - val_accuracy: 0.7568\n",
      "Epoch 1454/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.8301 - val_loss: 0.6316 - val_accuracy: 0.7564\n",
      "Epoch 1455/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.8306 - val_loss: 0.6316 - val_accuracy: 0.7568\n",
      "Epoch 1456/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.8306 - val_loss: 0.6316 - val_accuracy: 0.7568\n",
      "Epoch 1457/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.8308 - val_loss: 0.6317 - val_accuracy: 0.7573\n",
      "Epoch 1458/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.8305 - val_loss: 0.6316 - val_accuracy: 0.7568\n",
      "Epoch 1459/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.8307 - val_loss: 0.6316 - val_accuracy: 0.7568\n",
      "Epoch 1460/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.8309 - val_loss: 0.6317 - val_accuracy: 0.7564\n",
      "Epoch 1461/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.8309 - val_loss: 0.6317 - val_accuracy: 0.7568\n",
      "Epoch 1462/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.8312 - val_loss: 0.6318 - val_accuracy: 0.7568\n",
      "Epoch 1463/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.8306 - val_loss: 0.6318 - val_accuracy: 0.7568\n",
      "Epoch 1464/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.8308 - val_loss: 0.6318 - val_accuracy: 0.7573\n",
      "Epoch 1465/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.8306 - val_loss: 0.6318 - val_accuracy: 0.7568\n",
      "Epoch 1466/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.8305 - val_loss: 0.6318 - val_accuracy: 0.7573\n",
      "Epoch 1467/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.8305 - val_loss: 0.6319 - val_accuracy: 0.7573\n",
      "Epoch 1468/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.8309 - val_loss: 0.6319 - val_accuracy: 0.7573\n",
      "Epoch 1469/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.8308 - val_loss: 0.6320 - val_accuracy: 0.7573\n",
      "Epoch 1470/2000\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.4570 - accuracy: 0.8312 - val_loss: 0.6320 - val_accuracy: 0.7573\n",
      "Epoch 1471/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.8311 - val_loss: 0.6320 - val_accuracy: 0.7564\n",
      "Epoch 1472/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 0s 3ms/step - loss: 0.4569 - accuracy: 0.8307 - val_loss: 0.6319 - val_accuracy: 0.7568\n",
      "Epoch 1473/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.8307 - val_loss: 0.6320 - val_accuracy: 0.7568\n",
      "Epoch 1474/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.8306 - val_loss: 0.6320 - val_accuracy: 0.7568\n",
      "Epoch 1475/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.8309 - val_loss: 0.6321 - val_accuracy: 0.7568\n",
      "Epoch 1476/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.8311 - val_loss: 0.6321 - val_accuracy: 0.7568\n",
      "Epoch 1477/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.8312 - val_loss: 0.6321 - val_accuracy: 0.7568\n",
      "Epoch 1478/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.8311 - val_loss: 0.6321 - val_accuracy: 0.7568\n",
      "Epoch 1479/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.8311 - val_loss: 0.6321 - val_accuracy: 0.7564\n",
      "Epoch 1480/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.8311 - val_loss: 0.6321 - val_accuracy: 0.7568\n",
      "Epoch 1481/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.8311 - val_loss: 0.6322 - val_accuracy: 0.7573\n",
      "Epoch 1482/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.8309 - val_loss: 0.6321 - val_accuracy: 0.7568\n",
      "Epoch 1483/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.8306 - val_loss: 0.6321 - val_accuracy: 0.7564\n",
      "Epoch 1484/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.8308 - val_loss: 0.6322 - val_accuracy: 0.7568\n",
      "Epoch 1485/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.8307 - val_loss: 0.6322 - val_accuracy: 0.7568\n",
      "Epoch 1486/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.8311 - val_loss: 0.6322 - val_accuracy: 0.7568\n",
      "Epoch 1487/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.8312 - val_loss: 0.6323 - val_accuracy: 0.7568\n",
      "Epoch 1488/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.8313 - val_loss: 0.6323 - val_accuracy: 0.7568\n",
      "Epoch 1489/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.8309 - val_loss: 0.6323 - val_accuracy: 0.7564\n",
      "Epoch 1490/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.8315 - val_loss: 0.6325 - val_accuracy: 0.7564\n",
      "Epoch 1491/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.8312 - val_loss: 0.6324 - val_accuracy: 0.7568\n",
      "Epoch 1492/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.8308 - val_loss: 0.6324 - val_accuracy: 0.7568\n",
      "Epoch 1493/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.8313 - val_loss: 0.6325 - val_accuracy: 0.7568\n",
      "Epoch 1494/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.8308 - val_loss: 0.6324 - val_accuracy: 0.7568\n",
      "Epoch 1495/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.8311 - val_loss: 0.6325 - val_accuracy: 0.7568\n",
      "Epoch 1496/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.8312 - val_loss: 0.6325 - val_accuracy: 0.7564\n",
      "Epoch 1497/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.8307 - val_loss: 0.6325 - val_accuracy: 0.7560\n",
      "Epoch 1498/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.8314 - val_loss: 0.6325 - val_accuracy: 0.7564\n",
      "Epoch 1499/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.8313 - val_loss: 0.6325 - val_accuracy: 0.7564\n",
      "Epoch 1500/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.8312 - val_loss: 0.6325 - val_accuracy: 0.7564\n",
      "Epoch 1501/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.8308 - val_loss: 0.6326 - val_accuracy: 0.7564\n",
      "Epoch 1502/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.8313 - val_loss: 0.6325 - val_accuracy: 0.7564\n",
      "Epoch 1503/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.8309 - val_loss: 0.6326 - val_accuracy: 0.7568\n",
      "Epoch 1504/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.8309 - val_loss: 0.6326 - val_accuracy: 0.7564\n",
      "Epoch 1505/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.8309 - val_loss: 0.6327 - val_accuracy: 0.7564\n",
      "Epoch 1506/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.8316 - val_loss: 0.6327 - val_accuracy: 0.7568\n",
      "Epoch 1507/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.8308 - val_loss: 0.6327 - val_accuracy: 0.7560\n",
      "Epoch 1508/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.8309 - val_loss: 0.6328 - val_accuracy: 0.7564\n",
      "Epoch 1509/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.8313 - val_loss: 0.6328 - val_accuracy: 0.7564\n",
      "Epoch 1510/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.8311 - val_loss: 0.6328 - val_accuracy: 0.7560\n",
      "Epoch 1511/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.8308 - val_loss: 0.6329 - val_accuracy: 0.7564\n",
      "Epoch 1512/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.8309 - val_loss: 0.6329 - val_accuracy: 0.7564\n",
      "Epoch 1513/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.8312 - val_loss: 0.6329 - val_accuracy: 0.7564\n",
      "Epoch 1514/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.8312 - val_loss: 0.6329 - val_accuracy: 0.7560\n",
      "Epoch 1515/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.8304 - val_loss: 0.6330 - val_accuracy: 0.7560\n",
      "Epoch 1516/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.8314 - val_loss: 0.6330 - val_accuracy: 0.7560\n",
      "Epoch 1517/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.8309 - val_loss: 0.6330 - val_accuracy: 0.7556\n",
      "Epoch 1518/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.8309 - val_loss: 0.6330 - val_accuracy: 0.7560\n",
      "Epoch 1519/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.8307 - val_loss: 0.6330 - val_accuracy: 0.7560\n",
      "Epoch 1520/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.8307 - val_loss: 0.6331 - val_accuracy: 0.7560\n",
      "Epoch 1521/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.8306 - val_loss: 0.6331 - val_accuracy: 0.7556\n",
      "Epoch 1522/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.8313 - val_loss: 0.6332 - val_accuracy: 0.7560\n",
      "Epoch 1523/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.8306 - val_loss: 0.6331 - val_accuracy: 0.7560\n",
      "Epoch 1524/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.8305 - val_loss: 0.6331 - val_accuracy: 0.7564\n",
      "Epoch 1525/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.8309 - val_loss: 0.6332 - val_accuracy: 0.7560\n",
      "Epoch 1526/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.8308 - val_loss: 0.6333 - val_accuracy: 0.7568\n",
      "Epoch 1527/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.8311 - val_loss: 0.6333 - val_accuracy: 0.7556\n",
      "Epoch 1528/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.8316 - val_loss: 0.6333 - val_accuracy: 0.7560\n",
      "Epoch 1529/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.8313 - val_loss: 0.6332 - val_accuracy: 0.7573\n",
      "Epoch 1530/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.8315 - val_loss: 0.6333 - val_accuracy: 0.7564\n",
      "Epoch 1531/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.8315 - val_loss: 0.6333 - val_accuracy: 0.7564\n",
      "Epoch 1532/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.8311 - val_loss: 0.6334 - val_accuracy: 0.7560\n",
      "Epoch 1533/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.8311 - val_loss: 0.6335 - val_accuracy: 0.7560\n",
      "Epoch 1534/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.8319 - val_loss: 0.6335 - val_accuracy: 0.7568\n",
      "Epoch 1535/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.8315 - val_loss: 0.6335 - val_accuracy: 0.7564\n",
      "Epoch 1536/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.8314 - val_loss: 0.6335 - val_accuracy: 0.7564\n",
      "Epoch 1537/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.8315 - val_loss: 0.6335 - val_accuracy: 0.7568\n",
      "Epoch 1538/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.8316 - val_loss: 0.6336 - val_accuracy: 0.7568\n",
      "Epoch 1539/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.8312 - val_loss: 0.6335 - val_accuracy: 0.7573\n",
      "Epoch 1540/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.8311 - val_loss: 0.6335 - val_accuracy: 0.7568\n",
      "Epoch 1541/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.8315 - val_loss: 0.6336 - val_accuracy: 0.7573\n",
      "Epoch 1542/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.8316 - val_loss: 0.6336 - val_accuracy: 0.7573\n",
      "Epoch 1543/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.8314 - val_loss: 0.6337 - val_accuracy: 0.7568\n",
      "Epoch 1544/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.8317 - val_loss: 0.6337 - val_accuracy: 0.7568\n",
      "Epoch 1545/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.8317 - val_loss: 0.6337 - val_accuracy: 0.7568\n",
      "Epoch 1546/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.8313 - val_loss: 0.6338 - val_accuracy: 0.7564\n",
      "Epoch 1547/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.8316 - val_loss: 0.6337 - val_accuracy: 0.7564\n",
      "Epoch 1548/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.8313 - val_loss: 0.6336 - val_accuracy: 0.7564\n",
      "Epoch 1549/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.8316 - val_loss: 0.6337 - val_accuracy: 0.7564\n",
      "Epoch 1550/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.8319 - val_loss: 0.6337 - val_accuracy: 0.7564\n",
      "Epoch 1551/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.8317 - val_loss: 0.6339 - val_accuracy: 0.7564\n",
      "Epoch 1552/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.8314 - val_loss: 0.6339 - val_accuracy: 0.7564\n",
      "Epoch 1553/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.8315 - val_loss: 0.6340 - val_accuracy: 0.7568\n",
      "Epoch 1554/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.8316 - val_loss: 0.6339 - val_accuracy: 0.7577\n",
      "Epoch 1555/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.8322 - val_loss: 0.6339 - val_accuracy: 0.7564\n",
      "Epoch 1556/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.8317 - val_loss: 0.6339 - val_accuracy: 0.7568\n",
      "Epoch 1557/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.8313 - val_loss: 0.6338 - val_accuracy: 0.7573\n",
      "Epoch 1558/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.8315 - val_loss: 0.6339 - val_accuracy: 0.7564\n",
      "Epoch 1559/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.8317 - val_loss: 0.6340 - val_accuracy: 0.7568\n",
      "Epoch 1560/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.8317 - val_loss: 0.6340 - val_accuracy: 0.7564\n",
      "Epoch 1561/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.8317 - val_loss: 0.6340 - val_accuracy: 0.7564\n",
      "Epoch 1562/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.8313 - val_loss: 0.6340 - val_accuracy: 0.7564\n",
      "Epoch 1563/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.8313 - val_loss: 0.6341 - val_accuracy: 0.7564\n",
      "Epoch 1564/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.8315 - val_loss: 0.6341 - val_accuracy: 0.7560\n",
      "Epoch 1565/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.8315 - val_loss: 0.6341 - val_accuracy: 0.7564\n",
      "Epoch 1566/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.8320 - val_loss: 0.6342 - val_accuracy: 0.7556\n",
      "Epoch 1567/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.8317 - val_loss: 0.6342 - val_accuracy: 0.7556\n",
      "Epoch 1568/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.8316 - val_loss: 0.6342 - val_accuracy: 0.7564\n",
      "Epoch 1569/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.8316 - val_loss: 0.6342 - val_accuracy: 0.7564\n",
      "Epoch 1570/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.8311 - val_loss: 0.6342 - val_accuracy: 0.7556\n",
      "Epoch 1571/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.8315 - val_loss: 0.6343 - val_accuracy: 0.7556\n",
      "Epoch 1572/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.8317 - val_loss: 0.6343 - val_accuracy: 0.7556\n",
      "Epoch 1573/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.8317 - val_loss: 0.6343 - val_accuracy: 0.7577\n",
      "Epoch 1574/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.8315 - val_loss: 0.6343 - val_accuracy: 0.7568\n",
      "Epoch 1575/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.8313 - val_loss: 0.6343 - val_accuracy: 0.7573\n",
      "Epoch 1576/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.8315 - val_loss: 0.6344 - val_accuracy: 0.7573\n",
      "Epoch 1577/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.8317 - val_loss: 0.6344 - val_accuracy: 0.7568\n",
      "Epoch 1578/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.8314 - val_loss: 0.6344 - val_accuracy: 0.7568\n",
      "Epoch 1579/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.8320 - val_loss: 0.6344 - val_accuracy: 0.7564\n",
      "Epoch 1580/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.8315 - val_loss: 0.6345 - val_accuracy: 0.7564\n",
      "Epoch 1581/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.8314 - val_loss: 0.6345 - val_accuracy: 0.7564\n",
      "Epoch 1582/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.8317 - val_loss: 0.6345 - val_accuracy: 0.7564\n",
      "Epoch 1583/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.8316 - val_loss: 0.6344 - val_accuracy: 0.7573\n",
      "Epoch 1584/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.8316 - val_loss: 0.6345 - val_accuracy: 0.7560\n",
      "Epoch 1585/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.8314 - val_loss: 0.6347 - val_accuracy: 0.7564\n",
      "Epoch 1586/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.8309 - val_loss: 0.6347 - val_accuracy: 0.7573\n",
      "Epoch 1587/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.8315 - val_loss: 0.6347 - val_accuracy: 0.7564\n",
      "Epoch 1588/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.8309 - val_loss: 0.6347 - val_accuracy: 0.7564\n",
      "Epoch 1589/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.8314 - val_loss: 0.6347 - val_accuracy: 0.7564\n",
      "Epoch 1590/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.8315 - val_loss: 0.6348 - val_accuracy: 0.7573\n",
      "Epoch 1591/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.8317 - val_loss: 0.6346 - val_accuracy: 0.7568\n",
      "Epoch 1592/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.8312 - val_loss: 0.6348 - val_accuracy: 0.7573\n",
      "Epoch 1593/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.8318 - val_loss: 0.6348 - val_accuracy: 0.7573\n",
      "Epoch 1594/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.8315 - val_loss: 0.6348 - val_accuracy: 0.7568\n",
      "Epoch 1595/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.8309 - val_loss: 0.6348 - val_accuracy: 0.7573\n",
      "Epoch 1596/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.8318 - val_loss: 0.6348 - val_accuracy: 0.7573\n",
      "Epoch 1597/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.8322 - val_loss: 0.6348 - val_accuracy: 0.7573\n",
      "Epoch 1598/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.8315 - val_loss: 0.6348 - val_accuracy: 0.7585\n",
      "Epoch 1599/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.8317 - val_loss: 0.6349 - val_accuracy: 0.7581\n",
      "Epoch 1600/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.8317 - val_loss: 0.6349 - val_accuracy: 0.7581\n",
      "Epoch 1601/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.8317 - val_loss: 0.6350 - val_accuracy: 0.7581\n",
      "Epoch 1602/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.8316 - val_loss: 0.6349 - val_accuracy: 0.7577\n",
      "Epoch 1603/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.8318 - val_loss: 0.6350 - val_accuracy: 0.7568\n",
      "Epoch 1604/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.8316 - val_loss: 0.6350 - val_accuracy: 0.7573\n",
      "Epoch 1605/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.8318 - val_loss: 0.6349 - val_accuracy: 0.7568\n",
      "Epoch 1606/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.8315 - val_loss: 0.6350 - val_accuracy: 0.7568\n",
      "Epoch 1607/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.8318 - val_loss: 0.6351 - val_accuracy: 0.7568\n",
      "Epoch 1608/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.8320 - val_loss: 0.6351 - val_accuracy: 0.7564\n",
      "Epoch 1609/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.8321 - val_loss: 0.6352 - val_accuracy: 0.7568\n",
      "Epoch 1610/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.8320 - val_loss: 0.6351 - val_accuracy: 0.7564\n",
      "Epoch 1611/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.8318 - val_loss: 0.6352 - val_accuracy: 0.7564\n",
      "Epoch 1612/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.8320 - val_loss: 0.6353 - val_accuracy: 0.7564\n",
      "Epoch 1613/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.8322 - val_loss: 0.6353 - val_accuracy: 0.7568\n",
      "Epoch 1614/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.8315 - val_loss: 0.6353 - val_accuracy: 0.7568\n",
      "Epoch 1615/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.8318 - val_loss: 0.6352 - val_accuracy: 0.7573\n",
      "Epoch 1616/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.8322 - val_loss: 0.6353 - val_accuracy: 0.7577\n",
      "Epoch 1617/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.8320 - val_loss: 0.6354 - val_accuracy: 0.7564\n",
      "Epoch 1618/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.8320 - val_loss: 0.6354 - val_accuracy: 0.7573\n",
      "Epoch 1619/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.8318 - val_loss: 0.6354 - val_accuracy: 0.7577\n",
      "Epoch 1620/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.8318 - val_loss: 0.6354 - val_accuracy: 0.7577\n",
      "Epoch 1621/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.8318 - val_loss: 0.6354 - val_accuracy: 0.7577\n",
      "Epoch 1622/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.8321 - val_loss: 0.6354 - val_accuracy: 0.7577\n",
      "Epoch 1623/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.8317 - val_loss: 0.6355 - val_accuracy: 0.7577\n",
      "Epoch 1624/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.8321 - val_loss: 0.6355 - val_accuracy: 0.7581\n",
      "Epoch 1625/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.8316 - val_loss: 0.6356 - val_accuracy: 0.7577\n",
      "Epoch 1626/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.8317 - val_loss: 0.6356 - val_accuracy: 0.7581\n",
      "Epoch 1627/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.8322 - val_loss: 0.6356 - val_accuracy: 0.7577\n",
      "Epoch 1628/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.8319 - val_loss: 0.6356 - val_accuracy: 0.7581\n",
      "Epoch 1629/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4514 - accuracy: 0.8317 - val_loss: 0.6356 - val_accuracy: 0.7577\n",
      "Epoch 1630/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4514 - accuracy: 0.8320 - val_loss: 0.6356 - val_accuracy: 0.7577\n",
      "Epoch 1631/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4514 - accuracy: 0.8320 - val_loss: 0.6357 - val_accuracy: 0.7577\n",
      "Epoch 1632/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4514 - accuracy: 0.8319 - val_loss: 0.6356 - val_accuracy: 0.7577\n",
      "Epoch 1633/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.8322 - val_loss: 0.6357 - val_accuracy: 0.7573\n",
      "Epoch 1634/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.8323 - val_loss: 0.6358 - val_accuracy: 0.7568\n",
      "Epoch 1635/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.8323 - val_loss: 0.6358 - val_accuracy: 0.7573\n",
      "Epoch 1636/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.8323 - val_loss: 0.6358 - val_accuracy: 0.7568\n",
      "Epoch 1637/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.8319 - val_loss: 0.6357 - val_accuracy: 0.7577\n",
      "Epoch 1638/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.8321 - val_loss: 0.6359 - val_accuracy: 0.7573\n",
      "Epoch 1639/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.8323 - val_loss: 0.6358 - val_accuracy: 0.7577\n",
      "Epoch 1640/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.8323 - val_loss: 0.6358 - val_accuracy: 0.7577\n",
      "Epoch 1641/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.8321 - val_loss: 0.6359 - val_accuracy: 0.7568\n",
      "Epoch 1642/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.8321 - val_loss: 0.6358 - val_accuracy: 0.7573\n",
      "Epoch 1643/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.8322 - val_loss: 0.6358 - val_accuracy: 0.7573\n",
      "Epoch 1644/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.8323 - val_loss: 0.6359 - val_accuracy: 0.7577\n",
      "Epoch 1645/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.8328 - val_loss: 0.6359 - val_accuracy: 0.7577\n",
      "Epoch 1646/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.8327 - val_loss: 0.6359 - val_accuracy: 0.7577\n",
      "Epoch 1647/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.8320 - val_loss: 0.6360 - val_accuracy: 0.7577\n",
      "Epoch 1648/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.8324 - val_loss: 0.6360 - val_accuracy: 0.7577\n",
      "Epoch 1649/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.8327 - val_loss: 0.6361 - val_accuracy: 0.7573\n",
      "Epoch 1650/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.8318 - val_loss: 0.6359 - val_accuracy: 0.7577\n",
      "Epoch 1651/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.8323 - val_loss: 0.6360 - val_accuracy: 0.7577\n",
      "Epoch 1652/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.8327 - val_loss: 0.6360 - val_accuracy: 0.7573\n",
      "Epoch 1653/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.8323 - val_loss: 0.6361 - val_accuracy: 0.7568\n",
      "Epoch 1654/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.8328 - val_loss: 0.6361 - val_accuracy: 0.7573\n",
      "Epoch 1655/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.8321 - val_loss: 0.6361 - val_accuracy: 0.7568\n",
      "Epoch 1656/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.8323 - val_loss: 0.6361 - val_accuracy: 0.7577\n",
      "Epoch 1657/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.8327 - val_loss: 0.6362 - val_accuracy: 0.7568\n",
      "Epoch 1658/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.8325 - val_loss: 0.6362 - val_accuracy: 0.7568\n",
      "Epoch 1659/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.8320 - val_loss: 0.6362 - val_accuracy: 0.7568\n",
      "Epoch 1660/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.8323 - val_loss: 0.6362 - val_accuracy: 0.7568\n",
      "Epoch 1661/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.8322 - val_loss: 0.6362 - val_accuracy: 0.7568\n",
      "Epoch 1662/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.8325 - val_loss: 0.6362 - val_accuracy: 0.7573\n",
      "Epoch 1663/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.8321 - val_loss: 0.6362 - val_accuracy: 0.7573\n",
      "Epoch 1664/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.8324 - val_loss: 0.6362 - val_accuracy: 0.7573\n",
      "Epoch 1665/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.8327 - val_loss: 0.6362 - val_accuracy: 0.7573\n",
      "Epoch 1666/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.8327 - val_loss: 0.6363 - val_accuracy: 0.7568\n",
      "Epoch 1667/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.8324 - val_loss: 0.6363 - val_accuracy: 0.7581\n",
      "Epoch 1668/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.8324 - val_loss: 0.6363 - val_accuracy: 0.7581\n",
      "Epoch 1669/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.8330 - val_loss: 0.6363 - val_accuracy: 0.7577\n",
      "Epoch 1670/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.8328 - val_loss: 0.6364 - val_accuracy: 0.7581\n",
      "Epoch 1671/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.8324 - val_loss: 0.6364 - val_accuracy: 0.7577\n",
      "Epoch 1672/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.8329 - val_loss: 0.6363 - val_accuracy: 0.7581\n",
      "Epoch 1673/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.8330 - val_loss: 0.6365 - val_accuracy: 0.7581\n",
      "Epoch 1674/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.8329 - val_loss: 0.6365 - val_accuracy: 0.7585\n",
      "Epoch 1675/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.8327 - val_loss: 0.6364 - val_accuracy: 0.7581\n",
      "Epoch 1676/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.8332 - val_loss: 0.6364 - val_accuracy: 0.7581\n",
      "Epoch 1677/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.8332 - val_loss: 0.6365 - val_accuracy: 0.7585\n",
      "Epoch 1678/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.8331 - val_loss: 0.6365 - val_accuracy: 0.7585\n",
      "Epoch 1679/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.8330 - val_loss: 0.6365 - val_accuracy: 0.7585\n",
      "Epoch 1680/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.8330 - val_loss: 0.6365 - val_accuracy: 0.7585\n",
      "Epoch 1681/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.8328 - val_loss: 0.6366 - val_accuracy: 0.7585\n",
      "Epoch 1682/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.8329 - val_loss: 0.6365 - val_accuracy: 0.7585\n",
      "Epoch 1683/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.8325 - val_loss: 0.6367 - val_accuracy: 0.7581\n",
      "Epoch 1684/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.8330 - val_loss: 0.6366 - val_accuracy: 0.7577\n",
      "Epoch 1685/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.8328 - val_loss: 0.6366 - val_accuracy: 0.7577\n",
      "Epoch 1686/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.8328 - val_loss: 0.6367 - val_accuracy: 0.7581\n",
      "Epoch 1687/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.8325 - val_loss: 0.6368 - val_accuracy: 0.7577\n",
      "Epoch 1688/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.8325 - val_loss: 0.6369 - val_accuracy: 0.7590\n",
      "Epoch 1689/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.8328 - val_loss: 0.6368 - val_accuracy: 0.7573\n",
      "Epoch 1690/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.8330 - val_loss: 0.6368 - val_accuracy: 0.7577\n",
      "Epoch 1691/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.8324 - val_loss: 0.6368 - val_accuracy: 0.7581\n",
      "Epoch 1692/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.8331 - val_loss: 0.6368 - val_accuracy: 0.7581\n",
      "Epoch 1693/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.8328 - val_loss: 0.6369 - val_accuracy: 0.7581\n",
      "Epoch 1694/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.8323 - val_loss: 0.6369 - val_accuracy: 0.7577\n",
      "Epoch 1695/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.8329 - val_loss: 0.6369 - val_accuracy: 0.7577\n",
      "Epoch 1696/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.8327 - val_loss: 0.6369 - val_accuracy: 0.7568\n",
      "Epoch 1697/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.8329 - val_loss: 0.6369 - val_accuracy: 0.7568\n",
      "Epoch 1698/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.8330 - val_loss: 0.6371 - val_accuracy: 0.7573\n",
      "Epoch 1699/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.8327 - val_loss: 0.6371 - val_accuracy: 0.7573\n",
      "Epoch 1700/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.8330 - val_loss: 0.6371 - val_accuracy: 0.7568\n",
      "Epoch 1701/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.8327 - val_loss: 0.6371 - val_accuracy: 0.7577\n",
      "Epoch 1702/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.8333 - val_loss: 0.6371 - val_accuracy: 0.7573\n",
      "Epoch 1703/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.8328 - val_loss: 0.6372 - val_accuracy: 0.7581\n",
      "Epoch 1704/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.8330 - val_loss: 0.6372 - val_accuracy: 0.7573\n",
      "Epoch 1705/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.8323 - val_loss: 0.6372 - val_accuracy: 0.7577\n",
      "Epoch 1706/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.8328 - val_loss: 0.6372 - val_accuracy: 0.7577\n",
      "Epoch 1707/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.8331 - val_loss: 0.6371 - val_accuracy: 0.7577\n",
      "Epoch 1708/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.8331 - val_loss: 0.6372 - val_accuracy: 0.7573\n",
      "Epoch 1709/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.8330 - val_loss: 0.6371 - val_accuracy: 0.7573\n",
      "Epoch 1710/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.8331 - val_loss: 0.6372 - val_accuracy: 0.7577\n",
      "Epoch 1711/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.8329 - val_loss: 0.6372 - val_accuracy: 0.7573\n",
      "Epoch 1712/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.8328 - val_loss: 0.6373 - val_accuracy: 0.7573\n",
      "Epoch 1713/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.8332 - val_loss: 0.6372 - val_accuracy: 0.7577\n",
      "Epoch 1714/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.8328 - val_loss: 0.6373 - val_accuracy: 0.7577\n",
      "Epoch 1715/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.8328 - val_loss: 0.6373 - val_accuracy: 0.7573\n",
      "Epoch 1716/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.8331 - val_loss: 0.6374 - val_accuracy: 0.7573\n",
      "Epoch 1717/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.8333 - val_loss: 0.6374 - val_accuracy: 0.7573\n",
      "Epoch 1718/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.8335 - val_loss: 0.6374 - val_accuracy: 0.7573\n",
      "Epoch 1719/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.8333 - val_loss: 0.6374 - val_accuracy: 0.7577\n",
      "Epoch 1720/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.8335 - val_loss: 0.6373 - val_accuracy: 0.7577\n",
      "Epoch 1721/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.8334 - val_loss: 0.6374 - val_accuracy: 0.7577\n",
      "Epoch 1722/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.8334 - val_loss: 0.6374 - val_accuracy: 0.7577\n",
      "Epoch 1723/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.8333 - val_loss: 0.6374 - val_accuracy: 0.7577\n",
      "Epoch 1724/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.8335 - val_loss: 0.6373 - val_accuracy: 0.7577\n",
      "Epoch 1725/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.8331 - val_loss: 0.6374 - val_accuracy: 0.7577\n",
      "Epoch 1726/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.8336 - val_loss: 0.6374 - val_accuracy: 0.7577\n",
      "Epoch 1727/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.8339 - val_loss: 0.6374 - val_accuracy: 0.7577\n",
      "Epoch 1728/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.8336 - val_loss: 0.6374 - val_accuracy: 0.7577\n",
      "Epoch 1729/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.8336 - val_loss: 0.6375 - val_accuracy: 0.7577\n",
      "Epoch 1730/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.8340 - val_loss: 0.6375 - val_accuracy: 0.7577\n",
      "Epoch 1731/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.8334 - val_loss: 0.6376 - val_accuracy: 0.7577\n",
      "Epoch 1732/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.8337 - val_loss: 0.6376 - val_accuracy: 0.7577\n",
      "Epoch 1733/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.8334 - val_loss: 0.6377 - val_accuracy: 0.7577\n",
      "Epoch 1734/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.8336 - val_loss: 0.6378 - val_accuracy: 0.7577\n",
      "Epoch 1735/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.8331 - val_loss: 0.6378 - val_accuracy: 0.7573\n",
      "Epoch 1736/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.8336 - val_loss: 0.6379 - val_accuracy: 0.7577\n",
      "Epoch 1737/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.8332 - val_loss: 0.6379 - val_accuracy: 0.7568\n",
      "Epoch 1738/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.8336 - val_loss: 0.6379 - val_accuracy: 0.7577\n",
      "Epoch 1739/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.8335 - val_loss: 0.6380 - val_accuracy: 0.7577\n",
      "Epoch 1740/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.8335 - val_loss: 0.6380 - val_accuracy: 0.7577\n",
      "Epoch 1741/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.8335 - val_loss: 0.6381 - val_accuracy: 0.7577\n",
      "Epoch 1742/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.8335 - val_loss: 0.6380 - val_accuracy: 0.7577\n",
      "Epoch 1743/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.8334 - val_loss: 0.6381 - val_accuracy: 0.7577\n",
      "Epoch 1744/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.8333 - val_loss: 0.6381 - val_accuracy: 0.7568\n",
      "Epoch 1745/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.8336 - val_loss: 0.6381 - val_accuracy: 0.7577\n",
      "Epoch 1746/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.8335 - val_loss: 0.6381 - val_accuracy: 0.7577\n",
      "Epoch 1747/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.8335 - val_loss: 0.6382 - val_accuracy: 0.7573\n",
      "Epoch 1748/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.8337 - val_loss: 0.6382 - val_accuracy: 0.7573\n",
      "Epoch 1749/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.8334 - val_loss: 0.6382 - val_accuracy: 0.7577\n",
      "Epoch 1750/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.8333 - val_loss: 0.6382 - val_accuracy: 0.7577\n",
      "Epoch 1751/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.8335 - val_loss: 0.6383 - val_accuracy: 0.7573\n",
      "Epoch 1752/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.8334 - val_loss: 0.6382 - val_accuracy: 0.7573\n",
      "Epoch 1753/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.8331 - val_loss: 0.6382 - val_accuracy: 0.7577\n",
      "Epoch 1754/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.8335 - val_loss: 0.6383 - val_accuracy: 0.7577\n",
      "Epoch 1755/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.8332 - val_loss: 0.6383 - val_accuracy: 0.7573\n",
      "Epoch 1756/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.8329 - val_loss: 0.6384 - val_accuracy: 0.7568\n",
      "Epoch 1757/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.8333 - val_loss: 0.6384 - val_accuracy: 0.7577\n",
      "Epoch 1758/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.8338 - val_loss: 0.6384 - val_accuracy: 0.7577\n",
      "Epoch 1759/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.8336 - val_loss: 0.6383 - val_accuracy: 0.7573\n",
      "Epoch 1760/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.8335 - val_loss: 0.6385 - val_accuracy: 0.7573\n",
      "Epoch 1761/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.8336 - val_loss: 0.6384 - val_accuracy: 0.7577\n",
      "Epoch 1762/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.8337 - val_loss: 0.6385 - val_accuracy: 0.7573\n",
      "Epoch 1763/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.8336 - val_loss: 0.6386 - val_accuracy: 0.7568\n",
      "Epoch 1764/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.8338 - val_loss: 0.6385 - val_accuracy: 0.7581\n",
      "Epoch 1765/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.8337 - val_loss: 0.6385 - val_accuracy: 0.7568\n",
      "Epoch 1766/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.8342 - val_loss: 0.6385 - val_accuracy: 0.7577\n",
      "Epoch 1767/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.8328 - val_loss: 0.6386 - val_accuracy: 0.7568\n",
      "Epoch 1768/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.8334 - val_loss: 0.6386 - val_accuracy: 0.7577\n",
      "Epoch 1769/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.8332 - val_loss: 0.6387 - val_accuracy: 0.7577\n",
      "Epoch 1770/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.8336 - val_loss: 0.6387 - val_accuracy: 0.7573\n",
      "Epoch 1771/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.8334 - val_loss: 0.6387 - val_accuracy: 0.7573\n",
      "Epoch 1772/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.8335 - val_loss: 0.6388 - val_accuracy: 0.7568\n",
      "Epoch 1773/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.8336 - val_loss: 0.6387 - val_accuracy: 0.7573\n",
      "Epoch 1774/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.8336 - val_loss: 0.6388 - val_accuracy: 0.7568\n",
      "Epoch 1775/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.8335 - val_loss: 0.6388 - val_accuracy: 0.7573\n",
      "Epoch 1776/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.8335 - val_loss: 0.6388 - val_accuracy: 0.7573\n",
      "Epoch 1777/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.8343 - val_loss: 0.6388 - val_accuracy: 0.7560\n",
      "Epoch 1778/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.8338 - val_loss: 0.6389 - val_accuracy: 0.7564\n",
      "Epoch 1779/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.8340 - val_loss: 0.6390 - val_accuracy: 0.7573\n",
      "Epoch 1780/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.8339 - val_loss: 0.6389 - val_accuracy: 0.7573\n",
      "Epoch 1781/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.8338 - val_loss: 0.6389 - val_accuracy: 0.7568\n",
      "Epoch 1782/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.8332 - val_loss: 0.6390 - val_accuracy: 0.7573\n",
      "Epoch 1783/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.8335 - val_loss: 0.6390 - val_accuracy: 0.7581\n",
      "Epoch 1784/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.8332 - val_loss: 0.6391 - val_accuracy: 0.7577\n",
      "Epoch 1785/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.8336 - val_loss: 0.6390 - val_accuracy: 0.7568\n",
      "Epoch 1786/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.8342 - val_loss: 0.6391 - val_accuracy: 0.7573\n",
      "Epoch 1787/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.8334 - val_loss: 0.6391 - val_accuracy: 0.7577\n",
      "Epoch 1788/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.8336 - val_loss: 0.6391 - val_accuracy: 0.7581\n",
      "Epoch 1789/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.8338 - val_loss: 0.6391 - val_accuracy: 0.7573\n",
      "Epoch 1790/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.8336 - val_loss: 0.6391 - val_accuracy: 0.7568\n",
      "Epoch 1791/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.8336 - val_loss: 0.6392 - val_accuracy: 0.7577\n",
      "Epoch 1792/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.8333 - val_loss: 0.6392 - val_accuracy: 0.7568\n",
      "Epoch 1793/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.8334 - val_loss: 0.6392 - val_accuracy: 0.7577\n",
      "Epoch 1794/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.8332 - val_loss: 0.6393 - val_accuracy: 0.7577\n",
      "Epoch 1795/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.8333 - val_loss: 0.6392 - val_accuracy: 0.7573\n",
      "Epoch 1796/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.8336 - val_loss: 0.6393 - val_accuracy: 0.7581\n",
      "Epoch 1797/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.8333 - val_loss: 0.6392 - val_accuracy: 0.7577\n",
      "Epoch 1798/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.8335 - val_loss: 0.6392 - val_accuracy: 0.7577\n",
      "Epoch 1799/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.8335 - val_loss: 0.6393 - val_accuracy: 0.7573\n",
      "Epoch 1800/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.8333 - val_loss: 0.6394 - val_accuracy: 0.7585\n",
      "Epoch 1801/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.8334 - val_loss: 0.6394 - val_accuracy: 0.7581\n",
      "Epoch 1802/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.8333 - val_loss: 0.6394 - val_accuracy: 0.7573\n",
      "Epoch 1803/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.8330 - val_loss: 0.6394 - val_accuracy: 0.7577\n",
      "Epoch 1804/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.8336 - val_loss: 0.6394 - val_accuracy: 0.7573\n",
      "Epoch 1805/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.8334 - val_loss: 0.6394 - val_accuracy: 0.7573\n",
      "Epoch 1806/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.8333 - val_loss: 0.6395 - val_accuracy: 0.7568\n",
      "Epoch 1807/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.8330 - val_loss: 0.6395 - val_accuracy: 0.7573\n",
      "Epoch 1808/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.8332 - val_loss: 0.6394 - val_accuracy: 0.7573\n",
      "Epoch 1809/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.8331 - val_loss: 0.6394 - val_accuracy: 0.7577\n",
      "Epoch 1810/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.8331 - val_loss: 0.6395 - val_accuracy: 0.7577\n",
      "Epoch 1811/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.8333 - val_loss: 0.6396 - val_accuracy: 0.7573\n",
      "Epoch 1812/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.8329 - val_loss: 0.6396 - val_accuracy: 0.7581\n",
      "Epoch 1813/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.8333 - val_loss: 0.6396 - val_accuracy: 0.7581\n",
      "Epoch 1814/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.8334 - val_loss: 0.6396 - val_accuracy: 0.7577\n",
      "Epoch 1815/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.8330 - val_loss: 0.6397 - val_accuracy: 0.7581\n",
      "Epoch 1816/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.8333 - val_loss: 0.6397 - val_accuracy: 0.7577\n",
      "Epoch 1817/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.8333 - val_loss: 0.6397 - val_accuracy: 0.7577\n",
      "Epoch 1818/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.8331 - val_loss: 0.6397 - val_accuracy: 0.7581\n",
      "Epoch 1819/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.8332 - val_loss: 0.6397 - val_accuracy: 0.7577\n",
      "Epoch 1820/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.8333 - val_loss: 0.6398 - val_accuracy: 0.7577\n",
      "Epoch 1821/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.8331 - val_loss: 0.6397 - val_accuracy: 0.7577\n",
      "Epoch 1822/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.8333 - val_loss: 0.6397 - val_accuracy: 0.7581\n",
      "Epoch 1823/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.8330 - val_loss: 0.6398 - val_accuracy: 0.7577\n",
      "Epoch 1824/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.8330 - val_loss: 0.6398 - val_accuracy: 0.7577\n",
      "Epoch 1825/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.8333 - val_loss: 0.6397 - val_accuracy: 0.7573\n",
      "Epoch 1826/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.8329 - val_loss: 0.6398 - val_accuracy: 0.7577\n",
      "Epoch 1827/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.8334 - val_loss: 0.6398 - val_accuracy: 0.7577\n",
      "Epoch 1828/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.8331 - val_loss: 0.6398 - val_accuracy: 0.7573\n",
      "Epoch 1829/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.8335 - val_loss: 0.6398 - val_accuracy: 0.7577\n",
      "Epoch 1830/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.8329 - val_loss: 0.6399 - val_accuracy: 0.7568\n",
      "Epoch 1831/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.8331 - val_loss: 0.6399 - val_accuracy: 0.7568\n",
      "Epoch 1832/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.8332 - val_loss: 0.6399 - val_accuracy: 0.7573\n",
      "Epoch 1833/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.8331 - val_loss: 0.6399 - val_accuracy: 0.7581\n",
      "Epoch 1834/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.8333 - val_loss: 0.6399 - val_accuracy: 0.7577\n",
      "Epoch 1835/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.8331 - val_loss: 0.6400 - val_accuracy: 0.7568\n",
      "Epoch 1836/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.8334 - val_loss: 0.6399 - val_accuracy: 0.7577\n",
      "Epoch 1837/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.8339 - val_loss: 0.6399 - val_accuracy: 0.7577\n",
      "Epoch 1838/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.8332 - val_loss: 0.6401 - val_accuracy: 0.7568\n",
      "Epoch 1839/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.8334 - val_loss: 0.6400 - val_accuracy: 0.7564\n",
      "Epoch 1840/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.8334 - val_loss: 0.6400 - val_accuracy: 0.7568\n",
      "Epoch 1841/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.8333 - val_loss: 0.6400 - val_accuracy: 0.7573\n",
      "Epoch 1842/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.8336 - val_loss: 0.6401 - val_accuracy: 0.7577\n",
      "Epoch 1843/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.8336 - val_loss: 0.6401 - val_accuracy: 0.7573\n",
      "Epoch 1844/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.8333 - val_loss: 0.6401 - val_accuracy: 0.7568\n",
      "Epoch 1845/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.8334 - val_loss: 0.6401 - val_accuracy: 0.7568\n",
      "Epoch 1846/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.8335 - val_loss: 0.6401 - val_accuracy: 0.7568\n",
      "Epoch 1847/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.8337 - val_loss: 0.6400 - val_accuracy: 0.7573\n",
      "Epoch 1848/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.8328 - val_loss: 0.6403 - val_accuracy: 0.7568\n",
      "Epoch 1849/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.8333 - val_loss: 0.6403 - val_accuracy: 0.7564\n",
      "Epoch 1850/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.8333 - val_loss: 0.6403 - val_accuracy: 0.7564\n",
      "Epoch 1851/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.8334 - val_loss: 0.6403 - val_accuracy: 0.7568\n",
      "Epoch 1852/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.8331 - val_loss: 0.6404 - val_accuracy: 0.7568\n",
      "Epoch 1853/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.8333 - val_loss: 0.6404 - val_accuracy: 0.7564\n",
      "Epoch 1854/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.8339 - val_loss: 0.6404 - val_accuracy: 0.7564\n",
      "Epoch 1855/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.8331 - val_loss: 0.6404 - val_accuracy: 0.7564\n",
      "Epoch 1856/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.8334 - val_loss: 0.6404 - val_accuracy: 0.7564\n",
      "Epoch 1857/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.8332 - val_loss: 0.6404 - val_accuracy: 0.7568\n",
      "Epoch 1858/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.8334 - val_loss: 0.6404 - val_accuracy: 0.7564\n",
      "Epoch 1859/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.8335 - val_loss: 0.6405 - val_accuracy: 0.7568\n",
      "Epoch 1860/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.8332 - val_loss: 0.6405 - val_accuracy: 0.7573\n",
      "Epoch 1861/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.8334 - val_loss: 0.6404 - val_accuracy: 0.7568\n",
      "Epoch 1862/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.8335 - val_loss: 0.6405 - val_accuracy: 0.7564\n",
      "Epoch 1863/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.8337 - val_loss: 0.6405 - val_accuracy: 0.7568\n",
      "Epoch 1864/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.8336 - val_loss: 0.6406 - val_accuracy: 0.7573\n",
      "Epoch 1865/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.8332 - val_loss: 0.6406 - val_accuracy: 0.7573\n",
      "Epoch 1866/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.8331 - val_loss: 0.6406 - val_accuracy: 0.7573\n",
      "Epoch 1867/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.8328 - val_loss: 0.6406 - val_accuracy: 0.7573\n",
      "Epoch 1868/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.8334 - val_loss: 0.6407 - val_accuracy: 0.7573\n",
      "Epoch 1869/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.8329 - val_loss: 0.6407 - val_accuracy: 0.7573\n",
      "Epoch 1870/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.8331 - val_loss: 0.6407 - val_accuracy: 0.7573\n",
      "Epoch 1871/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.8331 - val_loss: 0.6408 - val_accuracy: 0.7573\n",
      "Epoch 1872/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.8333 - val_loss: 0.6407 - val_accuracy: 0.7577\n",
      "Epoch 1873/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.8334 - val_loss: 0.6407 - val_accuracy: 0.7573\n",
      "Epoch 1874/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.8328 - val_loss: 0.6407 - val_accuracy: 0.7573\n",
      "Epoch 1875/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.8331 - val_loss: 0.6407 - val_accuracy: 0.7573\n",
      "Epoch 1876/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.8331 - val_loss: 0.6408 - val_accuracy: 0.7573\n",
      "Epoch 1877/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.8335 - val_loss: 0.6407 - val_accuracy: 0.7568\n",
      "Epoch 1878/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.8331 - val_loss: 0.6407 - val_accuracy: 0.7568\n",
      "Epoch 1879/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.8332 - val_loss: 0.6408 - val_accuracy: 0.7568\n",
      "Epoch 1880/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.8337 - val_loss: 0.6407 - val_accuracy: 0.7573\n",
      "Epoch 1881/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.8332 - val_loss: 0.6408 - val_accuracy: 0.7568\n",
      "Epoch 1882/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.8330 - val_loss: 0.6408 - val_accuracy: 0.7568\n",
      "Epoch 1883/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.8333 - val_loss: 0.6409 - val_accuracy: 0.7568\n",
      "Epoch 1884/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.8333 - val_loss: 0.6409 - val_accuracy: 0.7568\n",
      "Epoch 1885/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.8333 - val_loss: 0.6408 - val_accuracy: 0.7568\n",
      "Epoch 1886/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.8332 - val_loss: 0.6409 - val_accuracy: 0.7581\n",
      "Epoch 1887/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.8334 - val_loss: 0.6409 - val_accuracy: 0.7573\n",
      "Epoch 1888/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.8332 - val_loss: 0.6409 - val_accuracy: 0.7577\n",
      "Epoch 1889/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.8332 - val_loss: 0.6409 - val_accuracy: 0.7577\n",
      "Epoch 1890/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.8335 - val_loss: 0.6410 - val_accuracy: 0.7568\n",
      "Epoch 1891/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.8334 - val_loss: 0.6411 - val_accuracy: 0.7568\n",
      "Epoch 1892/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.8333 - val_loss: 0.6410 - val_accuracy: 0.7564\n",
      "Epoch 1893/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.8333 - val_loss: 0.6410 - val_accuracy: 0.7564\n",
      "Epoch 1894/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.8333 - val_loss: 0.6411 - val_accuracy: 0.7564\n",
      "Epoch 1895/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.8333 - val_loss: 0.6410 - val_accuracy: 0.7564\n",
      "Epoch 1896/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.8330 - val_loss: 0.6409 - val_accuracy: 0.7560\n",
      "Epoch 1897/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.8332 - val_loss: 0.6409 - val_accuracy: 0.7568\n",
      "Epoch 1898/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.8334 - val_loss: 0.6409 - val_accuracy: 0.7573\n",
      "Epoch 1899/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.8333 - val_loss: 0.6409 - val_accuracy: 0.7564\n",
      "Epoch 1900/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.8329 - val_loss: 0.6410 - val_accuracy: 0.7564\n",
      "Epoch 1901/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.8331 - val_loss: 0.6409 - val_accuracy: 0.7568\n",
      "Epoch 1902/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.8328 - val_loss: 0.6409 - val_accuracy: 0.7564\n",
      "Epoch 1903/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.8336 - val_loss: 0.6410 - val_accuracy: 0.7564\n",
      "Epoch 1904/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.8327 - val_loss: 0.6410 - val_accuracy: 0.7564\n",
      "Epoch 1905/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.8331 - val_loss: 0.6409 - val_accuracy: 0.7564\n",
      "Epoch 1906/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.8330 - val_loss: 0.6411 - val_accuracy: 0.7560\n",
      "Epoch 1907/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.8332 - val_loss: 0.6410 - val_accuracy: 0.7568\n",
      "Epoch 1908/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.8330 - val_loss: 0.6410 - val_accuracy: 0.7564\n",
      "Epoch 1909/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.8330 - val_loss: 0.6411 - val_accuracy: 0.7568\n",
      "Epoch 1910/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.8332 - val_loss: 0.6411 - val_accuracy: 0.7564\n",
      "Epoch 1911/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.8333 - val_loss: 0.6411 - val_accuracy: 0.7568\n",
      "Epoch 1912/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.8330 - val_loss: 0.6412 - val_accuracy: 0.7564\n",
      "Epoch 1913/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.8328 - val_loss: 0.6411 - val_accuracy: 0.7564\n",
      "Epoch 1914/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.8338 - val_loss: 0.6410 - val_accuracy: 0.7560\n",
      "Epoch 1915/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.8334 - val_loss: 0.6411 - val_accuracy: 0.7556\n",
      "Epoch 1916/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.8331 - val_loss: 0.6411 - val_accuracy: 0.7560\n",
      "Epoch 1917/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.8329 - val_loss: 0.6412 - val_accuracy: 0.7560\n",
      "Epoch 1918/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.8331 - val_loss: 0.6413 - val_accuracy: 0.7556\n",
      "Epoch 1919/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.8330 - val_loss: 0.6413 - val_accuracy: 0.7556\n",
      "Epoch 1920/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.8332 - val_loss: 0.6412 - val_accuracy: 0.7551\n",
      "Epoch 1921/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.8332 - val_loss: 0.6413 - val_accuracy: 0.7556\n",
      "Epoch 1922/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.8334 - val_loss: 0.6413 - val_accuracy: 0.7560\n",
      "Epoch 1923/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.8332 - val_loss: 0.6413 - val_accuracy: 0.7568\n",
      "Epoch 1924/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.8332 - val_loss: 0.6414 - val_accuracy: 0.7564\n",
      "Epoch 1925/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.8330 - val_loss: 0.6414 - val_accuracy: 0.7564\n",
      "Epoch 1926/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.8328 - val_loss: 0.6415 - val_accuracy: 0.7556\n",
      "Epoch 1927/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.8330 - val_loss: 0.6415 - val_accuracy: 0.7564\n",
      "Epoch 1928/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.8329 - val_loss: 0.6416 - val_accuracy: 0.7564\n",
      "Epoch 1929/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.8333 - val_loss: 0.6416 - val_accuracy: 0.7560\n",
      "Epoch 1930/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.8334 - val_loss: 0.6416 - val_accuracy: 0.7560\n",
      "Epoch 1931/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.8334 - val_loss: 0.6415 - val_accuracy: 0.7556\n",
      "Epoch 1932/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.8329 - val_loss: 0.6416 - val_accuracy: 0.7560\n",
      "Epoch 1933/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.8337 - val_loss: 0.6416 - val_accuracy: 0.7556\n",
      "Epoch 1934/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.8328 - val_loss: 0.6416 - val_accuracy: 0.7560\n",
      "Epoch 1935/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.8331 - val_loss: 0.6416 - val_accuracy: 0.7560\n",
      "Epoch 1936/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.8336 - val_loss: 0.6416 - val_accuracy: 0.7564\n",
      "Epoch 1937/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.8342 - val_loss: 0.6416 - val_accuracy: 0.7564\n",
      "Epoch 1938/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.8332 - val_loss: 0.6416 - val_accuracy: 0.7560\n",
      "Epoch 1939/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.8331 - val_loss: 0.6417 - val_accuracy: 0.7564\n",
      "Epoch 1940/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.8329 - val_loss: 0.6417 - val_accuracy: 0.7568\n",
      "Epoch 1941/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.8332 - val_loss: 0.6417 - val_accuracy: 0.7564\n",
      "Epoch 1942/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.8329 - val_loss: 0.6417 - val_accuracy: 0.7560\n",
      "Epoch 1943/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.8336 - val_loss: 0.6416 - val_accuracy: 0.7564\n",
      "Epoch 1944/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.8332 - val_loss: 0.6418 - val_accuracy: 0.7564\n",
      "Epoch 1945/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.8337 - val_loss: 0.6416 - val_accuracy: 0.7564\n",
      "Epoch 1946/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.8327 - val_loss: 0.6417 - val_accuracy: 0.7564\n",
      "Epoch 1947/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.8331 - val_loss: 0.6417 - val_accuracy: 0.7564\n",
      "Epoch 1948/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.8333 - val_loss: 0.6418 - val_accuracy: 0.7556\n",
      "Epoch 1949/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.8333 - val_loss: 0.6419 - val_accuracy: 0.7560\n",
      "Epoch 1950/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.8330 - val_loss: 0.6418 - val_accuracy: 0.7560\n",
      "Epoch 1951/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.8333 - val_loss: 0.6418 - val_accuracy: 0.7556\n",
      "Epoch 1952/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.8336 - val_loss: 0.6419 - val_accuracy: 0.7560\n",
      "Epoch 1953/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.8331 - val_loss: 0.6419 - val_accuracy: 0.7556\n",
      "Epoch 1954/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.8332 - val_loss: 0.6419 - val_accuracy: 0.7551\n",
      "Epoch 1955/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.8333 - val_loss: 0.6419 - val_accuracy: 0.7556\n",
      "Epoch 1956/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.8330 - val_loss: 0.6420 - val_accuracy: 0.7556\n",
      "Epoch 1957/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.8331 - val_loss: 0.6421 - val_accuracy: 0.7560\n",
      "Epoch 1958/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.8335 - val_loss: 0.6419 - val_accuracy: 0.7556\n",
      "Epoch 1959/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.8333 - val_loss: 0.6419 - val_accuracy: 0.7560\n",
      "Epoch 1960/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.8327 - val_loss: 0.6419 - val_accuracy: 0.7564\n",
      "Epoch 1961/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.8333 - val_loss: 0.6420 - val_accuracy: 0.7564\n",
      "Epoch 1962/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.8327 - val_loss: 0.6420 - val_accuracy: 0.7560\n",
      "Epoch 1963/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.8331 - val_loss: 0.6420 - val_accuracy: 0.7568\n",
      "Epoch 1964/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.8331 - val_loss: 0.6420 - val_accuracy: 0.7560\n",
      "Epoch 1965/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.8331 - val_loss: 0.6421 - val_accuracy: 0.7556\n",
      "Epoch 1966/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.8335 - val_loss: 0.6421 - val_accuracy: 0.7560\n",
      "Epoch 1967/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.8331 - val_loss: 0.6421 - val_accuracy: 0.7564\n",
      "Epoch 1968/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.8334 - val_loss: 0.6422 - val_accuracy: 0.7560\n",
      "Epoch 1969/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.8335 - val_loss: 0.6423 - val_accuracy: 0.7564\n",
      "Epoch 1970/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.8335 - val_loss: 0.6423 - val_accuracy: 0.7556\n",
      "Epoch 1971/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.8337 - val_loss: 0.6423 - val_accuracy: 0.7560\n",
      "Epoch 1972/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.8338 - val_loss: 0.6423 - val_accuracy: 0.7560\n",
      "Epoch 1973/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.8337 - val_loss: 0.6423 - val_accuracy: 0.7560\n",
      "Epoch 1974/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.8334 - val_loss: 0.6423 - val_accuracy: 0.7564\n",
      "Epoch 1975/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.8339 - val_loss: 0.6423 - val_accuracy: 0.7560\n",
      "Epoch 1976/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.8334 - val_loss: 0.6423 - val_accuracy: 0.7560\n",
      "Epoch 1977/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.8333 - val_loss: 0.6424 - val_accuracy: 0.7560\n",
      "Epoch 1978/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.8335 - val_loss: 0.6423 - val_accuracy: 0.7564\n",
      "Epoch 1979/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.8335 - val_loss: 0.6424 - val_accuracy: 0.7564\n",
      "Epoch 1980/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.8336 - val_loss: 0.6423 - val_accuracy: 0.7568\n",
      "Epoch 1981/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.8335 - val_loss: 0.6424 - val_accuracy: 0.7564\n",
      "Epoch 1982/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.8333 - val_loss: 0.6424 - val_accuracy: 0.7564\n",
      "Epoch 1983/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.8339 - val_loss: 0.6424 - val_accuracy: 0.7564\n",
      "Epoch 1984/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.8336 - val_loss: 0.6425 - val_accuracy: 0.7564\n",
      "Epoch 1985/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.8329 - val_loss: 0.6426 - val_accuracy: 0.7560\n",
      "Epoch 1986/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.8335 - val_loss: 0.6425 - val_accuracy: 0.7564\n",
      "Epoch 1987/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.8335 - val_loss: 0.6426 - val_accuracy: 0.7568\n",
      "Epoch 1988/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.8336 - val_loss: 0.6427 - val_accuracy: 0.7564\n",
      "Epoch 1989/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.8331 - val_loss: 0.6426 - val_accuracy: 0.7573\n",
      "Epoch 1990/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.8338 - val_loss: 0.6427 - val_accuracy: 0.7564\n",
      "Epoch 1991/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.8333 - val_loss: 0.6426 - val_accuracy: 0.7568\n",
      "Epoch 1992/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.8329 - val_loss: 0.6426 - val_accuracy: 0.7564\n",
      "Epoch 1993/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.8340 - val_loss: 0.6426 - val_accuracy: 0.7568\n",
      "Epoch 1994/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.8332 - val_loss: 0.6426 - val_accuracy: 0.7564\n",
      "Epoch 1995/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.8335 - val_loss: 0.6426 - val_accuracy: 0.7568\n",
      "Epoch 1996/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.8334 - val_loss: 0.6425 - val_accuracy: 0.7564\n",
      "Epoch 1997/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.8333 - val_loss: 0.6427 - val_accuracy: 0.7564\n",
      "Epoch 1998/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.8336 - val_loss: 0.6427 - val_accuracy: 0.7568\n",
      "Epoch 1999/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.8337 - val_loss: 0.6427 - val_accuracy: 0.7564\n",
      "Epoch 2000/2000\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.8333 - val_loss: 0.6427 - val_accuracy: 0.7564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2661eaab910>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 2000\n",
    "history=model.fit(X_train_idf.toarray(), y_train, batch_size=batch_size, epochs=epochs, shuffle=True, verbose=1,validation_split=0.2)\n",
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d00c466",
   "metadata": {},
   "source": [
    "##### 6) Finding Training and Testing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d517703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training and testing accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9dc7b678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 1ms/step - loss: 0.6189 - accuracy: 0.7699\n",
      "Test Accuracy: 0.7699145078659058 and Test Loss: 0.6188592314720154\n"
     ]
    }
   ],
   "source": [
    "test_loss,test_acc=model.evaluate(X_test_idf.toarray(),y_test)\n",
    "print(f'Test Accuracy: {test_acc} and Test Loss: {test_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a47670",
   "metadata": {},
   "source": [
    "##### 7) Compute and plot the confusion matrix for the three classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7eb7ef1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.87      0.85      1835\n",
      "     neutral       0.60      0.57      0.58       617\n",
      "    positive       0.71      0.63      0.67       473\n",
      "\n",
      "    accuracy                           0.77      2925\n",
      "   macro avg       0.71      0.69      0.70      2925\n",
      "weighted avg       0.77      0.77      0.77      2925\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions=model.predict(X_test_idf.toarray())\n",
    "class_labels = ['negative', 'positive','neutral']\n",
    "predicted_class_labels = [class_labels[np.argmax(pred)] for pred in predictions]\n",
    "actual_class_labels=[class_labels[actual] for actual in y_test]\n",
    "print(classification_report(actual_class_labels, predicted_class_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9208658a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(actual_class_labels, predicted_class_labels, labels=class_labels)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Purples\", xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd974772",
   "metadata": {},
   "source": [
    "##### 8) Saving the final results in Excel sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0081b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision per class: [0.83663883 0.5952381  0.71021378]\n",
      "Recall per class: [0.87356948 0.56726094 0.63213531]\n"
     ]
    }
   ],
   "source": [
    "precision_per_class = precision_score(actual_class_labels, predicted_class_labels, average=None)\n",
    "recall_per_class = recall_score(actual_class_labels, predicted_class_labels, average=None)\n",
    "\n",
    "print(\"Precision per class:\", precision_per_class)\n",
    "print(\"Recall per class:\", recall_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7df0d2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1 Score: 0.7699145299145299\n",
      "Macro F1 Score: 0.701507359364231\n"
     ]
    }
   ],
   "source": [
    "f1_micro = f1_score(actual_class_labels, predicted_class_labels, average='micro')\n",
    "f1_macro = f1_score(actual_class_labels, predicted_class_labels, average='macro')\n",
    "\n",
    "print(\"Micro F1 Score:\", f1_micro)\n",
    "print(\"Macro F1 Score:\", f1_macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "713cef8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original_Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training Accuracy</th>\n",
       "      <td>0.834259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <td>0.769915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Micro F1 Score</th>\n",
       "      <td>0.769915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Macro F1 Score</th>\n",
       "      <td>0.701507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision for Negative sentiment</th>\n",
       "      <td>0.836639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision for Positive sentiment</th>\n",
       "      <td>0.595238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision for Neutral sentiment</th>\n",
       "      <td>0.710214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall for Negative sentiment</th>\n",
       "      <td>0.873569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall for Positive sentiment</th>\n",
       "      <td>0.567261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall for Neutral sentiment</th>\n",
       "      <td>0.632135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Original_Dataset\n",
       "Training Accuracy                         0.834259\n",
       "Testing Accuracy                          0.769915\n",
       "Micro F1 Score                            0.769915\n",
       "Macro F1 Score                            0.701507\n",
       "Precision for Negative sentiment          0.836639\n",
       "Precision for Positive sentiment          0.595238\n",
       "Precision for Neutral sentiment           0.710214\n",
       "Recall for Negative sentiment             0.873569\n",
       "Recall for Positive sentiment             0.567261\n",
       "Recall for Neutral sentiment              0.632135"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data={'Original_Dataset':[max(history.history['accuracy']),test_acc,f1_micro,f1_macro,precision_per_class[0],precision_per_class[1],precision_per_class[2],recall_per_class[0],recall_per_class[1],recall_per_class[2]]}\n",
    "result=pd.DataFrame(data,index=['Training Accuracy','Testing Accuracy','Micro F1 Score','Macro F1 Score','Precision for Negative sentiment','Precision for Positive sentiment','Precision for Neutral sentiment','Recall for Negative sentiment','Recall for Positive sentiment','Recall for Neutral sentiment'])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "448e60d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('SimpleDNNModelResults.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
