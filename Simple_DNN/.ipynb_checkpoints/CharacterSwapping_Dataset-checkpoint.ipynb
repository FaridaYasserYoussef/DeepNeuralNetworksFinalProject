{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6575869",
   "metadata": {},
   "source": [
    "# Simple DNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "934847a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Users\\Suzan Hatem\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import  Dense,Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978ceb42",
   "metadata": {},
   "source": [
    "##### 1)Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "272b56c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>preprocessed_abstract</th>\n",
       "      <th>length_after_cleaning</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>35</td>\n",
       "      <td>what say</td>\n",
       "      <td>8</td>\n",
       "      <td>['what', 'say']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>72</td>\n",
       "      <td>plus add commercial experience tacky</td>\n",
       "      <td>36</td>\n",
       "      <td>['plus', 'add', 'commercial', 'experience', 't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>71</td>\n",
       "      <td>i today must mean i need take another trip</td>\n",
       "      <td>42</td>\n",
       "      <td>['i', 'today', 'must', 'mean', 'i', 'need', 't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>126</td>\n",
       "      <td>really aggressive blast obnoxious entertainmen...</td>\n",
       "      <td>78</td>\n",
       "      <td>['really', 'aggressive', 'blast', 'obnoxious',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>55</td>\n",
       "      <td>really big bad thing</td>\n",
       "      <td>20</td>\n",
       "      <td>['really', 'big', 'bad', 'thing']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0  label  \\\n",
       "0             0           0      2   \n",
       "1             1           1      1   \n",
       "2             2           2      2   \n",
       "3             3           3      0   \n",
       "4             4           4      0   \n",
       "\n",
       "                                                text  length  \\\n",
       "0                @VirginAmerica What @dhepburn said.      35   \n",
       "1  @VirginAmerica plus you've added commercials t...      72   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...      71   \n",
       "3  @VirginAmerica it's really aggressive to blast...     126   \n",
       "4  @VirginAmerica and it's a really big bad thing...      55   \n",
       "\n",
       "                               preprocessed_abstract  length_after_cleaning  \\\n",
       "0                                           what say                      8   \n",
       "1               plus add commercial experience tacky                     36   \n",
       "2         i today must mean i need take another trip                     42   \n",
       "3  really aggressive blast obnoxious entertainmen...                     78   \n",
       "4                               really big bad thing                     20   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0                                    ['what', 'say']  \n",
       "1  ['plus', 'add', 'commercial', 'experience', 't...  \n",
       "2  ['i', 'today', 'must', 'mean', 'i', 'need', 't...  \n",
       "3  ['really', 'aggressive', 'blast', 'obnoxious',...  \n",
       "4                  ['really', 'big', 'bad', 'thing']  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"df_CharacterSwapping.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fc2dbfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0.1              0\n",
       "Unnamed: 0                0\n",
       "label                     0\n",
       "text                      0\n",
       "length                    0\n",
       "preprocessed_abstract    43\n",
       "length_after_cleaning     0\n",
       "tokenized_text            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4ad58fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e03b6a9",
   "metadata": {},
   "source": [
    "#####  2) Split , into Training and Validation Sets (80:20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8741840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: (21992,) (21992,)\n",
      "Test data: (5499,) (5499,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['preprocessed_abstract'], df['label'], test_size=0.2, stratify=df['label'], random_state=42)\n",
    "print(\"Train data:\",  X_train.shape, y_train.shape)\n",
    "print(\"Test data:\",  X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d5b7f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "colors = ['#4285f4', '#ea4335', '#fbbc05', '#34a853']\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.pie([len(y_train), len(y_test)],\n",
    "        labels=['Train','Test'],\n",
    "        colors=colors, autopct='%.1f%%', explode=(0.05,0.05),\n",
    "        startangle=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a556ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_TF-IDF shape:  (21992, 1179)\n",
      "X_test_TF-IDF shape:  (5499, 1179)\n"
     ]
    }
   ],
   "source": [
    "vect= TfidfVectorizer(min_df=20)\n",
    "X_train_idf = vect.fit_transform(X_train)\n",
    "X_test_idf = vect.transform(X_test)\n",
    "\n",
    "print('X_train_TF-IDF shape: ', X_train_idf.shape)\n",
    "print('X_test_TF-IDF shape: ', X_test_idf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ffb115",
   "metadata": {},
   "source": [
    "##### 4)Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4620a071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Users\\Suzan Hatem\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(8,input_shape=(X_train_idf.shape[1],),kernel_regularizer='l2'),\n",
    "    Dense(16,activation='relu'),\n",
    "    Dense(8,activation='relu'),\n",
    "    Dense(3, activation='softmax')#This is a multi-class Classification problem\n",
    "    \n",
    "])\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=0.00001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abfb9a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 8)                 9440      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                144       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 27        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9747 (38.07 KB)\n",
      "Trainable params: 9747 (38.07 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea9dbdd",
   "metadata": {},
   "source": [
    "##### 5) Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a3407cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "WARNING:tensorflow:From D:\\Users\\Suzan Hatem\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Users\\Suzan Hatem\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "138/138 [==============================] - 1s 4ms/step - loss: 1.2548 - accuracy: 0.3219 - val_loss: 1.2507 - val_accuracy: 0.3294\n",
      "Epoch 2/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.2467 - accuracy: 0.3251 - val_loss: 1.2428 - val_accuracy: 0.3360\n",
      "Epoch 3/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.2389 - accuracy: 0.3314 - val_loss: 1.2353 - val_accuracy: 0.3403\n",
      "Epoch 4/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.2315 - accuracy: 0.3355 - val_loss: 1.2280 - val_accuracy: 0.3412\n",
      "Epoch 5/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.2244 - accuracy: 0.3363 - val_loss: 1.2211 - val_accuracy: 0.3446\n",
      "Epoch 6/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.2176 - accuracy: 0.3399 - val_loss: 1.2144 - val_accuracy: 0.3485\n",
      "Epoch 7/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.2111 - accuracy: 0.3462 - val_loss: 1.2080 - val_accuracy: 0.3528\n",
      "Epoch 8/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.2048 - accuracy: 0.3487 - val_loss: 1.2019 - val_accuracy: 0.3533\n",
      "Epoch 9/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.1987 - accuracy: 0.3516 - val_loss: 1.1959 - val_accuracy: 0.3569\n",
      "Epoch 10/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.1928 - accuracy: 0.3576 - val_loss: 1.1902 - val_accuracy: 0.3608\n",
      "Epoch 11/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.1871 - accuracy: 0.3603 - val_loss: 1.1846 - val_accuracy: 0.3612\n",
      "Epoch 12/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.1816 - accuracy: 0.3631 - val_loss: 1.1792 - val_accuracy: 0.3603\n",
      "Epoch 13/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.1763 - accuracy: 0.3656 - val_loss: 1.1740 - val_accuracy: 0.3655\n",
      "Epoch 14/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.1712 - accuracy: 0.3662 - val_loss: 1.1690 - val_accuracy: 0.3662\n",
      "Epoch 15/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.1662 - accuracy: 0.3704 - val_loss: 1.1641 - val_accuracy: 0.3660\n",
      "Epoch 16/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.1614 - accuracy: 0.3716 - val_loss: 1.1594 - val_accuracy: 0.3708\n",
      "Epoch 17/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.1567 - accuracy: 0.3767 - val_loss: 1.1548 - val_accuracy: 0.3751\n",
      "Epoch 18/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.1521 - accuracy: 0.3779 - val_loss: 1.1503 - val_accuracy: 0.3769\n",
      "Epoch 19/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.1476 - accuracy: 0.3816 - val_loss: 1.1459 - val_accuracy: 0.3801\n",
      "Epoch 20/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.1433 - accuracy: 0.3860 - val_loss: 1.1417 - val_accuracy: 0.3865\n",
      "Epoch 21/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.1391 - accuracy: 0.3917 - val_loss: 1.1376 - val_accuracy: 0.3930\n",
      "Epoch 22/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.1350 - accuracy: 0.3986 - val_loss: 1.1335 - val_accuracy: 0.3985\n",
      "Epoch 23/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.1310 - accuracy: 0.4044 - val_loss: 1.1296 - val_accuracy: 0.4040\n",
      "Epoch 24/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.1271 - accuracy: 0.4088 - val_loss: 1.1258 - val_accuracy: 0.4067\n",
      "Epoch 25/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.1232 - accuracy: 0.4131 - val_loss: 1.1220 - val_accuracy: 0.4112\n",
      "Epoch 26/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.1195 - accuracy: 0.4153 - val_loss: 1.1184 - val_accuracy: 0.4153\n",
      "Epoch 27/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.1158 - accuracy: 0.4205 - val_loss: 1.1149 - val_accuracy: 0.4206\n",
      "Epoch 28/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.1123 - accuracy: 0.4253 - val_loss: 1.1114 - val_accuracy: 0.4258\n",
      "Epoch 29/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.1088 - accuracy: 0.4311 - val_loss: 1.1080 - val_accuracy: 0.4290\n",
      "Epoch 30/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.1054 - accuracy: 0.4347 - val_loss: 1.1047 - val_accuracy: 0.4356\n",
      "Epoch 31/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.1021 - accuracy: 0.4401 - val_loss: 1.1014 - val_accuracy: 0.4392\n",
      "Epoch 32/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.0988 - accuracy: 0.4429 - val_loss: 1.0983 - val_accuracy: 0.4424\n",
      "Epoch 33/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.0956 - accuracy: 0.4464 - val_loss: 1.0952 - val_accuracy: 0.4476\n",
      "Epoch 34/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.0924 - accuracy: 0.4506 - val_loss: 1.0921 - val_accuracy: 0.4481\n",
      "Epoch 35/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.0893 - accuracy: 0.4548 - val_loss: 1.0891 - val_accuracy: 0.4519\n",
      "Epoch 36/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.0863 - accuracy: 0.4564 - val_loss: 1.0861 - val_accuracy: 0.4549\n",
      "Epoch 37/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.0833 - accuracy: 0.4613 - val_loss: 1.0831 - val_accuracy: 0.4581\n",
      "Epoch 38/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.0803 - accuracy: 0.4654 - val_loss: 1.0802 - val_accuracy: 0.4612\n",
      "Epoch 39/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.0773 - accuracy: 0.4670 - val_loss: 1.0773 - val_accuracy: 0.4651\n",
      "Epoch 40/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.0744 - accuracy: 0.4735 - val_loss: 1.0745 - val_accuracy: 0.4710\n",
      "Epoch 41/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.0715 - accuracy: 0.4764 - val_loss: 1.0716 - val_accuracy: 0.4760\n",
      "Epoch 42/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.0686 - accuracy: 0.4795 - val_loss: 1.0688 - val_accuracy: 0.4785\n",
      "Epoch 43/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.0657 - accuracy: 0.4841 - val_loss: 1.0660 - val_accuracy: 0.4783\n",
      "Epoch 44/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.0629 - accuracy: 0.4879 - val_loss: 1.0632 - val_accuracy: 0.4824\n",
      "Epoch 45/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.0600 - accuracy: 0.4913 - val_loss: 1.0605 - val_accuracy: 0.4858\n",
      "Epoch 46/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.0572 - accuracy: 0.4957 - val_loss: 1.0577 - val_accuracy: 0.4894\n",
      "Epoch 47/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.0544 - accuracy: 0.4998 - val_loss: 1.0550 - val_accuracy: 0.4915\n",
      "Epoch 48/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.0516 - accuracy: 0.5027 - val_loss: 1.0524 - val_accuracy: 0.4956\n",
      "Epoch 49/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.0489 - accuracy: 0.5067 - val_loss: 1.0497 - val_accuracy: 0.4999\n",
      "Epoch 50/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.0462 - accuracy: 0.5119 - val_loss: 1.0471 - val_accuracy: 0.5047\n",
      "Epoch 51/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.0435 - accuracy: 0.5155 - val_loss: 1.0446 - val_accuracy: 0.5106\n",
      "Epoch 52/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.0408 - accuracy: 0.5176 - val_loss: 1.0420 - val_accuracy: 0.5140\n",
      "Epoch 53/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.0382 - accuracy: 0.5206 - val_loss: 1.0395 - val_accuracy: 0.5153\n",
      "Epoch 54/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 0s 2ms/step - loss: 1.0356 - accuracy: 0.5253 - val_loss: 1.0370 - val_accuracy: 0.5199\n",
      "Epoch 55/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.0330 - accuracy: 0.5279 - val_loss: 1.0345 - val_accuracy: 0.5226\n",
      "Epoch 56/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.0305 - accuracy: 0.5308 - val_loss: 1.0321 - val_accuracy: 0.5253\n",
      "Epoch 57/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.0279 - accuracy: 0.5332 - val_loss: 1.0296 - val_accuracy: 0.5278\n",
      "Epoch 58/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.0254 - accuracy: 0.5366 - val_loss: 1.0272 - val_accuracy: 0.5303\n",
      "Epoch 59/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.0228 - accuracy: 0.5396 - val_loss: 1.0248 - val_accuracy: 0.5335\n",
      "Epoch 60/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.0203 - accuracy: 0.5434 - val_loss: 1.0224 - val_accuracy: 0.5342\n",
      "Epoch 61/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.0178 - accuracy: 0.5465 - val_loss: 1.0200 - val_accuracy: 0.5392\n",
      "Epoch 62/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.0154 - accuracy: 0.5499 - val_loss: 1.0177 - val_accuracy: 0.5426\n",
      "Epoch 63/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.0129 - accuracy: 0.5525 - val_loss: 1.0153 - val_accuracy: 0.5449\n",
      "Epoch 64/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.0104 - accuracy: 0.5563 - val_loss: 1.0130 - val_accuracy: 0.5467\n",
      "Epoch 65/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.0080 - accuracy: 0.5589 - val_loss: 1.0107 - val_accuracy: 0.5506\n",
      "Epoch 66/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.0056 - accuracy: 0.5637 - val_loss: 1.0084 - val_accuracy: 0.5535\n",
      "Epoch 67/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.0032 - accuracy: 0.5643 - val_loss: 1.0061 - val_accuracy: 0.5576\n",
      "Epoch 68/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 1.0008 - accuracy: 0.5679 - val_loss: 1.0039 - val_accuracy: 0.5594\n",
      "Epoch 69/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9985 - accuracy: 0.5694 - val_loss: 1.0016 - val_accuracy: 0.5619\n",
      "Epoch 70/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9961 - accuracy: 0.5752 - val_loss: 0.9994 - val_accuracy: 0.5683\n",
      "Epoch 71/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9938 - accuracy: 0.5804 - val_loss: 0.9972 - val_accuracy: 0.5708\n",
      "Epoch 72/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9915 - accuracy: 0.5826 - val_loss: 0.9950 - val_accuracy: 0.5742\n",
      "Epoch 73/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9892 - accuracy: 0.5839 - val_loss: 0.9929 - val_accuracy: 0.5779\n",
      "Epoch 74/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9869 - accuracy: 0.5856 - val_loss: 0.9907 - val_accuracy: 0.5824\n",
      "Epoch 75/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9846 - accuracy: 0.5881 - val_loss: 0.9886 - val_accuracy: 0.5833\n",
      "Epoch 76/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9824 - accuracy: 0.5924 - val_loss: 0.9865 - val_accuracy: 0.5858\n",
      "Epoch 77/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9801 - accuracy: 0.5930 - val_loss: 0.9844 - val_accuracy: 0.5881\n",
      "Epoch 78/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9779 - accuracy: 0.5958 - val_loss: 0.9824 - val_accuracy: 0.5913\n",
      "Epoch 79/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9758 - accuracy: 0.5988 - val_loss: 0.9803 - val_accuracy: 0.5931\n",
      "Epoch 80/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9736 - accuracy: 0.6013 - val_loss: 0.9783 - val_accuracy: 0.5951\n",
      "Epoch 81/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9714 - accuracy: 0.6025 - val_loss: 0.9763 - val_accuracy: 0.5974\n",
      "Epoch 82/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9693 - accuracy: 0.6052 - val_loss: 0.9743 - val_accuracy: 0.5990\n",
      "Epoch 83/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9672 - accuracy: 0.6093 - val_loss: 0.9723 - val_accuracy: 0.6017\n",
      "Epoch 84/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9651 - accuracy: 0.6104 - val_loss: 0.9704 - val_accuracy: 0.6024\n",
      "Epoch 85/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9630 - accuracy: 0.6117 - val_loss: 0.9685 - val_accuracy: 0.6056\n",
      "Epoch 86/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9610 - accuracy: 0.6137 - val_loss: 0.9666 - val_accuracy: 0.6065\n",
      "Epoch 87/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9589 - accuracy: 0.6156 - val_loss: 0.9647 - val_accuracy: 0.6076\n",
      "Epoch 88/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9569 - accuracy: 0.6171 - val_loss: 0.9628 - val_accuracy: 0.6092\n",
      "Epoch 89/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9549 - accuracy: 0.6184 - val_loss: 0.9610 - val_accuracy: 0.6115\n",
      "Epoch 90/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9529 - accuracy: 0.6185 - val_loss: 0.9591 - val_accuracy: 0.6115\n",
      "Epoch 91/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9510 - accuracy: 0.6225 - val_loss: 0.9573 - val_accuracy: 0.6140\n",
      "Epoch 92/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9490 - accuracy: 0.6239 - val_loss: 0.9556 - val_accuracy: 0.6135\n",
      "Epoch 93/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9471 - accuracy: 0.6256 - val_loss: 0.9538 - val_accuracy: 0.6167\n",
      "Epoch 94/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9452 - accuracy: 0.6274 - val_loss: 0.9520 - val_accuracy: 0.6181\n",
      "Epoch 95/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9433 - accuracy: 0.6285 - val_loss: 0.9503 - val_accuracy: 0.6201\n",
      "Epoch 96/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9414 - accuracy: 0.6305 - val_loss: 0.9486 - val_accuracy: 0.6224\n",
      "Epoch 97/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9396 - accuracy: 0.6322 - val_loss: 0.9469 - val_accuracy: 0.6213\n",
      "Epoch 98/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9377 - accuracy: 0.6325 - val_loss: 0.9452 - val_accuracy: 0.6247\n",
      "Epoch 99/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9359 - accuracy: 0.6334 - val_loss: 0.9436 - val_accuracy: 0.6242\n",
      "Epoch 100/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9341 - accuracy: 0.6347 - val_loss: 0.9419 - val_accuracy: 0.6265\n",
      "Epoch 101/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9323 - accuracy: 0.6369 - val_loss: 0.9403 - val_accuracy: 0.6270\n",
      "Epoch 102/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9305 - accuracy: 0.6378 - val_loss: 0.9387 - val_accuracy: 0.6281\n",
      "Epoch 103/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9288 - accuracy: 0.6408 - val_loss: 0.9371 - val_accuracy: 0.6286\n",
      "Epoch 104/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9270 - accuracy: 0.6407 - val_loss: 0.9356 - val_accuracy: 0.6301\n",
      "Epoch 105/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9253 - accuracy: 0.6431 - val_loss: 0.9340 - val_accuracy: 0.6313\n",
      "Epoch 106/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9236 - accuracy: 0.6438 - val_loss: 0.9325 - val_accuracy: 0.6342\n",
      "Epoch 107/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9219 - accuracy: 0.6458 - val_loss: 0.9310 - val_accuracy: 0.6374\n",
      "Epoch 108/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9203 - accuracy: 0.6472 - val_loss: 0.9295 - val_accuracy: 0.6381\n",
      "Epoch 109/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9186 - accuracy: 0.6480 - val_loss: 0.9280 - val_accuracy: 0.6376\n",
      "Epoch 110/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9170 - accuracy: 0.6488 - val_loss: 0.9265 - val_accuracy: 0.6388\n",
      "Epoch 111/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9153 - accuracy: 0.6496 - val_loss: 0.9251 - val_accuracy: 0.6390\n",
      "Epoch 112/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9137 - accuracy: 0.6499 - val_loss: 0.9236 - val_accuracy: 0.6424\n",
      "Epoch 113/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9121 - accuracy: 0.6511 - val_loss: 0.9222 - val_accuracy: 0.6431\n",
      "Epoch 114/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9106 - accuracy: 0.6526 - val_loss: 0.9208 - val_accuracy: 0.6445\n",
      "Epoch 115/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9090 - accuracy: 0.6526 - val_loss: 0.9194 - val_accuracy: 0.6451\n",
      "Epoch 116/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9074 - accuracy: 0.6539 - val_loss: 0.9180 - val_accuracy: 0.6447\n",
      "Epoch 117/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9059 - accuracy: 0.6553 - val_loss: 0.9166 - val_accuracy: 0.6449\n",
      "Epoch 118/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9044 - accuracy: 0.6560 - val_loss: 0.9153 - val_accuracy: 0.6461\n",
      "Epoch 119/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9029 - accuracy: 0.6575 - val_loss: 0.9140 - val_accuracy: 0.6458\n",
      "Epoch 120/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.9014 - accuracy: 0.6583 - val_loss: 0.9126 - val_accuracy: 0.6472\n",
      "Epoch 121/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8999 - accuracy: 0.6580 - val_loss: 0.9113 - val_accuracy: 0.6486\n",
      "Epoch 122/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8984 - accuracy: 0.6586 - val_loss: 0.9100 - val_accuracy: 0.6486\n",
      "Epoch 123/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8970 - accuracy: 0.6600 - val_loss: 0.9087 - val_accuracy: 0.6497\n",
      "Epoch 124/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8955 - accuracy: 0.6610 - val_loss: 0.9074 - val_accuracy: 0.6508\n",
      "Epoch 125/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8941 - accuracy: 0.6621 - val_loss: 0.9062 - val_accuracy: 0.6522\n",
      "Epoch 126/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8927 - accuracy: 0.6630 - val_loss: 0.9049 - val_accuracy: 0.6536\n",
      "Epoch 127/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8913 - accuracy: 0.6651 - val_loss: 0.9037 - val_accuracy: 0.6531\n",
      "Epoch 128/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8899 - accuracy: 0.6646 - val_loss: 0.9025 - val_accuracy: 0.6540\n",
      "Epoch 129/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8885 - accuracy: 0.6659 - val_loss: 0.9012 - val_accuracy: 0.6545\n",
      "Epoch 130/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8871 - accuracy: 0.6669 - val_loss: 0.9000 - val_accuracy: 0.6551\n",
      "Epoch 131/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.8858 - accuracy: 0.6671 - val_loss: 0.8988 - val_accuracy: 0.6554\n",
      "Epoch 132/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8844 - accuracy: 0.6678 - val_loss: 0.8976 - val_accuracy: 0.6556\n",
      "Epoch 133/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8831 - accuracy: 0.6679 - val_loss: 0.8964 - val_accuracy: 0.6570\n",
      "Epoch 134/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8817 - accuracy: 0.6688 - val_loss: 0.8953 - val_accuracy: 0.6572\n",
      "Epoch 135/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8804 - accuracy: 0.6699 - val_loss: 0.8941 - val_accuracy: 0.6579\n",
      "Epoch 136/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8791 - accuracy: 0.6693 - val_loss: 0.8929 - val_accuracy: 0.6586\n",
      "Epoch 137/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8778 - accuracy: 0.6704 - val_loss: 0.8918 - val_accuracy: 0.6592\n",
      "Epoch 138/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8765 - accuracy: 0.6707 - val_loss: 0.8906 - val_accuracy: 0.6599\n",
      "Epoch 139/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8752 - accuracy: 0.6712 - val_loss: 0.8895 - val_accuracy: 0.6622\n",
      "Epoch 140/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8739 - accuracy: 0.6718 - val_loss: 0.8884 - val_accuracy: 0.6624\n",
      "Epoch 141/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8727 - accuracy: 0.6716 - val_loss: 0.8873 - val_accuracy: 0.6629\n",
      "Epoch 142/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8714 - accuracy: 0.6724 - val_loss: 0.8862 - val_accuracy: 0.6631\n",
      "Epoch 143/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8702 - accuracy: 0.6727 - val_loss: 0.8851 - val_accuracy: 0.6642\n",
      "Epoch 144/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8689 - accuracy: 0.6730 - val_loss: 0.8840 - val_accuracy: 0.6649\n",
      "Epoch 145/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8677 - accuracy: 0.6732 - val_loss: 0.8829 - val_accuracy: 0.6658\n",
      "Epoch 146/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8664 - accuracy: 0.6741 - val_loss: 0.8819 - val_accuracy: 0.6658\n",
      "Epoch 147/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8652 - accuracy: 0.6737 - val_loss: 0.8808 - val_accuracy: 0.6663\n",
      "Epoch 148/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8640 - accuracy: 0.6751 - val_loss: 0.8798 - val_accuracy: 0.6663\n",
      "Epoch 149/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8628 - accuracy: 0.6758 - val_loss: 0.8787 - val_accuracy: 0.6663\n",
      "Epoch 150/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8616 - accuracy: 0.6746 - val_loss: 0.8777 - val_accuracy: 0.6663\n",
      "Epoch 151/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8604 - accuracy: 0.6757 - val_loss: 0.8766 - val_accuracy: 0.6674\n",
      "Epoch 152/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8592 - accuracy: 0.6770 - val_loss: 0.8756 - val_accuracy: 0.6747\n",
      "Epoch 153/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8581 - accuracy: 0.6807 - val_loss: 0.8746 - val_accuracy: 0.6758\n",
      "Epoch 154/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8569 - accuracy: 0.6807 - val_loss: 0.8736 - val_accuracy: 0.6754\n",
      "Epoch 155/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8558 - accuracy: 0.6816 - val_loss: 0.8726 - val_accuracy: 0.6754\n",
      "Epoch 156/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8546 - accuracy: 0.6818 - val_loss: 0.8716 - val_accuracy: 0.6756\n",
      "Epoch 157/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8535 - accuracy: 0.6815 - val_loss: 0.8706 - val_accuracy: 0.6749\n",
      "Epoch 158/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8523 - accuracy: 0.6815 - val_loss: 0.8696 - val_accuracy: 0.6761\n",
      "Epoch 159/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8512 - accuracy: 0.6824 - val_loss: 0.8686 - val_accuracy: 0.6765\n",
      "Epoch 160/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8501 - accuracy: 0.6827 - val_loss: 0.8676 - val_accuracy: 0.6772\n",
      "Epoch 161/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8490 - accuracy: 0.6828 - val_loss: 0.8667 - val_accuracy: 0.6761\n",
      "Epoch 162/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8479 - accuracy: 0.6833 - val_loss: 0.8657 - val_accuracy: 0.6779\n",
      "Epoch 163/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8468 - accuracy: 0.6837 - val_loss: 0.8648 - val_accuracy: 0.6779\n",
      "Epoch 164/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8457 - accuracy: 0.6841 - val_loss: 0.8638 - val_accuracy: 0.6783\n",
      "Epoch 165/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8446 - accuracy: 0.6847 - val_loss: 0.8629 - val_accuracy: 0.6790\n",
      "Epoch 166/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8435 - accuracy: 0.6858 - val_loss: 0.8619 - val_accuracy: 0.6792\n",
      "Epoch 167/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8424 - accuracy: 0.6861 - val_loss: 0.8610 - val_accuracy: 0.6790\n",
      "Epoch 168/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8413 - accuracy: 0.6867 - val_loss: 0.8601 - val_accuracy: 0.6792\n",
      "Epoch 169/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8403 - accuracy: 0.6874 - val_loss: 0.8591 - val_accuracy: 0.6790\n",
      "Epoch 170/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8392 - accuracy: 0.6870 - val_loss: 0.8582 - val_accuracy: 0.6806\n",
      "Epoch 171/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8381 - accuracy: 0.6882 - val_loss: 0.8573 - val_accuracy: 0.6808\n",
      "Epoch 172/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8371 - accuracy: 0.6886 - val_loss: 0.8564 - val_accuracy: 0.6806\n",
      "Epoch 173/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8360 - accuracy: 0.6885 - val_loss: 0.8555 - val_accuracy: 0.6813\n",
      "Epoch 174/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8350 - accuracy: 0.6880 - val_loss: 0.8546 - val_accuracy: 0.6817\n",
      "Epoch 175/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8340 - accuracy: 0.6880 - val_loss: 0.8537 - val_accuracy: 0.6815\n",
      "Epoch 176/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8329 - accuracy: 0.6890 - val_loss: 0.8529 - val_accuracy: 0.6815\n",
      "Epoch 177/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8319 - accuracy: 0.6890 - val_loss: 0.8520 - val_accuracy: 0.6813\n",
      "Epoch 178/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8309 - accuracy: 0.6890 - val_loss: 0.8511 - val_accuracy: 0.6820\n",
      "Epoch 179/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8299 - accuracy: 0.6898 - val_loss: 0.8503 - val_accuracy: 0.6829\n",
      "Epoch 180/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8289 - accuracy: 0.6903 - val_loss: 0.8494 - val_accuracy: 0.6836\n",
      "Epoch 181/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8279 - accuracy: 0.6908 - val_loss: 0.8485 - val_accuracy: 0.6836\n",
      "Epoch 182/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8269 - accuracy: 0.6914 - val_loss: 0.8477 - val_accuracy: 0.6833\n",
      "Epoch 183/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8259 - accuracy: 0.6918 - val_loss: 0.8468 - val_accuracy: 0.6840\n",
      "Epoch 184/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8249 - accuracy: 0.6926 - val_loss: 0.8460 - val_accuracy: 0.6842\n",
      "Epoch 185/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8239 - accuracy: 0.6934 - val_loss: 0.8452 - val_accuracy: 0.6842\n",
      "Epoch 186/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8229 - accuracy: 0.6936 - val_loss: 0.8443 - val_accuracy: 0.6856\n",
      "Epoch 187/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8220 - accuracy: 0.6956 - val_loss: 0.8435 - val_accuracy: 0.6854\n",
      "Epoch 188/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8210 - accuracy: 0.6953 - val_loss: 0.8427 - val_accuracy: 0.6861\n",
      "Epoch 189/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8200 - accuracy: 0.6958 - val_loss: 0.8419 - val_accuracy: 0.6863\n",
      "Epoch 190/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8191 - accuracy: 0.6960 - val_loss: 0.8410 - val_accuracy: 0.6865\n",
      "Epoch 191/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8181 - accuracy: 0.6968 - val_loss: 0.8403 - val_accuracy: 0.6865\n",
      "Epoch 192/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8172 - accuracy: 0.6972 - val_loss: 0.8395 - val_accuracy: 0.6863\n",
      "Epoch 193/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8162 - accuracy: 0.6971 - val_loss: 0.8387 - val_accuracy: 0.6863\n",
      "Epoch 194/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8153 - accuracy: 0.6983 - val_loss: 0.8378 - val_accuracy: 0.6867\n",
      "Epoch 195/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8144 - accuracy: 0.6989 - val_loss: 0.8370 - val_accuracy: 0.6877\n",
      "Epoch 196/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8135 - accuracy: 0.6999 - val_loss: 0.8363 - val_accuracy: 0.6879\n",
      "Epoch 197/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8125 - accuracy: 0.7002 - val_loss: 0.8355 - val_accuracy: 0.6886\n",
      "Epoch 198/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8116 - accuracy: 0.7004 - val_loss: 0.8347 - val_accuracy: 0.6886\n",
      "Epoch 199/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8107 - accuracy: 0.7011 - val_loss: 0.8339 - val_accuracy: 0.6899\n",
      "Epoch 200/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8098 - accuracy: 0.7020 - val_loss: 0.8332 - val_accuracy: 0.6897\n",
      "Epoch 201/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8089 - accuracy: 0.7024 - val_loss: 0.8324 - val_accuracy: 0.6895\n",
      "Epoch 202/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8080 - accuracy: 0.7026 - val_loss: 0.8316 - val_accuracy: 0.6892\n",
      "Epoch 203/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8071 - accuracy: 0.7044 - val_loss: 0.8309 - val_accuracy: 0.6899\n",
      "Epoch 204/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8062 - accuracy: 0.7035 - val_loss: 0.8301 - val_accuracy: 0.6902\n",
      "Epoch 205/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8053 - accuracy: 0.7049 - val_loss: 0.8293 - val_accuracy: 0.6904\n",
      "Epoch 206/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8044 - accuracy: 0.7048 - val_loss: 0.8286 - val_accuracy: 0.6906\n",
      "Epoch 207/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8035 - accuracy: 0.7048 - val_loss: 0.8278 - val_accuracy: 0.6915\n",
      "Epoch 208/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8027 - accuracy: 0.7054 - val_loss: 0.8271 - val_accuracy: 0.6917\n",
      "Epoch 209/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8018 - accuracy: 0.7060 - val_loss: 0.8263 - val_accuracy: 0.6920\n",
      "Epoch 210/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8009 - accuracy: 0.7066 - val_loss: 0.8256 - val_accuracy: 0.6920\n",
      "Epoch 211/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.8001 - accuracy: 0.7066 - val_loss: 0.8249 - val_accuracy: 0.6929\n",
      "Epoch 212/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7992 - accuracy: 0.7066 - val_loss: 0.8241 - val_accuracy: 0.6927\n",
      "Epoch 213/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7983 - accuracy: 0.7072 - val_loss: 0.8234 - val_accuracy: 0.6922\n",
      "Epoch 214/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7975 - accuracy: 0.7078 - val_loss: 0.8227 - val_accuracy: 0.6924\n",
      "Epoch 215/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7966 - accuracy: 0.7082 - val_loss: 0.8220 - val_accuracy: 0.6929\n",
      "Epoch 216/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7958 - accuracy: 0.7084 - val_loss: 0.8213 - val_accuracy: 0.6938\n",
      "Epoch 217/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7950 - accuracy: 0.7093 - val_loss: 0.8206 - val_accuracy: 0.6936\n",
      "Epoch 218/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7941 - accuracy: 0.7091 - val_loss: 0.8198 - val_accuracy: 0.6933\n",
      "Epoch 219/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7933 - accuracy: 0.7100 - val_loss: 0.8191 - val_accuracy: 0.6940\n",
      "Epoch 220/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7925 - accuracy: 0.7101 - val_loss: 0.8185 - val_accuracy: 0.6942\n",
      "Epoch 221/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7916 - accuracy: 0.7107 - val_loss: 0.8178 - val_accuracy: 0.6942\n",
      "Epoch 222/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7908 - accuracy: 0.7114 - val_loss: 0.8171 - val_accuracy: 0.6936\n",
      "Epoch 223/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7900 - accuracy: 0.7110 - val_loss: 0.8164 - val_accuracy: 0.6940\n",
      "Epoch 224/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7892 - accuracy: 0.7119 - val_loss: 0.8157 - val_accuracy: 0.6938\n",
      "Epoch 225/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7884 - accuracy: 0.7117 - val_loss: 0.8150 - val_accuracy: 0.6936\n",
      "Epoch 226/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7876 - accuracy: 0.7127 - val_loss: 0.8143 - val_accuracy: 0.6954\n",
      "Epoch 227/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7868 - accuracy: 0.7127 - val_loss: 0.8137 - val_accuracy: 0.6933\n",
      "Epoch 228/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7860 - accuracy: 0.7127 - val_loss: 0.8130 - val_accuracy: 0.6947\n",
      "Epoch 229/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7852 - accuracy: 0.7132 - val_loss: 0.8123 - val_accuracy: 0.6952\n",
      "Epoch 230/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7844 - accuracy: 0.7137 - val_loss: 0.8116 - val_accuracy: 0.6961\n",
      "Epoch 231/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7836 - accuracy: 0.7141 - val_loss: 0.8110 - val_accuracy: 0.6961\n",
      "Epoch 232/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7828 - accuracy: 0.7137 - val_loss: 0.8103 - val_accuracy: 0.6963\n",
      "Epoch 233/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7820 - accuracy: 0.7139 - val_loss: 0.8096 - val_accuracy: 0.6956\n",
      "Epoch 234/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7812 - accuracy: 0.7144 - val_loss: 0.8090 - val_accuracy: 0.6958\n",
      "Epoch 235/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7804 - accuracy: 0.7151 - val_loss: 0.8083 - val_accuracy: 0.6958\n",
      "Epoch 236/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7797 - accuracy: 0.7147 - val_loss: 0.8077 - val_accuracy: 0.6967\n",
      "Epoch 237/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7789 - accuracy: 0.7154 - val_loss: 0.8070 - val_accuracy: 0.6972\n",
      "Epoch 238/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7781 - accuracy: 0.7155 - val_loss: 0.8064 - val_accuracy: 0.6979\n",
      "Epoch 239/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7774 - accuracy: 0.7159 - val_loss: 0.8057 - val_accuracy: 0.6983\n",
      "Epoch 240/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7766 - accuracy: 0.7159 - val_loss: 0.8051 - val_accuracy: 0.6988\n",
      "Epoch 241/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7758 - accuracy: 0.7158 - val_loss: 0.8044 - val_accuracy: 0.6992\n",
      "Epoch 242/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7751 - accuracy: 0.7160 - val_loss: 0.8038 - val_accuracy: 0.6992\n",
      "Epoch 243/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7743 - accuracy: 0.7163 - val_loss: 0.8032 - val_accuracy: 0.6995\n",
      "Epoch 244/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7736 - accuracy: 0.7162 - val_loss: 0.8025 - val_accuracy: 0.6997\n",
      "Epoch 245/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7728 - accuracy: 0.7164 - val_loss: 0.8019 - val_accuracy: 0.7002\n",
      "Epoch 246/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7721 - accuracy: 0.7164 - val_loss: 0.8013 - val_accuracy: 0.7008\n",
      "Epoch 247/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7713 - accuracy: 0.7169 - val_loss: 0.8007 - val_accuracy: 0.7013\n",
      "Epoch 248/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7706 - accuracy: 0.7166 - val_loss: 0.8000 - val_accuracy: 0.7015\n",
      "Epoch 249/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7699 - accuracy: 0.7175 - val_loss: 0.7994 - val_accuracy: 0.7027\n",
      "Epoch 250/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7691 - accuracy: 0.7178 - val_loss: 0.7988 - val_accuracy: 0.7029\n",
      "Epoch 251/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7684 - accuracy: 0.7181 - val_loss: 0.7982 - val_accuracy: 0.7027\n",
      "Epoch 252/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7677 - accuracy: 0.7188 - val_loss: 0.7976 - val_accuracy: 0.7038\n",
      "Epoch 253/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7670 - accuracy: 0.7188 - val_loss: 0.7970 - val_accuracy: 0.7036\n",
      "Epoch 254/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7662 - accuracy: 0.7188 - val_loss: 0.7964 - val_accuracy: 0.7038\n",
      "Epoch 255/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7655 - accuracy: 0.7194 - val_loss: 0.7958 - val_accuracy: 0.7045\n",
      "Epoch 256/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7648 - accuracy: 0.7200 - val_loss: 0.7951 - val_accuracy: 0.7047\n",
      "Epoch 257/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7641 - accuracy: 0.7208 - val_loss: 0.7945 - val_accuracy: 0.7045\n",
      "Epoch 258/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7634 - accuracy: 0.7209 - val_loss: 0.7939 - val_accuracy: 0.7045\n",
      "Epoch 259/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7627 - accuracy: 0.7210 - val_loss: 0.7933 - val_accuracy: 0.7045\n",
      "Epoch 260/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7620 - accuracy: 0.7217 - val_loss: 0.7927 - val_accuracy: 0.7047\n",
      "Epoch 261/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7613 - accuracy: 0.7219 - val_loss: 0.7922 - val_accuracy: 0.7052\n",
      "Epoch 262/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7606 - accuracy: 0.7222 - val_loss: 0.7916 - val_accuracy: 0.7052\n",
      "Epoch 263/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7599 - accuracy: 0.7227 - val_loss: 0.7910 - val_accuracy: 0.7058\n",
      "Epoch 264/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7592 - accuracy: 0.7230 - val_loss: 0.7904 - val_accuracy: 0.7056\n",
      "Epoch 265/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7585 - accuracy: 0.7232 - val_loss: 0.7898 - val_accuracy: 0.7052\n",
      "Epoch 266/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7578 - accuracy: 0.7240 - val_loss: 0.7893 - val_accuracy: 0.7058\n",
      "Epoch 267/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7571 - accuracy: 0.7232 - val_loss: 0.7887 - val_accuracy: 0.7056\n",
      "Epoch 268/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7565 - accuracy: 0.7246 - val_loss: 0.7881 - val_accuracy: 0.7056\n",
      "Epoch 269/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7558 - accuracy: 0.7252 - val_loss: 0.7875 - val_accuracy: 0.7063\n",
      "Epoch 270/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7551 - accuracy: 0.7253 - val_loss: 0.7870 - val_accuracy: 0.7061\n",
      "Epoch 271/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7544 - accuracy: 0.7256 - val_loss: 0.7864 - val_accuracy: 0.7063\n",
      "Epoch 272/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7537 - accuracy: 0.7259 - val_loss: 0.7858 - val_accuracy: 0.7061\n",
      "Epoch 273/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7531 - accuracy: 0.7260 - val_loss: 0.7852 - val_accuracy: 0.7063\n",
      "Epoch 274/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7524 - accuracy: 0.7264 - val_loss: 0.7847 - val_accuracy: 0.7077\n",
      "Epoch 275/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7518 - accuracy: 0.7264 - val_loss: 0.7841 - val_accuracy: 0.7070\n",
      "Epoch 276/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7511 - accuracy: 0.7262 - val_loss: 0.7836 - val_accuracy: 0.7074\n",
      "Epoch 277/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7504 - accuracy: 0.7269 - val_loss: 0.7830 - val_accuracy: 0.7077\n",
      "Epoch 278/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7498 - accuracy: 0.7269 - val_loss: 0.7825 - val_accuracy: 0.7088\n",
      "Epoch 279/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7491 - accuracy: 0.7269 - val_loss: 0.7819 - val_accuracy: 0.7093\n",
      "Epoch 280/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7485 - accuracy: 0.7272 - val_loss: 0.7813 - val_accuracy: 0.7095\n",
      "Epoch 281/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7478 - accuracy: 0.7271 - val_loss: 0.7808 - val_accuracy: 0.7099\n",
      "Epoch 282/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7471 - accuracy: 0.7278 - val_loss: 0.7802 - val_accuracy: 0.7097\n",
      "Epoch 283/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7465 - accuracy: 0.7274 - val_loss: 0.7797 - val_accuracy: 0.7104\n",
      "Epoch 284/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7459 - accuracy: 0.7274 - val_loss: 0.7791 - val_accuracy: 0.7111\n",
      "Epoch 285/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7452 - accuracy: 0.7280 - val_loss: 0.7786 - val_accuracy: 0.7113\n",
      "Epoch 286/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7446 - accuracy: 0.7281 - val_loss: 0.7781 - val_accuracy: 0.7106\n",
      "Epoch 287/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7440 - accuracy: 0.7287 - val_loss: 0.7775 - val_accuracy: 0.7108\n",
      "Epoch 288/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7433 - accuracy: 0.7289 - val_loss: 0.7770 - val_accuracy: 0.7115\n",
      "Epoch 289/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7427 - accuracy: 0.7293 - val_loss: 0.7765 - val_accuracy: 0.7118\n",
      "Epoch 290/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7420 - accuracy: 0.7297 - val_loss: 0.7760 - val_accuracy: 0.7118\n",
      "Epoch 291/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7414 - accuracy: 0.7296 - val_loss: 0.7754 - val_accuracy: 0.7118\n",
      "Epoch 292/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7408 - accuracy: 0.7299 - val_loss: 0.7749 - val_accuracy: 0.7120\n",
      "Epoch 293/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7402 - accuracy: 0.7301 - val_loss: 0.7744 - val_accuracy: 0.7127\n",
      "Epoch 294/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7396 - accuracy: 0.7302 - val_loss: 0.7739 - val_accuracy: 0.7129\n",
      "Epoch 295/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.7389 - accuracy: 0.7305 - val_loss: 0.7734 - val_accuracy: 0.7122\n",
      "Epoch 296/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7383 - accuracy: 0.7305 - val_loss: 0.7728 - val_accuracy: 0.7129\n",
      "Epoch 297/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7377 - accuracy: 0.7309 - val_loss: 0.7723 - val_accuracy: 0.7129\n",
      "Epoch 298/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7371 - accuracy: 0.7310 - val_loss: 0.7718 - val_accuracy: 0.7131\n",
      "Epoch 299/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7312 - val_loss: 0.7713 - val_accuracy: 0.7129\n",
      "Epoch 300/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7312 - val_loss: 0.7708 - val_accuracy: 0.7131\n",
      "Epoch 301/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7313 - val_loss: 0.7703 - val_accuracy: 0.7129\n",
      "Epoch 302/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7317 - val_loss: 0.7698 - val_accuracy: 0.7133\n",
      "Epoch 303/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7341 - accuracy: 0.7318 - val_loss: 0.7693 - val_accuracy: 0.7138\n",
      "Epoch 304/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7335 - accuracy: 0.7322 - val_loss: 0.7688 - val_accuracy: 0.7147\n",
      "Epoch 305/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7329 - accuracy: 0.7329 - val_loss: 0.7683 - val_accuracy: 0.7138\n",
      "Epoch 306/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7324 - accuracy: 0.7325 - val_loss: 0.7678 - val_accuracy: 0.7143\n",
      "Epoch 307/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7318 - accuracy: 0.7326 - val_loss: 0.7674 - val_accuracy: 0.7147\n",
      "Epoch 308/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7312 - accuracy: 0.7331 - val_loss: 0.7669 - val_accuracy: 0.7154\n",
      "Epoch 309/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7306 - accuracy: 0.7328 - val_loss: 0.7664 - val_accuracy: 0.7161\n",
      "Epoch 310/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7300 - accuracy: 0.7332 - val_loss: 0.7659 - val_accuracy: 0.7161\n",
      "Epoch 311/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7295 - accuracy: 0.7341 - val_loss: 0.7655 - val_accuracy: 0.7168\n",
      "Epoch 312/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7289 - accuracy: 0.7342 - val_loss: 0.7650 - val_accuracy: 0.7168\n",
      "Epoch 313/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7283 - accuracy: 0.7346 - val_loss: 0.7645 - val_accuracy: 0.7172\n",
      "Epoch 314/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7278 - accuracy: 0.7351 - val_loss: 0.7640 - val_accuracy: 0.7181\n",
      "Epoch 315/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7272 - accuracy: 0.7351 - val_loss: 0.7636 - val_accuracy: 0.7181\n",
      "Epoch 316/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7266 - accuracy: 0.7354 - val_loss: 0.7631 - val_accuracy: 0.7179\n",
      "Epoch 317/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7261 - accuracy: 0.7359 - val_loss: 0.7626 - val_accuracy: 0.7179\n",
      "Epoch 318/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7255 - accuracy: 0.7362 - val_loss: 0.7622 - val_accuracy: 0.7186\n",
      "Epoch 319/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7250 - accuracy: 0.7361 - val_loss: 0.7617 - val_accuracy: 0.7190\n",
      "Epoch 320/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7244 - accuracy: 0.7364 - val_loss: 0.7613 - val_accuracy: 0.7193\n",
      "Epoch 321/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7239 - accuracy: 0.7368 - val_loss: 0.7608 - val_accuracy: 0.7193\n",
      "Epoch 322/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7233 - accuracy: 0.7366 - val_loss: 0.7603 - val_accuracy: 0.7199\n",
      "Epoch 323/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7228 - accuracy: 0.7368 - val_loss: 0.7599 - val_accuracy: 0.7190\n",
      "Epoch 324/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7222 - accuracy: 0.7371 - val_loss: 0.7595 - val_accuracy: 0.7190\n",
      "Epoch 325/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7217 - accuracy: 0.7376 - val_loss: 0.7590 - val_accuracy: 0.7193\n",
      "Epoch 326/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7211 - accuracy: 0.7372 - val_loss: 0.7585 - val_accuracy: 0.7204\n",
      "Epoch 327/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7206 - accuracy: 0.7384 - val_loss: 0.7581 - val_accuracy: 0.7202\n",
      "Epoch 328/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7200 - accuracy: 0.7376 - val_loss: 0.7577 - val_accuracy: 0.7204\n",
      "Epoch 329/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7195 - accuracy: 0.7381 - val_loss: 0.7572 - val_accuracy: 0.7199\n",
      "Epoch 330/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7190 - accuracy: 0.7380 - val_loss: 0.7568 - val_accuracy: 0.7208\n",
      "Epoch 331/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7184 - accuracy: 0.7384 - val_loss: 0.7564 - val_accuracy: 0.7202\n",
      "Epoch 332/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7179 - accuracy: 0.7379 - val_loss: 0.7559 - val_accuracy: 0.7199\n",
      "Epoch 333/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7174 - accuracy: 0.7382 - val_loss: 0.7555 - val_accuracy: 0.7204\n",
      "Epoch 334/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7169 - accuracy: 0.7386 - val_loss: 0.7551 - val_accuracy: 0.7211\n",
      "Epoch 335/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7163 - accuracy: 0.7389 - val_loss: 0.7547 - val_accuracy: 0.7204\n",
      "Epoch 336/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7158 - accuracy: 0.7390 - val_loss: 0.7542 - val_accuracy: 0.7204\n",
      "Epoch 337/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7153 - accuracy: 0.7392 - val_loss: 0.7538 - val_accuracy: 0.7204\n",
      "Epoch 338/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7148 - accuracy: 0.7390 - val_loss: 0.7534 - val_accuracy: 0.7204\n",
      "Epoch 339/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7143 - accuracy: 0.7389 - val_loss: 0.7530 - val_accuracy: 0.7215\n",
      "Epoch 340/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7137 - accuracy: 0.7394 - val_loss: 0.7526 - val_accuracy: 0.7211\n",
      "Epoch 341/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7132 - accuracy: 0.7399 - val_loss: 0.7521 - val_accuracy: 0.7213\n",
      "Epoch 342/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7127 - accuracy: 0.7401 - val_loss: 0.7517 - val_accuracy: 0.7231\n",
      "Epoch 343/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7122 - accuracy: 0.7400 - val_loss: 0.7513 - val_accuracy: 0.7224\n",
      "Epoch 344/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7117 - accuracy: 0.7405 - val_loss: 0.7509 - val_accuracy: 0.7222\n",
      "Epoch 345/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7112 - accuracy: 0.7407 - val_loss: 0.7505 - val_accuracy: 0.7220\n",
      "Epoch 346/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7107 - accuracy: 0.7408 - val_loss: 0.7501 - val_accuracy: 0.7224\n",
      "Epoch 347/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7102 - accuracy: 0.7412 - val_loss: 0.7497 - val_accuracy: 0.7229\n",
      "Epoch 348/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7097 - accuracy: 0.7415 - val_loss: 0.7493 - val_accuracy: 0.7238\n",
      "Epoch 349/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7092 - accuracy: 0.7423 - val_loss: 0.7489 - val_accuracy: 0.7236\n",
      "Epoch 350/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7087 - accuracy: 0.7422 - val_loss: 0.7485 - val_accuracy: 0.7243\n",
      "Epoch 351/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7082 - accuracy: 0.7420 - val_loss: 0.7481 - val_accuracy: 0.7243\n",
      "Epoch 352/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7077 - accuracy: 0.7422 - val_loss: 0.7477 - val_accuracy: 0.7245\n",
      "Epoch 353/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7072 - accuracy: 0.7423 - val_loss: 0.7473 - val_accuracy: 0.7243\n",
      "Epoch 354/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7067 - accuracy: 0.7425 - val_loss: 0.7469 - val_accuracy: 0.7256\n",
      "Epoch 355/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7063 - accuracy: 0.7435 - val_loss: 0.7465 - val_accuracy: 0.7256\n",
      "Epoch 356/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7058 - accuracy: 0.7434 - val_loss: 0.7461 - val_accuracy: 0.7252\n",
      "Epoch 357/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7053 - accuracy: 0.7433 - val_loss: 0.7458 - val_accuracy: 0.7261\n",
      "Epoch 358/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7048 - accuracy: 0.7434 - val_loss: 0.7454 - val_accuracy: 0.7258\n",
      "Epoch 359/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7043 - accuracy: 0.7437 - val_loss: 0.7450 - val_accuracy: 0.7265\n",
      "Epoch 360/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7038 - accuracy: 0.7438 - val_loss: 0.7446 - val_accuracy: 0.7256\n",
      "Epoch 361/2000\n",
      "138/138 [==============================] - 1s 4ms/step - loss: 0.7034 - accuracy: 0.7436 - val_loss: 0.7442 - val_accuracy: 0.7261\n",
      "Epoch 362/2000\n",
      "138/138 [==============================] - 1s 4ms/step - loss: 0.7029 - accuracy: 0.7438 - val_loss: 0.7439 - val_accuracy: 0.7270\n",
      "Epoch 363/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7025 - accuracy: 0.7442 - val_loss: 0.7435 - val_accuracy: 0.7270\n",
      "Epoch 364/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7020 - accuracy: 0.7444 - val_loss: 0.7431 - val_accuracy: 0.7270\n",
      "Epoch 365/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7015 - accuracy: 0.7452 - val_loss: 0.7427 - val_accuracy: 0.7265\n",
      "Epoch 366/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7010 - accuracy: 0.7452 - val_loss: 0.7424 - val_accuracy: 0.7277\n",
      "Epoch 367/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7006 - accuracy: 0.7457 - val_loss: 0.7420 - val_accuracy: 0.7272\n",
      "Epoch 368/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.7001 - accuracy: 0.7458 - val_loss: 0.7417 - val_accuracy: 0.7274\n",
      "Epoch 369/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6997 - accuracy: 0.7460 - val_loss: 0.7413 - val_accuracy: 0.7279\n",
      "Epoch 370/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6992 - accuracy: 0.7461 - val_loss: 0.7409 - val_accuracy: 0.7281\n",
      "Epoch 371/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6987 - accuracy: 0.7469 - val_loss: 0.7406 - val_accuracy: 0.7286\n",
      "Epoch 372/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6983 - accuracy: 0.7469 - val_loss: 0.7402 - val_accuracy: 0.7281\n",
      "Epoch 373/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6978 - accuracy: 0.7467 - val_loss: 0.7398 - val_accuracy: 0.7290\n",
      "Epoch 374/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6974 - accuracy: 0.7472 - val_loss: 0.7395 - val_accuracy: 0.7290\n",
      "Epoch 375/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6969 - accuracy: 0.7473 - val_loss: 0.7391 - val_accuracy: 0.7293\n",
      "Epoch 376/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6965 - accuracy: 0.7477 - val_loss: 0.7388 - val_accuracy: 0.7290\n",
      "Epoch 377/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6960 - accuracy: 0.7480 - val_loss: 0.7384 - val_accuracy: 0.7293\n",
      "Epoch 378/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6955 - accuracy: 0.7482 - val_loss: 0.7380 - val_accuracy: 0.7288\n",
      "Epoch 379/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6951 - accuracy: 0.7482 - val_loss: 0.7377 - val_accuracy: 0.7297\n",
      "Epoch 380/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6947 - accuracy: 0.7486 - val_loss: 0.7373 - val_accuracy: 0.7299\n",
      "Epoch 381/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6942 - accuracy: 0.7489 - val_loss: 0.7369 - val_accuracy: 0.7295\n",
      "Epoch 382/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.7492 - val_loss: 0.7366 - val_accuracy: 0.7306\n",
      "Epoch 383/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.7493 - val_loss: 0.7363 - val_accuracy: 0.7311\n",
      "Epoch 384/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.7491 - val_loss: 0.7359 - val_accuracy: 0.7311\n",
      "Epoch 385/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6924 - accuracy: 0.7493 - val_loss: 0.7356 - val_accuracy: 0.7311\n",
      "Epoch 386/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6920 - accuracy: 0.7494 - val_loss: 0.7352 - val_accuracy: 0.7315\n",
      "Epoch 387/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6916 - accuracy: 0.7498 - val_loss: 0.7349 - val_accuracy: 0.7313\n",
      "Epoch 388/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6911 - accuracy: 0.7500 - val_loss: 0.7345 - val_accuracy: 0.7318\n",
      "Epoch 389/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6907 - accuracy: 0.7497 - val_loss: 0.7342 - val_accuracy: 0.7324\n",
      "Epoch 390/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6903 - accuracy: 0.7504 - val_loss: 0.7339 - val_accuracy: 0.7322\n",
      "Epoch 391/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6898 - accuracy: 0.7504 - val_loss: 0.7335 - val_accuracy: 0.7324\n",
      "Epoch 392/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6894 - accuracy: 0.7505 - val_loss: 0.7332 - val_accuracy: 0.7329\n",
      "Epoch 393/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6890 - accuracy: 0.7510 - val_loss: 0.7328 - val_accuracy: 0.7329\n",
      "Epoch 394/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6885 - accuracy: 0.7506 - val_loss: 0.7325 - val_accuracy: 0.7333\n",
      "Epoch 395/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6881 - accuracy: 0.7510 - val_loss: 0.7322 - val_accuracy: 0.7338\n",
      "Epoch 396/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6877 - accuracy: 0.7512 - val_loss: 0.7318 - val_accuracy: 0.7333\n",
      "Epoch 397/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6872 - accuracy: 0.7516 - val_loss: 0.7315 - val_accuracy: 0.7331\n",
      "Epoch 398/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6868 - accuracy: 0.7517 - val_loss: 0.7311 - val_accuracy: 0.7338\n",
      "Epoch 399/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6864 - accuracy: 0.7517 - val_loss: 0.7308 - val_accuracy: 0.7324\n",
      "Epoch 400/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6859 - accuracy: 0.7526 - val_loss: 0.7305 - val_accuracy: 0.7333\n",
      "Epoch 401/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6855 - accuracy: 0.7520 - val_loss: 0.7301 - val_accuracy: 0.7329\n",
      "Epoch 402/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6851 - accuracy: 0.7526 - val_loss: 0.7298 - val_accuracy: 0.7340\n",
      "Epoch 403/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6846 - accuracy: 0.7529 - val_loss: 0.7295 - val_accuracy: 0.7343\n",
      "Epoch 404/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6842 - accuracy: 0.7528 - val_loss: 0.7291 - val_accuracy: 0.7345\n",
      "Epoch 405/2000\n",
      "138/138 [==============================] - 1s 4ms/step - loss: 0.6838 - accuracy: 0.7529 - val_loss: 0.7288 - val_accuracy: 0.7345\n",
      "Epoch 406/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6834 - accuracy: 0.7531 - val_loss: 0.7285 - val_accuracy: 0.7340\n",
      "Epoch 407/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6829 - accuracy: 0.7535 - val_loss: 0.7281 - val_accuracy: 0.7345\n",
      "Epoch 408/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6825 - accuracy: 0.7529 - val_loss: 0.7278 - val_accuracy: 0.7343\n",
      "Epoch 409/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6821 - accuracy: 0.7535 - val_loss: 0.7275 - val_accuracy: 0.7347\n",
      "Epoch 410/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6816 - accuracy: 0.7534 - val_loss: 0.7271 - val_accuracy: 0.7352\n",
      "Epoch 411/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6811 - accuracy: 0.7535 - val_loss: 0.7267 - val_accuracy: 0.7349\n",
      "Epoch 412/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6807 - accuracy: 0.7540 - val_loss: 0.7263 - val_accuracy: 0.7358\n",
      "Epoch 413/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6802 - accuracy: 0.7537 - val_loss: 0.7260 - val_accuracy: 0.7356\n",
      "Epoch 414/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6798 - accuracy: 0.7538 - val_loss: 0.7257 - val_accuracy: 0.7365\n",
      "Epoch 415/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6793 - accuracy: 0.7540 - val_loss: 0.7253 - val_accuracy: 0.7354\n",
      "Epoch 416/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6789 - accuracy: 0.7545 - val_loss: 0.7250 - val_accuracy: 0.7361\n",
      "Epoch 417/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6785 - accuracy: 0.7546 - val_loss: 0.7246 - val_accuracy: 0.7365\n",
      "Epoch 418/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6780 - accuracy: 0.7542 - val_loss: 0.7243 - val_accuracy: 0.7368\n",
      "Epoch 419/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6776 - accuracy: 0.7547 - val_loss: 0.7240 - val_accuracy: 0.7365\n",
      "Epoch 420/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6772 - accuracy: 0.7548 - val_loss: 0.7236 - val_accuracy: 0.7374\n",
      "Epoch 421/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6768 - accuracy: 0.7550 - val_loss: 0.7233 - val_accuracy: 0.7374\n",
      "Epoch 422/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6763 - accuracy: 0.7549 - val_loss: 0.7230 - val_accuracy: 0.7372\n",
      "Epoch 423/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6759 - accuracy: 0.7551 - val_loss: 0.7226 - val_accuracy: 0.7370\n",
      "Epoch 424/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6754 - accuracy: 0.7552 - val_loss: 0.7223 - val_accuracy: 0.7377\n",
      "Epoch 425/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6750 - accuracy: 0.7558 - val_loss: 0.7219 - val_accuracy: 0.7374\n",
      "Epoch 426/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6746 - accuracy: 0.7555 - val_loss: 0.7216 - val_accuracy: 0.7377\n",
      "Epoch 427/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6742 - accuracy: 0.7555 - val_loss: 0.7213 - val_accuracy: 0.7374\n",
      "Epoch 428/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6737 - accuracy: 0.7556 - val_loss: 0.7209 - val_accuracy: 0.7372\n",
      "Epoch 429/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6733 - accuracy: 0.7560 - val_loss: 0.7206 - val_accuracy: 0.7372\n",
      "Epoch 430/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6729 - accuracy: 0.7568 - val_loss: 0.7203 - val_accuracy: 0.7372\n",
      "Epoch 431/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6725 - accuracy: 0.7572 - val_loss: 0.7199 - val_accuracy: 0.7390\n",
      "Epoch 432/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6720 - accuracy: 0.7573 - val_loss: 0.7196 - val_accuracy: 0.7381\n",
      "Epoch 433/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6716 - accuracy: 0.7580 - val_loss: 0.7192 - val_accuracy: 0.7377\n",
      "Epoch 434/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6712 - accuracy: 0.7581 - val_loss: 0.7189 - val_accuracy: 0.7377\n",
      "Epoch 435/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6708 - accuracy: 0.7584 - val_loss: 0.7186 - val_accuracy: 0.7379\n",
      "Epoch 436/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6703 - accuracy: 0.7588 - val_loss: 0.7182 - val_accuracy: 0.7374\n",
      "Epoch 437/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6699 - accuracy: 0.7589 - val_loss: 0.7179 - val_accuracy: 0.7377\n",
      "Epoch 438/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6695 - accuracy: 0.7594 - val_loss: 0.7175 - val_accuracy: 0.7383\n",
      "Epoch 439/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6690 - accuracy: 0.7594 - val_loss: 0.7172 - val_accuracy: 0.7374\n",
      "Epoch 440/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6686 - accuracy: 0.7600 - val_loss: 0.7168 - val_accuracy: 0.7381\n",
      "Epoch 441/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6682 - accuracy: 0.7603 - val_loss: 0.7165 - val_accuracy: 0.7381\n",
      "Epoch 442/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6678 - accuracy: 0.7603 - val_loss: 0.7162 - val_accuracy: 0.7383\n",
      "Epoch 443/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6673 - accuracy: 0.7607 - val_loss: 0.7159 - val_accuracy: 0.7383\n",
      "Epoch 444/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6669 - accuracy: 0.7611 - val_loss: 0.7155 - val_accuracy: 0.7383\n",
      "Epoch 445/2000\n",
      "138/138 [==============================] - 1s 4ms/step - loss: 0.6665 - accuracy: 0.7611 - val_loss: 0.7152 - val_accuracy: 0.7383\n",
      "Epoch 446/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6660 - accuracy: 0.7610 - val_loss: 0.7148 - val_accuracy: 0.7390\n",
      "Epoch 447/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6656 - accuracy: 0.7616 - val_loss: 0.7145 - val_accuracy: 0.7390\n",
      "Epoch 448/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6652 - accuracy: 0.7614 - val_loss: 0.7142 - val_accuracy: 0.7390\n",
      "Epoch 449/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6647 - accuracy: 0.7619 - val_loss: 0.7138 - val_accuracy: 0.7390\n",
      "Epoch 450/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6643 - accuracy: 0.7621 - val_loss: 0.7134 - val_accuracy: 0.7390\n",
      "Epoch 451/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6638 - accuracy: 0.7624 - val_loss: 0.7131 - val_accuracy: 0.7390\n",
      "Epoch 452/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.6634 - accuracy: 0.7625 - val_loss: 0.7127 - val_accuracy: 0.7383\n",
      "Epoch 453/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6630 - accuracy: 0.7633 - val_loss: 0.7124 - val_accuracy: 0.7395\n",
      "Epoch 454/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6625 - accuracy: 0.7634 - val_loss: 0.7120 - val_accuracy: 0.7397\n",
      "Epoch 455/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6621 - accuracy: 0.7635 - val_loss: 0.7117 - val_accuracy: 0.7402\n",
      "Epoch 456/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6616 - accuracy: 0.7637 - val_loss: 0.7113 - val_accuracy: 0.7388\n",
      "Epoch 457/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6612 - accuracy: 0.7639 - val_loss: 0.7109 - val_accuracy: 0.7390\n",
      "Epoch 458/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6607 - accuracy: 0.7642 - val_loss: 0.7106 - val_accuracy: 0.7388\n",
      "Epoch 459/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6603 - accuracy: 0.7644 - val_loss: 0.7102 - val_accuracy: 0.7393\n",
      "Epoch 460/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6598 - accuracy: 0.7648 - val_loss: 0.7099 - val_accuracy: 0.7390\n",
      "Epoch 461/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6594 - accuracy: 0.7659 - val_loss: 0.7095 - val_accuracy: 0.7390\n",
      "Epoch 462/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6589 - accuracy: 0.7650 - val_loss: 0.7092 - val_accuracy: 0.7390\n",
      "Epoch 463/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6585 - accuracy: 0.7652 - val_loss: 0.7088 - val_accuracy: 0.7395\n",
      "Epoch 464/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6580 - accuracy: 0.7659 - val_loss: 0.7084 - val_accuracy: 0.7404\n",
      "Epoch 465/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6576 - accuracy: 0.7658 - val_loss: 0.7080 - val_accuracy: 0.7397\n",
      "Epoch 466/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6571 - accuracy: 0.7660 - val_loss: 0.7077 - val_accuracy: 0.7399\n",
      "Epoch 467/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6567 - accuracy: 0.7667 - val_loss: 0.7073 - val_accuracy: 0.7395\n",
      "Epoch 468/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6562 - accuracy: 0.7663 - val_loss: 0.7070 - val_accuracy: 0.7395\n",
      "Epoch 469/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6558 - accuracy: 0.7671 - val_loss: 0.7066 - val_accuracy: 0.7395\n",
      "Epoch 470/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6553 - accuracy: 0.7668 - val_loss: 0.7062 - val_accuracy: 0.7395\n",
      "Epoch 471/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6549 - accuracy: 0.7675 - val_loss: 0.7059 - val_accuracy: 0.7397\n",
      "Epoch 472/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6544 - accuracy: 0.7676 - val_loss: 0.7055 - val_accuracy: 0.7395\n",
      "Epoch 473/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6540 - accuracy: 0.7683 - val_loss: 0.7051 - val_accuracy: 0.7395\n",
      "Epoch 474/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6535 - accuracy: 0.7680 - val_loss: 0.7047 - val_accuracy: 0.7402\n",
      "Epoch 475/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6531 - accuracy: 0.7685 - val_loss: 0.7044 - val_accuracy: 0.7406\n",
      "Epoch 476/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6526 - accuracy: 0.7684 - val_loss: 0.7039 - val_accuracy: 0.7402\n",
      "Epoch 477/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6522 - accuracy: 0.7688 - val_loss: 0.7036 - val_accuracy: 0.7406\n",
      "Epoch 478/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6517 - accuracy: 0.7688 - val_loss: 0.7032 - val_accuracy: 0.7397\n",
      "Epoch 479/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6513 - accuracy: 0.7689 - val_loss: 0.7028 - val_accuracy: 0.7402\n",
      "Epoch 480/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6508 - accuracy: 0.7689 - val_loss: 0.7024 - val_accuracy: 0.7409\n",
      "Epoch 481/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6503 - accuracy: 0.7692 - val_loss: 0.7020 - val_accuracy: 0.7413\n",
      "Epoch 482/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6498 - accuracy: 0.7693 - val_loss: 0.7017 - val_accuracy: 0.7415\n",
      "Epoch 483/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6494 - accuracy: 0.7696 - val_loss: 0.7013 - val_accuracy: 0.7418\n",
      "Epoch 484/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6489 - accuracy: 0.7697 - val_loss: 0.7009 - val_accuracy: 0.7411\n",
      "Epoch 485/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6484 - accuracy: 0.7697 - val_loss: 0.7005 - val_accuracy: 0.7415\n",
      "Epoch 486/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6480 - accuracy: 0.7705 - val_loss: 0.7001 - val_accuracy: 0.7415\n",
      "Epoch 487/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6475 - accuracy: 0.7703 - val_loss: 0.6997 - val_accuracy: 0.7413\n",
      "Epoch 488/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6470 - accuracy: 0.7708 - val_loss: 0.6993 - val_accuracy: 0.7418\n",
      "Epoch 489/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6466 - accuracy: 0.7708 - val_loss: 0.6989 - val_accuracy: 0.7422\n",
      "Epoch 490/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.6461 - accuracy: 0.7713 - val_loss: 0.6986 - val_accuracy: 0.7418\n",
      "Epoch 491/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.6456 - accuracy: 0.7718 - val_loss: 0.6982 - val_accuracy: 0.7427\n",
      "Epoch 492/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6452 - accuracy: 0.7716 - val_loss: 0.6978 - val_accuracy: 0.7434\n",
      "Epoch 493/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6447 - accuracy: 0.7724 - val_loss: 0.6974 - val_accuracy: 0.7436\n",
      "Epoch 494/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6442 - accuracy: 0.7724 - val_loss: 0.6970 - val_accuracy: 0.7440\n",
      "Epoch 495/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6438 - accuracy: 0.7722 - val_loss: 0.6966 - val_accuracy: 0.7440\n",
      "Epoch 496/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6433 - accuracy: 0.7725 - val_loss: 0.6962 - val_accuracy: 0.7438\n",
      "Epoch 497/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6428 - accuracy: 0.7730 - val_loss: 0.6958 - val_accuracy: 0.7445\n",
      "Epoch 498/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6423 - accuracy: 0.7735 - val_loss: 0.6954 - val_accuracy: 0.7449\n",
      "Epoch 499/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6418 - accuracy: 0.7734 - val_loss: 0.6950 - val_accuracy: 0.7452\n",
      "Epoch 500/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6413 - accuracy: 0.7734 - val_loss: 0.6946 - val_accuracy: 0.7456\n",
      "Epoch 501/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6408 - accuracy: 0.7743 - val_loss: 0.6942 - val_accuracy: 0.7463\n",
      "Epoch 502/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6404 - accuracy: 0.7742 - val_loss: 0.6938 - val_accuracy: 0.7461\n",
      "Epoch 503/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6399 - accuracy: 0.7742 - val_loss: 0.6934 - val_accuracy: 0.7459\n",
      "Epoch 504/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6394 - accuracy: 0.7750 - val_loss: 0.6930 - val_accuracy: 0.7463\n",
      "Epoch 505/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6390 - accuracy: 0.7751 - val_loss: 0.6927 - val_accuracy: 0.7465\n",
      "Epoch 506/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6385 - accuracy: 0.7749 - val_loss: 0.6922 - val_accuracy: 0.7465\n",
      "Epoch 507/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6380 - accuracy: 0.7751 - val_loss: 0.6918 - val_accuracy: 0.7470\n",
      "Epoch 508/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6375 - accuracy: 0.7751 - val_loss: 0.6914 - val_accuracy: 0.7470\n",
      "Epoch 509/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6370 - accuracy: 0.7759 - val_loss: 0.6910 - val_accuracy: 0.7468\n",
      "Epoch 510/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6365 - accuracy: 0.7757 - val_loss: 0.6906 - val_accuracy: 0.7468\n",
      "Epoch 511/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6360 - accuracy: 0.7762 - val_loss: 0.6902 - val_accuracy: 0.7465\n",
      "Epoch 512/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6356 - accuracy: 0.7762 - val_loss: 0.6898 - val_accuracy: 0.7461\n",
      "Epoch 513/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6351 - accuracy: 0.7771 - val_loss: 0.6894 - val_accuracy: 0.7472\n",
      "Epoch 514/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6346 - accuracy: 0.7770 - val_loss: 0.6890 - val_accuracy: 0.7468\n",
      "Epoch 515/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6341 - accuracy: 0.7774 - val_loss: 0.6887 - val_accuracy: 0.7470\n",
      "Epoch 516/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6336 - accuracy: 0.7773 - val_loss: 0.6883 - val_accuracy: 0.7474\n",
      "Epoch 517/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6331 - accuracy: 0.7780 - val_loss: 0.6878 - val_accuracy: 0.7481\n",
      "Epoch 518/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.7782 - val_loss: 0.6875 - val_accuracy: 0.7484\n",
      "Epoch 519/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.7782 - val_loss: 0.6870 - val_accuracy: 0.7488\n",
      "Epoch 520/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6316 - accuracy: 0.7787 - val_loss: 0.6866 - val_accuracy: 0.7481\n",
      "Epoch 521/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6311 - accuracy: 0.7789 - val_loss: 0.6862 - val_accuracy: 0.7484\n",
      "Epoch 522/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6307 - accuracy: 0.7789 - val_loss: 0.6858 - val_accuracy: 0.7474\n",
      "Epoch 523/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6302 - accuracy: 0.7790 - val_loss: 0.6854 - val_accuracy: 0.7479\n",
      "Epoch 524/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6297 - accuracy: 0.7789 - val_loss: 0.6850 - val_accuracy: 0.7484\n",
      "Epoch 525/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6292 - accuracy: 0.7795 - val_loss: 0.6846 - val_accuracy: 0.7488\n",
      "Epoch 526/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6287 - accuracy: 0.7795 - val_loss: 0.6842 - val_accuracy: 0.7488\n",
      "Epoch 527/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6282 - accuracy: 0.7803 - val_loss: 0.6838 - val_accuracy: 0.7479\n",
      "Epoch 528/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6277 - accuracy: 0.7804 - val_loss: 0.6834 - val_accuracy: 0.7486\n",
      "Epoch 529/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6272 - accuracy: 0.7801 - val_loss: 0.6830 - val_accuracy: 0.7484\n",
      "Epoch 530/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6267 - accuracy: 0.7801 - val_loss: 0.6826 - val_accuracy: 0.7484\n",
      "Epoch 531/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6262 - accuracy: 0.7813 - val_loss: 0.6822 - val_accuracy: 0.7474\n",
      "Epoch 532/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6257 - accuracy: 0.7801 - val_loss: 0.6818 - val_accuracy: 0.7477\n",
      "Epoch 533/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6252 - accuracy: 0.7803 - val_loss: 0.6813 - val_accuracy: 0.7477\n",
      "Epoch 534/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.6247 - accuracy: 0.7805 - val_loss: 0.6810 - val_accuracy: 0.7477\n",
      "Epoch 535/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6242 - accuracy: 0.7807 - val_loss: 0.6805 - val_accuracy: 0.7472\n",
      "Epoch 536/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6237 - accuracy: 0.7808 - val_loss: 0.6801 - val_accuracy: 0.7472\n",
      "Epoch 537/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6232 - accuracy: 0.7806 - val_loss: 0.6797 - val_accuracy: 0.7479\n",
      "Epoch 538/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.6227 - accuracy: 0.7809 - val_loss: 0.6793 - val_accuracy: 0.7486\n",
      "Epoch 539/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6222 - accuracy: 0.7808 - val_loss: 0.6789 - val_accuracy: 0.7486\n",
      "Epoch 540/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6217 - accuracy: 0.7813 - val_loss: 0.6785 - val_accuracy: 0.7486\n",
      "Epoch 541/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6212 - accuracy: 0.7816 - val_loss: 0.6781 - val_accuracy: 0.7486\n",
      "Epoch 542/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6207 - accuracy: 0.7814 - val_loss: 0.6777 - val_accuracy: 0.7493\n",
      "Epoch 543/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6202 - accuracy: 0.7821 - val_loss: 0.6773 - val_accuracy: 0.7497\n",
      "Epoch 544/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6197 - accuracy: 0.7818 - val_loss: 0.6768 - val_accuracy: 0.7495\n",
      "Epoch 545/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6192 - accuracy: 0.7820 - val_loss: 0.6765 - val_accuracy: 0.7497\n",
      "Epoch 546/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6187 - accuracy: 0.7824 - val_loss: 0.6760 - val_accuracy: 0.7497\n",
      "Epoch 547/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6182 - accuracy: 0.7823 - val_loss: 0.6756 - val_accuracy: 0.7502\n",
      "Epoch 548/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6177 - accuracy: 0.7824 - val_loss: 0.6752 - val_accuracy: 0.7509\n",
      "Epoch 549/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6172 - accuracy: 0.7824 - val_loss: 0.6748 - val_accuracy: 0.7511\n",
      "Epoch 550/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6166 - accuracy: 0.7826 - val_loss: 0.6744 - val_accuracy: 0.7515\n",
      "Epoch 551/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6161 - accuracy: 0.7827 - val_loss: 0.6740 - val_accuracy: 0.7527\n",
      "Epoch 552/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.6156 - accuracy: 0.7832 - val_loss: 0.6736 - val_accuracy: 0.7527\n",
      "Epoch 553/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6151 - accuracy: 0.7836 - val_loss: 0.6731 - val_accuracy: 0.7531\n",
      "Epoch 554/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6146 - accuracy: 0.7839 - val_loss: 0.6728 - val_accuracy: 0.7540\n",
      "Epoch 555/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6141 - accuracy: 0.7841 - val_loss: 0.6723 - val_accuracy: 0.7534\n",
      "Epoch 556/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6136 - accuracy: 0.7843 - val_loss: 0.6719 - val_accuracy: 0.7534\n",
      "Epoch 557/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6131 - accuracy: 0.7839 - val_loss: 0.6716 - val_accuracy: 0.7538\n",
      "Epoch 558/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6126 - accuracy: 0.7844 - val_loss: 0.6711 - val_accuracy: 0.7547\n",
      "Epoch 559/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6121 - accuracy: 0.7851 - val_loss: 0.6707 - val_accuracy: 0.7545\n",
      "Epoch 560/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6116 - accuracy: 0.7854 - val_loss: 0.6703 - val_accuracy: 0.7538\n",
      "Epoch 561/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6111 - accuracy: 0.7853 - val_loss: 0.6699 - val_accuracy: 0.7540\n",
      "Epoch 562/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6106 - accuracy: 0.7859 - val_loss: 0.6695 - val_accuracy: 0.7540\n",
      "Epoch 563/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6101 - accuracy: 0.7857 - val_loss: 0.6691 - val_accuracy: 0.7545\n",
      "Epoch 564/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6096 - accuracy: 0.7859 - val_loss: 0.6687 - val_accuracy: 0.7549\n",
      "Epoch 565/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6091 - accuracy: 0.7863 - val_loss: 0.6683 - val_accuracy: 0.7556\n",
      "Epoch 566/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.7864 - val_loss: 0.6679 - val_accuracy: 0.7559\n",
      "Epoch 567/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6081 - accuracy: 0.7866 - val_loss: 0.6675 - val_accuracy: 0.7554\n",
      "Epoch 568/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6076 - accuracy: 0.7870 - val_loss: 0.6671 - val_accuracy: 0.7559\n",
      "Epoch 569/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6072 - accuracy: 0.7871 - val_loss: 0.6667 - val_accuracy: 0.7570\n",
      "Epoch 570/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6066 - accuracy: 0.7872 - val_loss: 0.6663 - val_accuracy: 0.7568\n",
      "Epoch 571/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6061 - accuracy: 0.7878 - val_loss: 0.6659 - val_accuracy: 0.7574\n",
      "Epoch 572/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6056 - accuracy: 0.7871 - val_loss: 0.6655 - val_accuracy: 0.7570\n",
      "Epoch 573/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6052 - accuracy: 0.7875 - val_loss: 0.6651 - val_accuracy: 0.7570\n",
      "Epoch 574/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6047 - accuracy: 0.7879 - val_loss: 0.6647 - val_accuracy: 0.7568\n",
      "Epoch 575/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6042 - accuracy: 0.7883 - val_loss: 0.6643 - val_accuracy: 0.7570\n",
      "Epoch 576/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6037 - accuracy: 0.7886 - val_loss: 0.6640 - val_accuracy: 0.7568\n",
      "Epoch 577/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6032 - accuracy: 0.7879 - val_loss: 0.6636 - val_accuracy: 0.7574\n",
      "Epoch 578/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6027 - accuracy: 0.7889 - val_loss: 0.6632 - val_accuracy: 0.7577\n",
      "Epoch 579/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6022 - accuracy: 0.7890 - val_loss: 0.6628 - val_accuracy: 0.7574\n",
      "Epoch 580/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6017 - accuracy: 0.7887 - val_loss: 0.6624 - val_accuracy: 0.7577\n",
      "Epoch 581/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6012 - accuracy: 0.7892 - val_loss: 0.6620 - val_accuracy: 0.7574\n",
      "Epoch 582/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6007 - accuracy: 0.7893 - val_loss: 0.6616 - val_accuracy: 0.7579\n",
      "Epoch 583/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.6003 - accuracy: 0.7896 - val_loss: 0.6612 - val_accuracy: 0.7581\n",
      "Epoch 584/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5998 - accuracy: 0.7892 - val_loss: 0.6609 - val_accuracy: 0.7577\n",
      "Epoch 585/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5993 - accuracy: 0.7897 - val_loss: 0.6605 - val_accuracy: 0.7586\n",
      "Epoch 586/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5988 - accuracy: 0.7895 - val_loss: 0.6601 - val_accuracy: 0.7588\n",
      "Epoch 587/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5983 - accuracy: 0.7895 - val_loss: 0.6597 - val_accuracy: 0.7588\n",
      "Epoch 588/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5979 - accuracy: 0.7899 - val_loss: 0.6594 - val_accuracy: 0.7590\n",
      "Epoch 589/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5974 - accuracy: 0.7898 - val_loss: 0.6590 - val_accuracy: 0.7597\n",
      "Epoch 590/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5970 - accuracy: 0.7899 - val_loss: 0.6586 - val_accuracy: 0.7595\n",
      "Epoch 591/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5965 - accuracy: 0.7897 - val_loss: 0.6583 - val_accuracy: 0.7599\n",
      "Epoch 592/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5960 - accuracy: 0.7900 - val_loss: 0.6579 - val_accuracy: 0.7593\n",
      "Epoch 593/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5955 - accuracy: 0.7899 - val_loss: 0.6575 - val_accuracy: 0.7599\n",
      "Epoch 594/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5951 - accuracy: 0.7900 - val_loss: 0.6572 - val_accuracy: 0.7597\n",
      "Epoch 595/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5946 - accuracy: 0.7901 - val_loss: 0.6568 - val_accuracy: 0.7602\n",
      "Epoch 596/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5941 - accuracy: 0.7905 - val_loss: 0.6565 - val_accuracy: 0.7599\n",
      "Epoch 597/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5937 - accuracy: 0.7906 - val_loss: 0.6561 - val_accuracy: 0.7599\n",
      "Epoch 598/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5932 - accuracy: 0.7907 - val_loss: 0.6557 - val_accuracy: 0.7602\n",
      "Epoch 599/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5928 - accuracy: 0.7911 - val_loss: 0.6554 - val_accuracy: 0.7604\n",
      "Epoch 600/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5923 - accuracy: 0.7913 - val_loss: 0.6551 - val_accuracy: 0.7604\n",
      "Epoch 601/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5919 - accuracy: 0.7904 - val_loss: 0.6547 - val_accuracy: 0.7602\n",
      "Epoch 602/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5914 - accuracy: 0.7912 - val_loss: 0.6543 - val_accuracy: 0.7602\n",
      "Epoch 603/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.5910 - accuracy: 0.7915 - val_loss: 0.6540 - val_accuracy: 0.7599\n",
      "Epoch 604/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.5905 - accuracy: 0.7913 - val_loss: 0.6537 - val_accuracy: 0.7604\n",
      "Epoch 605/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5901 - accuracy: 0.7912 - val_loss: 0.6534 - val_accuracy: 0.7611\n",
      "Epoch 606/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5896 - accuracy: 0.7911 - val_loss: 0.6530 - val_accuracy: 0.7611\n",
      "Epoch 607/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5892 - accuracy: 0.7915 - val_loss: 0.6527 - val_accuracy: 0.7615\n",
      "Epoch 608/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5888 - accuracy: 0.7913 - val_loss: 0.6523 - val_accuracy: 0.7613\n",
      "Epoch 609/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5883 - accuracy: 0.7917 - val_loss: 0.6520 - val_accuracy: 0.7615\n",
      "Epoch 610/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5878 - accuracy: 0.7914 - val_loss: 0.6517 - val_accuracy: 0.7620\n",
      "Epoch 611/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5874 - accuracy: 0.7920 - val_loss: 0.6514 - val_accuracy: 0.7620\n",
      "Epoch 612/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5870 - accuracy: 0.7921 - val_loss: 0.6511 - val_accuracy: 0.7631\n",
      "Epoch 613/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5866 - accuracy: 0.7922 - val_loss: 0.6508 - val_accuracy: 0.7627\n",
      "Epoch 614/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5861 - accuracy: 0.7924 - val_loss: 0.6504 - val_accuracy: 0.7627\n",
      "Epoch 615/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5857 - accuracy: 0.7922 - val_loss: 0.6501 - val_accuracy: 0.7631\n",
      "Epoch 616/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5853 - accuracy: 0.7926 - val_loss: 0.6498 - val_accuracy: 0.7640\n",
      "Epoch 617/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5849 - accuracy: 0.7924 - val_loss: 0.6495 - val_accuracy: 0.7634\n",
      "Epoch 618/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5844 - accuracy: 0.7929 - val_loss: 0.6492 - val_accuracy: 0.7631\n",
      "Epoch 619/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5840 - accuracy: 0.7927 - val_loss: 0.6489 - val_accuracy: 0.7636\n",
      "Epoch 620/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5836 - accuracy: 0.7925 - val_loss: 0.6486 - val_accuracy: 0.7634\n",
      "Epoch 621/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5832 - accuracy: 0.7930 - val_loss: 0.6483 - val_accuracy: 0.7636\n",
      "Epoch 622/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5828 - accuracy: 0.7932 - val_loss: 0.6480 - val_accuracy: 0.7638\n",
      "Epoch 623/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5824 - accuracy: 0.7938 - val_loss: 0.6477 - val_accuracy: 0.7645\n",
      "Epoch 624/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5819 - accuracy: 0.7935 - val_loss: 0.6474 - val_accuracy: 0.7638\n",
      "Epoch 625/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5815 - accuracy: 0.7935 - val_loss: 0.6471 - val_accuracy: 0.7640\n",
      "Epoch 626/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5811 - accuracy: 0.7938 - val_loss: 0.6468 - val_accuracy: 0.7638\n",
      "Epoch 627/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5807 - accuracy: 0.7940 - val_loss: 0.6465 - val_accuracy: 0.7645\n",
      "Epoch 628/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5803 - accuracy: 0.7942 - val_loss: 0.6462 - val_accuracy: 0.7647\n",
      "Epoch 629/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5799 - accuracy: 0.7941 - val_loss: 0.6459 - val_accuracy: 0.7645\n",
      "Epoch 630/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5795 - accuracy: 0.7946 - val_loss: 0.6456 - val_accuracy: 0.7643\n",
      "Epoch 631/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5791 - accuracy: 0.7948 - val_loss: 0.6454 - val_accuracy: 0.7643\n",
      "Epoch 632/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5787 - accuracy: 0.7949 - val_loss: 0.6451 - val_accuracy: 0.7640\n",
      "Epoch 633/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5783 - accuracy: 0.7953 - val_loss: 0.6449 - val_accuracy: 0.7638\n",
      "Epoch 634/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5780 - accuracy: 0.7949 - val_loss: 0.6446 - val_accuracy: 0.7638\n",
      "Epoch 635/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5775 - accuracy: 0.7957 - val_loss: 0.6443 - val_accuracy: 0.7643\n",
      "Epoch 636/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5772 - accuracy: 0.7954 - val_loss: 0.6440 - val_accuracy: 0.7643\n",
      "Epoch 637/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5768 - accuracy: 0.7951 - val_loss: 0.6437 - val_accuracy: 0.7645\n",
      "Epoch 638/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5764 - accuracy: 0.7957 - val_loss: 0.6434 - val_accuracy: 0.7645\n",
      "Epoch 639/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5760 - accuracy: 0.7964 - val_loss: 0.6432 - val_accuracy: 0.7647\n",
      "Epoch 640/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5756 - accuracy: 0.7962 - val_loss: 0.6429 - val_accuracy: 0.7643\n",
      "Epoch 641/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5753 - accuracy: 0.7963 - val_loss: 0.6426 - val_accuracy: 0.7643\n",
      "Epoch 642/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5749 - accuracy: 0.7963 - val_loss: 0.6424 - val_accuracy: 0.7654\n",
      "Epoch 643/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5745 - accuracy: 0.7965 - val_loss: 0.6422 - val_accuracy: 0.7654\n",
      "Epoch 644/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5742 - accuracy: 0.7965 - val_loss: 0.6419 - val_accuracy: 0.7649\n",
      "Epoch 645/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5738 - accuracy: 0.7967 - val_loss: 0.6417 - val_accuracy: 0.7654\n",
      "Epoch 646/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5734 - accuracy: 0.7971 - val_loss: 0.6414 - val_accuracy: 0.7647\n",
      "Epoch 647/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5731 - accuracy: 0.7960 - val_loss: 0.6411 - val_accuracy: 0.7649\n",
      "Epoch 648/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5727 - accuracy: 0.7976 - val_loss: 0.6409 - val_accuracy: 0.7654\n",
      "Epoch 649/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5724 - accuracy: 0.7971 - val_loss: 0.6407 - val_accuracy: 0.7654\n",
      "Epoch 650/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5720 - accuracy: 0.7970 - val_loss: 0.6404 - val_accuracy: 0.7645\n",
      "Epoch 651/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5716 - accuracy: 0.7971 - val_loss: 0.6402 - val_accuracy: 0.7647\n",
      "Epoch 652/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.5713 - accuracy: 0.7979 - val_loss: 0.6399 - val_accuracy: 0.7649\n",
      "Epoch 653/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5709 - accuracy: 0.7976 - val_loss: 0.6397 - val_accuracy: 0.7649\n",
      "Epoch 654/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5706 - accuracy: 0.7979 - val_loss: 0.6394 - val_accuracy: 0.7645\n",
      "Epoch 655/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5702 - accuracy: 0.7978 - val_loss: 0.6392 - val_accuracy: 0.7652\n",
      "Epoch 656/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5699 - accuracy: 0.7975 - val_loss: 0.6390 - val_accuracy: 0.7649\n",
      "Epoch 657/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5695 - accuracy: 0.7979 - val_loss: 0.6387 - val_accuracy: 0.7654\n",
      "Epoch 658/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5692 - accuracy: 0.7980 - val_loss: 0.6385 - val_accuracy: 0.7649\n",
      "Epoch 659/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5689 - accuracy: 0.7976 - val_loss: 0.6383 - val_accuracy: 0.7645\n",
      "Epoch 660/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5685 - accuracy: 0.7979 - val_loss: 0.6381 - val_accuracy: 0.7652\n",
      "Epoch 661/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5682 - accuracy: 0.7983 - val_loss: 0.6379 - val_accuracy: 0.7656\n",
      "Epoch 662/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.5678 - accuracy: 0.7982 - val_loss: 0.6376 - val_accuracy: 0.7656\n",
      "Epoch 663/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5675 - accuracy: 0.7982 - val_loss: 0.6374 - val_accuracy: 0.7656\n",
      "Epoch 664/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.5672 - accuracy: 0.7980 - val_loss: 0.6372 - val_accuracy: 0.7656\n",
      "Epoch 665/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5668 - accuracy: 0.7987 - val_loss: 0.6370 - val_accuracy: 0.7659\n",
      "Epoch 666/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5665 - accuracy: 0.7988 - val_loss: 0.6368 - val_accuracy: 0.7663\n",
      "Epoch 667/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.5662 - accuracy: 0.7988 - val_loss: 0.6366 - val_accuracy: 0.7656\n",
      "Epoch 668/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5659 - accuracy: 0.7990 - val_loss: 0.6364 - val_accuracy: 0.7654\n",
      "Epoch 669/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5656 - accuracy: 0.7984 - val_loss: 0.6362 - val_accuracy: 0.7656\n",
      "Epoch 670/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5653 - accuracy: 0.7992 - val_loss: 0.6360 - val_accuracy: 0.7659\n",
      "Epoch 671/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5649 - accuracy: 0.7992 - val_loss: 0.6358 - val_accuracy: 0.7659\n",
      "Epoch 672/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5646 - accuracy: 0.7993 - val_loss: 0.6356 - val_accuracy: 0.7656\n",
      "Epoch 673/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5643 - accuracy: 0.7993 - val_loss: 0.6354 - val_accuracy: 0.7656\n",
      "Epoch 674/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5640 - accuracy: 0.7995 - val_loss: 0.6352 - val_accuracy: 0.7661\n",
      "Epoch 675/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5637 - accuracy: 0.7997 - val_loss: 0.6350 - val_accuracy: 0.7661\n",
      "Epoch 676/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5634 - accuracy: 0.7997 - val_loss: 0.6348 - val_accuracy: 0.7661\n",
      "Epoch 677/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5631 - accuracy: 0.7997 - val_loss: 0.6346 - val_accuracy: 0.7659\n",
      "Epoch 678/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5628 - accuracy: 0.8004 - val_loss: 0.6344 - val_accuracy: 0.7663\n",
      "Epoch 679/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5625 - accuracy: 0.7998 - val_loss: 0.6342 - val_accuracy: 0.7661\n",
      "Epoch 680/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5622 - accuracy: 0.8001 - val_loss: 0.6341 - val_accuracy: 0.7661\n",
      "Epoch 681/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5619 - accuracy: 0.8005 - val_loss: 0.6339 - val_accuracy: 0.7661\n",
      "Epoch 682/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5616 - accuracy: 0.7998 - val_loss: 0.6337 - val_accuracy: 0.7659\n",
      "Epoch 683/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5613 - accuracy: 0.8007 - val_loss: 0.6335 - val_accuracy: 0.7661\n",
      "Epoch 684/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5610 - accuracy: 0.8004 - val_loss: 0.6334 - val_accuracy: 0.7663\n",
      "Epoch 685/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5607 - accuracy: 0.8004 - val_loss: 0.6332 - val_accuracy: 0.7663\n",
      "Epoch 686/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5604 - accuracy: 0.8010 - val_loss: 0.6330 - val_accuracy: 0.7659\n",
      "Epoch 687/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5601 - accuracy: 0.8007 - val_loss: 0.6329 - val_accuracy: 0.7656\n",
      "Epoch 688/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5598 - accuracy: 0.8009 - val_loss: 0.6327 - val_accuracy: 0.7663\n",
      "Epoch 689/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5595 - accuracy: 0.8009 - val_loss: 0.6326 - val_accuracy: 0.7654\n",
      "Epoch 690/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5593 - accuracy: 0.8011 - val_loss: 0.6324 - val_accuracy: 0.7661\n",
      "Epoch 691/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5590 - accuracy: 0.8011 - val_loss: 0.6322 - val_accuracy: 0.7659\n",
      "Epoch 692/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5587 - accuracy: 0.8016 - val_loss: 0.6321 - val_accuracy: 0.7659\n",
      "Epoch 693/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5584 - accuracy: 0.8015 - val_loss: 0.6319 - val_accuracy: 0.7663\n",
      "Epoch 694/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5582 - accuracy: 0.8013 - val_loss: 0.6318 - val_accuracy: 0.7670\n",
      "Epoch 695/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5579 - accuracy: 0.8015 - val_loss: 0.6316 - val_accuracy: 0.7670\n",
      "Epoch 696/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5576 - accuracy: 0.8017 - val_loss: 0.6315 - val_accuracy: 0.7670\n",
      "Epoch 697/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5573 - accuracy: 0.8017 - val_loss: 0.6313 - val_accuracy: 0.7681\n",
      "Epoch 698/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5571 - accuracy: 0.8013 - val_loss: 0.6312 - val_accuracy: 0.7677\n",
      "Epoch 699/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5568 - accuracy: 0.8017 - val_loss: 0.6310 - val_accuracy: 0.7677\n",
      "Epoch 700/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5565 - accuracy: 0.8016 - val_loss: 0.6309 - val_accuracy: 0.7674\n",
      "Epoch 701/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5562 - accuracy: 0.8019 - val_loss: 0.6307 - val_accuracy: 0.7672\n",
      "Epoch 702/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5560 - accuracy: 0.8016 - val_loss: 0.6306 - val_accuracy: 0.7674\n",
      "Epoch 703/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5557 - accuracy: 0.8019 - val_loss: 0.6305 - val_accuracy: 0.7674\n",
      "Epoch 704/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5555 - accuracy: 0.8019 - val_loss: 0.6303 - val_accuracy: 0.7677\n",
      "Epoch 705/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5552 - accuracy: 0.8017 - val_loss: 0.6302 - val_accuracy: 0.7681\n",
      "Epoch 706/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5550 - accuracy: 0.8018 - val_loss: 0.6300 - val_accuracy: 0.7674\n",
      "Epoch 707/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5547 - accuracy: 0.8020 - val_loss: 0.6299 - val_accuracy: 0.7665\n",
      "Epoch 708/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5544 - accuracy: 0.8020 - val_loss: 0.6298 - val_accuracy: 0.7672\n",
      "Epoch 709/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5542 - accuracy: 0.8021 - val_loss: 0.6296 - val_accuracy: 0.7665\n",
      "Epoch 710/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5540 - accuracy: 0.8017 - val_loss: 0.6295 - val_accuracy: 0.7663\n",
      "Epoch 711/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5537 - accuracy: 0.8018 - val_loss: 0.6294 - val_accuracy: 0.7665\n",
      "Epoch 712/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5535 - accuracy: 0.8018 - val_loss: 0.6292 - val_accuracy: 0.7674\n",
      "Epoch 713/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5532 - accuracy: 0.8023 - val_loss: 0.6291 - val_accuracy: 0.7677\n",
      "Epoch 714/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5530 - accuracy: 0.8023 - val_loss: 0.6290 - val_accuracy: 0.7668\n",
      "Epoch 715/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5527 - accuracy: 0.8019 - val_loss: 0.6288 - val_accuracy: 0.7672\n",
      "Epoch 716/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5525 - accuracy: 0.8024 - val_loss: 0.6287 - val_accuracy: 0.7674\n",
      "Epoch 717/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.5522 - accuracy: 0.8029 - val_loss: 0.6286 - val_accuracy: 0.7674\n",
      "Epoch 718/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5520 - accuracy: 0.8021 - val_loss: 0.6285 - val_accuracy: 0.7668\n",
      "Epoch 719/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5518 - accuracy: 0.8021 - val_loss: 0.6283 - val_accuracy: 0.7677\n",
      "Epoch 720/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.5515 - accuracy: 0.8024 - val_loss: 0.6282 - val_accuracy: 0.7674\n",
      "Epoch 721/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5513 - accuracy: 0.8019 - val_loss: 0.6281 - val_accuracy: 0.7677\n",
      "Epoch 722/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5510 - accuracy: 0.8022 - val_loss: 0.6279 - val_accuracy: 0.7672\n",
      "Epoch 723/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5508 - accuracy: 0.8021 - val_loss: 0.6278 - val_accuracy: 0.7663\n",
      "Epoch 724/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5506 - accuracy: 0.8021 - val_loss: 0.6277 - val_accuracy: 0.7674\n",
      "Epoch 725/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5503 - accuracy: 0.8026 - val_loss: 0.6276 - val_accuracy: 0.7661\n",
      "Epoch 726/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5501 - accuracy: 0.8023 - val_loss: 0.6275 - val_accuracy: 0.7670\n",
      "Epoch 727/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5499 - accuracy: 0.8026 - val_loss: 0.6274 - val_accuracy: 0.7672\n",
      "Epoch 728/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5497 - accuracy: 0.8022 - val_loss: 0.6272 - val_accuracy: 0.7670\n",
      "Epoch 729/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5494 - accuracy: 0.8024 - val_loss: 0.6271 - val_accuracy: 0.7670\n",
      "Epoch 730/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5492 - accuracy: 0.8028 - val_loss: 0.6270 - val_accuracy: 0.7665\n",
      "Epoch 731/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5490 - accuracy: 0.8028 - val_loss: 0.6269 - val_accuracy: 0.7656\n",
      "Epoch 732/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5487 - accuracy: 0.8028 - val_loss: 0.6268 - val_accuracy: 0.7663\n",
      "Epoch 733/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5485 - accuracy: 0.8031 - val_loss: 0.6267 - val_accuracy: 0.7659\n",
      "Epoch 734/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5483 - accuracy: 0.8036 - val_loss: 0.6265 - val_accuracy: 0.7665\n",
      "Epoch 735/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5481 - accuracy: 0.8032 - val_loss: 0.6264 - val_accuracy: 0.7665\n",
      "Epoch 736/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5479 - accuracy: 0.8033 - val_loss: 0.6263 - val_accuracy: 0.7665\n",
      "Epoch 737/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5476 - accuracy: 0.8032 - val_loss: 0.6262 - val_accuracy: 0.7665\n",
      "Epoch 738/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5474 - accuracy: 0.8034 - val_loss: 0.6261 - val_accuracy: 0.7665\n",
      "Epoch 739/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5472 - accuracy: 0.8033 - val_loss: 0.6260 - val_accuracy: 0.7668\n",
      "Epoch 740/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5470 - accuracy: 0.8039 - val_loss: 0.6258 - val_accuracy: 0.7670\n",
      "Epoch 741/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5468 - accuracy: 0.8038 - val_loss: 0.6257 - val_accuracy: 0.7668\n",
      "Epoch 742/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5466 - accuracy: 0.8040 - val_loss: 0.6257 - val_accuracy: 0.7672\n",
      "Epoch 743/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5464 - accuracy: 0.8032 - val_loss: 0.6255 - val_accuracy: 0.7663\n",
      "Epoch 744/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5462 - accuracy: 0.8042 - val_loss: 0.6255 - val_accuracy: 0.7661\n",
      "Epoch 745/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5459 - accuracy: 0.8041 - val_loss: 0.6254 - val_accuracy: 0.7665\n",
      "Epoch 746/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5457 - accuracy: 0.8043 - val_loss: 0.6253 - val_accuracy: 0.7674\n",
      "Epoch 747/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5455 - accuracy: 0.8039 - val_loss: 0.6252 - val_accuracy: 0.7661\n",
      "Epoch 748/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5453 - accuracy: 0.8037 - val_loss: 0.6251 - val_accuracy: 0.7659\n",
      "Epoch 749/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5451 - accuracy: 0.8037 - val_loss: 0.6250 - val_accuracy: 0.7674\n",
      "Epoch 750/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5449 - accuracy: 0.8042 - val_loss: 0.6249 - val_accuracy: 0.7659\n",
      "Epoch 751/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5447 - accuracy: 0.8042 - val_loss: 0.6248 - val_accuracy: 0.7672\n",
      "Epoch 752/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5445 - accuracy: 0.8042 - val_loss: 0.6246 - val_accuracy: 0.7661\n",
      "Epoch 753/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5443 - accuracy: 0.8043 - val_loss: 0.6245 - val_accuracy: 0.7661\n",
      "Epoch 754/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5441 - accuracy: 0.8044 - val_loss: 0.6245 - val_accuracy: 0.7665\n",
      "Epoch 755/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5439 - accuracy: 0.8046 - val_loss: 0.6244 - val_accuracy: 0.7663\n",
      "Epoch 756/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5437 - accuracy: 0.8045 - val_loss: 0.6243 - val_accuracy: 0.7665\n",
      "Epoch 757/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5435 - accuracy: 0.8044 - val_loss: 0.6242 - val_accuracy: 0.7659\n",
      "Epoch 758/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5433 - accuracy: 0.8044 - val_loss: 0.6242 - val_accuracy: 0.7663\n",
      "Epoch 759/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5431 - accuracy: 0.8047 - val_loss: 0.6240 - val_accuracy: 0.7659\n",
      "Epoch 760/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5429 - accuracy: 0.8049 - val_loss: 0.6240 - val_accuracy: 0.7659\n",
      "Epoch 761/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5427 - accuracy: 0.8049 - val_loss: 0.6238 - val_accuracy: 0.7659\n",
      "Epoch 762/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5426 - accuracy: 0.8048 - val_loss: 0.6238 - val_accuracy: 0.7661\n",
      "Epoch 763/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5423 - accuracy: 0.8045 - val_loss: 0.6237 - val_accuracy: 0.7654\n",
      "Epoch 764/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5421 - accuracy: 0.8050 - val_loss: 0.6236 - val_accuracy: 0.7663\n",
      "Epoch 765/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5420 - accuracy: 0.8049 - val_loss: 0.6236 - val_accuracy: 0.7663\n",
      "Epoch 766/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5418 - accuracy: 0.8048 - val_loss: 0.6234 - val_accuracy: 0.7659\n",
      "Epoch 767/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5416 - accuracy: 0.8052 - val_loss: 0.6234 - val_accuracy: 0.7661\n",
      "Epoch 768/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5414 - accuracy: 0.8053 - val_loss: 0.6233 - val_accuracy: 0.7665\n",
      "Epoch 769/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5412 - accuracy: 0.8053 - val_loss: 0.6232 - val_accuracy: 0.7659\n",
      "Epoch 770/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5410 - accuracy: 0.8051 - val_loss: 0.6231 - val_accuracy: 0.7656\n",
      "Epoch 771/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5409 - accuracy: 0.8052 - val_loss: 0.6230 - val_accuracy: 0.7661\n",
      "Epoch 772/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5407 - accuracy: 0.8056 - val_loss: 0.6229 - val_accuracy: 0.7665\n",
      "Epoch 773/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5405 - accuracy: 0.8050 - val_loss: 0.6229 - val_accuracy: 0.7665\n",
      "Epoch 774/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5403 - accuracy: 0.8058 - val_loss: 0.6228 - val_accuracy: 0.7659\n",
      "Epoch 775/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5401 - accuracy: 0.8058 - val_loss: 0.6227 - val_accuracy: 0.7665\n",
      "Epoch 776/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5399 - accuracy: 0.8061 - val_loss: 0.6226 - val_accuracy: 0.7672\n",
      "Epoch 777/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5398 - accuracy: 0.8061 - val_loss: 0.6226 - val_accuracy: 0.7661\n",
      "Epoch 778/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5396 - accuracy: 0.8059 - val_loss: 0.6225 - val_accuracy: 0.7659\n",
      "Epoch 779/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5394 - accuracy: 0.8057 - val_loss: 0.6224 - val_accuracy: 0.7674\n",
      "Epoch 780/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5393 - accuracy: 0.8062 - val_loss: 0.6224 - val_accuracy: 0.7665\n",
      "Epoch 781/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5391 - accuracy: 0.8063 - val_loss: 0.6222 - val_accuracy: 0.7663\n",
      "Epoch 782/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5389 - accuracy: 0.8064 - val_loss: 0.6222 - val_accuracy: 0.7663\n",
      "Epoch 783/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5388 - accuracy: 0.8062 - val_loss: 0.6221 - val_accuracy: 0.7663\n",
      "Epoch 784/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5386 - accuracy: 0.8063 - val_loss: 0.6221 - val_accuracy: 0.7661\n",
      "Epoch 785/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5384 - accuracy: 0.8064 - val_loss: 0.6220 - val_accuracy: 0.7663\n",
      "Epoch 786/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5382 - accuracy: 0.8067 - val_loss: 0.6220 - val_accuracy: 0.7670\n",
      "Epoch 787/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5381 - accuracy: 0.8067 - val_loss: 0.6219 - val_accuracy: 0.7665\n",
      "Epoch 788/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.5379 - accuracy: 0.8065 - val_loss: 0.6218 - val_accuracy: 0.7670\n",
      "Epoch 789/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5377 - accuracy: 0.8066 - val_loss: 0.6218 - val_accuracy: 0.7665\n",
      "Epoch 790/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5375 - accuracy: 0.8065 - val_loss: 0.6217 - val_accuracy: 0.7670\n",
      "Epoch 791/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5374 - accuracy: 0.8072 - val_loss: 0.6216 - val_accuracy: 0.7665\n",
      "Epoch 792/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5372 - accuracy: 0.8070 - val_loss: 0.6215 - val_accuracy: 0.7674\n",
      "Epoch 793/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5371 - accuracy: 0.8070 - val_loss: 0.6214 - val_accuracy: 0.7677\n",
      "Epoch 794/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5369 - accuracy: 0.8071 - val_loss: 0.6214 - val_accuracy: 0.7674\n",
      "Epoch 795/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5367 - accuracy: 0.8071 - val_loss: 0.6213 - val_accuracy: 0.7670\n",
      "Epoch 796/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5366 - accuracy: 0.8070 - val_loss: 0.6213 - val_accuracy: 0.7670\n",
      "Epoch 797/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5364 - accuracy: 0.8075 - val_loss: 0.6212 - val_accuracy: 0.7670\n",
      "Epoch 798/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5363 - accuracy: 0.8071 - val_loss: 0.6212 - val_accuracy: 0.7670\n",
      "Epoch 799/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5361 - accuracy: 0.8073 - val_loss: 0.6211 - val_accuracy: 0.7668\n",
      "Epoch 800/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5359 - accuracy: 0.8079 - val_loss: 0.6210 - val_accuracy: 0.7672\n",
      "Epoch 801/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5358 - accuracy: 0.8073 - val_loss: 0.6210 - val_accuracy: 0.7668\n",
      "Epoch 802/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5356 - accuracy: 0.8076 - val_loss: 0.6209 - val_accuracy: 0.7670\n",
      "Epoch 803/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5354 - accuracy: 0.8080 - val_loss: 0.6209 - val_accuracy: 0.7668\n",
      "Epoch 804/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5353 - accuracy: 0.8075 - val_loss: 0.6208 - val_accuracy: 0.7672\n",
      "Epoch 805/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5352 - accuracy: 0.8078 - val_loss: 0.6207 - val_accuracy: 0.7672\n",
      "Epoch 806/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5350 - accuracy: 0.8075 - val_loss: 0.6207 - val_accuracy: 0.7672\n",
      "Epoch 807/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5349 - accuracy: 0.8075 - val_loss: 0.6206 - val_accuracy: 0.7668\n",
      "Epoch 808/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5347 - accuracy: 0.8084 - val_loss: 0.6205 - val_accuracy: 0.7674\n",
      "Epoch 809/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5345 - accuracy: 0.8083 - val_loss: 0.6205 - val_accuracy: 0.7670\n",
      "Epoch 810/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5344 - accuracy: 0.8082 - val_loss: 0.6205 - val_accuracy: 0.7670\n",
      "Epoch 811/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5342 - accuracy: 0.8079 - val_loss: 0.6204 - val_accuracy: 0.7665\n",
      "Epoch 812/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5340 - accuracy: 0.8080 - val_loss: 0.6203 - val_accuracy: 0.7672\n",
      "Epoch 813/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5339 - accuracy: 0.8083 - val_loss: 0.6203 - val_accuracy: 0.7670\n",
      "Epoch 814/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5338 - accuracy: 0.8084 - val_loss: 0.6202 - val_accuracy: 0.7670\n",
      "Epoch 815/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5336 - accuracy: 0.8082 - val_loss: 0.6202 - val_accuracy: 0.7670\n",
      "Epoch 816/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5335 - accuracy: 0.8084 - val_loss: 0.6201 - val_accuracy: 0.7665\n",
      "Epoch 817/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5333 - accuracy: 0.8084 - val_loss: 0.6200 - val_accuracy: 0.7663\n",
      "Epoch 818/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5332 - accuracy: 0.8091 - val_loss: 0.6200 - val_accuracy: 0.7663\n",
      "Epoch 819/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5330 - accuracy: 0.8091 - val_loss: 0.6199 - val_accuracy: 0.7668\n",
      "Epoch 820/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.5329 - accuracy: 0.8087 - val_loss: 0.6198 - val_accuracy: 0.7672\n",
      "Epoch 821/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5328 - accuracy: 0.8089 - val_loss: 0.6198 - val_accuracy: 0.7661\n",
      "Epoch 822/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5326 - accuracy: 0.8089 - val_loss: 0.6198 - val_accuracy: 0.7656\n",
      "Epoch 823/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5325 - accuracy: 0.8090 - val_loss: 0.6197 - val_accuracy: 0.7661\n",
      "Epoch 824/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5323 - accuracy: 0.8094 - val_loss: 0.6197 - val_accuracy: 0.7654\n",
      "Epoch 825/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5321 - accuracy: 0.8096 - val_loss: 0.6196 - val_accuracy: 0.7661\n",
      "Epoch 826/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5320 - accuracy: 0.8097 - val_loss: 0.6195 - val_accuracy: 0.7659\n",
      "Epoch 827/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5319 - accuracy: 0.8098 - val_loss: 0.6195 - val_accuracy: 0.7663\n",
      "Epoch 828/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5317 - accuracy: 0.8094 - val_loss: 0.6194 - val_accuracy: 0.7663\n",
      "Epoch 829/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5316 - accuracy: 0.8095 - val_loss: 0.6194 - val_accuracy: 0.7670\n",
      "Epoch 830/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5315 - accuracy: 0.8103 - val_loss: 0.6193 - val_accuracy: 0.7661\n",
      "Epoch 831/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5313 - accuracy: 0.8100 - val_loss: 0.6193 - val_accuracy: 0.7661\n",
      "Epoch 832/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5312 - accuracy: 0.8100 - val_loss: 0.6192 - val_accuracy: 0.7665\n",
      "Epoch 833/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5311 - accuracy: 0.8096 - val_loss: 0.6191 - val_accuracy: 0.7670\n",
      "Epoch 834/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5309 - accuracy: 0.8103 - val_loss: 0.6191 - val_accuracy: 0.7670\n",
      "Epoch 835/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5308 - accuracy: 0.8103 - val_loss: 0.6191 - val_accuracy: 0.7668\n",
      "Epoch 836/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5306 - accuracy: 0.8104 - val_loss: 0.6190 - val_accuracy: 0.7670\n",
      "Epoch 837/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5305 - accuracy: 0.8103 - val_loss: 0.6190 - val_accuracy: 0.7670\n",
      "Epoch 838/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5304 - accuracy: 0.8107 - val_loss: 0.6189 - val_accuracy: 0.7665\n",
      "Epoch 839/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5302 - accuracy: 0.8108 - val_loss: 0.6189 - val_accuracy: 0.7661\n",
      "Epoch 840/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5301 - accuracy: 0.8110 - val_loss: 0.6189 - val_accuracy: 0.7665\n",
      "Epoch 841/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5299 - accuracy: 0.8109 - val_loss: 0.6187 - val_accuracy: 0.7665\n",
      "Epoch 842/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5298 - accuracy: 0.8111 - val_loss: 0.6187 - val_accuracy: 0.7668\n",
      "Epoch 843/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5297 - accuracy: 0.8111 - val_loss: 0.6186 - val_accuracy: 0.7663\n",
      "Epoch 844/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5296 - accuracy: 0.8108 - val_loss: 0.6186 - val_accuracy: 0.7668\n",
      "Epoch 845/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5294 - accuracy: 0.8113 - val_loss: 0.6186 - val_accuracy: 0.7665\n",
      "Epoch 846/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5293 - accuracy: 0.8110 - val_loss: 0.6185 - val_accuracy: 0.7663\n",
      "Epoch 847/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.5292 - accuracy: 0.8112 - val_loss: 0.6185 - val_accuracy: 0.7665\n",
      "Epoch 848/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5290 - accuracy: 0.8115 - val_loss: 0.6184 - val_accuracy: 0.7661\n",
      "Epoch 849/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5289 - accuracy: 0.8111 - val_loss: 0.6184 - val_accuracy: 0.7661\n",
      "Epoch 850/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5288 - accuracy: 0.8115 - val_loss: 0.6183 - val_accuracy: 0.7663\n",
      "Epoch 851/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5287 - accuracy: 0.8115 - val_loss: 0.6183 - val_accuracy: 0.7661\n",
      "Epoch 852/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5285 - accuracy: 0.8116 - val_loss: 0.6183 - val_accuracy: 0.7659\n",
      "Epoch 853/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5284 - accuracy: 0.8117 - val_loss: 0.6182 - val_accuracy: 0.7661\n",
      "Epoch 854/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5283 - accuracy: 0.8123 - val_loss: 0.6181 - val_accuracy: 0.7668\n",
      "Epoch 855/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5282 - accuracy: 0.8123 - val_loss: 0.6181 - val_accuracy: 0.7663\n",
      "Epoch 856/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5280 - accuracy: 0.8122 - val_loss: 0.6181 - val_accuracy: 0.7665\n",
      "Epoch 857/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5279 - accuracy: 0.8123 - val_loss: 0.6181 - val_accuracy: 0.7665\n",
      "Epoch 858/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5278 - accuracy: 0.8121 - val_loss: 0.6180 - val_accuracy: 0.7668\n",
      "Epoch 859/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5276 - accuracy: 0.8117 - val_loss: 0.6180 - val_accuracy: 0.7668\n",
      "Epoch 860/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5275 - accuracy: 0.8122 - val_loss: 0.6179 - val_accuracy: 0.7661\n",
      "Epoch 861/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5274 - accuracy: 0.8125 - val_loss: 0.6179 - val_accuracy: 0.7668\n",
      "Epoch 862/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5273 - accuracy: 0.8121 - val_loss: 0.6178 - val_accuracy: 0.7670\n",
      "Epoch 863/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5271 - accuracy: 0.8124 - val_loss: 0.6178 - val_accuracy: 0.7665\n",
      "Epoch 864/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5270 - accuracy: 0.8121 - val_loss: 0.6177 - val_accuracy: 0.7665\n",
      "Epoch 865/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5269 - accuracy: 0.8121 - val_loss: 0.6177 - val_accuracy: 0.7663\n",
      "Epoch 866/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5268 - accuracy: 0.8126 - val_loss: 0.6176 - val_accuracy: 0.7661\n",
      "Epoch 867/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5267 - accuracy: 0.8126 - val_loss: 0.6176 - val_accuracy: 0.7659\n",
      "Epoch 868/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5266 - accuracy: 0.8127 - val_loss: 0.6175 - val_accuracy: 0.7661\n",
      "Epoch 869/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5264 - accuracy: 0.8121 - val_loss: 0.6176 - val_accuracy: 0.7661\n",
      "Epoch 870/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5263 - accuracy: 0.8130 - val_loss: 0.6175 - val_accuracy: 0.7659\n",
      "Epoch 871/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5262 - accuracy: 0.8129 - val_loss: 0.6174 - val_accuracy: 0.7656\n",
      "Epoch 872/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5260 - accuracy: 0.8125 - val_loss: 0.6174 - val_accuracy: 0.7659\n",
      "Epoch 873/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5259 - accuracy: 0.8126 - val_loss: 0.6173 - val_accuracy: 0.7665\n",
      "Epoch 874/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5258 - accuracy: 0.8127 - val_loss: 0.6173 - val_accuracy: 0.7661\n",
      "Epoch 875/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5257 - accuracy: 0.8129 - val_loss: 0.6172 - val_accuracy: 0.7659\n",
      "Epoch 876/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5255 - accuracy: 0.8132 - val_loss: 0.6172 - val_accuracy: 0.7656\n",
      "Epoch 877/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5254 - accuracy: 0.8134 - val_loss: 0.6172 - val_accuracy: 0.7665\n",
      "Epoch 878/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5253 - accuracy: 0.8130 - val_loss: 0.6171 - val_accuracy: 0.7665\n",
      "Epoch 879/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5252 - accuracy: 0.8131 - val_loss: 0.6171 - val_accuracy: 0.7665\n",
      "Epoch 880/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5251 - accuracy: 0.8131 - val_loss: 0.6170 - val_accuracy: 0.7665\n",
      "Epoch 881/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5250 - accuracy: 0.8133 - val_loss: 0.6169 - val_accuracy: 0.7659\n",
      "Epoch 882/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5249 - accuracy: 0.8134 - val_loss: 0.6169 - val_accuracy: 0.7661\n",
      "Epoch 883/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5247 - accuracy: 0.8129 - val_loss: 0.6168 - val_accuracy: 0.7659\n",
      "Epoch 884/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5246 - accuracy: 0.8130 - val_loss: 0.6168 - val_accuracy: 0.7659\n",
      "Epoch 885/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5245 - accuracy: 0.8134 - val_loss: 0.6168 - val_accuracy: 0.7661\n",
      "Epoch 886/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5244 - accuracy: 0.8130 - val_loss: 0.6168 - val_accuracy: 0.7659\n",
      "Epoch 887/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5243 - accuracy: 0.8131 - val_loss: 0.6167 - val_accuracy: 0.7659\n",
      "Epoch 888/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5241 - accuracy: 0.8134 - val_loss: 0.6166 - val_accuracy: 0.7659\n",
      "Epoch 889/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5240 - accuracy: 0.8131 - val_loss: 0.6166 - val_accuracy: 0.7665\n",
      "Epoch 890/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5239 - accuracy: 0.8133 - val_loss: 0.6165 - val_accuracy: 0.7661\n",
      "Epoch 891/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5238 - accuracy: 0.8133 - val_loss: 0.6165 - val_accuracy: 0.7661\n",
      "Epoch 892/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5237 - accuracy: 0.8133 - val_loss: 0.6165 - val_accuracy: 0.7661\n",
      "Epoch 893/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5236 - accuracy: 0.8137 - val_loss: 0.6165 - val_accuracy: 0.7661\n",
      "Epoch 894/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5235 - accuracy: 0.8134 - val_loss: 0.6164 - val_accuracy: 0.7659\n",
      "Epoch 895/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5233 - accuracy: 0.8133 - val_loss: 0.6163 - val_accuracy: 0.7659\n",
      "Epoch 896/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5232 - accuracy: 0.8135 - val_loss: 0.6163 - val_accuracy: 0.7659\n",
      "Epoch 897/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5231 - accuracy: 0.8134 - val_loss: 0.6163 - val_accuracy: 0.7670\n",
      "Epoch 898/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5230 - accuracy: 0.8136 - val_loss: 0.6162 - val_accuracy: 0.7665\n",
      "Epoch 899/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5229 - accuracy: 0.8137 - val_loss: 0.6162 - val_accuracy: 0.7672\n",
      "Epoch 900/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5228 - accuracy: 0.8136 - val_loss: 0.6162 - val_accuracy: 0.7663\n",
      "Epoch 901/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5227 - accuracy: 0.8133 - val_loss: 0.6161 - val_accuracy: 0.7665\n",
      "Epoch 902/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5226 - accuracy: 0.8136 - val_loss: 0.6161 - val_accuracy: 0.7665\n",
      "Epoch 903/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5225 - accuracy: 0.8136 - val_loss: 0.6160 - val_accuracy: 0.7668\n",
      "Epoch 904/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5223 - accuracy: 0.8135 - val_loss: 0.6160 - val_accuracy: 0.7672\n",
      "Epoch 905/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5223 - accuracy: 0.8138 - val_loss: 0.6160 - val_accuracy: 0.7672\n",
      "Epoch 906/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5221 - accuracy: 0.8136 - val_loss: 0.6159 - val_accuracy: 0.7670\n",
      "Epoch 907/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5220 - accuracy: 0.8140 - val_loss: 0.6159 - val_accuracy: 0.7674\n",
      "Epoch 908/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5219 - accuracy: 0.8139 - val_loss: 0.6159 - val_accuracy: 0.7672\n",
      "Epoch 909/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5218 - accuracy: 0.8137 - val_loss: 0.6158 - val_accuracy: 0.7670\n",
      "Epoch 910/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5217 - accuracy: 0.8137 - val_loss: 0.6157 - val_accuracy: 0.7674\n",
      "Epoch 911/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5216 - accuracy: 0.8138 - val_loss: 0.6157 - val_accuracy: 0.7674\n",
      "Epoch 912/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5215 - accuracy: 0.8136 - val_loss: 0.6157 - val_accuracy: 0.7670\n",
      "Epoch 913/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5213 - accuracy: 0.8138 - val_loss: 0.6156 - val_accuracy: 0.7674\n",
      "Epoch 914/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5212 - accuracy: 0.8138 - val_loss: 0.6156 - val_accuracy: 0.7672\n",
      "Epoch 915/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5211 - accuracy: 0.8142 - val_loss: 0.6155 - val_accuracy: 0.7672\n",
      "Epoch 916/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5210 - accuracy: 0.8146 - val_loss: 0.6156 - val_accuracy: 0.7672\n",
      "Epoch 917/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5209 - accuracy: 0.8141 - val_loss: 0.6155 - val_accuracy: 0.7672\n",
      "Epoch 918/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5208 - accuracy: 0.8143 - val_loss: 0.6154 - val_accuracy: 0.7668\n",
      "Epoch 919/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.5207 - accuracy: 0.8144 - val_loss: 0.6154 - val_accuracy: 0.7670\n",
      "Epoch 920/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.8142 - val_loss: 0.6154 - val_accuracy: 0.7672\n",
      "Epoch 921/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5205 - accuracy: 0.8144 - val_loss: 0.6154 - val_accuracy: 0.7670\n",
      "Epoch 922/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5204 - accuracy: 0.8146 - val_loss: 0.6153 - val_accuracy: 0.7670\n",
      "Epoch 923/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5203 - accuracy: 0.8148 - val_loss: 0.6152 - val_accuracy: 0.7668\n",
      "Epoch 924/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5202 - accuracy: 0.8142 - val_loss: 0.6152 - val_accuracy: 0.7665\n",
      "Epoch 925/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5201 - accuracy: 0.8148 - val_loss: 0.6152 - val_accuracy: 0.7670\n",
      "Epoch 926/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5200 - accuracy: 0.8145 - val_loss: 0.6151 - val_accuracy: 0.7668\n",
      "Epoch 927/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5199 - accuracy: 0.8145 - val_loss: 0.6151 - val_accuracy: 0.7665\n",
      "Epoch 928/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5198 - accuracy: 0.8148 - val_loss: 0.6151 - val_accuracy: 0.7668\n",
      "Epoch 929/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5197 - accuracy: 0.8144 - val_loss: 0.6150 - val_accuracy: 0.7665\n",
      "Epoch 930/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5196 - accuracy: 0.8145 - val_loss: 0.6150 - val_accuracy: 0.7668\n",
      "Epoch 931/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5195 - accuracy: 0.8150 - val_loss: 0.6150 - val_accuracy: 0.7672\n",
      "Epoch 932/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5194 - accuracy: 0.8148 - val_loss: 0.6150 - val_accuracy: 0.7672\n",
      "Epoch 933/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.8150 - val_loss: 0.6149 - val_accuracy: 0.7670\n",
      "Epoch 934/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5192 - accuracy: 0.8152 - val_loss: 0.6149 - val_accuracy: 0.7663\n",
      "Epoch 935/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5191 - accuracy: 0.8147 - val_loss: 0.6149 - val_accuracy: 0.7663\n",
      "Epoch 936/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5190 - accuracy: 0.8145 - val_loss: 0.6148 - val_accuracy: 0.7670\n",
      "Epoch 937/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5189 - accuracy: 0.8149 - val_loss: 0.6147 - val_accuracy: 0.7668\n",
      "Epoch 938/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5188 - accuracy: 0.8145 - val_loss: 0.6147 - val_accuracy: 0.7665\n",
      "Epoch 939/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5187 - accuracy: 0.8144 - val_loss: 0.6147 - val_accuracy: 0.7665\n",
      "Epoch 940/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5186 - accuracy: 0.8146 - val_loss: 0.6146 - val_accuracy: 0.7668\n",
      "Epoch 941/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5185 - accuracy: 0.8151 - val_loss: 0.6147 - val_accuracy: 0.7663\n",
      "Epoch 942/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5184 - accuracy: 0.8147 - val_loss: 0.6146 - val_accuracy: 0.7665\n",
      "Epoch 943/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.8149 - val_loss: 0.6146 - val_accuracy: 0.7668\n",
      "Epoch 944/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5182 - accuracy: 0.8147 - val_loss: 0.6145 - val_accuracy: 0.7668\n",
      "Epoch 945/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5181 - accuracy: 0.8148 - val_loss: 0.6145 - val_accuracy: 0.7668\n",
      "Epoch 946/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5180 - accuracy: 0.8150 - val_loss: 0.6145 - val_accuracy: 0.7668\n",
      "Epoch 947/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5179 - accuracy: 0.8145 - val_loss: 0.6144 - val_accuracy: 0.7670\n",
      "Epoch 948/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5178 - accuracy: 0.8152 - val_loss: 0.6144 - val_accuracy: 0.7672\n",
      "Epoch 949/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5177 - accuracy: 0.8152 - val_loss: 0.6144 - val_accuracy: 0.7672\n",
      "Epoch 950/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5176 - accuracy: 0.8147 - val_loss: 0.6144 - val_accuracy: 0.7674\n",
      "Epoch 951/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5175 - accuracy: 0.8146 - val_loss: 0.6143 - val_accuracy: 0.7670\n",
      "Epoch 952/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.8146 - val_loss: 0.6143 - val_accuracy: 0.7679\n",
      "Epoch 953/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5173 - accuracy: 0.8149 - val_loss: 0.6143 - val_accuracy: 0.7677\n",
      "Epoch 954/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5172 - accuracy: 0.8147 - val_loss: 0.6142 - val_accuracy: 0.7677\n",
      "Epoch 955/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5172 - accuracy: 0.8150 - val_loss: 0.6142 - val_accuracy: 0.7672\n",
      "Epoch 956/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5171 - accuracy: 0.8151 - val_loss: 0.6141 - val_accuracy: 0.7674\n",
      "Epoch 957/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.8148 - val_loss: 0.6142 - val_accuracy: 0.7674\n",
      "Epoch 958/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.8148 - val_loss: 0.6141 - val_accuracy: 0.7679\n",
      "Epoch 959/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.8149 - val_loss: 0.6141 - val_accuracy: 0.7674\n",
      "Epoch 960/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5167 - accuracy: 0.8149 - val_loss: 0.6141 - val_accuracy: 0.7674\n",
      "Epoch 961/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5166 - accuracy: 0.8146 - val_loss: 0.6140 - val_accuracy: 0.7668\n",
      "Epoch 962/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5165 - accuracy: 0.8149 - val_loss: 0.6140 - val_accuracy: 0.7674\n",
      "Epoch 963/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5164 - accuracy: 0.8153 - val_loss: 0.6140 - val_accuracy: 0.7674\n",
      "Epoch 964/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5163 - accuracy: 0.8151 - val_loss: 0.6139 - val_accuracy: 0.7674\n",
      "Epoch 965/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.8149 - val_loss: 0.6139 - val_accuracy: 0.7679\n",
      "Epoch 966/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.8153 - val_loss: 0.6139 - val_accuracy: 0.7679\n",
      "Epoch 967/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5160 - accuracy: 0.8150 - val_loss: 0.6138 - val_accuracy: 0.7674\n",
      "Epoch 968/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5160 - accuracy: 0.8149 - val_loss: 0.6138 - val_accuracy: 0.7674\n",
      "Epoch 969/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5159 - accuracy: 0.8150 - val_loss: 0.6139 - val_accuracy: 0.7681\n",
      "Epoch 970/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.8150 - val_loss: 0.6138 - val_accuracy: 0.7677\n",
      "Epoch 971/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.8153 - val_loss: 0.6138 - val_accuracy: 0.7684\n",
      "Epoch 972/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.8157 - val_loss: 0.6138 - val_accuracy: 0.7686\n",
      "Epoch 973/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5155 - accuracy: 0.8154 - val_loss: 0.6138 - val_accuracy: 0.7686\n",
      "Epoch 974/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5154 - accuracy: 0.8154 - val_loss: 0.6137 - val_accuracy: 0.7686\n",
      "Epoch 975/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5154 - accuracy: 0.8152 - val_loss: 0.6137 - val_accuracy: 0.7688\n",
      "Epoch 976/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5153 - accuracy: 0.8155 - val_loss: 0.6137 - val_accuracy: 0.7684\n",
      "Epoch 977/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5152 - accuracy: 0.8153 - val_loss: 0.6137 - val_accuracy: 0.7686\n",
      "Epoch 978/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5151 - accuracy: 0.8151 - val_loss: 0.6136 - val_accuracy: 0.7686\n",
      "Epoch 979/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5150 - accuracy: 0.8156 - val_loss: 0.6136 - val_accuracy: 0.7686\n",
      "Epoch 980/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5149 - accuracy: 0.8157 - val_loss: 0.6136 - val_accuracy: 0.7684\n",
      "Epoch 981/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.8156 - val_loss: 0.6135 - val_accuracy: 0.7686\n",
      "Epoch 982/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5148 - accuracy: 0.8157 - val_loss: 0.6135 - val_accuracy: 0.7681\n",
      "Epoch 983/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5147 - accuracy: 0.8160 - val_loss: 0.6135 - val_accuracy: 0.7686\n",
      "Epoch 984/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5146 - accuracy: 0.8157 - val_loss: 0.6134 - val_accuracy: 0.7686\n",
      "Epoch 985/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5145 - accuracy: 0.8163 - val_loss: 0.6134 - val_accuracy: 0.7686\n",
      "Epoch 986/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5144 - accuracy: 0.8154 - val_loss: 0.6133 - val_accuracy: 0.7681\n",
      "Epoch 987/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5143 - accuracy: 0.8161 - val_loss: 0.6134 - val_accuracy: 0.7681\n",
      "Epoch 988/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5142 - accuracy: 0.8158 - val_loss: 0.6133 - val_accuracy: 0.7686\n",
      "Epoch 989/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5142 - accuracy: 0.8158 - val_loss: 0.6133 - val_accuracy: 0.7686\n",
      "Epoch 990/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5141 - accuracy: 0.8157 - val_loss: 0.6133 - val_accuracy: 0.7681\n",
      "Epoch 991/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5140 - accuracy: 0.8162 - val_loss: 0.6132 - val_accuracy: 0.7686\n",
      "Epoch 992/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5139 - accuracy: 0.8159 - val_loss: 0.6132 - val_accuracy: 0.7684\n",
      "Epoch 993/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5138 - accuracy: 0.8163 - val_loss: 0.6132 - val_accuracy: 0.7686\n",
      "Epoch 994/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.8163 - val_loss: 0.6132 - val_accuracy: 0.7686\n",
      "Epoch 995/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.8162 - val_loss: 0.6132 - val_accuracy: 0.7686\n",
      "Epoch 996/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5136 - accuracy: 0.8165 - val_loss: 0.6131 - val_accuracy: 0.7688\n",
      "Epoch 997/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5135 - accuracy: 0.8162 - val_loss: 0.6131 - val_accuracy: 0.7686\n",
      "Epoch 998/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5135 - accuracy: 0.8161 - val_loss: 0.6131 - val_accuracy: 0.7686\n",
      "Epoch 999/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5134 - accuracy: 0.8161 - val_loss: 0.6131 - val_accuracy: 0.7686\n",
      "Epoch 1000/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5132 - accuracy: 0.8159 - val_loss: 0.6130 - val_accuracy: 0.7688\n",
      "Epoch 1001/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5132 - accuracy: 0.8165 - val_loss: 0.6131 - val_accuracy: 0.7688\n",
      "Epoch 1002/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5131 - accuracy: 0.8165 - val_loss: 0.6131 - val_accuracy: 0.7688\n",
      "Epoch 1003/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5130 - accuracy: 0.8163 - val_loss: 0.6130 - val_accuracy: 0.7686\n",
      "Epoch 1004/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5129 - accuracy: 0.8166 - val_loss: 0.6129 - val_accuracy: 0.7686\n",
      "Epoch 1005/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5129 - accuracy: 0.8166 - val_loss: 0.6130 - val_accuracy: 0.7688\n",
      "Epoch 1006/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5128 - accuracy: 0.8163 - val_loss: 0.6129 - val_accuracy: 0.7686\n",
      "Epoch 1007/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5127 - accuracy: 0.8161 - val_loss: 0.6129 - val_accuracy: 0.7693\n",
      "Epoch 1008/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5126 - accuracy: 0.8166 - val_loss: 0.6129 - val_accuracy: 0.7686\n",
      "Epoch 1009/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.8167 - val_loss: 0.6129 - val_accuracy: 0.7688\n",
      "Epoch 1010/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5125 - accuracy: 0.8158 - val_loss: 0.6128 - val_accuracy: 0.7693\n",
      "Epoch 1011/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5124 - accuracy: 0.8169 - val_loss: 0.6128 - val_accuracy: 0.7690\n",
      "Epoch 1012/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5123 - accuracy: 0.8165 - val_loss: 0.6128 - val_accuracy: 0.7686\n",
      "Epoch 1013/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5123 - accuracy: 0.8165 - val_loss: 0.6128 - val_accuracy: 0.7688\n",
      "Epoch 1014/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.8162 - val_loss: 0.6128 - val_accuracy: 0.7686\n",
      "Epoch 1015/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5121 - accuracy: 0.8165 - val_loss: 0.6128 - val_accuracy: 0.7690\n",
      "Epoch 1016/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5120 - accuracy: 0.8169 - val_loss: 0.6127 - val_accuracy: 0.7690\n",
      "Epoch 1017/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5119 - accuracy: 0.8169 - val_loss: 0.6127 - val_accuracy: 0.7686\n",
      "Epoch 1018/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5119 - accuracy: 0.8159 - val_loss: 0.6127 - val_accuracy: 0.7686\n",
      "Epoch 1019/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5118 - accuracy: 0.8165 - val_loss: 0.6127 - val_accuracy: 0.7686\n",
      "Epoch 1020/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5117 - accuracy: 0.8166 - val_loss: 0.6127 - val_accuracy: 0.7686\n",
      "Epoch 1021/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5116 - accuracy: 0.8166 - val_loss: 0.6127 - val_accuracy: 0.7688\n",
      "Epoch 1022/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5116 - accuracy: 0.8166 - val_loss: 0.6126 - val_accuracy: 0.7695\n",
      "Epoch 1023/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.8164 - val_loss: 0.6126 - val_accuracy: 0.7695\n",
      "Epoch 1024/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5114 - accuracy: 0.8165 - val_loss: 0.6126 - val_accuracy: 0.7697\n",
      "Epoch 1025/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5114 - accuracy: 0.8173 - val_loss: 0.6126 - val_accuracy: 0.7697\n",
      "Epoch 1026/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5113 - accuracy: 0.8168 - val_loss: 0.6125 - val_accuracy: 0.7702\n",
      "Epoch 1027/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5112 - accuracy: 0.8167 - val_loss: 0.6125 - val_accuracy: 0.7693\n",
      "Epoch 1028/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.8166 - val_loss: 0.6125 - val_accuracy: 0.7699\n",
      "Epoch 1029/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.8167 - val_loss: 0.6125 - val_accuracy: 0.7702\n",
      "Epoch 1030/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.8171 - val_loss: 0.6124 - val_accuracy: 0.7697\n",
      "Epoch 1031/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5109 - accuracy: 0.8167 - val_loss: 0.6125 - val_accuracy: 0.7704\n",
      "Epoch 1032/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5108 - accuracy: 0.8170 - val_loss: 0.6124 - val_accuracy: 0.7702\n",
      "Epoch 1033/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5108 - accuracy: 0.8170 - val_loss: 0.6124 - val_accuracy: 0.7704\n",
      "Epoch 1034/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5107 - accuracy: 0.8172 - val_loss: 0.6124 - val_accuracy: 0.7699\n",
      "Epoch 1035/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.8170 - val_loss: 0.6124 - val_accuracy: 0.7702\n",
      "Epoch 1036/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.8169 - val_loss: 0.6124 - val_accuracy: 0.7702\n",
      "Epoch 1037/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.8174 - val_loss: 0.6124 - val_accuracy: 0.7706\n",
      "Epoch 1038/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5104 - accuracy: 0.8169 - val_loss: 0.6124 - val_accuracy: 0.7699\n",
      "Epoch 1039/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5104 - accuracy: 0.8169 - val_loss: 0.6124 - val_accuracy: 0.7709\n",
      "Epoch 1040/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.8173 - val_loss: 0.6124 - val_accuracy: 0.7702\n",
      "Epoch 1041/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5102 - accuracy: 0.8170 - val_loss: 0.6123 - val_accuracy: 0.7704\n",
      "Epoch 1042/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5101 - accuracy: 0.8173 - val_loss: 0.6123 - val_accuracy: 0.7704\n",
      "Epoch 1043/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5101 - accuracy: 0.8169 - val_loss: 0.6122 - val_accuracy: 0.7704\n",
      "Epoch 1044/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.8178 - val_loss: 0.6123 - val_accuracy: 0.7706\n",
      "Epoch 1045/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.8174 - val_loss: 0.6122 - val_accuracy: 0.7706\n",
      "Epoch 1046/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.8171 - val_loss: 0.6122 - val_accuracy: 0.7706\n",
      "Epoch 1047/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.8172 - val_loss: 0.6122 - val_accuracy: 0.7706\n",
      "Epoch 1048/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.8172 - val_loss: 0.6122 - val_accuracy: 0.7706\n",
      "Epoch 1049/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.8178 - val_loss: 0.6122 - val_accuracy: 0.7709\n",
      "Epoch 1050/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.8175 - val_loss: 0.6121 - val_accuracy: 0.7711\n",
      "Epoch 1051/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5095 - accuracy: 0.8172 - val_loss: 0.6121 - val_accuracy: 0.7709\n",
      "Epoch 1052/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.8174 - val_loss: 0.6121 - val_accuracy: 0.7706\n",
      "Epoch 1053/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.8177 - val_loss: 0.6122 - val_accuracy: 0.7709\n",
      "Epoch 1054/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.8175 - val_loss: 0.6121 - val_accuracy: 0.7711\n",
      "Epoch 1055/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.8177 - val_loss: 0.6121 - val_accuracy: 0.7709\n",
      "Epoch 1056/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.8171 - val_loss: 0.6121 - val_accuracy: 0.7711\n",
      "Epoch 1057/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5091 - accuracy: 0.8172 - val_loss: 0.6121 - val_accuracy: 0.7709\n",
      "Epoch 1058/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.8174 - val_loss: 0.6121 - val_accuracy: 0.7711\n",
      "Epoch 1059/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.8176 - val_loss: 0.6121 - val_accuracy: 0.7711\n",
      "Epoch 1060/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.8176 - val_loss: 0.6121 - val_accuracy: 0.7711\n",
      "Epoch 1061/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.8179 - val_loss: 0.6120 - val_accuracy: 0.7713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1062/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.8174 - val_loss: 0.6121 - val_accuracy: 0.7711\n",
      "Epoch 1063/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.8177 - val_loss: 0.6120 - val_accuracy: 0.7715\n",
      "Epoch 1064/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.8177 - val_loss: 0.6121 - val_accuracy: 0.7711\n",
      "Epoch 1065/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.8180 - val_loss: 0.6119 - val_accuracy: 0.7715\n",
      "Epoch 1066/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.8178 - val_loss: 0.6120 - val_accuracy: 0.7718\n",
      "Epoch 1067/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.8173 - val_loss: 0.6120 - val_accuracy: 0.7709\n",
      "Epoch 1068/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.8178 - val_loss: 0.6120 - val_accuracy: 0.7720\n",
      "Epoch 1069/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.8175 - val_loss: 0.6119 - val_accuracy: 0.7718\n",
      "Epoch 1070/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.8174 - val_loss: 0.6120 - val_accuracy: 0.7720\n",
      "Epoch 1071/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5082 - accuracy: 0.8172 - val_loss: 0.6119 - val_accuracy: 0.7713\n",
      "Epoch 1072/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.8180 - val_loss: 0.6119 - val_accuracy: 0.7718\n",
      "Epoch 1073/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.8169 - val_loss: 0.6119 - val_accuracy: 0.7718\n",
      "Epoch 1074/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.8176 - val_loss: 0.6119 - val_accuracy: 0.7718\n",
      "Epoch 1075/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.8177 - val_loss: 0.6119 - val_accuracy: 0.7711\n",
      "Epoch 1076/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.8179 - val_loss: 0.6118 - val_accuracy: 0.7713\n",
      "Epoch 1077/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.8172 - val_loss: 0.6118 - val_accuracy: 0.7720\n",
      "Epoch 1078/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.8172 - val_loss: 0.6118 - val_accuracy: 0.7713\n",
      "Epoch 1079/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.8179 - val_loss: 0.6118 - val_accuracy: 0.7718\n",
      "Epoch 1080/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.8177 - val_loss: 0.6118 - val_accuracy: 0.7715\n",
      "Epoch 1081/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.8178 - val_loss: 0.6118 - val_accuracy: 0.7711\n",
      "Epoch 1082/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.8173 - val_loss: 0.6118 - val_accuracy: 0.7720\n",
      "Epoch 1083/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.8173 - val_loss: 0.6117 - val_accuracy: 0.7720\n",
      "Epoch 1084/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.8177 - val_loss: 0.6117 - val_accuracy: 0.7720\n",
      "Epoch 1085/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.8174 - val_loss: 0.6118 - val_accuracy: 0.7715\n",
      "Epoch 1086/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.8173 - val_loss: 0.6118 - val_accuracy: 0.7718\n",
      "Epoch 1087/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.8183 - val_loss: 0.6117 - val_accuracy: 0.7715\n",
      "Epoch 1088/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.8177 - val_loss: 0.6117 - val_accuracy: 0.7715\n",
      "Epoch 1089/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.8175 - val_loss: 0.6117 - val_accuracy: 0.7718\n",
      "Epoch 1090/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.8177 - val_loss: 0.6116 - val_accuracy: 0.7720\n",
      "Epoch 1091/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.8177 - val_loss: 0.6117 - val_accuracy: 0.7722\n",
      "Epoch 1092/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.8181 - val_loss: 0.6117 - val_accuracy: 0.7722\n",
      "Epoch 1093/2000\n",
      "138/138 [==============================] - 1s 4ms/step - loss: 0.5068 - accuracy: 0.8174 - val_loss: 0.6117 - val_accuracy: 0.7718\n",
      "Epoch 1094/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.8175 - val_loss: 0.6117 - val_accuracy: 0.7720\n",
      "Epoch 1095/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.8176 - val_loss: 0.6116 - val_accuracy: 0.7720\n",
      "Epoch 1096/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.8175 - val_loss: 0.6116 - val_accuracy: 0.7722\n",
      "Epoch 1097/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.8177 - val_loss: 0.6116 - val_accuracy: 0.7720\n",
      "Epoch 1098/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.8179 - val_loss: 0.6117 - val_accuracy: 0.7715\n",
      "Epoch 1099/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.8177 - val_loss: 0.6116 - val_accuracy: 0.7715\n",
      "Epoch 1100/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.8177 - val_loss: 0.6116 - val_accuracy: 0.7718\n",
      "Epoch 1101/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.8174 - val_loss: 0.6116 - val_accuracy: 0.7713\n",
      "Epoch 1102/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.8174 - val_loss: 0.6116 - val_accuracy: 0.7718\n",
      "Epoch 1103/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.8178 - val_loss: 0.6116 - val_accuracy: 0.7715\n",
      "Epoch 1104/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.8179 - val_loss: 0.6116 - val_accuracy: 0.7715\n",
      "Epoch 1105/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.8176 - val_loss: 0.6115 - val_accuracy: 0.7715\n",
      "Epoch 1106/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.8175 - val_loss: 0.6115 - val_accuracy: 0.7713\n",
      "Epoch 1107/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.8181 - val_loss: 0.6115 - val_accuracy: 0.7718\n",
      "Epoch 1108/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.8179 - val_loss: 0.6115 - val_accuracy: 0.7718\n",
      "Epoch 1109/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.8182 - val_loss: 0.6115 - val_accuracy: 0.7718\n",
      "Epoch 1110/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.8177 - val_loss: 0.6116 - val_accuracy: 0.7715\n",
      "Epoch 1111/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.8179 - val_loss: 0.6115 - val_accuracy: 0.7718\n",
      "Epoch 1112/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.8178 - val_loss: 0.6115 - val_accuracy: 0.7715\n",
      "Epoch 1113/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.8177 - val_loss: 0.6115 - val_accuracy: 0.7715\n",
      "Epoch 1114/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.8177 - val_loss: 0.6115 - val_accuracy: 0.7720\n",
      "Epoch 1115/2000\n",
      "138/138 [==============================] - 1s 4ms/step - loss: 0.5055 - accuracy: 0.8175 - val_loss: 0.6115 - val_accuracy: 0.7715\n",
      "Epoch 1116/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.8182 - val_loss: 0.6115 - val_accuracy: 0.7715\n",
      "Epoch 1117/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.8179 - val_loss: 0.6115 - val_accuracy: 0.7715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1118/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.8179 - val_loss: 0.6114 - val_accuracy: 0.7720\n",
      "Epoch 1119/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.8180 - val_loss: 0.6114 - val_accuracy: 0.7720\n",
      "Epoch 1120/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.8180 - val_loss: 0.6114 - val_accuracy: 0.7718\n",
      "Epoch 1121/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.8182 - val_loss: 0.6114 - val_accuracy: 0.7720\n",
      "Epoch 1122/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.8176 - val_loss: 0.6114 - val_accuracy: 0.7720\n",
      "Epoch 1123/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.8182 - val_loss: 0.6114 - val_accuracy: 0.7720\n",
      "Epoch 1124/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.8176 - val_loss: 0.6114 - val_accuracy: 0.7718\n",
      "Epoch 1125/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.8178 - val_loss: 0.6114 - val_accuracy: 0.7711\n",
      "Epoch 1126/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.8180 - val_loss: 0.6114 - val_accuracy: 0.7720\n",
      "Epoch 1127/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.8179 - val_loss: 0.6114 - val_accuracy: 0.7718\n",
      "Epoch 1128/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.8183 - val_loss: 0.6114 - val_accuracy: 0.7715\n",
      "Epoch 1129/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.8184 - val_loss: 0.6114 - val_accuracy: 0.7718\n",
      "Epoch 1130/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.8182 - val_loss: 0.6113 - val_accuracy: 0.7715\n",
      "Epoch 1131/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.8180 - val_loss: 0.6114 - val_accuracy: 0.7711\n",
      "Epoch 1132/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.8178 - val_loss: 0.6113 - val_accuracy: 0.7715\n",
      "Epoch 1133/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.8180 - val_loss: 0.6113 - val_accuracy: 0.7715\n",
      "Epoch 1134/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.8180 - val_loss: 0.6113 - val_accuracy: 0.7713\n",
      "Epoch 1135/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.8183 - val_loss: 0.6113 - val_accuracy: 0.7715\n",
      "Epoch 1136/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.8181 - val_loss: 0.6113 - val_accuracy: 0.7715\n",
      "Epoch 1137/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.8182 - val_loss: 0.6113 - val_accuracy: 0.7711\n",
      "Epoch 1138/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.8179 - val_loss: 0.6113 - val_accuracy: 0.7720\n",
      "Epoch 1139/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.8179 - val_loss: 0.6113 - val_accuracy: 0.7720\n",
      "Epoch 1140/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.8178 - val_loss: 0.6112 - val_accuracy: 0.7720\n",
      "Epoch 1141/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.8181 - val_loss: 0.6112 - val_accuracy: 0.7720\n",
      "Epoch 1142/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.8181 - val_loss: 0.6112 - val_accuracy: 0.7722\n",
      "Epoch 1143/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.8181 - val_loss: 0.6112 - val_accuracy: 0.7722\n",
      "Epoch 1144/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.8183 - val_loss: 0.6113 - val_accuracy: 0.7720\n",
      "Epoch 1145/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.8181 - val_loss: 0.6112 - val_accuracy: 0.7722\n",
      "Epoch 1146/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.8178 - val_loss: 0.6112 - val_accuracy: 0.7720\n",
      "Epoch 1147/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5037 - accuracy: 0.8181 - val_loss: 0.6112 - val_accuracy: 0.7718\n",
      "Epoch 1148/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5037 - accuracy: 0.8185 - val_loss: 0.6112 - val_accuracy: 0.7718\n",
      "Epoch 1149/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5036 - accuracy: 0.8178 - val_loss: 0.6112 - val_accuracy: 0.7715\n",
      "Epoch 1150/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5036 - accuracy: 0.8181 - val_loss: 0.6112 - val_accuracy: 0.7720\n",
      "Epoch 1151/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5035 - accuracy: 0.8178 - val_loss: 0.6112 - val_accuracy: 0.7720\n",
      "Epoch 1152/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5035 - accuracy: 0.8179 - val_loss: 0.6111 - val_accuracy: 0.7720\n",
      "Epoch 1153/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5034 - accuracy: 0.8183 - val_loss: 0.6112 - val_accuracy: 0.7724\n",
      "Epoch 1154/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5033 - accuracy: 0.8182 - val_loss: 0.6111 - val_accuracy: 0.7722\n",
      "Epoch 1155/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5033 - accuracy: 0.8179 - val_loss: 0.6111 - val_accuracy: 0.7722\n",
      "Epoch 1156/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5032 - accuracy: 0.8185 - val_loss: 0.6112 - val_accuracy: 0.7722\n",
      "Epoch 1157/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5032 - accuracy: 0.8178 - val_loss: 0.6111 - val_accuracy: 0.7722\n",
      "Epoch 1158/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5032 - accuracy: 0.8186 - val_loss: 0.6111 - val_accuracy: 0.7724\n",
      "Epoch 1159/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5031 - accuracy: 0.8184 - val_loss: 0.6111 - val_accuracy: 0.7720\n",
      "Epoch 1160/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5030 - accuracy: 0.8184 - val_loss: 0.6111 - val_accuracy: 0.7722\n",
      "Epoch 1161/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.8183 - val_loss: 0.6111 - val_accuracy: 0.7720\n",
      "Epoch 1162/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5030 - accuracy: 0.8183 - val_loss: 0.6111 - val_accuracy: 0.7720\n",
      "Epoch 1163/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.8185 - val_loss: 0.6111 - val_accuracy: 0.7722\n",
      "Epoch 1164/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.8188 - val_loss: 0.6111 - val_accuracy: 0.7727\n",
      "Epoch 1165/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5028 - accuracy: 0.8182 - val_loss: 0.6111 - val_accuracy: 0.7724\n",
      "Epoch 1166/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5028 - accuracy: 0.8183 - val_loss: 0.6110 - val_accuracy: 0.7718\n",
      "Epoch 1167/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.8183 - val_loss: 0.6110 - val_accuracy: 0.7724\n",
      "Epoch 1168/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.8185 - val_loss: 0.6111 - val_accuracy: 0.7718\n",
      "Epoch 1169/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5026 - accuracy: 0.8184 - val_loss: 0.6110 - val_accuracy: 0.7720\n",
      "Epoch 1170/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5026 - accuracy: 0.8181 - val_loss: 0.6110 - val_accuracy: 0.7720\n",
      "Epoch 1171/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5025 - accuracy: 0.8181 - val_loss: 0.6110 - val_accuracy: 0.7724\n",
      "Epoch 1172/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5024 - accuracy: 0.8186 - val_loss: 0.6110 - val_accuracy: 0.7724\n",
      "Epoch 1173/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5024 - accuracy: 0.8181 - val_loss: 0.6111 - val_accuracy: 0.7720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1174/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5024 - accuracy: 0.8182 - val_loss: 0.6111 - val_accuracy: 0.7724\n",
      "Epoch 1175/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5023 - accuracy: 0.8183 - val_loss: 0.6110 - val_accuracy: 0.7722\n",
      "Epoch 1176/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5022 - accuracy: 0.8184 - val_loss: 0.6110 - val_accuracy: 0.7722\n",
      "Epoch 1177/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5022 - accuracy: 0.8182 - val_loss: 0.6110 - val_accuracy: 0.7724\n",
      "Epoch 1178/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5021 - accuracy: 0.8185 - val_loss: 0.6110 - val_accuracy: 0.7720\n",
      "Epoch 1179/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5021 - accuracy: 0.8181 - val_loss: 0.6109 - val_accuracy: 0.7715\n",
      "Epoch 1180/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5020 - accuracy: 0.8182 - val_loss: 0.6110 - val_accuracy: 0.7724\n",
      "Epoch 1181/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5020 - accuracy: 0.8182 - val_loss: 0.6109 - val_accuracy: 0.7724\n",
      "Epoch 1182/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5020 - accuracy: 0.8181 - val_loss: 0.6109 - val_accuracy: 0.7724\n",
      "Epoch 1183/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5019 - accuracy: 0.8178 - val_loss: 0.6109 - val_accuracy: 0.7724\n",
      "Epoch 1184/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5018 - accuracy: 0.8179 - val_loss: 0.6109 - val_accuracy: 0.7727\n",
      "Epoch 1185/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5018 - accuracy: 0.8187 - val_loss: 0.6109 - val_accuracy: 0.7724\n",
      "Epoch 1186/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5017 - accuracy: 0.8183 - val_loss: 0.6109 - val_accuracy: 0.7727\n",
      "Epoch 1187/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5017 - accuracy: 0.8182 - val_loss: 0.6109 - val_accuracy: 0.7727\n",
      "Epoch 1188/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5016 - accuracy: 0.8183 - val_loss: 0.6109 - val_accuracy: 0.7724\n",
      "Epoch 1189/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5016 - accuracy: 0.8181 - val_loss: 0.6109 - val_accuracy: 0.7727\n",
      "Epoch 1190/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5016 - accuracy: 0.8182 - val_loss: 0.6109 - val_accuracy: 0.7724\n",
      "Epoch 1191/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5015 - accuracy: 0.8185 - val_loss: 0.6109 - val_accuracy: 0.7722\n",
      "Epoch 1192/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5015 - accuracy: 0.8178 - val_loss: 0.6109 - val_accuracy: 0.7720\n",
      "Epoch 1193/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5014 - accuracy: 0.8187 - val_loss: 0.6108 - val_accuracy: 0.7727\n",
      "Epoch 1194/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5014 - accuracy: 0.8179 - val_loss: 0.6109 - val_accuracy: 0.7722\n",
      "Epoch 1195/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5013 - accuracy: 0.8182 - val_loss: 0.6108 - val_accuracy: 0.7722\n",
      "Epoch 1196/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5012 - accuracy: 0.8181 - val_loss: 0.6108 - val_accuracy: 0.7722\n",
      "Epoch 1197/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5012 - accuracy: 0.8181 - val_loss: 0.6108 - val_accuracy: 0.7722\n",
      "Epoch 1198/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5012 - accuracy: 0.8182 - val_loss: 0.6108 - val_accuracy: 0.7718\n",
      "Epoch 1199/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5011 - accuracy: 0.8181 - val_loss: 0.6108 - val_accuracy: 0.7724\n",
      "Epoch 1200/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5010 - accuracy: 0.8178 - val_loss: 0.6108 - val_accuracy: 0.7722\n",
      "Epoch 1201/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5010 - accuracy: 0.8180 - val_loss: 0.6108 - val_accuracy: 0.7715\n",
      "Epoch 1202/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5010 - accuracy: 0.8178 - val_loss: 0.6108 - val_accuracy: 0.7718\n",
      "Epoch 1203/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5009 - accuracy: 0.8183 - val_loss: 0.6107 - val_accuracy: 0.7722\n",
      "Epoch 1204/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5009 - accuracy: 0.8183 - val_loss: 0.6108 - val_accuracy: 0.7720\n",
      "Epoch 1205/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5008 - accuracy: 0.8183 - val_loss: 0.6107 - val_accuracy: 0.7715\n",
      "Epoch 1206/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.5008 - accuracy: 0.8182 - val_loss: 0.6107 - val_accuracy: 0.7715\n",
      "Epoch 1207/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5007 - accuracy: 0.8183 - val_loss: 0.6107 - val_accuracy: 0.7724\n",
      "Epoch 1208/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5007 - accuracy: 0.8182 - val_loss: 0.6107 - val_accuracy: 0.7720\n",
      "Epoch 1209/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5007 - accuracy: 0.8183 - val_loss: 0.6107 - val_accuracy: 0.7722\n",
      "Epoch 1210/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5006 - accuracy: 0.8179 - val_loss: 0.6107 - val_accuracy: 0.7715\n",
      "Epoch 1211/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5006 - accuracy: 0.8180 - val_loss: 0.6107 - val_accuracy: 0.7718\n",
      "Epoch 1212/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5005 - accuracy: 0.8182 - val_loss: 0.6107 - val_accuracy: 0.7718\n",
      "Epoch 1213/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5005 - accuracy: 0.8182 - val_loss: 0.6107 - val_accuracy: 0.7718\n",
      "Epoch 1214/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5004 - accuracy: 0.8178 - val_loss: 0.6107 - val_accuracy: 0.7706\n",
      "Epoch 1215/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.5004 - accuracy: 0.8181 - val_loss: 0.6106 - val_accuracy: 0.7711\n",
      "Epoch 1216/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5003 - accuracy: 0.8182 - val_loss: 0.6106 - val_accuracy: 0.7715\n",
      "Epoch 1217/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5003 - accuracy: 0.8182 - val_loss: 0.6106 - val_accuracy: 0.7713\n",
      "Epoch 1218/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5002 - accuracy: 0.8181 - val_loss: 0.6106 - val_accuracy: 0.7715\n",
      "Epoch 1219/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5002 - accuracy: 0.8183 - val_loss: 0.6106 - val_accuracy: 0.7711\n",
      "Epoch 1220/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5001 - accuracy: 0.8181 - val_loss: 0.6106 - val_accuracy: 0.7715\n",
      "Epoch 1221/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5001 - accuracy: 0.8182 - val_loss: 0.6106 - val_accuracy: 0.7709\n",
      "Epoch 1222/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.8186 - val_loss: 0.6106 - val_accuracy: 0.7715\n",
      "Epoch 1223/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.8181 - val_loss: 0.6106 - val_accuracy: 0.7713\n",
      "Epoch 1224/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.8183 - val_loss: 0.6106 - val_accuracy: 0.7720\n",
      "Epoch 1225/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.8181 - val_loss: 0.6106 - val_accuracy: 0.7722\n",
      "Epoch 1226/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.4999 - accuracy: 0.8178 - val_loss: 0.6106 - val_accuracy: 0.7713\n",
      "Epoch 1227/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4998 - accuracy: 0.8185 - val_loss: 0.6106 - val_accuracy: 0.7704\n",
      "Epoch 1228/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4998 - accuracy: 0.8181 - val_loss: 0.6105 - val_accuracy: 0.7711\n",
      "Epoch 1229/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4998 - accuracy: 0.8182 - val_loss: 0.6105 - val_accuracy: 0.7709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1230/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4997 - accuracy: 0.8179 - val_loss: 0.6105 - val_accuracy: 0.7706\n",
      "Epoch 1231/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4997 - accuracy: 0.8183 - val_loss: 0.6105 - val_accuracy: 0.7711\n",
      "Epoch 1232/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4996 - accuracy: 0.8181 - val_loss: 0.6105 - val_accuracy: 0.7709\n",
      "Epoch 1233/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4996 - accuracy: 0.8186 - val_loss: 0.6105 - val_accuracy: 0.7722\n",
      "Epoch 1234/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4995 - accuracy: 0.8182 - val_loss: 0.6105 - val_accuracy: 0.7713\n",
      "Epoch 1235/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4995 - accuracy: 0.8180 - val_loss: 0.6104 - val_accuracy: 0.7711\n",
      "Epoch 1236/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4994 - accuracy: 0.8183 - val_loss: 0.6105 - val_accuracy: 0.7706\n",
      "Epoch 1237/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4994 - accuracy: 0.8185 - val_loss: 0.6105 - val_accuracy: 0.7709\n",
      "Epoch 1238/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4994 - accuracy: 0.8184 - val_loss: 0.6104 - val_accuracy: 0.7704\n",
      "Epoch 1239/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4993 - accuracy: 0.8180 - val_loss: 0.6105 - val_accuracy: 0.7706\n",
      "Epoch 1240/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4993 - accuracy: 0.8184 - val_loss: 0.6104 - val_accuracy: 0.7706\n",
      "Epoch 1241/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4992 - accuracy: 0.8185 - val_loss: 0.6105 - val_accuracy: 0.7706\n",
      "Epoch 1242/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4992 - accuracy: 0.8183 - val_loss: 0.6104 - val_accuracy: 0.7711\n",
      "Epoch 1243/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4992 - accuracy: 0.8181 - val_loss: 0.6104 - val_accuracy: 0.7706\n",
      "Epoch 1244/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4991 - accuracy: 0.8179 - val_loss: 0.6103 - val_accuracy: 0.7713\n",
      "Epoch 1245/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4990 - accuracy: 0.8179 - val_loss: 0.6104 - val_accuracy: 0.7711\n",
      "Epoch 1246/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4990 - accuracy: 0.8181 - val_loss: 0.6104 - val_accuracy: 0.7706\n",
      "Epoch 1247/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4990 - accuracy: 0.8179 - val_loss: 0.6103 - val_accuracy: 0.7711\n",
      "Epoch 1248/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4989 - accuracy: 0.8183 - val_loss: 0.6103 - val_accuracy: 0.7711\n",
      "Epoch 1249/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4989 - accuracy: 0.8182 - val_loss: 0.6102 - val_accuracy: 0.7715\n",
      "Epoch 1250/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4988 - accuracy: 0.8188 - val_loss: 0.6103 - val_accuracy: 0.7711\n",
      "Epoch 1251/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4988 - accuracy: 0.8175 - val_loss: 0.6103 - val_accuracy: 0.7706\n",
      "Epoch 1252/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4988 - accuracy: 0.8180 - val_loss: 0.6102 - val_accuracy: 0.7713\n",
      "Epoch 1253/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4987 - accuracy: 0.8183 - val_loss: 0.6103 - val_accuracy: 0.7713\n",
      "Epoch 1254/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.4987 - accuracy: 0.8182 - val_loss: 0.6103 - val_accuracy: 0.7718\n",
      "Epoch 1255/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4986 - accuracy: 0.8183 - val_loss: 0.6102 - val_accuracy: 0.7711\n",
      "Epoch 1256/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4986 - accuracy: 0.8183 - val_loss: 0.6102 - val_accuracy: 0.7706\n",
      "Epoch 1257/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.8183 - val_loss: 0.6102 - val_accuracy: 0.7713\n",
      "Epoch 1258/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4985 - accuracy: 0.8182 - val_loss: 0.6102 - val_accuracy: 0.7711\n",
      "Epoch 1259/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4985 - accuracy: 0.8179 - val_loss: 0.6102 - val_accuracy: 0.7713\n",
      "Epoch 1260/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4984 - accuracy: 0.8182 - val_loss: 0.6102 - val_accuracy: 0.7713\n",
      "Epoch 1261/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4984 - accuracy: 0.8180 - val_loss: 0.6102 - val_accuracy: 0.7711\n",
      "Epoch 1262/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4983 - accuracy: 0.8179 - val_loss: 0.6101 - val_accuracy: 0.7711\n",
      "Epoch 1263/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4983 - accuracy: 0.8187 - val_loss: 0.6102 - val_accuracy: 0.7713\n",
      "Epoch 1264/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4983 - accuracy: 0.8178 - val_loss: 0.6102 - val_accuracy: 0.7713\n",
      "Epoch 1265/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4982 - accuracy: 0.8187 - val_loss: 0.6101 - val_accuracy: 0.7720\n",
      "Epoch 1266/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4982 - accuracy: 0.8183 - val_loss: 0.6101 - val_accuracy: 0.7715\n",
      "Epoch 1267/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.8181 - val_loss: 0.6101 - val_accuracy: 0.7718\n",
      "Epoch 1268/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4981 - accuracy: 0.8184 - val_loss: 0.6101 - val_accuracy: 0.7715\n",
      "Epoch 1269/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4981 - accuracy: 0.8178 - val_loss: 0.6101 - val_accuracy: 0.7715\n",
      "Epoch 1270/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4980 - accuracy: 0.8179 - val_loss: 0.6101 - val_accuracy: 0.7715\n",
      "Epoch 1271/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4980 - accuracy: 0.8181 - val_loss: 0.6101 - val_accuracy: 0.7720\n",
      "Epoch 1272/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4979 - accuracy: 0.8181 - val_loss: 0.6101 - val_accuracy: 0.7715\n",
      "Epoch 1273/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4979 - accuracy: 0.8185 - val_loss: 0.6101 - val_accuracy: 0.7718\n",
      "Epoch 1274/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4978 - accuracy: 0.8179 - val_loss: 0.6100 - val_accuracy: 0.7720\n",
      "Epoch 1275/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4978 - accuracy: 0.8183 - val_loss: 0.6101 - val_accuracy: 0.7713\n",
      "Epoch 1276/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4978 - accuracy: 0.8183 - val_loss: 0.6101 - val_accuracy: 0.7715\n",
      "Epoch 1277/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4977 - accuracy: 0.8185 - val_loss: 0.6101 - val_accuracy: 0.7715\n",
      "Epoch 1278/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4977 - accuracy: 0.8180 - val_loss: 0.6101 - val_accuracy: 0.7720\n",
      "Epoch 1279/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4976 - accuracy: 0.8184 - val_loss: 0.6101 - val_accuracy: 0.7715\n",
      "Epoch 1280/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4976 - accuracy: 0.8182 - val_loss: 0.6100 - val_accuracy: 0.7715\n",
      "Epoch 1281/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4976 - accuracy: 0.8184 - val_loss: 0.6100 - val_accuracy: 0.7722\n",
      "Epoch 1282/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4975 - accuracy: 0.8186 - val_loss: 0.6101 - val_accuracy: 0.7718\n",
      "Epoch 1283/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4975 - accuracy: 0.8183 - val_loss: 0.6100 - val_accuracy: 0.7713\n",
      "Epoch 1284/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4974 - accuracy: 0.8184 - val_loss: 0.6100 - val_accuracy: 0.7724\n",
      "Epoch 1285/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4974 - accuracy: 0.8181 - val_loss: 0.6100 - val_accuracy: 0.7718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1286/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4974 - accuracy: 0.8185 - val_loss: 0.6100 - val_accuracy: 0.7720\n",
      "Epoch 1287/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4973 - accuracy: 0.8186 - val_loss: 0.6100 - val_accuracy: 0.7718\n",
      "Epoch 1288/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4973 - accuracy: 0.8183 - val_loss: 0.6100 - val_accuracy: 0.7720\n",
      "Epoch 1289/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4973 - accuracy: 0.8186 - val_loss: 0.6100 - val_accuracy: 0.7722\n",
      "Epoch 1290/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4972 - accuracy: 0.8183 - val_loss: 0.6100 - val_accuracy: 0.7720\n",
      "Epoch 1291/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4972 - accuracy: 0.8185 - val_loss: 0.6099 - val_accuracy: 0.7722\n",
      "Epoch 1292/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4971 - accuracy: 0.8182 - val_loss: 0.6099 - val_accuracy: 0.7727\n",
      "Epoch 1293/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4971 - accuracy: 0.8186 - val_loss: 0.6099 - val_accuracy: 0.7724\n",
      "Epoch 1294/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4971 - accuracy: 0.8183 - val_loss: 0.6099 - val_accuracy: 0.7727\n",
      "Epoch 1295/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4970 - accuracy: 0.8185 - val_loss: 0.6099 - val_accuracy: 0.7720\n",
      "Epoch 1296/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4970 - accuracy: 0.8185 - val_loss: 0.6099 - val_accuracy: 0.7718\n",
      "Epoch 1297/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4970 - accuracy: 0.8186 - val_loss: 0.6099 - val_accuracy: 0.7720\n",
      "Epoch 1298/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4969 - accuracy: 0.8188 - val_loss: 0.6099 - val_accuracy: 0.7722\n",
      "Epoch 1299/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4969 - accuracy: 0.8186 - val_loss: 0.6099 - val_accuracy: 0.7722\n",
      "Epoch 1300/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4968 - accuracy: 0.8187 - val_loss: 0.6099 - val_accuracy: 0.7724\n",
      "Epoch 1301/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4968 - accuracy: 0.8183 - val_loss: 0.6099 - val_accuracy: 0.7722\n",
      "Epoch 1302/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4967 - accuracy: 0.8188 - val_loss: 0.6098 - val_accuracy: 0.7724\n",
      "Epoch 1303/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4967 - accuracy: 0.8184 - val_loss: 0.6099 - val_accuracy: 0.7720\n",
      "Epoch 1304/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4966 - accuracy: 0.8183 - val_loss: 0.6098 - val_accuracy: 0.7727\n",
      "Epoch 1305/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4966 - accuracy: 0.8191 - val_loss: 0.6099 - val_accuracy: 0.7724\n",
      "Epoch 1306/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4966 - accuracy: 0.8181 - val_loss: 0.6098 - val_accuracy: 0.7722\n",
      "Epoch 1307/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4966 - accuracy: 0.8188 - val_loss: 0.6098 - val_accuracy: 0.7713\n",
      "Epoch 1308/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4965 - accuracy: 0.8186 - val_loss: 0.6098 - val_accuracy: 0.7722\n",
      "Epoch 1309/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4965 - accuracy: 0.8185 - val_loss: 0.6099 - val_accuracy: 0.7727\n",
      "Epoch 1310/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4965 - accuracy: 0.8185 - val_loss: 0.6099 - val_accuracy: 0.7722\n",
      "Epoch 1311/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4964 - accuracy: 0.8182 - val_loss: 0.6098 - val_accuracy: 0.7724\n",
      "Epoch 1312/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4963 - accuracy: 0.8186 - val_loss: 0.6097 - val_accuracy: 0.7718\n",
      "Epoch 1313/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4963 - accuracy: 0.8187 - val_loss: 0.6097 - val_accuracy: 0.7715\n",
      "Epoch 1314/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4963 - accuracy: 0.8183 - val_loss: 0.6098 - val_accuracy: 0.7729\n",
      "Epoch 1315/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4963 - accuracy: 0.8185 - val_loss: 0.6098 - val_accuracy: 0.7720\n",
      "Epoch 1316/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4962 - accuracy: 0.8187 - val_loss: 0.6097 - val_accuracy: 0.7720\n",
      "Epoch 1317/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4962 - accuracy: 0.8183 - val_loss: 0.6098 - val_accuracy: 0.7722\n",
      "Epoch 1318/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4961 - accuracy: 0.8183 - val_loss: 0.6097 - val_accuracy: 0.7720\n",
      "Epoch 1319/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4961 - accuracy: 0.8183 - val_loss: 0.6097 - val_accuracy: 0.7718\n",
      "Epoch 1320/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4961 - accuracy: 0.8190 - val_loss: 0.6097 - val_accuracy: 0.7720\n",
      "Epoch 1321/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4960 - accuracy: 0.8183 - val_loss: 0.6097 - val_accuracy: 0.7731\n",
      "Epoch 1322/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4960 - accuracy: 0.8185 - val_loss: 0.6097 - val_accuracy: 0.7715\n",
      "Epoch 1323/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4960 - accuracy: 0.8188 - val_loss: 0.6097 - val_accuracy: 0.7727\n",
      "Epoch 1324/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4959 - accuracy: 0.8190 - val_loss: 0.6097 - val_accuracy: 0.7727\n",
      "Epoch 1325/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.8188 - val_loss: 0.6097 - val_accuracy: 0.7715\n",
      "Epoch 1326/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4959 - accuracy: 0.8187 - val_loss: 0.6097 - val_accuracy: 0.7718\n",
      "Epoch 1327/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4958 - accuracy: 0.8186 - val_loss: 0.6096 - val_accuracy: 0.7718\n",
      "Epoch 1328/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4958 - accuracy: 0.8187 - val_loss: 0.6097 - val_accuracy: 0.7720\n",
      "Epoch 1329/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4957 - accuracy: 0.8185 - val_loss: 0.6096 - val_accuracy: 0.7720\n",
      "Epoch 1330/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4957 - accuracy: 0.8187 - val_loss: 0.6096 - val_accuracy: 0.7715\n",
      "Epoch 1331/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4957 - accuracy: 0.8187 - val_loss: 0.6096 - val_accuracy: 0.7713\n",
      "Epoch 1332/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4956 - accuracy: 0.8191 - val_loss: 0.6096 - val_accuracy: 0.7720\n",
      "Epoch 1333/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4956 - accuracy: 0.8185 - val_loss: 0.6097 - val_accuracy: 0.7720\n",
      "Epoch 1334/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4955 - accuracy: 0.8187 - val_loss: 0.6096 - val_accuracy: 0.7718\n",
      "Epoch 1335/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4955 - accuracy: 0.8188 - val_loss: 0.6096 - val_accuracy: 0.7720\n",
      "Epoch 1336/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4955 - accuracy: 0.8184 - val_loss: 0.6096 - val_accuracy: 0.7724\n",
      "Epoch 1337/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4955 - accuracy: 0.8187 - val_loss: 0.6096 - val_accuracy: 0.7718\n",
      "Epoch 1338/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4954 - accuracy: 0.8188 - val_loss: 0.6096 - val_accuracy: 0.7713\n",
      "Epoch 1339/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.8185 - val_loss: 0.6096 - val_accuracy: 0.7720\n",
      "Epoch 1340/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4953 - accuracy: 0.8182 - val_loss: 0.6096 - val_accuracy: 0.7722\n",
      "Epoch 1341/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4953 - accuracy: 0.8184 - val_loss: 0.6096 - val_accuracy: 0.7720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1342/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4953 - accuracy: 0.8186 - val_loss: 0.6095 - val_accuracy: 0.7711\n",
      "Epoch 1343/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.4952 - accuracy: 0.8187 - val_loss: 0.6095 - val_accuracy: 0.7709\n",
      "Epoch 1344/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4952 - accuracy: 0.8186 - val_loss: 0.6095 - val_accuracy: 0.7713\n",
      "Epoch 1345/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4952 - accuracy: 0.8187 - val_loss: 0.6096 - val_accuracy: 0.7720\n",
      "Epoch 1346/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4951 - accuracy: 0.8185 - val_loss: 0.6096 - val_accuracy: 0.7718\n",
      "Epoch 1347/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4951 - accuracy: 0.8190 - val_loss: 0.6096 - val_accuracy: 0.7720\n",
      "Epoch 1348/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4951 - accuracy: 0.8191 - val_loss: 0.6096 - val_accuracy: 0.7718\n",
      "Epoch 1349/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4950 - accuracy: 0.8187 - val_loss: 0.6095 - val_accuracy: 0.7713\n",
      "Epoch 1350/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4950 - accuracy: 0.8182 - val_loss: 0.6095 - val_accuracy: 0.7713\n",
      "Epoch 1351/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4949 - accuracy: 0.8192 - val_loss: 0.6095 - val_accuracy: 0.7713\n",
      "Epoch 1352/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4949 - accuracy: 0.8186 - val_loss: 0.6095 - val_accuracy: 0.7713\n",
      "Epoch 1353/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4949 - accuracy: 0.8188 - val_loss: 0.6094 - val_accuracy: 0.7713\n",
      "Epoch 1354/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4949 - accuracy: 0.8187 - val_loss: 0.6095 - val_accuracy: 0.7715\n",
      "Epoch 1355/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4948 - accuracy: 0.8187 - val_loss: 0.6095 - val_accuracy: 0.7720\n",
      "Epoch 1356/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4948 - accuracy: 0.8187 - val_loss: 0.6095 - val_accuracy: 0.7715\n",
      "Epoch 1357/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4947 - accuracy: 0.8185 - val_loss: 0.6095 - val_accuracy: 0.7711\n",
      "Epoch 1358/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4947 - accuracy: 0.8185 - val_loss: 0.6094 - val_accuracy: 0.7713\n",
      "Epoch 1359/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4946 - accuracy: 0.8185 - val_loss: 0.6095 - val_accuracy: 0.7722\n",
      "Epoch 1360/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4946 - accuracy: 0.8187 - val_loss: 0.6094 - val_accuracy: 0.7711\n",
      "Epoch 1361/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4946 - accuracy: 0.8183 - val_loss: 0.6094 - val_accuracy: 0.7713\n",
      "Epoch 1362/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4946 - accuracy: 0.8187 - val_loss: 0.6094 - val_accuracy: 0.7709\n",
      "Epoch 1363/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4945 - accuracy: 0.8189 - val_loss: 0.6094 - val_accuracy: 0.7715\n",
      "Epoch 1364/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4945 - accuracy: 0.8186 - val_loss: 0.6094 - val_accuracy: 0.7711\n",
      "Epoch 1365/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4944 - accuracy: 0.8183 - val_loss: 0.6094 - val_accuracy: 0.7713\n",
      "Epoch 1366/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4944 - accuracy: 0.8183 - val_loss: 0.6095 - val_accuracy: 0.7724\n",
      "Epoch 1367/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4944 - accuracy: 0.8187 - val_loss: 0.6094 - val_accuracy: 0.7715\n",
      "Epoch 1368/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4943 - accuracy: 0.8183 - val_loss: 0.6094 - val_accuracy: 0.7711\n",
      "Epoch 1369/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4943 - accuracy: 0.8188 - val_loss: 0.6094 - val_accuracy: 0.7709\n",
      "Epoch 1370/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4943 - accuracy: 0.8190 - val_loss: 0.6094 - val_accuracy: 0.7711\n",
      "Epoch 1371/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4942 - accuracy: 0.8188 - val_loss: 0.6093 - val_accuracy: 0.7706\n",
      "Epoch 1372/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4942 - accuracy: 0.8186 - val_loss: 0.6094 - val_accuracy: 0.7713\n",
      "Epoch 1373/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4942 - accuracy: 0.8184 - val_loss: 0.6094 - val_accuracy: 0.7711\n",
      "Epoch 1374/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4942 - accuracy: 0.8193 - val_loss: 0.6093 - val_accuracy: 0.7706\n",
      "Epoch 1375/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4941 - accuracy: 0.8184 - val_loss: 0.6093 - val_accuracy: 0.7704\n",
      "Epoch 1376/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4941 - accuracy: 0.8186 - val_loss: 0.6093 - val_accuracy: 0.7706\n",
      "Epoch 1377/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4940 - accuracy: 0.8188 - val_loss: 0.6093 - val_accuracy: 0.7709\n",
      "Epoch 1378/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4940 - accuracy: 0.8186 - val_loss: 0.6093 - val_accuracy: 0.7709\n",
      "Epoch 1379/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4940 - accuracy: 0.8186 - val_loss: 0.6093 - val_accuracy: 0.7711\n",
      "Epoch 1380/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4939 - accuracy: 0.8190 - val_loss: 0.6093 - val_accuracy: 0.7704\n",
      "Epoch 1381/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4939 - accuracy: 0.8186 - val_loss: 0.6094 - val_accuracy: 0.7722\n",
      "Epoch 1382/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4939 - accuracy: 0.8190 - val_loss: 0.6093 - val_accuracy: 0.7706\n",
      "Epoch 1383/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4938 - accuracy: 0.8191 - val_loss: 0.6092 - val_accuracy: 0.7709\n",
      "Epoch 1384/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4938 - accuracy: 0.8186 - val_loss: 0.6092 - val_accuracy: 0.7704\n",
      "Epoch 1385/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4938 - accuracy: 0.8187 - val_loss: 0.6093 - val_accuracy: 0.7706\n",
      "Epoch 1386/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4938 - accuracy: 0.8191 - val_loss: 0.6093 - val_accuracy: 0.7724\n",
      "Epoch 1387/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4937 - accuracy: 0.8190 - val_loss: 0.6092 - val_accuracy: 0.7711\n",
      "Epoch 1388/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4936 - accuracy: 0.8187 - val_loss: 0.6093 - val_accuracy: 0.7718\n",
      "Epoch 1389/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4936 - accuracy: 0.8188 - val_loss: 0.6092 - val_accuracy: 0.7715\n",
      "Epoch 1390/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4936 - accuracy: 0.8190 - val_loss: 0.6092 - val_accuracy: 0.7713\n",
      "Epoch 1391/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4936 - accuracy: 0.8194 - val_loss: 0.6092 - val_accuracy: 0.7713\n",
      "Epoch 1392/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4935 - accuracy: 0.8188 - val_loss: 0.6092 - val_accuracy: 0.7704\n",
      "Epoch 1393/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4935 - accuracy: 0.8190 - val_loss: 0.6092 - val_accuracy: 0.7711\n",
      "Epoch 1394/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4935 - accuracy: 0.8182 - val_loss: 0.6092 - val_accuracy: 0.7715\n",
      "Epoch 1395/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4934 - accuracy: 0.8190 - val_loss: 0.6092 - val_accuracy: 0.7718\n",
      "Epoch 1396/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4934 - accuracy: 0.8188 - val_loss: 0.6092 - val_accuracy: 0.7704\n",
      "Epoch 1397/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.4934 - accuracy: 0.8186 - val_loss: 0.6091 - val_accuracy: 0.7713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1398/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4933 - accuracy: 0.8190 - val_loss: 0.6091 - val_accuracy: 0.7704\n",
      "Epoch 1399/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4933 - accuracy: 0.8187 - val_loss: 0.6091 - val_accuracy: 0.7709\n",
      "Epoch 1400/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4933 - accuracy: 0.8190 - val_loss: 0.6091 - val_accuracy: 0.7704\n",
      "Epoch 1401/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4932 - accuracy: 0.8186 - val_loss: 0.6091 - val_accuracy: 0.7704\n",
      "Epoch 1402/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4932 - accuracy: 0.8191 - val_loss: 0.6091 - val_accuracy: 0.7709\n",
      "Epoch 1403/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4932 - accuracy: 0.8187 - val_loss: 0.6091 - val_accuracy: 0.7713\n",
      "Epoch 1404/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4932 - accuracy: 0.8190 - val_loss: 0.6091 - val_accuracy: 0.7713\n",
      "Epoch 1405/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4931 - accuracy: 0.8192 - val_loss: 0.6091 - val_accuracy: 0.7706\n",
      "Epoch 1406/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4931 - accuracy: 0.8191 - val_loss: 0.6090 - val_accuracy: 0.7706\n",
      "Epoch 1407/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4931 - accuracy: 0.8187 - val_loss: 0.6091 - val_accuracy: 0.7702\n",
      "Epoch 1408/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4930 - accuracy: 0.8186 - val_loss: 0.6090 - val_accuracy: 0.7709\n",
      "Epoch 1409/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4930 - accuracy: 0.8192 - val_loss: 0.6091 - val_accuracy: 0.7704\n",
      "Epoch 1410/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4930 - accuracy: 0.8189 - val_loss: 0.6091 - val_accuracy: 0.7706\n",
      "Epoch 1411/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.8190 - val_loss: 0.6090 - val_accuracy: 0.7706\n",
      "Epoch 1412/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4929 - accuracy: 0.8185 - val_loss: 0.6090 - val_accuracy: 0.7718\n",
      "Epoch 1413/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4929 - accuracy: 0.8187 - val_loss: 0.6090 - val_accuracy: 0.7713\n",
      "Epoch 1414/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4928 - accuracy: 0.8188 - val_loss: 0.6090 - val_accuracy: 0.7711\n",
      "Epoch 1415/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4928 - accuracy: 0.8181 - val_loss: 0.6089 - val_accuracy: 0.7706\n",
      "Epoch 1416/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4928 - accuracy: 0.8186 - val_loss: 0.6089 - val_accuracy: 0.7702\n",
      "Epoch 1417/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4927 - accuracy: 0.8186 - val_loss: 0.6090 - val_accuracy: 0.7709\n",
      "Epoch 1418/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4927 - accuracy: 0.8192 - val_loss: 0.6090 - val_accuracy: 0.7709\n",
      "Epoch 1419/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4927 - accuracy: 0.8191 - val_loss: 0.6090 - val_accuracy: 0.7704\n",
      "Epoch 1420/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4926 - accuracy: 0.8185 - val_loss: 0.6090 - val_accuracy: 0.7711\n",
      "Epoch 1421/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4926 - accuracy: 0.8189 - val_loss: 0.6089 - val_accuracy: 0.7697\n",
      "Epoch 1422/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4926 - accuracy: 0.8191 - val_loss: 0.6090 - val_accuracy: 0.7709\n",
      "Epoch 1423/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4925 - accuracy: 0.8191 - val_loss: 0.6090 - val_accuracy: 0.7718\n",
      "Epoch 1424/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4925 - accuracy: 0.8188 - val_loss: 0.6090 - val_accuracy: 0.7702\n",
      "Epoch 1425/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4925 - accuracy: 0.8191 - val_loss: 0.6090 - val_accuracy: 0.7711\n",
      "Epoch 1426/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4924 - accuracy: 0.8190 - val_loss: 0.6089 - val_accuracy: 0.7704\n",
      "Epoch 1427/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4924 - accuracy: 0.8190 - val_loss: 0.6089 - val_accuracy: 0.7699\n",
      "Epoch 1428/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4924 - accuracy: 0.8186 - val_loss: 0.6089 - val_accuracy: 0.7706\n",
      "Epoch 1429/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4924 - accuracy: 0.8188 - val_loss: 0.6089 - val_accuracy: 0.7709\n",
      "Epoch 1430/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4923 - accuracy: 0.8188 - val_loss: 0.6089 - val_accuracy: 0.7699\n",
      "Epoch 1431/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4923 - accuracy: 0.8187 - val_loss: 0.6089 - val_accuracy: 0.7699\n",
      "Epoch 1432/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4922 - accuracy: 0.8190 - val_loss: 0.6089 - val_accuracy: 0.7704\n",
      "Epoch 1433/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4922 - accuracy: 0.8192 - val_loss: 0.6089 - val_accuracy: 0.7704\n",
      "Epoch 1434/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4922 - accuracy: 0.8190 - val_loss: 0.6089 - val_accuracy: 0.7704\n",
      "Epoch 1435/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4921 - accuracy: 0.8185 - val_loss: 0.6089 - val_accuracy: 0.7713\n",
      "Epoch 1436/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4921 - accuracy: 0.8196 - val_loss: 0.6088 - val_accuracy: 0.7699\n",
      "Epoch 1437/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4921 - accuracy: 0.8188 - val_loss: 0.6089 - val_accuracy: 0.7695\n",
      "Epoch 1438/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4921 - accuracy: 0.8189 - val_loss: 0.6088 - val_accuracy: 0.7693\n",
      "Epoch 1439/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4920 - accuracy: 0.8191 - val_loss: 0.6088 - val_accuracy: 0.7699\n",
      "Epoch 1440/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4920 - accuracy: 0.8188 - val_loss: 0.6088 - val_accuracy: 0.7702\n",
      "Epoch 1441/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4920 - accuracy: 0.8194 - val_loss: 0.6088 - val_accuracy: 0.7695\n",
      "Epoch 1442/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4920 - accuracy: 0.8182 - val_loss: 0.6089 - val_accuracy: 0.7706\n",
      "Epoch 1443/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4919 - accuracy: 0.8187 - val_loss: 0.6089 - val_accuracy: 0.7711\n",
      "Epoch 1444/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4919 - accuracy: 0.8186 - val_loss: 0.6089 - val_accuracy: 0.7702\n",
      "Epoch 1445/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4918 - accuracy: 0.8191 - val_loss: 0.6089 - val_accuracy: 0.7711\n",
      "Epoch 1446/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4918 - accuracy: 0.8191 - val_loss: 0.6088 - val_accuracy: 0.7709\n",
      "Epoch 1447/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4918 - accuracy: 0.8195 - val_loss: 0.6088 - val_accuracy: 0.7706\n",
      "Epoch 1448/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4917 - accuracy: 0.8191 - val_loss: 0.6088 - val_accuracy: 0.7695\n",
      "Epoch 1449/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.4917 - accuracy: 0.8191 - val_loss: 0.6088 - val_accuracy: 0.7695\n",
      "Epoch 1450/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4917 - accuracy: 0.8191 - val_loss: 0.6088 - val_accuracy: 0.7695\n",
      "Epoch 1451/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4916 - accuracy: 0.8194 - val_loss: 0.6088 - val_accuracy: 0.7702\n",
      "Epoch 1452/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4916 - accuracy: 0.8193 - val_loss: 0.6088 - val_accuracy: 0.7704\n",
      "Epoch 1453/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4916 - accuracy: 0.8192 - val_loss: 0.6088 - val_accuracy: 0.7704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1454/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4916 - accuracy: 0.8192 - val_loss: 0.6088 - val_accuracy: 0.7699\n",
      "Epoch 1455/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4915 - accuracy: 0.8191 - val_loss: 0.6087 - val_accuracy: 0.7702\n",
      "Epoch 1456/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4915 - accuracy: 0.8197 - val_loss: 0.6087 - val_accuracy: 0.7695\n",
      "Epoch 1457/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4915 - accuracy: 0.8191 - val_loss: 0.6087 - val_accuracy: 0.7699\n",
      "Epoch 1458/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4915 - accuracy: 0.8190 - val_loss: 0.6087 - val_accuracy: 0.7702\n",
      "Epoch 1459/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4914 - accuracy: 0.8191 - val_loss: 0.6088 - val_accuracy: 0.7702\n",
      "Epoch 1460/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4914 - accuracy: 0.8190 - val_loss: 0.6087 - val_accuracy: 0.7702\n",
      "Epoch 1461/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4914 - accuracy: 0.8194 - val_loss: 0.6088 - val_accuracy: 0.7697\n",
      "Epoch 1462/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4914 - accuracy: 0.8187 - val_loss: 0.6087 - val_accuracy: 0.7697\n",
      "Epoch 1463/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.4913 - accuracy: 0.8190 - val_loss: 0.6088 - val_accuracy: 0.7711\n",
      "Epoch 1464/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.4913 - accuracy: 0.8195 - val_loss: 0.6087 - val_accuracy: 0.7697\n",
      "Epoch 1465/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4912 - accuracy: 0.8190 - val_loss: 0.6088 - val_accuracy: 0.7709\n",
      "Epoch 1466/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4912 - accuracy: 0.8191 - val_loss: 0.6087 - val_accuracy: 0.7693\n",
      "Epoch 1467/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4912 - accuracy: 0.8193 - val_loss: 0.6087 - val_accuracy: 0.7704\n",
      "Epoch 1468/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4912 - accuracy: 0.8190 - val_loss: 0.6087 - val_accuracy: 0.7713\n",
      "Epoch 1469/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4911 - accuracy: 0.8192 - val_loss: 0.6087 - val_accuracy: 0.7695\n",
      "Epoch 1470/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4911 - accuracy: 0.8195 - val_loss: 0.6087 - val_accuracy: 0.7697\n",
      "Epoch 1471/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4911 - accuracy: 0.8192 - val_loss: 0.6087 - val_accuracy: 0.7695\n",
      "Epoch 1472/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4910 - accuracy: 0.8190 - val_loss: 0.6087 - val_accuracy: 0.7706\n",
      "Epoch 1473/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4910 - accuracy: 0.8191 - val_loss: 0.6087 - val_accuracy: 0.7704\n",
      "Epoch 1474/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4910 - accuracy: 0.8191 - val_loss: 0.6087 - val_accuracy: 0.7706\n",
      "Epoch 1475/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4910 - accuracy: 0.8195 - val_loss: 0.6087 - val_accuracy: 0.7702\n",
      "Epoch 1476/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4909 - accuracy: 0.8196 - val_loss: 0.6087 - val_accuracy: 0.7697\n",
      "Epoch 1477/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4909 - accuracy: 0.8192 - val_loss: 0.6086 - val_accuracy: 0.7697\n",
      "Epoch 1478/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.8192 - val_loss: 0.6087 - val_accuracy: 0.7699\n",
      "Epoch 1479/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4908 - accuracy: 0.8191 - val_loss: 0.6087 - val_accuracy: 0.7693\n",
      "Epoch 1480/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4908 - accuracy: 0.8188 - val_loss: 0.6087 - val_accuracy: 0.7702\n",
      "Epoch 1481/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.4908 - accuracy: 0.8192 - val_loss: 0.6087 - val_accuracy: 0.7704\n",
      "Epoch 1482/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4908 - accuracy: 0.8191 - val_loss: 0.6087 - val_accuracy: 0.7711\n",
      "Epoch 1483/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4907 - accuracy: 0.8189 - val_loss: 0.6086 - val_accuracy: 0.7695\n",
      "Epoch 1484/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4907 - accuracy: 0.8190 - val_loss: 0.6087 - val_accuracy: 0.7709\n",
      "Epoch 1485/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4907 - accuracy: 0.8193 - val_loss: 0.6087 - val_accuracy: 0.7706\n",
      "Epoch 1486/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4906 - accuracy: 0.8194 - val_loss: 0.6086 - val_accuracy: 0.7711\n",
      "Epoch 1487/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4906 - accuracy: 0.8192 - val_loss: 0.6086 - val_accuracy: 0.7706\n",
      "Epoch 1488/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4906 - accuracy: 0.8194 - val_loss: 0.6086 - val_accuracy: 0.7695\n",
      "Epoch 1489/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4906 - accuracy: 0.8197 - val_loss: 0.6086 - val_accuracy: 0.7706\n",
      "Epoch 1490/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4905 - accuracy: 0.8192 - val_loss: 0.6086 - val_accuracy: 0.7704\n",
      "Epoch 1491/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4905 - accuracy: 0.8194 - val_loss: 0.6086 - val_accuracy: 0.7706\n",
      "Epoch 1492/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4905 - accuracy: 0.8198 - val_loss: 0.6086 - val_accuracy: 0.7711\n",
      "Epoch 1493/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4904 - accuracy: 0.8192 - val_loss: 0.6085 - val_accuracy: 0.7709\n",
      "Epoch 1494/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4904 - accuracy: 0.8195 - val_loss: 0.6085 - val_accuracy: 0.7706\n",
      "Epoch 1495/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4904 - accuracy: 0.8192 - val_loss: 0.6085 - val_accuracy: 0.7704\n",
      "Epoch 1496/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4903 - accuracy: 0.8195 - val_loss: 0.6085 - val_accuracy: 0.7702\n",
      "Epoch 1497/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4903 - accuracy: 0.8191 - val_loss: 0.6086 - val_accuracy: 0.7718\n",
      "Epoch 1498/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4903 - accuracy: 0.8196 - val_loss: 0.6085 - val_accuracy: 0.7709\n",
      "Epoch 1499/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4903 - accuracy: 0.8191 - val_loss: 0.6085 - val_accuracy: 0.7699\n",
      "Epoch 1500/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4902 - accuracy: 0.8196 - val_loss: 0.6085 - val_accuracy: 0.7702\n",
      "Epoch 1501/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4902 - accuracy: 0.8189 - val_loss: 0.6085 - val_accuracy: 0.7704\n",
      "Epoch 1502/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4902 - accuracy: 0.8201 - val_loss: 0.6085 - val_accuracy: 0.7709\n",
      "Epoch 1503/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4901 - accuracy: 0.8196 - val_loss: 0.6085 - val_accuracy: 0.7704\n",
      "Epoch 1504/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4901 - accuracy: 0.8195 - val_loss: 0.6086 - val_accuracy: 0.7699\n",
      "Epoch 1505/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4901 - accuracy: 0.8197 - val_loss: 0.6084 - val_accuracy: 0.7704\n",
      "Epoch 1506/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4900 - accuracy: 0.8199 - val_loss: 0.6085 - val_accuracy: 0.7704\n",
      "Epoch 1507/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4901 - accuracy: 0.8192 - val_loss: 0.6085 - val_accuracy: 0.7706\n",
      "Epoch 1508/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.8197 - val_loss: 0.6085 - val_accuracy: 0.7706\n",
      "Epoch 1509/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4900 - accuracy: 0.8195 - val_loss: 0.6085 - val_accuracy: 0.7702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1510/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4899 - accuracy: 0.8194 - val_loss: 0.6084 - val_accuracy: 0.7702\n",
      "Epoch 1511/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4899 - accuracy: 0.8199 - val_loss: 0.6084 - val_accuracy: 0.7715\n",
      "Epoch 1512/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4899 - accuracy: 0.8201 - val_loss: 0.6085 - val_accuracy: 0.7713\n",
      "Epoch 1513/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4899 - accuracy: 0.8199 - val_loss: 0.6085 - val_accuracy: 0.7697\n",
      "Epoch 1514/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4898 - accuracy: 0.8194 - val_loss: 0.6084 - val_accuracy: 0.7699\n",
      "Epoch 1515/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4898 - accuracy: 0.8194 - val_loss: 0.6085 - val_accuracy: 0.7695\n",
      "Epoch 1516/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4898 - accuracy: 0.8192 - val_loss: 0.6085 - val_accuracy: 0.7695\n",
      "Epoch 1517/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4897 - accuracy: 0.8193 - val_loss: 0.6085 - val_accuracy: 0.7704\n",
      "Epoch 1518/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4897 - accuracy: 0.8198 - val_loss: 0.6084 - val_accuracy: 0.7695\n",
      "Epoch 1519/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4897 - accuracy: 0.8196 - val_loss: 0.6084 - val_accuracy: 0.7704\n",
      "Epoch 1520/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4896 - accuracy: 0.8196 - val_loss: 0.6084 - val_accuracy: 0.7699\n",
      "Epoch 1521/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4896 - accuracy: 0.8194 - val_loss: 0.6085 - val_accuracy: 0.7709\n",
      "Epoch 1522/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4896 - accuracy: 0.8196 - val_loss: 0.6084 - val_accuracy: 0.7697\n",
      "Epoch 1523/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4896 - accuracy: 0.8198 - val_loss: 0.6084 - val_accuracy: 0.7706\n",
      "Epoch 1524/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4896 - accuracy: 0.8199 - val_loss: 0.6083 - val_accuracy: 0.7699\n",
      "Epoch 1525/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4896 - accuracy: 0.8194 - val_loss: 0.6084 - val_accuracy: 0.7702\n",
      "Epoch 1526/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4895 - accuracy: 0.8198 - val_loss: 0.6084 - val_accuracy: 0.7699\n",
      "Epoch 1527/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4895 - accuracy: 0.8196 - val_loss: 0.6084 - val_accuracy: 0.7699\n",
      "Epoch 1528/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4894 - accuracy: 0.8197 - val_loss: 0.6084 - val_accuracy: 0.7702\n",
      "Epoch 1529/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4894 - accuracy: 0.8196 - val_loss: 0.6083 - val_accuracy: 0.7695\n",
      "Epoch 1530/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4894 - accuracy: 0.8193 - val_loss: 0.6083 - val_accuracy: 0.7697\n",
      "Epoch 1531/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.8194 - val_loss: 0.6083 - val_accuracy: 0.7702\n",
      "Epoch 1532/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4893 - accuracy: 0.8194 - val_loss: 0.6083 - val_accuracy: 0.7706\n",
      "Epoch 1533/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4893 - accuracy: 0.8194 - val_loss: 0.6084 - val_accuracy: 0.7704\n",
      "Epoch 1534/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4893 - accuracy: 0.8198 - val_loss: 0.6083 - val_accuracy: 0.7695\n",
      "Epoch 1535/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4892 - accuracy: 0.8201 - val_loss: 0.6084 - val_accuracy: 0.7711\n",
      "Epoch 1536/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4892 - accuracy: 0.8197 - val_loss: 0.6083 - val_accuracy: 0.7699\n",
      "Epoch 1537/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.4892 - accuracy: 0.8199 - val_loss: 0.6083 - val_accuracy: 0.7702\n",
      "Epoch 1538/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4892 - accuracy: 0.8196 - val_loss: 0.6083 - val_accuracy: 0.7695\n",
      "Epoch 1539/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.4892 - accuracy: 0.8200 - val_loss: 0.6083 - val_accuracy: 0.7704\n",
      "Epoch 1540/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4891 - accuracy: 0.8199 - val_loss: 0.6083 - val_accuracy: 0.7699\n",
      "Epoch 1541/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4891 - accuracy: 0.8199 - val_loss: 0.6082 - val_accuracy: 0.7699\n",
      "Epoch 1542/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4890 - accuracy: 0.8196 - val_loss: 0.6082 - val_accuracy: 0.7699\n",
      "Epoch 1543/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4890 - accuracy: 0.8200 - val_loss: 0.6082 - val_accuracy: 0.7702\n",
      "Epoch 1544/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.4890 - accuracy: 0.8195 - val_loss: 0.6082 - val_accuracy: 0.7704\n",
      "Epoch 1545/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4890 - accuracy: 0.8201 - val_loss: 0.6083 - val_accuracy: 0.7702\n",
      "Epoch 1546/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4889 - accuracy: 0.8198 - val_loss: 0.6082 - val_accuracy: 0.7699\n",
      "Epoch 1547/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4889 - accuracy: 0.8195 - val_loss: 0.6082 - val_accuracy: 0.7702\n",
      "Epoch 1548/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4889 - accuracy: 0.8200 - val_loss: 0.6082 - val_accuracy: 0.7709\n",
      "Epoch 1549/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.8196 - val_loss: 0.6082 - val_accuracy: 0.7699\n",
      "Epoch 1550/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4888 - accuracy: 0.8189 - val_loss: 0.6082 - val_accuracy: 0.7699\n",
      "Epoch 1551/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4888 - accuracy: 0.8200 - val_loss: 0.6082 - val_accuracy: 0.7706\n",
      "Epoch 1552/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4888 - accuracy: 0.8199 - val_loss: 0.6082 - val_accuracy: 0.7704\n",
      "Epoch 1553/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4887 - accuracy: 0.8199 - val_loss: 0.6082 - val_accuracy: 0.7702\n",
      "Epoch 1554/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4887 - accuracy: 0.8200 - val_loss: 0.6082 - val_accuracy: 0.7704\n",
      "Epoch 1555/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4887 - accuracy: 0.8199 - val_loss: 0.6082 - val_accuracy: 0.7704\n",
      "Epoch 1556/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4887 - accuracy: 0.8200 - val_loss: 0.6082 - val_accuracy: 0.7711\n",
      "Epoch 1557/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4887 - accuracy: 0.8201 - val_loss: 0.6082 - val_accuracy: 0.7706\n",
      "Epoch 1558/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4886 - accuracy: 0.8199 - val_loss: 0.6081 - val_accuracy: 0.7706\n",
      "Epoch 1559/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4886 - accuracy: 0.8195 - val_loss: 0.6081 - val_accuracy: 0.7702\n",
      "Epoch 1560/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4885 - accuracy: 0.8196 - val_loss: 0.6081 - val_accuracy: 0.7711\n",
      "Epoch 1561/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.8199 - val_loss: 0.6081 - val_accuracy: 0.7706\n",
      "Epoch 1562/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.8199 - val_loss: 0.6081 - val_accuracy: 0.7706\n",
      "Epoch 1563/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4885 - accuracy: 0.8196 - val_loss: 0.6081 - val_accuracy: 0.7711\n",
      "Epoch 1564/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4884 - accuracy: 0.8193 - val_loss: 0.6081 - val_accuracy: 0.7709\n",
      "Epoch 1565/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4884 - accuracy: 0.8197 - val_loss: 0.6081 - val_accuracy: 0.7706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1566/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4884 - accuracy: 0.8198 - val_loss: 0.6081 - val_accuracy: 0.7702\n",
      "Epoch 1567/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4884 - accuracy: 0.8194 - val_loss: 0.6082 - val_accuracy: 0.7706\n",
      "Epoch 1568/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4883 - accuracy: 0.8199 - val_loss: 0.6081 - val_accuracy: 0.7711\n",
      "Epoch 1569/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4883 - accuracy: 0.8204 - val_loss: 0.6081 - val_accuracy: 0.7709\n",
      "Epoch 1570/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4883 - accuracy: 0.8196 - val_loss: 0.6082 - val_accuracy: 0.7709\n",
      "Epoch 1571/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4883 - accuracy: 0.8200 - val_loss: 0.6082 - val_accuracy: 0.7706\n",
      "Epoch 1572/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4883 - accuracy: 0.8197 - val_loss: 0.6081 - val_accuracy: 0.7706\n",
      "Epoch 1573/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4882 - accuracy: 0.8201 - val_loss: 0.6082 - val_accuracy: 0.7702\n",
      "Epoch 1574/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4882 - accuracy: 0.8198 - val_loss: 0.6082 - val_accuracy: 0.7706\n",
      "Epoch 1575/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4882 - accuracy: 0.8204 - val_loss: 0.6081 - val_accuracy: 0.7704\n",
      "Epoch 1576/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4881 - accuracy: 0.8201 - val_loss: 0.6081 - val_accuracy: 0.7699\n",
      "Epoch 1577/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4881 - accuracy: 0.8197 - val_loss: 0.6081 - val_accuracy: 0.7704\n",
      "Epoch 1578/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4881 - accuracy: 0.8194 - val_loss: 0.6081 - val_accuracy: 0.7704\n",
      "Epoch 1579/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4880 - accuracy: 0.8200 - val_loss: 0.6083 - val_accuracy: 0.7711\n",
      "Epoch 1580/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4881 - accuracy: 0.8194 - val_loss: 0.6082 - val_accuracy: 0.7706\n",
      "Epoch 1581/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4880 - accuracy: 0.8196 - val_loss: 0.6081 - val_accuracy: 0.7711\n",
      "Epoch 1582/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4880 - accuracy: 0.8202 - val_loss: 0.6082 - val_accuracy: 0.7704\n",
      "Epoch 1583/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4880 - accuracy: 0.8199 - val_loss: 0.6082 - val_accuracy: 0.7699\n",
      "Epoch 1584/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4879 - accuracy: 0.8196 - val_loss: 0.6082 - val_accuracy: 0.7704\n",
      "Epoch 1585/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4879 - accuracy: 0.8200 - val_loss: 0.6081 - val_accuracy: 0.7713\n",
      "Epoch 1586/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4879 - accuracy: 0.8198 - val_loss: 0.6081 - val_accuracy: 0.7709\n",
      "Epoch 1587/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4878 - accuracy: 0.8200 - val_loss: 0.6081 - val_accuracy: 0.7706\n",
      "Epoch 1588/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4878 - accuracy: 0.8196 - val_loss: 0.6081 - val_accuracy: 0.7711\n",
      "Epoch 1589/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4878 - accuracy: 0.8198 - val_loss: 0.6081 - val_accuracy: 0.7704\n",
      "Epoch 1590/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.4878 - accuracy: 0.8196 - val_loss: 0.6082 - val_accuracy: 0.7704\n",
      "Epoch 1591/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4877 - accuracy: 0.8195 - val_loss: 0.6081 - val_accuracy: 0.7706\n",
      "Epoch 1592/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4877 - accuracy: 0.8199 - val_loss: 0.6082 - val_accuracy: 0.7706\n",
      "Epoch 1593/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4877 - accuracy: 0.8192 - val_loss: 0.6081 - val_accuracy: 0.7713\n",
      "Epoch 1594/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4877 - accuracy: 0.8203 - val_loss: 0.6081 - val_accuracy: 0.7715\n",
      "Epoch 1595/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4876 - accuracy: 0.8197 - val_loss: 0.6081 - val_accuracy: 0.7702\n",
      "Epoch 1596/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4876 - accuracy: 0.8204 - val_loss: 0.6081 - val_accuracy: 0.7706\n",
      "Epoch 1597/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4876 - accuracy: 0.8198 - val_loss: 0.6082 - val_accuracy: 0.7709\n",
      "Epoch 1598/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4876 - accuracy: 0.8199 - val_loss: 0.6081 - val_accuracy: 0.7709\n",
      "Epoch 1599/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4875 - accuracy: 0.8199 - val_loss: 0.6081 - val_accuracy: 0.7709\n",
      "Epoch 1600/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4875 - accuracy: 0.8200 - val_loss: 0.6081 - val_accuracy: 0.7713\n",
      "Epoch 1601/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4875 - accuracy: 0.8201 - val_loss: 0.6080 - val_accuracy: 0.7709\n",
      "Epoch 1602/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4875 - accuracy: 0.8200 - val_loss: 0.6080 - val_accuracy: 0.7706\n",
      "Epoch 1603/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4875 - accuracy: 0.8203 - val_loss: 0.6080 - val_accuracy: 0.7709\n",
      "Epoch 1604/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4874 - accuracy: 0.8200 - val_loss: 0.6081 - val_accuracy: 0.7718\n",
      "Epoch 1605/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4874 - accuracy: 0.8198 - val_loss: 0.6081 - val_accuracy: 0.7704\n",
      "Epoch 1606/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.4874 - accuracy: 0.8203 - val_loss: 0.6081 - val_accuracy: 0.7704\n",
      "Epoch 1607/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4873 - accuracy: 0.8203 - val_loss: 0.6080 - val_accuracy: 0.7711\n",
      "Epoch 1608/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4873 - accuracy: 0.8202 - val_loss: 0.6081 - val_accuracy: 0.7706\n",
      "Epoch 1609/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4873 - accuracy: 0.8200 - val_loss: 0.6080 - val_accuracy: 0.7711\n",
      "Epoch 1610/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4872 - accuracy: 0.8202 - val_loss: 0.6080 - val_accuracy: 0.7713\n",
      "Epoch 1611/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4872 - accuracy: 0.8199 - val_loss: 0.6081 - val_accuracy: 0.7704\n",
      "Epoch 1612/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4872 - accuracy: 0.8195 - val_loss: 0.6081 - val_accuracy: 0.7709\n",
      "Epoch 1613/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4872 - accuracy: 0.8203 - val_loss: 0.6081 - val_accuracy: 0.7704\n",
      "Epoch 1614/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4872 - accuracy: 0.8204 - val_loss: 0.6081 - val_accuracy: 0.7709\n",
      "Epoch 1615/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4871 - accuracy: 0.8194 - val_loss: 0.6082 - val_accuracy: 0.7706\n",
      "Epoch 1616/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4871 - accuracy: 0.8198 - val_loss: 0.6080 - val_accuracy: 0.7704\n",
      "Epoch 1617/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4871 - accuracy: 0.8197 - val_loss: 0.6080 - val_accuracy: 0.7709\n",
      "Epoch 1618/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4870 - accuracy: 0.8203 - val_loss: 0.6080 - val_accuracy: 0.7706\n",
      "Epoch 1619/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4870 - accuracy: 0.8200 - val_loss: 0.6080 - val_accuracy: 0.7706\n",
      "Epoch 1620/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4870 - accuracy: 0.8206 - val_loss: 0.6081 - val_accuracy: 0.7706\n",
      "Epoch 1621/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4870 - accuracy: 0.8200 - val_loss: 0.6081 - val_accuracy: 0.7706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1622/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4869 - accuracy: 0.8197 - val_loss: 0.6080 - val_accuracy: 0.7709\n",
      "Epoch 1623/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4869 - accuracy: 0.8199 - val_loss: 0.6080 - val_accuracy: 0.7709\n",
      "Epoch 1624/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4869 - accuracy: 0.8198 - val_loss: 0.6080 - val_accuracy: 0.7711\n",
      "Epoch 1625/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4869 - accuracy: 0.8193 - val_loss: 0.6079 - val_accuracy: 0.7715\n",
      "Epoch 1626/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4868 - accuracy: 0.8206 - val_loss: 0.6079 - val_accuracy: 0.7715\n",
      "Epoch 1627/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4868 - accuracy: 0.8200 - val_loss: 0.6080 - val_accuracy: 0.7706\n",
      "Epoch 1628/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4869 - accuracy: 0.8196 - val_loss: 0.6080 - val_accuracy: 0.7713\n",
      "Epoch 1629/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4868 - accuracy: 0.8202 - val_loss: 0.6079 - val_accuracy: 0.7713\n",
      "Epoch 1630/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4867 - accuracy: 0.8199 - val_loss: 0.6079 - val_accuracy: 0.7711\n",
      "Epoch 1631/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4867 - accuracy: 0.8202 - val_loss: 0.6079 - val_accuracy: 0.7709\n",
      "Epoch 1632/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4866 - accuracy: 0.8203 - val_loss: 0.6079 - val_accuracy: 0.7711\n",
      "Epoch 1633/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4866 - accuracy: 0.8200 - val_loss: 0.6079 - val_accuracy: 0.7713\n",
      "Epoch 1634/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4867 - accuracy: 0.8206 - val_loss: 0.6079 - val_accuracy: 0.7711\n",
      "Epoch 1635/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4866 - accuracy: 0.8200 - val_loss: 0.6078 - val_accuracy: 0.7713\n",
      "Epoch 1636/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4865 - accuracy: 0.8196 - val_loss: 0.6079 - val_accuracy: 0.7709\n",
      "Epoch 1637/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4866 - accuracy: 0.8203 - val_loss: 0.6078 - val_accuracy: 0.7713\n",
      "Epoch 1638/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4865 - accuracy: 0.8202 - val_loss: 0.6079 - val_accuracy: 0.7709\n",
      "Epoch 1639/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4865 - accuracy: 0.8200 - val_loss: 0.6079 - val_accuracy: 0.7715\n",
      "Epoch 1640/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4865 - accuracy: 0.8193 - val_loss: 0.6078 - val_accuracy: 0.7711\n",
      "Epoch 1641/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4864 - accuracy: 0.8203 - val_loss: 0.6078 - val_accuracy: 0.7718\n",
      "Epoch 1642/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4864 - accuracy: 0.8204 - val_loss: 0.6078 - val_accuracy: 0.7713\n",
      "Epoch 1643/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4864 - accuracy: 0.8202 - val_loss: 0.6078 - val_accuracy: 0.7713\n",
      "Epoch 1644/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4863 - accuracy: 0.8200 - val_loss: 0.6078 - val_accuracy: 0.7713\n",
      "Epoch 1645/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4863 - accuracy: 0.8207 - val_loss: 0.6078 - val_accuracy: 0.7713\n",
      "Epoch 1646/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4863 - accuracy: 0.8200 - val_loss: 0.6078 - val_accuracy: 0.7715\n",
      "Epoch 1647/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4862 - accuracy: 0.8201 - val_loss: 0.6078 - val_accuracy: 0.7713\n",
      "Epoch 1648/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4862 - accuracy: 0.8199 - val_loss: 0.6078 - val_accuracy: 0.7718\n",
      "Epoch 1649/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4862 - accuracy: 0.8198 - val_loss: 0.6078 - val_accuracy: 0.7715\n",
      "Epoch 1650/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4862 - accuracy: 0.8199 - val_loss: 0.6078 - val_accuracy: 0.7713\n",
      "Epoch 1651/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4862 - accuracy: 0.8200 - val_loss: 0.6078 - val_accuracy: 0.7711\n",
      "Epoch 1652/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4861 - accuracy: 0.8199 - val_loss: 0.6078 - val_accuracy: 0.7711\n",
      "Epoch 1653/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4861 - accuracy: 0.8195 - val_loss: 0.6078 - val_accuracy: 0.7709\n",
      "Epoch 1654/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4861 - accuracy: 0.8201 - val_loss: 0.6078 - val_accuracy: 0.7711\n",
      "Epoch 1655/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4860 - accuracy: 0.8207 - val_loss: 0.6078 - val_accuracy: 0.7718\n",
      "Epoch 1656/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4860 - accuracy: 0.8201 - val_loss: 0.6077 - val_accuracy: 0.7715\n",
      "Epoch 1657/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.4860 - accuracy: 0.8204 - val_loss: 0.6079 - val_accuracy: 0.7729\n",
      "Epoch 1658/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4860 - accuracy: 0.8202 - val_loss: 0.6078 - val_accuracy: 0.7715\n",
      "Epoch 1659/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4860 - accuracy: 0.8199 - val_loss: 0.6077 - val_accuracy: 0.7713\n",
      "Epoch 1660/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.8201 - val_loss: 0.6078 - val_accuracy: 0.7706\n",
      "Epoch 1661/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4859 - accuracy: 0.8199 - val_loss: 0.6077 - val_accuracy: 0.7713\n",
      "Epoch 1662/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4859 - accuracy: 0.8200 - val_loss: 0.6078 - val_accuracy: 0.7722\n",
      "Epoch 1663/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4859 - accuracy: 0.8199 - val_loss: 0.6078 - val_accuracy: 0.7715\n",
      "Epoch 1664/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4858 - accuracy: 0.8198 - val_loss: 0.6078 - val_accuracy: 0.7713\n",
      "Epoch 1665/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4858 - accuracy: 0.8207 - val_loss: 0.6078 - val_accuracy: 0.7715\n",
      "Epoch 1666/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4857 - accuracy: 0.8208 - val_loss: 0.6077 - val_accuracy: 0.7713\n",
      "Epoch 1667/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4857 - accuracy: 0.8202 - val_loss: 0.6077 - val_accuracy: 0.7715\n",
      "Epoch 1668/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4857 - accuracy: 0.8205 - val_loss: 0.6078 - val_accuracy: 0.7715\n",
      "Epoch 1669/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4857 - accuracy: 0.8201 - val_loss: 0.6077 - val_accuracy: 0.7724\n",
      "Epoch 1670/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4857 - accuracy: 0.8207 - val_loss: 0.6076 - val_accuracy: 0.7720\n",
      "Epoch 1671/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4856 - accuracy: 0.8203 - val_loss: 0.6077 - val_accuracy: 0.7720\n",
      "Epoch 1672/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4856 - accuracy: 0.8204 - val_loss: 0.6077 - val_accuracy: 0.7709\n",
      "Epoch 1673/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4856 - accuracy: 0.8208 - val_loss: 0.6077 - val_accuracy: 0.7718\n",
      "Epoch 1674/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4856 - accuracy: 0.8203 - val_loss: 0.6076 - val_accuracy: 0.7718\n",
      "Epoch 1675/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4855 - accuracy: 0.8205 - val_loss: 0.6077 - val_accuracy: 0.7715\n",
      "Epoch 1676/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4855 - accuracy: 0.8204 - val_loss: 0.6076 - val_accuracy: 0.7720\n",
      "Epoch 1677/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4855 - accuracy: 0.8202 - val_loss: 0.6076 - val_accuracy: 0.7713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1678/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4854 - accuracy: 0.8206 - val_loss: 0.6077 - val_accuracy: 0.7711\n",
      "Epoch 1679/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4854 - accuracy: 0.8210 - val_loss: 0.6076 - val_accuracy: 0.7718\n",
      "Epoch 1680/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4854 - accuracy: 0.8206 - val_loss: 0.6076 - val_accuracy: 0.7713\n",
      "Epoch 1681/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4854 - accuracy: 0.8203 - val_loss: 0.6076 - val_accuracy: 0.7727\n",
      "Epoch 1682/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4853 - accuracy: 0.8202 - val_loss: 0.6076 - val_accuracy: 0.7715\n",
      "Epoch 1683/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4853 - accuracy: 0.8204 - val_loss: 0.6075 - val_accuracy: 0.7715\n",
      "Epoch 1684/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4853 - accuracy: 0.8209 - val_loss: 0.6076 - val_accuracy: 0.7718\n",
      "Epoch 1685/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4853 - accuracy: 0.8204 - val_loss: 0.6076 - val_accuracy: 0.7724\n",
      "Epoch 1686/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4853 - accuracy: 0.8207 - val_loss: 0.6076 - val_accuracy: 0.7715\n",
      "Epoch 1687/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4852 - accuracy: 0.8209 - val_loss: 0.6076 - val_accuracy: 0.7722\n",
      "Epoch 1688/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4852 - accuracy: 0.8207 - val_loss: 0.6076 - val_accuracy: 0.7718\n",
      "Epoch 1689/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4851 - accuracy: 0.8206 - val_loss: 0.6075 - val_accuracy: 0.7722\n",
      "Epoch 1690/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4851 - accuracy: 0.8206 - val_loss: 0.6075 - val_accuracy: 0.7718\n",
      "Epoch 1691/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4851 - accuracy: 0.8206 - val_loss: 0.6075 - val_accuracy: 0.7718\n",
      "Epoch 1692/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4850 - accuracy: 0.8207 - val_loss: 0.6076 - val_accuracy: 0.7720\n",
      "Epoch 1693/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4850 - accuracy: 0.8199 - val_loss: 0.6076 - val_accuracy: 0.7720\n",
      "Epoch 1694/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4850 - accuracy: 0.8206 - val_loss: 0.6076 - val_accuracy: 0.7718\n",
      "Epoch 1695/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4850 - accuracy: 0.8212 - val_loss: 0.6076 - val_accuracy: 0.7724\n",
      "Epoch 1696/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4850 - accuracy: 0.8209 - val_loss: 0.6076 - val_accuracy: 0.7720\n",
      "Epoch 1697/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4849 - accuracy: 0.8204 - val_loss: 0.6076 - val_accuracy: 0.7722\n",
      "Epoch 1698/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4849 - accuracy: 0.8208 - val_loss: 0.6075 - val_accuracy: 0.7720\n",
      "Epoch 1699/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4849 - accuracy: 0.8213 - val_loss: 0.6076 - val_accuracy: 0.7722\n",
      "Epoch 1700/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4848 - accuracy: 0.8208 - val_loss: 0.6074 - val_accuracy: 0.7722\n",
      "Epoch 1701/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4848 - accuracy: 0.8206 - val_loss: 0.6074 - val_accuracy: 0.7718\n",
      "Epoch 1702/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4848 - accuracy: 0.8207 - val_loss: 0.6075 - val_accuracy: 0.7722\n",
      "Epoch 1703/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4847 - accuracy: 0.8210 - val_loss: 0.6075 - val_accuracy: 0.7718\n",
      "Epoch 1704/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4847 - accuracy: 0.8209 - val_loss: 0.6074 - val_accuracy: 0.7724\n",
      "Epoch 1705/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4847 - accuracy: 0.8211 - val_loss: 0.6075 - val_accuracy: 0.7727\n",
      "Epoch 1706/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4847 - accuracy: 0.8211 - val_loss: 0.6076 - val_accuracy: 0.7724\n",
      "Epoch 1707/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4847 - accuracy: 0.8208 - val_loss: 0.6075 - val_accuracy: 0.7720\n",
      "Epoch 1708/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4846 - accuracy: 0.8206 - val_loss: 0.6075 - val_accuracy: 0.7720\n",
      "Epoch 1709/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4846 - accuracy: 0.8209 - val_loss: 0.6075 - val_accuracy: 0.7720\n",
      "Epoch 1710/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4846 - accuracy: 0.8206 - val_loss: 0.6075 - val_accuracy: 0.7718\n",
      "Epoch 1711/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4845 - accuracy: 0.8209 - val_loss: 0.6074 - val_accuracy: 0.7727\n",
      "Epoch 1712/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4845 - accuracy: 0.8208 - val_loss: 0.6075 - val_accuracy: 0.7724\n",
      "Epoch 1713/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4845 - accuracy: 0.8209 - val_loss: 0.6074 - val_accuracy: 0.7724\n",
      "Epoch 1714/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4845 - accuracy: 0.8209 - val_loss: 0.6074 - val_accuracy: 0.7729\n",
      "Epoch 1715/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4844 - accuracy: 0.8208 - val_loss: 0.6074 - val_accuracy: 0.7720\n",
      "Epoch 1716/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4844 - accuracy: 0.8210 - val_loss: 0.6075 - val_accuracy: 0.7724\n",
      "Epoch 1717/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4844 - accuracy: 0.8210 - val_loss: 0.6074 - val_accuracy: 0.7720\n",
      "Epoch 1718/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4844 - accuracy: 0.8207 - val_loss: 0.6074 - val_accuracy: 0.7724\n",
      "Epoch 1719/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4843 - accuracy: 0.8210 - val_loss: 0.6075 - val_accuracy: 0.7722\n",
      "Epoch 1720/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4843 - accuracy: 0.8204 - val_loss: 0.6074 - val_accuracy: 0.7724\n",
      "Epoch 1721/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4843 - accuracy: 0.8208 - val_loss: 0.6074 - val_accuracy: 0.7722\n",
      "Epoch 1722/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4843 - accuracy: 0.8211 - val_loss: 0.6074 - val_accuracy: 0.7729\n",
      "Epoch 1723/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.4842 - accuracy: 0.8208 - val_loss: 0.6073 - val_accuracy: 0.7722\n",
      "Epoch 1724/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4842 - accuracy: 0.8212 - val_loss: 0.6073 - val_accuracy: 0.7724\n",
      "Epoch 1725/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4842 - accuracy: 0.8208 - val_loss: 0.6073 - val_accuracy: 0.7722\n",
      "Epoch 1726/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4841 - accuracy: 0.8213 - val_loss: 0.6073 - val_accuracy: 0.7720\n",
      "Epoch 1727/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4842 - accuracy: 0.8209 - val_loss: 0.6073 - val_accuracy: 0.7727\n",
      "Epoch 1728/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4841 - accuracy: 0.8209 - val_loss: 0.6072 - val_accuracy: 0.7727\n",
      "Epoch 1729/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4841 - accuracy: 0.8208 - val_loss: 0.6073 - val_accuracy: 0.7722\n",
      "Epoch 1730/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.8209 - val_loss: 0.6073 - val_accuracy: 0.7722\n",
      "Epoch 1731/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4840 - accuracy: 0.8206 - val_loss: 0.6072 - val_accuracy: 0.7727\n",
      "Epoch 1732/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4840 - accuracy: 0.8216 - val_loss: 0.6072 - val_accuracy: 0.7722\n",
      "Epoch 1733/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4840 - accuracy: 0.8212 - val_loss: 0.6072 - val_accuracy: 0.7720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1734/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4840 - accuracy: 0.8211 - val_loss: 0.6073 - val_accuracy: 0.7724\n",
      "Epoch 1735/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4840 - accuracy: 0.8211 - val_loss: 0.6073 - val_accuracy: 0.7727\n",
      "Epoch 1736/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4839 - accuracy: 0.8212 - val_loss: 0.6072 - val_accuracy: 0.7727\n",
      "Epoch 1737/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4839 - accuracy: 0.8211 - val_loss: 0.6072 - val_accuracy: 0.7718\n",
      "Epoch 1738/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4839 - accuracy: 0.8213 - val_loss: 0.6072 - val_accuracy: 0.7722\n",
      "Epoch 1739/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4838 - accuracy: 0.8213 - val_loss: 0.6072 - val_accuracy: 0.7715\n",
      "Epoch 1740/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4838 - accuracy: 0.8210 - val_loss: 0.6072 - val_accuracy: 0.7720\n",
      "Epoch 1741/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4838 - accuracy: 0.8212 - val_loss: 0.6072 - val_accuracy: 0.7724\n",
      "Epoch 1742/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4837 - accuracy: 0.8209 - val_loss: 0.6072 - val_accuracy: 0.7715\n",
      "Epoch 1743/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4838 - accuracy: 0.8206 - val_loss: 0.6072 - val_accuracy: 0.7720\n",
      "Epoch 1744/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4837 - accuracy: 0.8209 - val_loss: 0.6072 - val_accuracy: 0.7727\n",
      "Epoch 1745/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4837 - accuracy: 0.8208 - val_loss: 0.6072 - val_accuracy: 0.7715\n",
      "Epoch 1746/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4837 - accuracy: 0.8210 - val_loss: 0.6071 - val_accuracy: 0.7724\n",
      "Epoch 1747/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4836 - accuracy: 0.8211 - val_loss: 0.6071 - val_accuracy: 0.7720\n",
      "Epoch 1748/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4836 - accuracy: 0.8210 - val_loss: 0.6071 - val_accuracy: 0.7722\n",
      "Epoch 1749/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4836 - accuracy: 0.8206 - val_loss: 0.6071 - val_accuracy: 0.7715\n",
      "Epoch 1750/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4835 - accuracy: 0.8211 - val_loss: 0.6072 - val_accuracy: 0.7720\n",
      "Epoch 1751/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4836 - accuracy: 0.8209 - val_loss: 0.6072 - val_accuracy: 0.7724\n",
      "Epoch 1752/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4835 - accuracy: 0.8212 - val_loss: 0.6071 - val_accuracy: 0.7724\n",
      "Epoch 1753/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4835 - accuracy: 0.8213 - val_loss: 0.6071 - val_accuracy: 0.7724\n",
      "Epoch 1754/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4835 - accuracy: 0.8217 - val_loss: 0.6071 - val_accuracy: 0.7724\n",
      "Epoch 1755/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4834 - accuracy: 0.8210 - val_loss: 0.6071 - val_accuracy: 0.7722\n",
      "Epoch 1756/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4834 - accuracy: 0.8210 - val_loss: 0.6071 - val_accuracy: 0.7722\n",
      "Epoch 1757/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.4834 - accuracy: 0.8215 - val_loss: 0.6071 - val_accuracy: 0.7722\n",
      "Epoch 1758/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4833 - accuracy: 0.8213 - val_loss: 0.6071 - val_accuracy: 0.7724\n",
      "Epoch 1759/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4834 - accuracy: 0.8213 - val_loss: 0.6071 - val_accuracy: 0.7727\n",
      "Epoch 1760/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4833 - accuracy: 0.8215 - val_loss: 0.6070 - val_accuracy: 0.7720\n",
      "Epoch 1761/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4833 - accuracy: 0.8210 - val_loss: 0.6071 - val_accuracy: 0.7727\n",
      "Epoch 1762/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4832 - accuracy: 0.8214 - val_loss: 0.6070 - val_accuracy: 0.7727\n",
      "Epoch 1763/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4832 - accuracy: 0.8210 - val_loss: 0.6070 - val_accuracy: 0.7724\n",
      "Epoch 1764/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4832 - accuracy: 0.8212 - val_loss: 0.6071 - val_accuracy: 0.7724\n",
      "Epoch 1765/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4832 - accuracy: 0.8210 - val_loss: 0.6070 - val_accuracy: 0.7718\n",
      "Epoch 1766/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4832 - accuracy: 0.8213 - val_loss: 0.6071 - val_accuracy: 0.7720\n",
      "Epoch 1767/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4831 - accuracy: 0.8211 - val_loss: 0.6069 - val_accuracy: 0.7729\n",
      "Epoch 1768/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4831 - accuracy: 0.8212 - val_loss: 0.6070 - val_accuracy: 0.7724\n",
      "Epoch 1769/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4831 - accuracy: 0.8212 - val_loss: 0.6069 - val_accuracy: 0.7724\n",
      "Epoch 1770/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4831 - accuracy: 0.8217 - val_loss: 0.6069 - val_accuracy: 0.7720\n",
      "Epoch 1771/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4831 - accuracy: 0.8213 - val_loss: 0.6069 - val_accuracy: 0.7724\n",
      "Epoch 1772/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4830 - accuracy: 0.8215 - val_loss: 0.6070 - val_accuracy: 0.7727\n",
      "Epoch 1773/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4830 - accuracy: 0.8213 - val_loss: 0.6070 - val_accuracy: 0.7720\n",
      "Epoch 1774/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4830 - accuracy: 0.8213 - val_loss: 0.6070 - val_accuracy: 0.7727\n",
      "Epoch 1775/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4830 - accuracy: 0.8211 - val_loss: 0.6071 - val_accuracy: 0.7722\n",
      "Epoch 1776/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4829 - accuracy: 0.8213 - val_loss: 0.6069 - val_accuracy: 0.7724\n",
      "Epoch 1777/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4829 - accuracy: 0.8216 - val_loss: 0.6069 - val_accuracy: 0.7722\n",
      "Epoch 1778/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4828 - accuracy: 0.8206 - val_loss: 0.6070 - val_accuracy: 0.7720\n",
      "Epoch 1779/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4828 - accuracy: 0.8211 - val_loss: 0.6069 - val_accuracy: 0.7727\n",
      "Epoch 1780/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4828 - accuracy: 0.8208 - val_loss: 0.6069 - val_accuracy: 0.7722\n",
      "Epoch 1781/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4828 - accuracy: 0.8206 - val_loss: 0.6069 - val_accuracy: 0.7727\n",
      "Epoch 1782/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4828 - accuracy: 0.8212 - val_loss: 0.6069 - val_accuracy: 0.7724\n",
      "Epoch 1783/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4828 - accuracy: 0.8206 - val_loss: 0.6069 - val_accuracy: 0.7727\n",
      "Epoch 1784/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4827 - accuracy: 0.8214 - val_loss: 0.6069 - val_accuracy: 0.7727\n",
      "Epoch 1785/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4827 - accuracy: 0.8210 - val_loss: 0.6069 - val_accuracy: 0.7722\n",
      "Epoch 1786/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4827 - accuracy: 0.8211 - val_loss: 0.6069 - val_accuracy: 0.7724\n",
      "Epoch 1787/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4827 - accuracy: 0.8212 - val_loss: 0.6069 - val_accuracy: 0.7727\n",
      "Epoch 1788/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4826 - accuracy: 0.8213 - val_loss: 0.6069 - val_accuracy: 0.7722\n",
      "Epoch 1789/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4826 - accuracy: 0.8211 - val_loss: 0.6068 - val_accuracy: 0.7727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1790/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4826 - accuracy: 0.8213 - val_loss: 0.6068 - val_accuracy: 0.7720\n",
      "Epoch 1791/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4826 - accuracy: 0.8215 - val_loss: 0.6069 - val_accuracy: 0.7722\n",
      "Epoch 1792/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4825 - accuracy: 0.8211 - val_loss: 0.6069 - val_accuracy: 0.7724\n",
      "Epoch 1793/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4825 - accuracy: 0.8211 - val_loss: 0.6069 - val_accuracy: 0.7722\n",
      "Epoch 1794/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4825 - accuracy: 0.8212 - val_loss: 0.6069 - val_accuracy: 0.7724\n",
      "Epoch 1795/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4825 - accuracy: 0.8211 - val_loss: 0.6068 - val_accuracy: 0.7722\n",
      "Epoch 1796/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4825 - accuracy: 0.8211 - val_loss: 0.6068 - val_accuracy: 0.7722\n",
      "Epoch 1797/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4824 - accuracy: 0.8210 - val_loss: 0.6068 - val_accuracy: 0.7727\n",
      "Epoch 1798/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4824 - accuracy: 0.8210 - val_loss: 0.6068 - val_accuracy: 0.7731\n",
      "Epoch 1799/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4824 - accuracy: 0.8206 - val_loss: 0.6068 - val_accuracy: 0.7731\n",
      "Epoch 1800/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4824 - accuracy: 0.8209 - val_loss: 0.6068 - val_accuracy: 0.7722\n",
      "Epoch 1801/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4823 - accuracy: 0.8211 - val_loss: 0.6068 - val_accuracy: 0.7727\n",
      "Epoch 1802/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4823 - accuracy: 0.8206 - val_loss: 0.6068 - val_accuracy: 0.7724\n",
      "Epoch 1803/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4823 - accuracy: 0.8209 - val_loss: 0.6069 - val_accuracy: 0.7736\n",
      "Epoch 1804/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4823 - accuracy: 0.8215 - val_loss: 0.6067 - val_accuracy: 0.7727\n",
      "Epoch 1805/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4822 - accuracy: 0.8207 - val_loss: 0.6068 - val_accuracy: 0.7724\n",
      "Epoch 1806/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4822 - accuracy: 0.8211 - val_loss: 0.6068 - val_accuracy: 0.7736\n",
      "Epoch 1807/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4822 - accuracy: 0.8213 - val_loss: 0.6068 - val_accuracy: 0.7722\n",
      "Epoch 1808/2000\n",
      "138/138 [==============================] - 1s 4ms/step - loss: 0.4822 - accuracy: 0.8211 - val_loss: 0.6068 - val_accuracy: 0.7729\n",
      "Epoch 1809/2000\n",
      "138/138 [==============================] - 1s 4ms/step - loss: 0.4821 - accuracy: 0.8215 - val_loss: 0.6068 - val_accuracy: 0.7724\n",
      "Epoch 1810/2000\n",
      "138/138 [==============================] - 0s 4ms/step - loss: 0.4822 - accuracy: 0.8215 - val_loss: 0.6067 - val_accuracy: 0.7736\n",
      "Epoch 1811/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4821 - accuracy: 0.8212 - val_loss: 0.6068 - val_accuracy: 0.7724\n",
      "Epoch 1812/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4821 - accuracy: 0.8209 - val_loss: 0.6068 - val_accuracy: 0.7727\n",
      "Epoch 1813/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4820 - accuracy: 0.8214 - val_loss: 0.6067 - val_accuracy: 0.7727\n",
      "Epoch 1814/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4820 - accuracy: 0.8217 - val_loss: 0.6068 - val_accuracy: 0.7731\n",
      "Epoch 1815/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4820 - accuracy: 0.8213 - val_loss: 0.6067 - val_accuracy: 0.7724\n",
      "Epoch 1816/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4820 - accuracy: 0.8210 - val_loss: 0.6068 - val_accuracy: 0.7736\n",
      "Epoch 1817/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4820 - accuracy: 0.8216 - val_loss: 0.6068 - val_accuracy: 0.7727\n",
      "Epoch 1818/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4820 - accuracy: 0.8211 - val_loss: 0.6068 - val_accuracy: 0.7727\n",
      "Epoch 1819/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4819 - accuracy: 0.8215 - val_loss: 0.6067 - val_accuracy: 0.7729\n",
      "Epoch 1820/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4819 - accuracy: 0.8212 - val_loss: 0.6067 - val_accuracy: 0.7722\n",
      "Epoch 1821/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4819 - accuracy: 0.8212 - val_loss: 0.6067 - val_accuracy: 0.7720\n",
      "Epoch 1822/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4819 - accuracy: 0.8210 - val_loss: 0.6068 - val_accuracy: 0.7724\n",
      "Epoch 1823/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4818 - accuracy: 0.8211 - val_loss: 0.6067 - val_accuracy: 0.7724\n",
      "Epoch 1824/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4818 - accuracy: 0.8209 - val_loss: 0.6066 - val_accuracy: 0.7731\n",
      "Epoch 1825/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4818 - accuracy: 0.8212 - val_loss: 0.6067 - val_accuracy: 0.7731\n",
      "Epoch 1826/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4817 - accuracy: 0.8215 - val_loss: 0.6066 - val_accuracy: 0.7731\n",
      "Epoch 1827/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4817 - accuracy: 0.8212 - val_loss: 0.6067 - val_accuracy: 0.7736\n",
      "Epoch 1828/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4817 - accuracy: 0.8217 - val_loss: 0.6067 - val_accuracy: 0.7736\n",
      "Epoch 1829/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4817 - accuracy: 0.8218 - val_loss: 0.6067 - val_accuracy: 0.7729\n",
      "Epoch 1830/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4817 - accuracy: 0.8212 - val_loss: 0.6067 - val_accuracy: 0.7724\n",
      "Epoch 1831/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4816 - accuracy: 0.8213 - val_loss: 0.6067 - val_accuracy: 0.7729\n",
      "Epoch 1832/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4816 - accuracy: 0.8210 - val_loss: 0.6066 - val_accuracy: 0.7736\n",
      "Epoch 1833/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4816 - accuracy: 0.8211 - val_loss: 0.6066 - val_accuracy: 0.7729\n",
      "Epoch 1834/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4816 - accuracy: 0.8212 - val_loss: 0.6066 - val_accuracy: 0.7727\n",
      "Epoch 1835/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4815 - accuracy: 0.8214 - val_loss: 0.6066 - val_accuracy: 0.7731\n",
      "Epoch 1836/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4815 - accuracy: 0.8216 - val_loss: 0.6065 - val_accuracy: 0.7722\n",
      "Epoch 1837/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4815 - accuracy: 0.8215 - val_loss: 0.6066 - val_accuracy: 0.7727\n",
      "Epoch 1838/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4815 - accuracy: 0.8213 - val_loss: 0.6066 - val_accuracy: 0.7729\n",
      "Epoch 1839/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4815 - accuracy: 0.8217 - val_loss: 0.6067 - val_accuracy: 0.7727\n",
      "Epoch 1840/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4814 - accuracy: 0.8212 - val_loss: 0.6067 - val_accuracy: 0.7729\n",
      "Epoch 1841/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4814 - accuracy: 0.8215 - val_loss: 0.6066 - val_accuracy: 0.7727\n",
      "Epoch 1842/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4814 - accuracy: 0.8216 - val_loss: 0.6066 - val_accuracy: 0.7731\n",
      "Epoch 1843/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4814 - accuracy: 0.8212 - val_loss: 0.6066 - val_accuracy: 0.7734\n",
      "Epoch 1844/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4813 - accuracy: 0.8208 - val_loss: 0.6066 - val_accuracy: 0.7729\n",
      "Epoch 1845/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4813 - accuracy: 0.8212 - val_loss: 0.6066 - val_accuracy: 0.7724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1846/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4813 - accuracy: 0.8213 - val_loss: 0.6067 - val_accuracy: 0.7727\n",
      "Epoch 1847/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4812 - accuracy: 0.8215 - val_loss: 0.6065 - val_accuracy: 0.7731\n",
      "Epoch 1848/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4813 - accuracy: 0.8213 - val_loss: 0.6067 - val_accuracy: 0.7731\n",
      "Epoch 1849/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4813 - accuracy: 0.8216 - val_loss: 0.6067 - val_accuracy: 0.7722\n",
      "Epoch 1850/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4812 - accuracy: 0.8211 - val_loss: 0.6065 - val_accuracy: 0.7731\n",
      "Epoch 1851/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4812 - accuracy: 0.8212 - val_loss: 0.6066 - val_accuracy: 0.7736\n",
      "Epoch 1852/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4812 - accuracy: 0.8214 - val_loss: 0.6066 - val_accuracy: 0.7729\n",
      "Epoch 1853/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4812 - accuracy: 0.8210 - val_loss: 0.6066 - val_accuracy: 0.7724\n",
      "Epoch 1854/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4811 - accuracy: 0.8217 - val_loss: 0.6065 - val_accuracy: 0.7729\n",
      "Epoch 1855/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4811 - accuracy: 0.8212 - val_loss: 0.6066 - val_accuracy: 0.7729\n",
      "Epoch 1856/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4811 - accuracy: 0.8209 - val_loss: 0.6065 - val_accuracy: 0.7724\n",
      "Epoch 1857/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4810 - accuracy: 0.8213 - val_loss: 0.6065 - val_accuracy: 0.7731\n",
      "Epoch 1858/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4810 - accuracy: 0.8216 - val_loss: 0.6065 - val_accuracy: 0.7724\n",
      "Epoch 1859/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4810 - accuracy: 0.8215 - val_loss: 0.6065 - val_accuracy: 0.7724\n",
      "Epoch 1860/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.4810 - accuracy: 0.8212 - val_loss: 0.6065 - val_accuracy: 0.7727\n",
      "Epoch 1861/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4810 - accuracy: 0.8213 - val_loss: 0.6065 - val_accuracy: 0.7724\n",
      "Epoch 1862/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4809 - accuracy: 0.8217 - val_loss: 0.6065 - val_accuracy: 0.7724\n",
      "Epoch 1863/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4809 - accuracy: 0.8213 - val_loss: 0.6065 - val_accuracy: 0.7729\n",
      "Epoch 1864/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4809 - accuracy: 0.8214 - val_loss: 0.6065 - val_accuracy: 0.7731\n",
      "Epoch 1865/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4809 - accuracy: 0.8210 - val_loss: 0.6065 - val_accuracy: 0.7727\n",
      "Epoch 1866/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4809 - accuracy: 0.8213 - val_loss: 0.6065 - val_accuracy: 0.7729\n",
      "Epoch 1867/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4808 - accuracy: 0.8214 - val_loss: 0.6065 - val_accuracy: 0.7727\n",
      "Epoch 1868/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4808 - accuracy: 0.8217 - val_loss: 0.6065 - val_accuracy: 0.7731\n",
      "Epoch 1869/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4808 - accuracy: 0.8211 - val_loss: 0.6065 - val_accuracy: 0.7727\n",
      "Epoch 1870/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4808 - accuracy: 0.8215 - val_loss: 0.6065 - val_accuracy: 0.7727\n",
      "Epoch 1871/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4807 - accuracy: 0.8217 - val_loss: 0.6065 - val_accuracy: 0.7729\n",
      "Epoch 1872/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4807 - accuracy: 0.8216 - val_loss: 0.6065 - val_accuracy: 0.7731\n",
      "Epoch 1873/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4807 - accuracy: 0.8210 - val_loss: 0.6065 - val_accuracy: 0.7736\n",
      "Epoch 1874/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4807 - accuracy: 0.8219 - val_loss: 0.6065 - val_accuracy: 0.7731\n",
      "Epoch 1875/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.8220 - val_loss: 0.6064 - val_accuracy: 0.7731\n",
      "Epoch 1876/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4806 - accuracy: 0.8211 - val_loss: 0.6065 - val_accuracy: 0.7727\n",
      "Epoch 1877/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4806 - accuracy: 0.8212 - val_loss: 0.6065 - val_accuracy: 0.7736\n",
      "Epoch 1878/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4806 - accuracy: 0.8211 - val_loss: 0.6065 - val_accuracy: 0.7731\n",
      "Epoch 1879/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4806 - accuracy: 0.8216 - val_loss: 0.6065 - val_accuracy: 0.7729\n",
      "Epoch 1880/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4806 - accuracy: 0.8216 - val_loss: 0.6065 - val_accuracy: 0.7731\n",
      "Epoch 1881/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4805 - accuracy: 0.8215 - val_loss: 0.6065 - val_accuracy: 0.7729\n",
      "Epoch 1882/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4805 - accuracy: 0.8215 - val_loss: 0.6065 - val_accuracy: 0.7734\n",
      "Epoch 1883/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4805 - accuracy: 0.8215 - val_loss: 0.6065 - val_accuracy: 0.7729\n",
      "Epoch 1884/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4805 - accuracy: 0.8219 - val_loss: 0.6065 - val_accuracy: 0.7734\n",
      "Epoch 1885/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4804 - accuracy: 0.8215 - val_loss: 0.6064 - val_accuracy: 0.7729\n",
      "Epoch 1886/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4804 - accuracy: 0.8217 - val_loss: 0.6065 - val_accuracy: 0.7736\n",
      "Epoch 1887/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4804 - accuracy: 0.8215 - val_loss: 0.6064 - val_accuracy: 0.7734\n",
      "Epoch 1888/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4804 - accuracy: 0.8213 - val_loss: 0.6064 - val_accuracy: 0.7729\n",
      "Epoch 1889/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4803 - accuracy: 0.8215 - val_loss: 0.6064 - val_accuracy: 0.7731\n",
      "Epoch 1890/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4803 - accuracy: 0.8218 - val_loss: 0.6065 - val_accuracy: 0.7731\n",
      "Epoch 1891/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4803 - accuracy: 0.8211 - val_loss: 0.6064 - val_accuracy: 0.7734\n",
      "Epoch 1892/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4803 - accuracy: 0.8210 - val_loss: 0.6065 - val_accuracy: 0.7729\n",
      "Epoch 1893/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4803 - accuracy: 0.8217 - val_loss: 0.6065 - val_accuracy: 0.7731\n",
      "Epoch 1894/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4802 - accuracy: 0.8219 - val_loss: 0.6065 - val_accuracy: 0.7734\n",
      "Epoch 1895/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4802 - accuracy: 0.8216 - val_loss: 0.6065 - val_accuracy: 0.7734\n",
      "Epoch 1896/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4802 - accuracy: 0.8218 - val_loss: 0.6065 - val_accuracy: 0.7736\n",
      "Epoch 1897/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4802 - accuracy: 0.8219 - val_loss: 0.6065 - val_accuracy: 0.7731\n",
      "Epoch 1898/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4802 - accuracy: 0.8213 - val_loss: 0.6065 - val_accuracy: 0.7727\n",
      "Epoch 1899/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4801 - accuracy: 0.8215 - val_loss: 0.6065 - val_accuracy: 0.7734\n",
      "Epoch 1900/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4801 - accuracy: 0.8219 - val_loss: 0.6064 - val_accuracy: 0.7731\n",
      "Epoch 1901/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.8216 - val_loss: 0.6064 - val_accuracy: 0.7734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1902/2000\n",
      "138/138 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.8211 - val_loss: 0.6064 - val_accuracy: 0.7734\n",
      "Epoch 1903/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4800 - accuracy: 0.8216 - val_loss: 0.6064 - val_accuracy: 0.7734\n",
      "Epoch 1904/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4800 - accuracy: 0.8217 - val_loss: 0.6064 - val_accuracy: 0.7734\n",
      "Epoch 1905/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4800 - accuracy: 0.8219 - val_loss: 0.6064 - val_accuracy: 0.7729\n",
      "Epoch 1906/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4800 - accuracy: 0.8220 - val_loss: 0.6064 - val_accuracy: 0.7731\n",
      "Epoch 1907/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4800 - accuracy: 0.8215 - val_loss: 0.6064 - val_accuracy: 0.7727\n",
      "Epoch 1908/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4799 - accuracy: 0.8218 - val_loss: 0.6064 - val_accuracy: 0.7731\n",
      "Epoch 1909/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4799 - accuracy: 0.8217 - val_loss: 0.6064 - val_accuracy: 0.7731\n",
      "Epoch 1910/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4800 - accuracy: 0.8213 - val_loss: 0.6064 - val_accuracy: 0.7731\n",
      "Epoch 1911/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4799 - accuracy: 0.8212 - val_loss: 0.6063 - val_accuracy: 0.7729\n",
      "Epoch 1912/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4799 - accuracy: 0.8218 - val_loss: 0.6064 - val_accuracy: 0.7727\n",
      "Epoch 1913/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4798 - accuracy: 0.8220 - val_loss: 0.6064 - val_accuracy: 0.7724\n",
      "Epoch 1914/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4798 - accuracy: 0.8220 - val_loss: 0.6063 - val_accuracy: 0.7734\n",
      "Epoch 1915/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4798 - accuracy: 0.8217 - val_loss: 0.6063 - val_accuracy: 0.7729\n",
      "Epoch 1916/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4798 - accuracy: 0.8218 - val_loss: 0.6063 - val_accuracy: 0.7727\n",
      "Epoch 1917/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4797 - accuracy: 0.8220 - val_loss: 0.6063 - val_accuracy: 0.7729\n",
      "Epoch 1918/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4797 - accuracy: 0.8218 - val_loss: 0.6063 - val_accuracy: 0.7736\n",
      "Epoch 1919/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4797 - accuracy: 0.8219 - val_loss: 0.6063 - val_accuracy: 0.7731\n",
      "Epoch 1920/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4797 - accuracy: 0.8217 - val_loss: 0.6064 - val_accuracy: 0.7734\n",
      "Epoch 1921/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4797 - accuracy: 0.8217 - val_loss: 0.6063 - val_accuracy: 0.7729\n",
      "Epoch 1922/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4796 - accuracy: 0.8221 - val_loss: 0.6063 - val_accuracy: 0.7729\n",
      "Epoch 1923/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4796 - accuracy: 0.8219 - val_loss: 0.6063 - val_accuracy: 0.7729\n",
      "Epoch 1924/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4796 - accuracy: 0.8224 - val_loss: 0.6063 - val_accuracy: 0.7724\n",
      "Epoch 1925/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4796 - accuracy: 0.8215 - val_loss: 0.6062 - val_accuracy: 0.7731\n",
      "Epoch 1926/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4795 - accuracy: 0.8220 - val_loss: 0.6062 - val_accuracy: 0.7734\n",
      "Epoch 1927/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4795 - accuracy: 0.8219 - val_loss: 0.6062 - val_accuracy: 0.7731\n",
      "Epoch 1928/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4795 - accuracy: 0.8219 - val_loss: 0.6062 - val_accuracy: 0.7734\n",
      "Epoch 1929/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4795 - accuracy: 0.8219 - val_loss: 0.6062 - val_accuracy: 0.7731\n",
      "Epoch 1930/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4795 - accuracy: 0.8212 - val_loss: 0.6062 - val_accuracy: 0.7731\n",
      "Epoch 1931/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4795 - accuracy: 0.8217 - val_loss: 0.6061 - val_accuracy: 0.7729\n",
      "Epoch 1932/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4794 - accuracy: 0.8219 - val_loss: 0.6061 - val_accuracy: 0.7727\n",
      "Epoch 1933/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4794 - accuracy: 0.8215 - val_loss: 0.6062 - val_accuracy: 0.7731\n",
      "Epoch 1934/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4794 - accuracy: 0.8216 - val_loss: 0.6062 - val_accuracy: 0.7736\n",
      "Epoch 1935/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4794 - accuracy: 0.8218 - val_loss: 0.6061 - val_accuracy: 0.7724\n",
      "Epoch 1936/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4793 - accuracy: 0.8220 - val_loss: 0.6062 - val_accuracy: 0.7734\n",
      "Epoch 1937/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4793 - accuracy: 0.8218 - val_loss: 0.6061 - val_accuracy: 0.7736\n",
      "Epoch 1938/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4793 - accuracy: 0.8224 - val_loss: 0.6061 - val_accuracy: 0.7729\n",
      "Epoch 1939/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4793 - accuracy: 0.8221 - val_loss: 0.6062 - val_accuracy: 0.7729\n",
      "Epoch 1940/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4793 - accuracy: 0.8215 - val_loss: 0.6062 - val_accuracy: 0.7736\n",
      "Epoch 1941/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4792 - accuracy: 0.8225 - val_loss: 0.6061 - val_accuracy: 0.7734\n",
      "Epoch 1942/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4792 - accuracy: 0.8219 - val_loss: 0.6062 - val_accuracy: 0.7736\n",
      "Epoch 1943/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4793 - accuracy: 0.8219 - val_loss: 0.6062 - val_accuracy: 0.7731\n",
      "Epoch 1944/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4792 - accuracy: 0.8218 - val_loss: 0.6061 - val_accuracy: 0.7734\n",
      "Epoch 1945/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4792 - accuracy: 0.8219 - val_loss: 0.6061 - val_accuracy: 0.7734\n",
      "Epoch 1946/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4792 - accuracy: 0.8221 - val_loss: 0.6060 - val_accuracy: 0.7731\n",
      "Epoch 1947/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4791 - accuracy: 0.8216 - val_loss: 0.6061 - val_accuracy: 0.7729\n",
      "Epoch 1948/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4791 - accuracy: 0.8216 - val_loss: 0.6060 - val_accuracy: 0.7729\n",
      "Epoch 1949/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4791 - accuracy: 0.8216 - val_loss: 0.6061 - val_accuracy: 0.7731\n",
      "Epoch 1950/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4791 - accuracy: 0.8223 - val_loss: 0.6060 - val_accuracy: 0.7734\n",
      "Epoch 1951/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4791 - accuracy: 0.8220 - val_loss: 0.6061 - val_accuracy: 0.7734\n",
      "Epoch 1952/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4791 - accuracy: 0.8219 - val_loss: 0.6060 - val_accuracy: 0.7731\n",
      "Epoch 1953/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4790 - accuracy: 0.8223 - val_loss: 0.6060 - val_accuracy: 0.7740\n",
      "Epoch 1954/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4790 - accuracy: 0.8223 - val_loss: 0.6060 - val_accuracy: 0.7729\n",
      "Epoch 1955/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4789 - accuracy: 0.8222 - val_loss: 0.6060 - val_accuracy: 0.7729\n",
      "Epoch 1956/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4790 - accuracy: 0.8221 - val_loss: 0.6060 - val_accuracy: 0.7731\n",
      "Epoch 1957/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4789 - accuracy: 0.8218 - val_loss: 0.6060 - val_accuracy: 0.7736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1958/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4789 - accuracy: 0.8222 - val_loss: 0.6059 - val_accuracy: 0.7734\n",
      "Epoch 1959/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4789 - accuracy: 0.8219 - val_loss: 0.6059 - val_accuracy: 0.7734\n",
      "Epoch 1960/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4789 - accuracy: 0.8216 - val_loss: 0.6060 - val_accuracy: 0.7738\n",
      "Epoch 1961/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4788 - accuracy: 0.8216 - val_loss: 0.6059 - val_accuracy: 0.7734\n",
      "Epoch 1962/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4788 - accuracy: 0.8222 - val_loss: 0.6060 - val_accuracy: 0.7727\n",
      "Epoch 1963/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4788 - accuracy: 0.8222 - val_loss: 0.6059 - val_accuracy: 0.7729\n",
      "Epoch 1964/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4788 - accuracy: 0.8217 - val_loss: 0.6059 - val_accuracy: 0.7731\n",
      "Epoch 1965/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4788 - accuracy: 0.8217 - val_loss: 0.6059 - val_accuracy: 0.7724\n",
      "Epoch 1966/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4787 - accuracy: 0.8220 - val_loss: 0.6059 - val_accuracy: 0.7729\n",
      "Epoch 1967/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4787 - accuracy: 0.8218 - val_loss: 0.6060 - val_accuracy: 0.7724\n",
      "Epoch 1968/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4787 - accuracy: 0.8221 - val_loss: 0.6059 - val_accuracy: 0.7738\n",
      "Epoch 1969/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4787 - accuracy: 0.8216 - val_loss: 0.6060 - val_accuracy: 0.7729\n",
      "Epoch 1970/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4786 - accuracy: 0.8221 - val_loss: 0.6059 - val_accuracy: 0.7734\n",
      "Epoch 1971/2000\n",
      "138/138 [==============================] - 0s 4ms/step - loss: 0.4786 - accuracy: 0.8219 - val_loss: 0.6059 - val_accuracy: 0.7729\n",
      "Epoch 1972/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4786 - accuracy: 0.8219 - val_loss: 0.6060 - val_accuracy: 0.7731\n",
      "Epoch 1973/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4786 - accuracy: 0.8219 - val_loss: 0.6059 - val_accuracy: 0.7734\n",
      "Epoch 1974/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4786 - accuracy: 0.8223 - val_loss: 0.6059 - val_accuracy: 0.7736\n",
      "Epoch 1975/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4786 - accuracy: 0.8220 - val_loss: 0.6059 - val_accuracy: 0.7720\n",
      "Epoch 1976/2000\n",
      "138/138 [==============================] - 1s 5ms/step - loss: 0.4785 - accuracy: 0.8217 - val_loss: 0.6058 - val_accuracy: 0.7727\n",
      "Epoch 1977/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4785 - accuracy: 0.8217 - val_loss: 0.6059 - val_accuracy: 0.7734\n",
      "Epoch 1978/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4785 - accuracy: 0.8223 - val_loss: 0.6058 - val_accuracy: 0.7729\n",
      "Epoch 1979/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4785 - accuracy: 0.8224 - val_loss: 0.6059 - val_accuracy: 0.7724\n",
      "Epoch 1980/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4784 - accuracy: 0.8219 - val_loss: 0.6058 - val_accuracy: 0.7727\n",
      "Epoch 1981/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4785 - accuracy: 0.8226 - val_loss: 0.6058 - val_accuracy: 0.7724\n",
      "Epoch 1982/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4785 - accuracy: 0.8220 - val_loss: 0.6058 - val_accuracy: 0.7731\n",
      "Epoch 1983/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4784 - accuracy: 0.8225 - val_loss: 0.6059 - val_accuracy: 0.7734\n",
      "Epoch 1984/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4784 - accuracy: 0.8217 - val_loss: 0.6058 - val_accuracy: 0.7729\n",
      "Epoch 1985/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4783 - accuracy: 0.8220 - val_loss: 0.6058 - val_accuracy: 0.7734\n",
      "Epoch 1986/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4783 - accuracy: 0.8217 - val_loss: 0.6058 - val_accuracy: 0.7727\n",
      "Epoch 1987/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4783 - accuracy: 0.8221 - val_loss: 0.6059 - val_accuracy: 0.7727\n",
      "Epoch 1988/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4783 - accuracy: 0.8220 - val_loss: 0.6059 - val_accuracy: 0.7727\n",
      "Epoch 1989/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4783 - accuracy: 0.8217 - val_loss: 0.6059 - val_accuracy: 0.7727\n",
      "Epoch 1990/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4783 - accuracy: 0.8221 - val_loss: 0.6058 - val_accuracy: 0.7731\n",
      "Epoch 1991/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4782 - accuracy: 0.8221 - val_loss: 0.6058 - val_accuracy: 0.7729\n",
      "Epoch 1992/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4782 - accuracy: 0.8220 - val_loss: 0.6058 - val_accuracy: 0.7736\n",
      "Epoch 1993/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4782 - accuracy: 0.8223 - val_loss: 0.6059 - val_accuracy: 0.7727\n",
      "Epoch 1994/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4782 - accuracy: 0.8219 - val_loss: 0.6058 - val_accuracy: 0.7720\n",
      "Epoch 1995/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4782 - accuracy: 0.8219 - val_loss: 0.6058 - val_accuracy: 0.7729\n",
      "Epoch 1996/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4781 - accuracy: 0.8222 - val_loss: 0.6058 - val_accuracy: 0.7729\n",
      "Epoch 1997/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4782 - accuracy: 0.8218 - val_loss: 0.6058 - val_accuracy: 0.7729\n",
      "Epoch 1998/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4781 - accuracy: 0.8224 - val_loss: 0.6058 - val_accuracy: 0.7738\n",
      "Epoch 1999/2000\n",
      "138/138 [==============================] - 0s 3ms/step - loss: 0.4781 - accuracy: 0.8217 - val_loss: 0.6059 - val_accuracy: 0.7734\n",
      "Epoch 2000/2000\n",
      "138/138 [==============================] - 1s 4ms/step - loss: 0.4781 - accuracy: 0.8222 - val_loss: 0.6058 - val_accuracy: 0.7729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x29ad5b87850>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 2000\n",
    "history=model.fit(X_train_idf.toarray(), y_train, batch_size=batch_size, epochs=epochs, shuffle=True, verbose=1,validation_split=0.2)\n",
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d00c466",
   "metadata": {},
   "source": [
    "##### 6) Finding Training and Testing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d517703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training and testing accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9dc7b678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 1s 3ms/step - loss: 0.6306 - accuracy: 0.7614\n",
      "Test Accuracy: 0.761411190032959 and Test Loss: 0.630631685256958\n"
     ]
    }
   ],
   "source": [
    "test_loss,test_acc=model.evaluate(X_test_idf.toarray(),y_test)\n",
    "print(f'Test Accuracy: {test_acc} and Test Loss: {test_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a47670",
   "metadata": {},
   "source": [
    "##### 7) Compute and plot the confusion matrix for the three classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7eb7ef1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 1s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.76      0.77      1835\n",
      "     neutral       0.72      0.72      0.72      1828\n",
      "    positive       0.79      0.81      0.80      1836\n",
      "\n",
      "    accuracy                           0.76      5499\n",
      "   macro avg       0.76      0.76      0.76      5499\n",
      "weighted avg       0.76      0.76      0.76      5499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions=model.predict(X_test_idf.toarray())\n",
    "class_labels = ['negative', 'positive','neutral']\n",
    "predicted_class_labels = [class_labels[np.argmax(pred)] for pred in predictions]\n",
    "actual_class_labels=[class_labels[actual] for actual in y_test]\n",
    "print(classification_report(actual_class_labels, predicted_class_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9208658a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(actual_class_labels, predicted_class_labels, labels=class_labels)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Purples\", xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd974772",
   "metadata": {},
   "source": [
    "##### 8) Saving the final results in Excel sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0081b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision per class: [0.77746637 0.71886895 0.78784648]\n",
      "Recall per class: [0.75585831 0.72319475 0.80501089]\n"
     ]
    }
   ],
   "source": [
    "precision_per_class = precision_score(actual_class_labels, predicted_class_labels, average=None)\n",
    "recall_per_class = recall_score(actual_class_labels, predicted_class_labels, average=None)\n",
    "\n",
    "print(\"Precision per class:\", precision_per_class)\n",
    "print(\"Recall per class:\", recall_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7df0d2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1 Score: 0.7614111656664847\n",
      "Macro F1 Score: 0.7612905512954539\n"
     ]
    }
   ],
   "source": [
    "f1_micro = f1_score(actual_class_labels, predicted_class_labels, average='micro')\n",
    "f1_macro = f1_score(actual_class_labels, predicted_class_labels, average='macro')\n",
    "\n",
    "print(\"Micro F1 Score:\", f1_micro)\n",
    "print(\"Macro F1 Score:\", f1_macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8684f6a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>CharacterSwapping_Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Training Accuracy</td>\n",
       "      <td>0.822600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Testing Accuracy</td>\n",
       "      <td>0.761411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Micro F1 Score</td>\n",
       "      <td>0.761411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Macro F1 Score</td>\n",
       "      <td>0.761291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Precision for Negative sentiment</td>\n",
       "      <td>0.777466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Precision for Positive sentiment</td>\n",
       "      <td>0.718869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Precision for Neutral sentiment</td>\n",
       "      <td>0.787846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Recall for Negative sentiment</td>\n",
       "      <td>0.755858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Recall for Positive sentiment</td>\n",
       "      <td>0.723195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Recall for Neutral sentiment</td>\n",
       "      <td>0.805011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Unnamed: 0  CharacterSwapping_Dataset\n",
       "0                 Training Accuracy                   0.822600\n",
       "1                  Testing Accuracy                   0.761411\n",
       "2                    Micro F1 Score                   0.761411\n",
       "3                    Macro F1 Score                   0.761291\n",
       "4  Precision for Negative sentiment                   0.777466\n",
       "5  Precision for Positive sentiment                   0.718869\n",
       "6   Precision for Neutral sentiment                   0.787846\n",
       "7     Recall for Negative sentiment                   0.755858\n",
       "8     Recall for Positive sentiment                   0.723195\n",
       "9      Recall for Neutral sentiment                   0.805011"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=pd.read_csv('SimpleDNNModelResults.csv')\n",
    "result['CharacterSwapping_Dataset']=[max(history.history['accuracy']),test_acc,f1_micro,f1_macro,precision_per_class[0],precision_per_class[1],precision_per_class[2],recall_per_class[0],recall_per_class[1],recall_per_class[2]]\n",
    "result[['Unnamed: 0','CharacterSwapping_Dataset']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "448e60d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('SimpleDNNModelResults.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
