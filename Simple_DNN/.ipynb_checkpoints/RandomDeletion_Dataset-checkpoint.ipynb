{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6575869",
   "metadata": {},
   "source": [
    "# Simple DNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "934847a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Users\\Suzan Hatem\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import  Dense,Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978ceb42",
   "metadata": {},
   "source": [
    "##### 1)Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "272b56c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>preprocessed_abstract</th>\n",
       "      <th>length_after_cleaning</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>35</td>\n",
       "      <td>what say</td>\n",
       "      <td>8</td>\n",
       "      <td>['what', 'say']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>72</td>\n",
       "      <td>plus add commercial experience tacky</td>\n",
       "      <td>36</td>\n",
       "      <td>['plus', 'add', 'commercial', 'experience', 't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>71</td>\n",
       "      <td>i today must mean i need take another trip</td>\n",
       "      <td>42</td>\n",
       "      <td>['i', 'today', 'must', 'mean', 'i', 'need', 't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>126</td>\n",
       "      <td>really aggressive blast obnoxious entertainmen...</td>\n",
       "      <td>78</td>\n",
       "      <td>['really', 'aggressive', 'blast', 'obnoxious',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>55</td>\n",
       "      <td>really big bad thing</td>\n",
       "      <td>20</td>\n",
       "      <td>['really', 'big', 'bad', 'thing']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0  label  \\\n",
       "0             0           0      2   \n",
       "1             1           1      1   \n",
       "2             2           2      2   \n",
       "3             3           3      0   \n",
       "4             4           4      0   \n",
       "\n",
       "                                                text  length  \\\n",
       "0                @VirginAmerica What @dhepburn said.      35   \n",
       "1  @VirginAmerica plus you've added commercials t...      72   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...      71   \n",
       "3  @VirginAmerica it's really aggressive to blast...     126   \n",
       "4  @VirginAmerica and it's a really big bad thing...      55   \n",
       "\n",
       "                               preprocessed_abstract  length_after_cleaning  \\\n",
       "0                                           what say                      8   \n",
       "1               plus add commercial experience tacky                     36   \n",
       "2         i today must mean i need take another trip                     42   \n",
       "3  really aggressive blast obnoxious entertainmen...                     78   \n",
       "4                               really big bad thing                     20   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0                                    ['what', 'say']  \n",
       "1  ['plus', 'add', 'commercial', 'experience', 't...  \n",
       "2  ['i', 'today', 'must', 'mean', 'i', 'need', 't...  \n",
       "3  ['really', 'aggressive', 'blast', 'obnoxious',...  \n",
       "4                  ['really', 'big', 'bad', 'thing']  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"df_RandomDeletion.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fc2dbfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0.1               0\n",
       "Unnamed: 0                 0\n",
       "label                      0\n",
       "text                       0\n",
       "length                     0\n",
       "preprocessed_abstract    408\n",
       "length_after_cleaning      0\n",
       "tokenized_text             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4ad58fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e03b6a9",
   "metadata": {},
   "source": [
    "#####  2) Split , into Training and Validation Sets (80:20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8741840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: (21700,) (21700,)\n",
      "Test data: (5426,) (5426,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['preprocessed_abstract'], df['label'], test_size=0.2, stratify=df['label'], random_state=42)\n",
    "print(\"Train data:\",  X_train.shape, y_train.shape)\n",
    "print(\"Test data:\",  X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d5b7f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "colors = ['#4285f4', '#ea4335', '#fbbc05', '#34a853']\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.pie([len(y_train), len(y_test)],\n",
    "        labels=['Train','Test'],\n",
    "        colors=colors, autopct='%.1f%%', explode=(0.05,0.05),\n",
    "        startangle=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a556ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_TF-IDF shape:  (21700, 1191)\n",
      "X_test_TF-IDF shape:  (5426, 1191)\n"
     ]
    }
   ],
   "source": [
    "vect= TfidfVectorizer(min_df=20)\n",
    "X_train_idf = vect.fit_transform(X_train)\n",
    "X_test_idf = vect.transform(X_test)\n",
    "\n",
    "print('X_train_TF-IDF shape: ', X_train_idf.shape)\n",
    "print('X_test_TF-IDF shape: ', X_test_idf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ffb115",
   "metadata": {},
   "source": [
    "##### 4)Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4620a071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Users\\Suzan Hatem\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(8,input_shape=(X_train_idf.shape[1],),kernel_regularizer='l2'),\n",
    "    Dense(16,activation='relu'),\n",
    "    Dense(8,activation='relu'),\n",
    "    Dense(3, activation='softmax')#This is a multi-class Classification problem\n",
    "    \n",
    "])\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=0.00001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abfb9a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 8)                 9536      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                144       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 27        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9843 (38.45 KB)\n",
      "Trainable params: 9843 (38.45 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea9dbdd",
   "metadata": {},
   "source": [
    "##### 5) Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a3407cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "WARNING:tensorflow:From D:\\Users\\Suzan Hatem\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Users\\Suzan Hatem\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "136/136 [==============================] - 1s 4ms/step - loss: 1.2529 - accuracy: 0.3327 - val_loss: 1.2487 - val_accuracy: 0.3406\n",
      "Epoch 2/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 1.2450 - accuracy: 0.3377 - val_loss: 1.2410 - val_accuracy: 0.3454\n",
      "Epoch 3/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.2375 - accuracy: 0.3401 - val_loss: 1.2336 - val_accuracy: 0.3507\n",
      "Epoch 4/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.2302 - accuracy: 0.3455 - val_loss: 1.2265 - val_accuracy: 0.3585\n",
      "Epoch 5/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.2233 - accuracy: 0.3513 - val_loss: 1.2197 - val_accuracy: 0.3647\n",
      "Epoch 6/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.2166 - accuracy: 0.3556 - val_loss: 1.2132 - val_accuracy: 0.3742\n",
      "Epoch 7/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.2103 - accuracy: 0.3610 - val_loss: 1.2069 - val_accuracy: 0.3765\n",
      "Epoch 8/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.2041 - accuracy: 0.3646 - val_loss: 1.2010 - val_accuracy: 0.3760\n",
      "Epoch 9/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1982 - accuracy: 0.3692 - val_loss: 1.1952 - val_accuracy: 0.3774\n",
      "Epoch 10/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1926 - accuracy: 0.3741 - val_loss: 1.1897 - val_accuracy: 0.3788\n",
      "Epoch 11/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1871 - accuracy: 0.3820 - val_loss: 1.1843 - val_accuracy: 0.3894\n",
      "Epoch 12/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1818 - accuracy: 0.3889 - val_loss: 1.1792 - val_accuracy: 0.3929\n",
      "Epoch 13/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1767 - accuracy: 0.3932 - val_loss: 1.1742 - val_accuracy: 0.3961\n",
      "Epoch 14/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1717 - accuracy: 0.4000 - val_loss: 1.1693 - val_accuracy: 0.4030\n",
      "Epoch 15/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1669 - accuracy: 0.4074 - val_loss: 1.1646 - val_accuracy: 0.4088\n",
      "Epoch 16/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1622 - accuracy: 0.4140 - val_loss: 1.1600 - val_accuracy: 0.4152\n",
      "Epoch 17/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1576 - accuracy: 0.4199 - val_loss: 1.1556 - val_accuracy: 0.4207\n",
      "Epoch 18/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1532 - accuracy: 0.4255 - val_loss: 1.1512 - val_accuracy: 0.4251\n",
      "Epoch 19/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1489 - accuracy: 0.4313 - val_loss: 1.1470 - val_accuracy: 0.4311\n",
      "Epoch 20/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1447 - accuracy: 0.4374 - val_loss: 1.1430 - val_accuracy: 0.4336\n",
      "Epoch 21/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1406 - accuracy: 0.4430 - val_loss: 1.1390 - val_accuracy: 0.4385\n",
      "Epoch 22/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1367 - accuracy: 0.4501 - val_loss: 1.1352 - val_accuracy: 0.4433\n",
      "Epoch 23/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1329 - accuracy: 0.4552 - val_loss: 1.1315 - val_accuracy: 0.4475\n",
      "Epoch 24/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1292 - accuracy: 0.4606 - val_loss: 1.1279 - val_accuracy: 0.4544\n",
      "Epoch 25/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1256 - accuracy: 0.4664 - val_loss: 1.1245 - val_accuracy: 0.4611\n",
      "Epoch 26/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1222 - accuracy: 0.4729 - val_loss: 1.1212 - val_accuracy: 0.4654\n",
      "Epoch 27/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1188 - accuracy: 0.4767 - val_loss: 1.1179 - val_accuracy: 0.4700\n",
      "Epoch 28/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1156 - accuracy: 0.4810 - val_loss: 1.1148 - val_accuracy: 0.4730\n",
      "Epoch 29/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1125 - accuracy: 0.4839 - val_loss: 1.1118 - val_accuracy: 0.4783\n",
      "Epoch 30/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1094 - accuracy: 0.4889 - val_loss: 1.1089 - val_accuracy: 0.4811\n",
      "Epoch 31/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1065 - accuracy: 0.4923 - val_loss: 1.1061 - val_accuracy: 0.4857\n",
      "Epoch 32/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1037 - accuracy: 0.4957 - val_loss: 1.1033 - val_accuracy: 0.4892\n",
      "Epoch 33/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1009 - accuracy: 0.4981 - val_loss: 1.1006 - val_accuracy: 0.4910\n",
      "Epoch 34/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0982 - accuracy: 0.5009 - val_loss: 1.0980 - val_accuracy: 0.4929\n",
      "Epoch 35/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0956 - accuracy: 0.5039 - val_loss: 1.0955 - val_accuracy: 0.4959\n",
      "Epoch 36/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0931 - accuracy: 0.5066 - val_loss: 1.0931 - val_accuracy: 0.4993\n",
      "Epoch 37/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0906 - accuracy: 0.5097 - val_loss: 1.0907 - val_accuracy: 0.5018\n",
      "Epoch 38/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0881 - accuracy: 0.5114 - val_loss: 1.0883 - val_accuracy: 0.5044\n",
      "Epoch 39/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0858 - accuracy: 0.5133 - val_loss: 1.0860 - val_accuracy: 0.5055\n",
      "Epoch 40/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0834 - accuracy: 0.5164 - val_loss: 1.0838 - val_accuracy: 0.5085\n",
      "Epoch 41/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0811 - accuracy: 0.5183 - val_loss: 1.0816 - val_accuracy: 0.5108\n",
      "Epoch 42/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0789 - accuracy: 0.5204 - val_loss: 1.0794 - val_accuracy: 0.5115\n",
      "Epoch 43/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0766 - accuracy: 0.5222 - val_loss: 1.0772 - val_accuracy: 0.5147\n",
      "Epoch 44/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0744 - accuracy: 0.5242 - val_loss: 1.0751 - val_accuracy: 0.5161\n",
      "Epoch 45/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0723 - accuracy: 0.5253 - val_loss: 1.0730 - val_accuracy: 0.5175\n",
      "Epoch 46/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0701 - accuracy: 0.5272 - val_loss: 1.0710 - val_accuracy: 0.5194\n",
      "Epoch 47/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0680 - accuracy: 0.5292 - val_loss: 1.0690 - val_accuracy: 0.5189\n",
      "Epoch 48/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0659 - accuracy: 0.5302 - val_loss: 1.0670 - val_accuracy: 0.5200\n",
      "Epoch 49/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0639 - accuracy: 0.5320 - val_loss: 1.0650 - val_accuracy: 0.5203\n",
      "Epoch 50/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0618 - accuracy: 0.5322 - val_loss: 1.0630 - val_accuracy: 0.5217\n",
      "Epoch 51/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0598 - accuracy: 0.5342 - val_loss: 1.0611 - val_accuracy: 0.5221\n",
      "Epoch 52/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0578 - accuracy: 0.5345 - val_loss: 1.0591 - val_accuracy: 0.5240\n",
      "Epoch 53/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0558 - accuracy: 0.5357 - val_loss: 1.0572 - val_accuracy: 0.5249\n",
      "Epoch 54/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0538 - accuracy: 0.5372 - val_loss: 1.0553 - val_accuracy: 0.5249\n",
      "Epoch 55/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0519 - accuracy: 0.5380 - val_loss: 1.0535 - val_accuracy: 0.5256\n",
      "Epoch 56/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0499 - accuracy: 0.5392 - val_loss: 1.0516 - val_accuracy: 0.5256\n",
      "Epoch 57/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0480 - accuracy: 0.5399 - val_loss: 1.0498 - val_accuracy: 0.5258\n",
      "Epoch 58/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0461 - accuracy: 0.5407 - val_loss: 1.0479 - val_accuracy: 0.5253\n",
      "Epoch 59/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0442 - accuracy: 0.5415 - val_loss: 1.0461 - val_accuracy: 0.5258\n",
      "Epoch 60/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0423 - accuracy: 0.5424 - val_loss: 1.0443 - val_accuracy: 0.5272\n",
      "Epoch 61/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0404 - accuracy: 0.5431 - val_loss: 1.0425 - val_accuracy: 0.5281\n",
      "Epoch 62/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0385 - accuracy: 0.5443 - val_loss: 1.0407 - val_accuracy: 0.5279\n",
      "Epoch 63/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0366 - accuracy: 0.5455 - val_loss: 1.0389 - val_accuracy: 0.5286\n",
      "Epoch 64/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0347 - accuracy: 0.5459 - val_loss: 1.0371 - val_accuracy: 0.5288\n",
      "Epoch 65/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0329 - accuracy: 0.5466 - val_loss: 1.0353 - val_accuracy: 0.5293\n",
      "Epoch 66/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0310 - accuracy: 0.5471 - val_loss: 1.0336 - val_accuracy: 0.5293\n",
      "Epoch 67/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0292 - accuracy: 0.5477 - val_loss: 1.0318 - val_accuracy: 0.5304\n",
      "Epoch 68/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0273 - accuracy: 0.5484 - val_loss: 1.0301 - val_accuracy: 0.5304\n",
      "Epoch 69/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0255 - accuracy: 0.5491 - val_loss: 1.0283 - val_accuracy: 0.5316\n",
      "Epoch 70/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0236 - accuracy: 0.5495 - val_loss: 1.0266 - val_accuracy: 0.5320\n",
      "Epoch 71/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0218 - accuracy: 0.5498 - val_loss: 1.0248 - val_accuracy: 0.5325\n",
      "Epoch 72/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0200 - accuracy: 0.5495 - val_loss: 1.0231 - val_accuracy: 0.5325\n",
      "Epoch 73/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0182 - accuracy: 0.5511 - val_loss: 1.0213 - val_accuracy: 0.5325\n",
      "Epoch 74/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0164 - accuracy: 0.5515 - val_loss: 1.0196 - val_accuracy: 0.5329\n",
      "Epoch 75/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0145 - accuracy: 0.5519 - val_loss: 1.0179 - val_accuracy: 0.5339\n",
      "Epoch 76/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0127 - accuracy: 0.5525 - val_loss: 1.0162 - val_accuracy: 0.5346\n",
      "Epoch 77/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0109 - accuracy: 0.5531 - val_loss: 1.0145 - val_accuracy: 0.5348\n",
      "Epoch 78/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0091 - accuracy: 0.5536 - val_loss: 1.0127 - val_accuracy: 0.5350\n",
      "Epoch 79/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0073 - accuracy: 0.5540 - val_loss: 1.0110 - val_accuracy: 0.5350\n",
      "Epoch 80/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0055 - accuracy: 0.5549 - val_loss: 1.0093 - val_accuracy: 0.5353\n",
      "Epoch 81/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0038 - accuracy: 0.5547 - val_loss: 1.0076 - val_accuracy: 0.5357\n",
      "Epoch 82/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0020 - accuracy: 0.5553 - val_loss: 1.0060 - val_accuracy: 0.5364\n",
      "Epoch 83/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0002 - accuracy: 0.5555 - val_loss: 1.0043 - val_accuracy: 0.5369\n",
      "Epoch 84/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.9984 - accuracy: 0.5558 - val_loss: 1.0026 - val_accuracy: 0.5373\n",
      "Epoch 85/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.9966 - accuracy: 0.5569 - val_loss: 1.0009 - val_accuracy: 0.5380\n",
      "Epoch 86/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.9949 - accuracy: 0.5573 - val_loss: 0.9993 - val_accuracy: 0.5389\n",
      "Epoch 87/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.9931 - accuracy: 0.5590 - val_loss: 0.9976 - val_accuracy: 0.5431\n",
      "Epoch 88/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.9914 - accuracy: 0.5615 - val_loss: 0.9959 - val_accuracy: 0.5449\n",
      "Epoch 89/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.9896 - accuracy: 0.5626 - val_loss: 0.9943 - val_accuracy: 0.5449\n",
      "Epoch 90/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.9879 - accuracy: 0.5628 - val_loss: 0.9927 - val_accuracy: 0.5459\n",
      "Epoch 91/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.9862 - accuracy: 0.5637 - val_loss: 0.9910 - val_accuracy: 0.5463\n",
      "Epoch 92/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.9844 - accuracy: 0.5641 - val_loss: 0.9894 - val_accuracy: 0.5475\n",
      "Epoch 93/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.9827 - accuracy: 0.5645 - val_loss: 0.9878 - val_accuracy: 0.5482\n",
      "Epoch 94/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.9810 - accuracy: 0.5653 - val_loss: 0.9862 - val_accuracy: 0.5495\n",
      "Epoch 95/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.9793 - accuracy: 0.5656 - val_loss: 0.9846 - val_accuracy: 0.5500\n",
      "Epoch 96/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.9776 - accuracy: 0.5672 - val_loss: 0.9829 - val_accuracy: 0.5505\n",
      "Epoch 97/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.9759 - accuracy: 0.5673 - val_loss: 0.9814 - val_accuracy: 0.5509\n",
      "Epoch 98/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.9742 - accuracy: 0.5679 - val_loss: 0.9798 - val_accuracy: 0.5512\n",
      "Epoch 99/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.9725 - accuracy: 0.5687 - val_loss: 0.9782 - val_accuracy: 0.5516\n",
      "Epoch 100/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.9708 - accuracy: 0.5691 - val_loss: 0.9766 - val_accuracy: 0.5518\n",
      "Epoch 101/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.9691 - accuracy: 0.5698 - val_loss: 0.9750 - val_accuracy: 0.5525\n",
      "Epoch 102/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.9675 - accuracy: 0.5702 - val_loss: 0.9735 - val_accuracy: 0.5535\n",
      "Epoch 103/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.9658 - accuracy: 0.5710 - val_loss: 0.9719 - val_accuracy: 0.5541\n",
      "Epoch 104/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.9641 - accuracy: 0.5717 - val_loss: 0.9704 - val_accuracy: 0.5535\n",
      "Epoch 105/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.9625 - accuracy: 0.5724 - val_loss: 0.9688 - val_accuracy: 0.5537\n",
      "Epoch 106/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.9609 - accuracy: 0.5724 - val_loss: 0.9673 - val_accuracy: 0.5544\n",
      "Epoch 107/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.9592 - accuracy: 0.5731 - val_loss: 0.9658 - val_accuracy: 0.5555\n",
      "Epoch 108/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.9576 - accuracy: 0.5737 - val_loss: 0.9643 - val_accuracy: 0.5558\n",
      "Epoch 109/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.9560 - accuracy: 0.5743 - val_loss: 0.9628 - val_accuracy: 0.5560\n",
      "Epoch 110/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 2ms/step - loss: 0.9544 - accuracy: 0.5749 - val_loss: 0.9613 - val_accuracy: 0.5560\n",
      "Epoch 111/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.9528 - accuracy: 0.5755 - val_loss: 0.9598 - val_accuracy: 0.5574\n",
      "Epoch 112/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.9512 - accuracy: 0.5759 - val_loss: 0.9583 - val_accuracy: 0.5597\n",
      "Epoch 113/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.9496 - accuracy: 0.5766 - val_loss: 0.9568 - val_accuracy: 0.5599\n",
      "Epoch 114/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.9480 - accuracy: 0.5770 - val_loss: 0.9554 - val_accuracy: 0.5608\n",
      "Epoch 115/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.9465 - accuracy: 0.5780 - val_loss: 0.9539 - val_accuracy: 0.5604\n",
      "Epoch 116/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.9449 - accuracy: 0.5782 - val_loss: 0.9525 - val_accuracy: 0.5613\n",
      "Epoch 117/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.9434 - accuracy: 0.5789 - val_loss: 0.9511 - val_accuracy: 0.5613\n",
      "Epoch 118/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.9418 - accuracy: 0.5819 - val_loss: 0.9496 - val_accuracy: 0.5680\n",
      "Epoch 119/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.9403 - accuracy: 0.5861 - val_loss: 0.9482 - val_accuracy: 0.5696\n",
      "Epoch 120/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.9388 - accuracy: 0.5869 - val_loss: 0.9468 - val_accuracy: 0.5698\n",
      "Epoch 121/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.9373 - accuracy: 0.5877 - val_loss: 0.9454 - val_accuracy: 0.5705\n",
      "Epoch 122/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.9357 - accuracy: 0.5887 - val_loss: 0.9440 - val_accuracy: 0.5717\n",
      "Epoch 123/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.9342 - accuracy: 0.5907 - val_loss: 0.9426 - val_accuracy: 0.5758\n",
      "Epoch 124/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.9327 - accuracy: 0.5928 - val_loss: 0.9412 - val_accuracy: 0.5767\n",
      "Epoch 125/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.9312 - accuracy: 0.5935 - val_loss: 0.9399 - val_accuracy: 0.5774\n",
      "Epoch 126/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.9298 - accuracy: 0.5949 - val_loss: 0.9385 - val_accuracy: 0.5786\n",
      "Epoch 127/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.9283 - accuracy: 0.5954 - val_loss: 0.9371 - val_accuracy: 0.5806\n",
      "Epoch 128/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.9268 - accuracy: 0.5964 - val_loss: 0.9358 - val_accuracy: 0.5811\n",
      "Epoch 129/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.9254 - accuracy: 0.5971 - val_loss: 0.9344 - val_accuracy: 0.5820\n",
      "Epoch 130/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.9239 - accuracy: 0.5974 - val_loss: 0.9331 - val_accuracy: 0.5825\n",
      "Epoch 131/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.9225 - accuracy: 0.5979 - val_loss: 0.9318 - val_accuracy: 0.5829\n",
      "Epoch 132/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.9210 - accuracy: 0.5994 - val_loss: 0.9305 - val_accuracy: 0.5841\n",
      "Epoch 133/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.9196 - accuracy: 0.6002 - val_loss: 0.9292 - val_accuracy: 0.5853\n",
      "Epoch 134/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.9182 - accuracy: 0.6007 - val_loss: 0.9279 - val_accuracy: 0.5850\n",
      "Epoch 135/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.9168 - accuracy: 0.6016 - val_loss: 0.9266 - val_accuracy: 0.5862\n",
      "Epoch 136/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.9154 - accuracy: 0.6024 - val_loss: 0.9253 - val_accuracy: 0.5866\n",
      "Epoch 137/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.9140 - accuracy: 0.6027 - val_loss: 0.9240 - val_accuracy: 0.5876\n",
      "Epoch 138/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.9126 - accuracy: 0.6037 - val_loss: 0.9228 - val_accuracy: 0.5885\n",
      "Epoch 139/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.9112 - accuracy: 0.6047 - val_loss: 0.9215 - val_accuracy: 0.5894\n",
      "Epoch 140/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.9098 - accuracy: 0.6053 - val_loss: 0.9202 - val_accuracy: 0.5903\n",
      "Epoch 141/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.9085 - accuracy: 0.6065 - val_loss: 0.9190 - val_accuracy: 0.5917\n",
      "Epoch 142/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.9071 - accuracy: 0.6073 - val_loss: 0.9178 - val_accuracy: 0.5924\n",
      "Epoch 143/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.9057 - accuracy: 0.6079 - val_loss: 0.9165 - val_accuracy: 0.5931\n",
      "Epoch 144/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.9044 - accuracy: 0.6087 - val_loss: 0.9153 - val_accuracy: 0.5940\n",
      "Epoch 145/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.9030 - accuracy: 0.6103 - val_loss: 0.9141 - val_accuracy: 0.5952\n",
      "Epoch 146/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.9017 - accuracy: 0.6112 - val_loss: 0.9129 - val_accuracy: 0.5975\n",
      "Epoch 147/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.9004 - accuracy: 0.6129 - val_loss: 0.9117 - val_accuracy: 0.5979\n",
      "Epoch 148/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8991 - accuracy: 0.6134 - val_loss: 0.9105 - val_accuracy: 0.5991\n",
      "Epoch 149/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.8978 - accuracy: 0.6153 - val_loss: 0.9093 - val_accuracy: 0.6018\n",
      "Epoch 150/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.8964 - accuracy: 0.6155 - val_loss: 0.9081 - val_accuracy: 0.6018\n",
      "Epoch 151/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.8951 - accuracy: 0.6162 - val_loss: 0.9070 - val_accuracy: 0.6030\n",
      "Epoch 152/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8938 - accuracy: 0.6190 - val_loss: 0.9058 - val_accuracy: 0.6041\n",
      "Epoch 153/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.8926 - accuracy: 0.6206 - val_loss: 0.9047 - val_accuracy: 0.6051\n",
      "Epoch 154/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8913 - accuracy: 0.6216 - val_loss: 0.9035 - val_accuracy: 0.6067\n",
      "Epoch 155/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8900 - accuracy: 0.6226 - val_loss: 0.9023 - val_accuracy: 0.6069\n",
      "Epoch 156/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8887 - accuracy: 0.6234 - val_loss: 0.9012 - val_accuracy: 0.6078\n",
      "Epoch 157/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.8874 - accuracy: 0.6244 - val_loss: 0.9000 - val_accuracy: 0.6090\n",
      "Epoch 158/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8862 - accuracy: 0.6253 - val_loss: 0.8989 - val_accuracy: 0.6097\n",
      "Epoch 159/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8849 - accuracy: 0.6266 - val_loss: 0.8978 - val_accuracy: 0.6106\n",
      "Epoch 160/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8837 - accuracy: 0.6271 - val_loss: 0.8967 - val_accuracy: 0.6120\n",
      "Epoch 161/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8824 - accuracy: 0.6286 - val_loss: 0.8955 - val_accuracy: 0.6122\n",
      "Epoch 162/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8812 - accuracy: 0.6301 - val_loss: 0.8944 - val_accuracy: 0.6136\n",
      "Epoch 163/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.8800 - accuracy: 0.6320 - val_loss: 0.8933 - val_accuracy: 0.6152\n",
      "Epoch 164/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8787 - accuracy: 0.6331 - val_loss: 0.8922 - val_accuracy: 0.6159\n",
      "Epoch 165/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8775 - accuracy: 0.6342 - val_loss: 0.8911 - val_accuracy: 0.6166\n",
      "Epoch 166/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8763 - accuracy: 0.6350 - val_loss: 0.8900 - val_accuracy: 0.6177\n",
      "Epoch 167/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8751 - accuracy: 0.6361 - val_loss: 0.8890 - val_accuracy: 0.6189\n",
      "Epoch 168/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8739 - accuracy: 0.6376 - val_loss: 0.8879 - val_accuracy: 0.6205\n",
      "Epoch 169/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8727 - accuracy: 0.6395 - val_loss: 0.8868 - val_accuracy: 0.6228\n",
      "Epoch 170/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8715 - accuracy: 0.6406 - val_loss: 0.8857 - val_accuracy: 0.6242\n",
      "Epoch 171/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8703 - accuracy: 0.6417 - val_loss: 0.8847 - val_accuracy: 0.6251\n",
      "Epoch 172/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8691 - accuracy: 0.6423 - val_loss: 0.8836 - val_accuracy: 0.6267\n",
      "Epoch 173/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8679 - accuracy: 0.6439 - val_loss: 0.8826 - val_accuracy: 0.6274\n",
      "Epoch 174/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8667 - accuracy: 0.6456 - val_loss: 0.8815 - val_accuracy: 0.6276\n",
      "Epoch 175/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8655 - accuracy: 0.6464 - val_loss: 0.8805 - val_accuracy: 0.6281\n",
      "Epoch 176/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8644 - accuracy: 0.6469 - val_loss: 0.8794 - val_accuracy: 0.6279\n",
      "Epoch 177/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8632 - accuracy: 0.6490 - val_loss: 0.8784 - val_accuracy: 0.6274\n",
      "Epoch 178/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.8620 - accuracy: 0.6502 - val_loss: 0.8774 - val_accuracy: 0.6293\n",
      "Epoch 179/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.8609 - accuracy: 0.6517 - val_loss: 0.8764 - val_accuracy: 0.6297\n",
      "Epoch 180/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.8597 - accuracy: 0.6528 - val_loss: 0.8753 - val_accuracy: 0.6306\n",
      "Epoch 181/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.8586 - accuracy: 0.6539 - val_loss: 0.8743 - val_accuracy: 0.6316\n",
      "Epoch 182/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8575 - accuracy: 0.6551 - val_loss: 0.8733 - val_accuracy: 0.6334\n",
      "Epoch 183/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.8563 - accuracy: 0.6559 - val_loss: 0.8724 - val_accuracy: 0.6353\n",
      "Epoch 184/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8552 - accuracy: 0.6572 - val_loss: 0.8713 - val_accuracy: 0.6357\n",
      "Epoch 185/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8541 - accuracy: 0.6581 - val_loss: 0.8704 - val_accuracy: 0.6362\n",
      "Epoch 186/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8530 - accuracy: 0.6594 - val_loss: 0.8694 - val_accuracy: 0.6373\n",
      "Epoch 187/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8518 - accuracy: 0.6605 - val_loss: 0.8684 - val_accuracy: 0.6373\n",
      "Epoch 188/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8507 - accuracy: 0.6609 - val_loss: 0.8674 - val_accuracy: 0.6378\n",
      "Epoch 189/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8496 - accuracy: 0.6622 - val_loss: 0.8665 - val_accuracy: 0.6399\n",
      "Epoch 190/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8485 - accuracy: 0.6632 - val_loss: 0.8655 - val_accuracy: 0.6408\n",
      "Epoch 191/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8474 - accuracy: 0.6642 - val_loss: 0.8645 - val_accuracy: 0.6410\n",
      "Epoch 192/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8463 - accuracy: 0.6650 - val_loss: 0.8636 - val_accuracy: 0.6417\n",
      "Epoch 193/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8453 - accuracy: 0.6660 - val_loss: 0.8627 - val_accuracy: 0.6417\n",
      "Epoch 194/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8442 - accuracy: 0.6675 - val_loss: 0.8617 - val_accuracy: 0.6447\n",
      "Epoch 195/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8431 - accuracy: 0.6693 - val_loss: 0.8608 - val_accuracy: 0.6445\n",
      "Epoch 196/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8420 - accuracy: 0.6707 - val_loss: 0.8598 - val_accuracy: 0.6449\n",
      "Epoch 197/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8410 - accuracy: 0.6715 - val_loss: 0.8589 - val_accuracy: 0.6449\n",
      "Epoch 198/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8399 - accuracy: 0.6726 - val_loss: 0.8579 - val_accuracy: 0.6463\n",
      "Epoch 199/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8388 - accuracy: 0.6733 - val_loss: 0.8570 - val_accuracy: 0.6475\n",
      "Epoch 200/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8378 - accuracy: 0.6751 - val_loss: 0.8561 - val_accuracy: 0.6491\n",
      "Epoch 201/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8367 - accuracy: 0.6752 - val_loss: 0.8552 - val_accuracy: 0.6500\n",
      "Epoch 202/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8357 - accuracy: 0.6767 - val_loss: 0.8543 - val_accuracy: 0.6507\n",
      "Epoch 203/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.8346 - accuracy: 0.6774 - val_loss: 0.8533 - val_accuracy: 0.6509\n",
      "Epoch 204/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8336 - accuracy: 0.6775 - val_loss: 0.8524 - val_accuracy: 0.6523\n",
      "Epoch 205/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8325 - accuracy: 0.6782 - val_loss: 0.8515 - val_accuracy: 0.6528\n",
      "Epoch 206/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8315 - accuracy: 0.6804 - val_loss: 0.8506 - val_accuracy: 0.6539\n",
      "Epoch 207/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.8305 - accuracy: 0.6798 - val_loss: 0.8497 - val_accuracy: 0.6555\n",
      "Epoch 208/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8294 - accuracy: 0.6817 - val_loss: 0.8488 - val_accuracy: 0.6567\n",
      "Epoch 209/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8284 - accuracy: 0.6833 - val_loss: 0.8480 - val_accuracy: 0.6574\n",
      "Epoch 210/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8274 - accuracy: 0.6836 - val_loss: 0.8471 - val_accuracy: 0.6583\n",
      "Epoch 211/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8264 - accuracy: 0.6849 - val_loss: 0.8462 - val_accuracy: 0.6592\n",
      "Epoch 212/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8254 - accuracy: 0.6857 - val_loss: 0.8453 - val_accuracy: 0.6599\n",
      "Epoch 213/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8244 - accuracy: 0.6877 - val_loss: 0.8445 - val_accuracy: 0.6615\n",
      "Epoch 214/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8234 - accuracy: 0.6884 - val_loss: 0.8436 - val_accuracy: 0.6634\n",
      "Epoch 215/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8224 - accuracy: 0.6896 - val_loss: 0.8427 - val_accuracy: 0.6634\n",
      "Epoch 216/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8214 - accuracy: 0.6905 - val_loss: 0.8418 - val_accuracy: 0.6643\n",
      "Epoch 217/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8204 - accuracy: 0.6910 - val_loss: 0.8410 - val_accuracy: 0.6650\n",
      "Epoch 218/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.8194 - accuracy: 0.6923 - val_loss: 0.8401 - val_accuracy: 0.6650\n",
      "Epoch 219/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8184 - accuracy: 0.6930 - val_loss: 0.8393 - val_accuracy: 0.6654\n",
      "Epoch 220/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8174 - accuracy: 0.6934 - val_loss: 0.8385 - val_accuracy: 0.6664\n",
      "Epoch 221/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8164 - accuracy: 0.6948 - val_loss: 0.8376 - val_accuracy: 0.6668\n",
      "Epoch 222/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8154 - accuracy: 0.6954 - val_loss: 0.8368 - val_accuracy: 0.6673\n",
      "Epoch 223/2000\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 0.8145 - accuracy: 0.6967 - val_loss: 0.8359 - val_accuracy: 0.6680\n",
      "Epoch 224/2000\n",
      "136/136 [==============================] - 1s 4ms/step - loss: 0.8135 - accuracy: 0.6980 - val_loss: 0.8351 - val_accuracy: 0.6698\n",
      "Epoch 225/2000\n",
      "136/136 [==============================] - 1s 4ms/step - loss: 0.8125 - accuracy: 0.6988 - val_loss: 0.8342 - val_accuracy: 0.6703\n",
      "Epoch 226/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8116 - accuracy: 0.7002 - val_loss: 0.8334 - val_accuracy: 0.6703\n",
      "Epoch 227/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8106 - accuracy: 0.7007 - val_loss: 0.8326 - val_accuracy: 0.6721\n",
      "Epoch 228/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8096 - accuracy: 0.7023 - val_loss: 0.8318 - val_accuracy: 0.6730\n",
      "Epoch 229/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8087 - accuracy: 0.7038 - val_loss: 0.8309 - val_accuracy: 0.6747\n",
      "Epoch 230/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8077 - accuracy: 0.7044 - val_loss: 0.8301 - val_accuracy: 0.6760\n",
      "Epoch 231/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8068 - accuracy: 0.7059 - val_loss: 0.8293 - val_accuracy: 0.6776\n",
      "Epoch 232/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8058 - accuracy: 0.7062 - val_loss: 0.8285 - val_accuracy: 0.6783\n",
      "Epoch 233/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8049 - accuracy: 0.7067 - val_loss: 0.8277 - val_accuracy: 0.6795\n",
      "Epoch 234/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8040 - accuracy: 0.7073 - val_loss: 0.8269 - val_accuracy: 0.6800\n",
      "Epoch 235/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8030 - accuracy: 0.7079 - val_loss: 0.8261 - val_accuracy: 0.6811\n",
      "Epoch 236/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8021 - accuracy: 0.7088 - val_loss: 0.8253 - val_accuracy: 0.6820\n",
      "Epoch 237/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8012 - accuracy: 0.7092 - val_loss: 0.8245 - val_accuracy: 0.6825\n",
      "Epoch 238/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8002 - accuracy: 0.7102 - val_loss: 0.8237 - val_accuracy: 0.6829\n",
      "Epoch 239/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7993 - accuracy: 0.7107 - val_loss: 0.8229 - val_accuracy: 0.6839\n",
      "Epoch 240/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7984 - accuracy: 0.7112 - val_loss: 0.8221 - val_accuracy: 0.6859\n",
      "Epoch 241/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7975 - accuracy: 0.7119 - val_loss: 0.8213 - val_accuracy: 0.6859\n",
      "Epoch 242/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7966 - accuracy: 0.7122 - val_loss: 0.8206 - val_accuracy: 0.6864\n",
      "Epoch 243/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7956 - accuracy: 0.7129 - val_loss: 0.8198 - val_accuracy: 0.6876\n",
      "Epoch 244/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7947 - accuracy: 0.7141 - val_loss: 0.8190 - val_accuracy: 0.6878\n",
      "Epoch 245/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7938 - accuracy: 0.7148 - val_loss: 0.8182 - val_accuracy: 0.6889\n",
      "Epoch 246/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7929 - accuracy: 0.7157 - val_loss: 0.8175 - val_accuracy: 0.6896\n",
      "Epoch 247/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7920 - accuracy: 0.7164 - val_loss: 0.8167 - val_accuracy: 0.6899\n",
      "Epoch 248/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7911 - accuracy: 0.7167 - val_loss: 0.8159 - val_accuracy: 0.6903\n",
      "Epoch 249/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.7902 - accuracy: 0.7170 - val_loss: 0.8151 - val_accuracy: 0.6908\n",
      "Epoch 250/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7893 - accuracy: 0.7180 - val_loss: 0.8144 - val_accuracy: 0.6915\n",
      "Epoch 251/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7884 - accuracy: 0.7191 - val_loss: 0.8136 - val_accuracy: 0.6924\n",
      "Epoch 252/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7875 - accuracy: 0.7198 - val_loss: 0.8128 - val_accuracy: 0.6929\n",
      "Epoch 253/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7866 - accuracy: 0.7210 - val_loss: 0.8121 - val_accuracy: 0.6945\n",
      "Epoch 254/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7857 - accuracy: 0.7207 - val_loss: 0.8113 - val_accuracy: 0.6954\n",
      "Epoch 255/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.7848 - accuracy: 0.7225 - val_loss: 0.8105 - val_accuracy: 0.6959\n",
      "Epoch 256/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7840 - accuracy: 0.7233 - val_loss: 0.8098 - val_accuracy: 0.6959\n",
      "Epoch 257/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7831 - accuracy: 0.7238 - val_loss: 0.8091 - val_accuracy: 0.6970\n",
      "Epoch 258/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7822 - accuracy: 0.7250 - val_loss: 0.8083 - val_accuracy: 0.6965\n",
      "Epoch 259/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7813 - accuracy: 0.7255 - val_loss: 0.8076 - val_accuracy: 0.6975\n",
      "Epoch 260/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7804 - accuracy: 0.7266 - val_loss: 0.8068 - val_accuracy: 0.6975\n",
      "Epoch 261/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7795 - accuracy: 0.7267 - val_loss: 0.8061 - val_accuracy: 0.6982\n",
      "Epoch 262/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7787 - accuracy: 0.7277 - val_loss: 0.8053 - val_accuracy: 0.7007\n",
      "Epoch 263/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7778 - accuracy: 0.7277 - val_loss: 0.8046 - val_accuracy: 0.7007\n",
      "Epoch 264/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7769 - accuracy: 0.7290 - val_loss: 0.8038 - val_accuracy: 0.7016\n",
      "Epoch 265/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7761 - accuracy: 0.7297 - val_loss: 0.8031 - val_accuracy: 0.7016\n",
      "Epoch 266/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7752 - accuracy: 0.7301 - val_loss: 0.8023 - val_accuracy: 0.7028\n",
      "Epoch 267/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7743 - accuracy: 0.7308 - val_loss: 0.8016 - val_accuracy: 0.7035\n",
      "Epoch 268/2000\n",
      "136/136 [==============================] - 1s 4ms/step - loss: 0.7735 - accuracy: 0.7319 - val_loss: 0.8009 - val_accuracy: 0.7037\n",
      "Epoch 269/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7726 - accuracy: 0.7321 - val_loss: 0.8002 - val_accuracy: 0.7048\n",
      "Epoch 270/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7717 - accuracy: 0.7327 - val_loss: 0.7994 - val_accuracy: 0.7046\n",
      "Epoch 271/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7709 - accuracy: 0.7331 - val_loss: 0.7987 - val_accuracy: 0.7048\n",
      "Epoch 272/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7700 - accuracy: 0.7338 - val_loss: 0.7980 - val_accuracy: 0.7053\n",
      "Epoch 273/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7692 - accuracy: 0.7344 - val_loss: 0.7973 - val_accuracy: 0.7055\n",
      "Epoch 274/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7683 - accuracy: 0.7350 - val_loss: 0.7966 - val_accuracy: 0.7065\n",
      "Epoch 275/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7674 - accuracy: 0.7357 - val_loss: 0.7957 - val_accuracy: 0.7067\n",
      "Epoch 276/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7665 - accuracy: 0.7364 - val_loss: 0.7949 - val_accuracy: 0.7074\n",
      "Epoch 277/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7655 - accuracy: 0.7369 - val_loss: 0.7941 - val_accuracy: 0.7088\n",
      "Epoch 278/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7645 - accuracy: 0.7381 - val_loss: 0.7933 - val_accuracy: 0.7094\n",
      "Epoch 279/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7635 - accuracy: 0.7387 - val_loss: 0.7924 - val_accuracy: 0.7111\n",
      "Epoch 280/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7626 - accuracy: 0.7393 - val_loss: 0.7916 - val_accuracy: 0.7118\n",
      "Epoch 281/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7616 - accuracy: 0.7403 - val_loss: 0.7908 - val_accuracy: 0.7124\n",
      "Epoch 282/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7607 - accuracy: 0.7416 - val_loss: 0.7900 - val_accuracy: 0.7138\n",
      "Epoch 283/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7598 - accuracy: 0.7418 - val_loss: 0.7892 - val_accuracy: 0.7127\n",
      "Epoch 284/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7589 - accuracy: 0.7422 - val_loss: 0.7884 - val_accuracy: 0.7141\n",
      "Epoch 285/2000\n",
      "136/136 [==============================] - 1s 4ms/step - loss: 0.7580 - accuracy: 0.7432 - val_loss: 0.7876 - val_accuracy: 0.7150\n",
      "Epoch 286/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7571 - accuracy: 0.7438 - val_loss: 0.7869 - val_accuracy: 0.7166\n",
      "Epoch 287/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7562 - accuracy: 0.7443 - val_loss: 0.7861 - val_accuracy: 0.7168\n",
      "Epoch 288/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7553 - accuracy: 0.7449 - val_loss: 0.7853 - val_accuracy: 0.7171\n",
      "Epoch 289/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7544 - accuracy: 0.7456 - val_loss: 0.7846 - val_accuracy: 0.7173\n",
      "Epoch 290/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7535 - accuracy: 0.7459 - val_loss: 0.7839 - val_accuracy: 0.7166\n",
      "Epoch 291/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7527 - accuracy: 0.7464 - val_loss: 0.7832 - val_accuracy: 0.7175\n",
      "Epoch 292/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7518 - accuracy: 0.7468 - val_loss: 0.7823 - val_accuracy: 0.7180\n",
      "Epoch 293/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7509 - accuracy: 0.7479 - val_loss: 0.7816 - val_accuracy: 0.7182\n",
      "Epoch 294/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7501 - accuracy: 0.7481 - val_loss: 0.7809 - val_accuracy: 0.7191\n",
      "Epoch 295/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7492 - accuracy: 0.7491 - val_loss: 0.7801 - val_accuracy: 0.7189\n",
      "Epoch 296/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.7483 - accuracy: 0.7493 - val_loss: 0.7794 - val_accuracy: 0.7194\n",
      "Epoch 297/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7475 - accuracy: 0.7498 - val_loss: 0.7786 - val_accuracy: 0.7189\n",
      "Epoch 298/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7466 - accuracy: 0.7504 - val_loss: 0.7779 - val_accuracy: 0.7198\n",
      "Epoch 299/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7458 - accuracy: 0.7516 - val_loss: 0.7772 - val_accuracy: 0.7210\n",
      "Epoch 300/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7449 - accuracy: 0.7520 - val_loss: 0.7765 - val_accuracy: 0.7226\n",
      "Epoch 301/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7441 - accuracy: 0.7524 - val_loss: 0.7758 - val_accuracy: 0.7228\n",
      "Epoch 302/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7432 - accuracy: 0.7534 - val_loss: 0.7750 - val_accuracy: 0.7240\n",
      "Epoch 303/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7424 - accuracy: 0.7537 - val_loss: 0.7743 - val_accuracy: 0.7249\n",
      "Epoch 304/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7415 - accuracy: 0.7543 - val_loss: 0.7736 - val_accuracy: 0.7260\n",
      "Epoch 305/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7407 - accuracy: 0.7546 - val_loss: 0.7729 - val_accuracy: 0.7258\n",
      "Epoch 306/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7399 - accuracy: 0.7554 - val_loss: 0.7722 - val_accuracy: 0.7258\n",
      "Epoch 307/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7390 - accuracy: 0.7564 - val_loss: 0.7715 - val_accuracy: 0.7256\n",
      "Epoch 308/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7382 - accuracy: 0.7566 - val_loss: 0.7708 - val_accuracy: 0.7260\n",
      "Epoch 309/2000\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 0.7374 - accuracy: 0.7573 - val_loss: 0.7700 - val_accuracy: 0.7270\n",
      "Epoch 310/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.7365 - accuracy: 0.7578 - val_loss: 0.7693 - val_accuracy: 0.7276\n",
      "Epoch 311/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.7586 - val_loss: 0.7686 - val_accuracy: 0.7281\n",
      "Epoch 312/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7592 - val_loss: 0.7679 - val_accuracy: 0.7288\n",
      "Epoch 313/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7340 - accuracy: 0.7600 - val_loss: 0.7672 - val_accuracy: 0.7283\n",
      "Epoch 314/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7332 - accuracy: 0.7600 - val_loss: 0.7665 - val_accuracy: 0.7293\n",
      "Epoch 315/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7324 - accuracy: 0.7600 - val_loss: 0.7658 - val_accuracy: 0.7295\n",
      "Epoch 316/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7316 - accuracy: 0.7605 - val_loss: 0.7651 - val_accuracy: 0.7293\n",
      "Epoch 317/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7308 - accuracy: 0.7609 - val_loss: 0.7644 - val_accuracy: 0.7297\n",
      "Epoch 318/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7300 - accuracy: 0.7612 - val_loss: 0.7637 - val_accuracy: 0.7306\n",
      "Epoch 319/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7291 - accuracy: 0.7620 - val_loss: 0.7630 - val_accuracy: 0.7306\n",
      "Epoch 320/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7283 - accuracy: 0.7618 - val_loss: 0.7624 - val_accuracy: 0.7306\n",
      "Epoch 321/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7275 - accuracy: 0.7627 - val_loss: 0.7617 - val_accuracy: 0.7311\n",
      "Epoch 322/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7267 - accuracy: 0.7631 - val_loss: 0.7610 - val_accuracy: 0.7309\n",
      "Epoch 323/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7259 - accuracy: 0.7646 - val_loss: 0.7603 - val_accuracy: 0.7323\n",
      "Epoch 324/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7251 - accuracy: 0.7647 - val_loss: 0.7596 - val_accuracy: 0.7325\n",
      "Epoch 325/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7243 - accuracy: 0.7650 - val_loss: 0.7589 - val_accuracy: 0.7329\n",
      "Epoch 326/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7235 - accuracy: 0.7656 - val_loss: 0.7582 - val_accuracy: 0.7332\n",
      "Epoch 327/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7227 - accuracy: 0.7660 - val_loss: 0.7575 - val_accuracy: 0.7334\n",
      "Epoch 328/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.7219 - accuracy: 0.7661 - val_loss: 0.7568 - val_accuracy: 0.7346\n",
      "Epoch 329/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7210 - accuracy: 0.7666 - val_loss: 0.7561 - val_accuracy: 0.7348\n",
      "Epoch 330/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7202 - accuracy: 0.7672 - val_loss: 0.7555 - val_accuracy: 0.7353\n",
      "Epoch 331/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7195 - accuracy: 0.7680 - val_loss: 0.7549 - val_accuracy: 0.7359\n",
      "Epoch 332/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7186 - accuracy: 0.7685 - val_loss: 0.7541 - val_accuracy: 0.7357\n",
      "Epoch 333/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7178 - accuracy: 0.7685 - val_loss: 0.7535 - val_accuracy: 0.7366\n",
      "Epoch 334/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7170 - accuracy: 0.7694 - val_loss: 0.7528 - val_accuracy: 0.7364\n",
      "Epoch 335/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7162 - accuracy: 0.7699 - val_loss: 0.7521 - val_accuracy: 0.7366\n",
      "Epoch 336/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7154 - accuracy: 0.7706 - val_loss: 0.7514 - val_accuracy: 0.7371\n",
      "Epoch 337/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7146 - accuracy: 0.7705 - val_loss: 0.7507 - val_accuracy: 0.7376\n",
      "Epoch 338/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7139 - accuracy: 0.7709 - val_loss: 0.7500 - val_accuracy: 0.7373\n",
      "Epoch 339/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7131 - accuracy: 0.7717 - val_loss: 0.7494 - val_accuracy: 0.7373\n",
      "Epoch 340/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7123 - accuracy: 0.7721 - val_loss: 0.7487 - val_accuracy: 0.7373\n",
      "Epoch 341/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.7115 - accuracy: 0.7723 - val_loss: 0.7481 - val_accuracy: 0.7376\n",
      "Epoch 342/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7107 - accuracy: 0.7728 - val_loss: 0.7474 - val_accuracy: 0.7385\n",
      "Epoch 343/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7099 - accuracy: 0.7727 - val_loss: 0.7468 - val_accuracy: 0.7387\n",
      "Epoch 344/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7092 - accuracy: 0.7734 - val_loss: 0.7461 - val_accuracy: 0.7385\n",
      "Epoch 345/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7084 - accuracy: 0.7737 - val_loss: 0.7454 - val_accuracy: 0.7389\n",
      "Epoch 346/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7076 - accuracy: 0.7748 - val_loss: 0.7448 - val_accuracy: 0.7394\n",
      "Epoch 347/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7068 - accuracy: 0.7751 - val_loss: 0.7441 - val_accuracy: 0.7394\n",
      "Epoch 348/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7061 - accuracy: 0.7751 - val_loss: 0.7435 - val_accuracy: 0.7396\n",
      "Epoch 349/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.7053 - accuracy: 0.7756 - val_loss: 0.7428 - val_accuracy: 0.7399\n",
      "Epoch 350/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7045 - accuracy: 0.7762 - val_loss: 0.7421 - val_accuracy: 0.7403\n",
      "Epoch 351/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7037 - accuracy: 0.7763 - val_loss: 0.7415 - val_accuracy: 0.7410\n",
      "Epoch 352/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7030 - accuracy: 0.7768 - val_loss: 0.7409 - val_accuracy: 0.7408\n",
      "Epoch 353/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7022 - accuracy: 0.7770 - val_loss: 0.7402 - val_accuracy: 0.7408\n",
      "Epoch 354/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7014 - accuracy: 0.7773 - val_loss: 0.7395 - val_accuracy: 0.7412\n",
      "Epoch 355/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7007 - accuracy: 0.7781 - val_loss: 0.7389 - val_accuracy: 0.7415\n",
      "Epoch 356/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.6999 - accuracy: 0.7783 - val_loss: 0.7383 - val_accuracy: 0.7419\n",
      "Epoch 357/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6992 - accuracy: 0.7785 - val_loss: 0.7377 - val_accuracy: 0.7429\n",
      "Epoch 358/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.6984 - accuracy: 0.7790 - val_loss: 0.7370 - val_accuracy: 0.7429\n",
      "Epoch 359/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.6976 - accuracy: 0.7787 - val_loss: 0.7364 - val_accuracy: 0.7429\n",
      "Epoch 360/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6969 - accuracy: 0.7791 - val_loss: 0.7358 - val_accuracy: 0.7438\n",
      "Epoch 361/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6961 - accuracy: 0.7797 - val_loss: 0.7351 - val_accuracy: 0.7442\n",
      "Epoch 362/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6954 - accuracy: 0.7802 - val_loss: 0.7345 - val_accuracy: 0.7449\n",
      "Epoch 363/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6947 - accuracy: 0.7804 - val_loss: 0.7338 - val_accuracy: 0.7447\n",
      "Epoch 364/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.7802 - val_loss: 0.7332 - val_accuracy: 0.7449\n",
      "Epoch 365/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.7806 - val_loss: 0.7326 - val_accuracy: 0.7454\n",
      "Epoch 366/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.6924 - accuracy: 0.7811 - val_loss: 0.7320 - val_accuracy: 0.7456\n",
      "Epoch 367/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.6917 - accuracy: 0.7817 - val_loss: 0.7313 - val_accuracy: 0.7463\n",
      "Epoch 368/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6909 - accuracy: 0.7821 - val_loss: 0.7307 - val_accuracy: 0.7468\n",
      "Epoch 369/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6902 - accuracy: 0.7821 - val_loss: 0.7301 - val_accuracy: 0.7470\n",
      "Epoch 370/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6894 - accuracy: 0.7824 - val_loss: 0.7295 - val_accuracy: 0.7472\n",
      "Epoch 371/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6887 - accuracy: 0.7830 - val_loss: 0.7289 - val_accuracy: 0.7472\n",
      "Epoch 372/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6880 - accuracy: 0.7826 - val_loss: 0.7283 - val_accuracy: 0.7477\n",
      "Epoch 373/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6872 - accuracy: 0.7825 - val_loss: 0.7276 - val_accuracy: 0.7479\n",
      "Epoch 374/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6865 - accuracy: 0.7831 - val_loss: 0.7270 - val_accuracy: 0.7482\n",
      "Epoch 375/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.6857 - accuracy: 0.7838 - val_loss: 0.7263 - val_accuracy: 0.7488\n",
      "Epoch 376/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6850 - accuracy: 0.7839 - val_loss: 0.7258 - val_accuracy: 0.7493\n",
      "Epoch 377/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6843 - accuracy: 0.7841 - val_loss: 0.7251 - val_accuracy: 0.7498\n",
      "Epoch 378/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6835 - accuracy: 0.7849 - val_loss: 0.7245 - val_accuracy: 0.7500\n",
      "Epoch 379/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6828 - accuracy: 0.7849 - val_loss: 0.7239 - val_accuracy: 0.7500\n",
      "Epoch 380/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6821 - accuracy: 0.7857 - val_loss: 0.7233 - val_accuracy: 0.7507\n",
      "Epoch 381/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6813 - accuracy: 0.7859 - val_loss: 0.7227 - val_accuracy: 0.7502\n",
      "Epoch 382/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6806 - accuracy: 0.7867 - val_loss: 0.7221 - val_accuracy: 0.7507\n",
      "Epoch 383/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.6799 - accuracy: 0.7866 - val_loss: 0.7215 - val_accuracy: 0.7502\n",
      "Epoch 384/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6792 - accuracy: 0.7872 - val_loss: 0.7209 - val_accuracy: 0.7505\n",
      "Epoch 385/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6784 - accuracy: 0.7878 - val_loss: 0.7203 - val_accuracy: 0.7507\n",
      "Epoch 386/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6777 - accuracy: 0.7880 - val_loss: 0.7197 - val_accuracy: 0.7521\n",
      "Epoch 387/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6770 - accuracy: 0.7877 - val_loss: 0.7191 - val_accuracy: 0.7521\n",
      "Epoch 388/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6763 - accuracy: 0.7878 - val_loss: 0.7184 - val_accuracy: 0.7523\n",
      "Epoch 389/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6756 - accuracy: 0.7879 - val_loss: 0.7178 - val_accuracy: 0.7523\n",
      "Epoch 390/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6749 - accuracy: 0.7889 - val_loss: 0.7172 - val_accuracy: 0.7523\n",
      "Epoch 391/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6741 - accuracy: 0.7889 - val_loss: 0.7167 - val_accuracy: 0.7523\n",
      "Epoch 392/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6734 - accuracy: 0.7888 - val_loss: 0.7161 - val_accuracy: 0.7528\n",
      "Epoch 393/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6727 - accuracy: 0.7896 - val_loss: 0.7155 - val_accuracy: 0.7535\n",
      "Epoch 394/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6720 - accuracy: 0.7899 - val_loss: 0.7149 - val_accuracy: 0.7539\n",
      "Epoch 395/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6713 - accuracy: 0.7901 - val_loss: 0.7143 - val_accuracy: 0.7546\n",
      "Epoch 396/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6706 - accuracy: 0.7903 - val_loss: 0.7137 - val_accuracy: 0.7544\n",
      "Epoch 397/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6699 - accuracy: 0.7907 - val_loss: 0.7132 - val_accuracy: 0.7546\n",
      "Epoch 398/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6692 - accuracy: 0.7910 - val_loss: 0.7126 - val_accuracy: 0.7551\n",
      "Epoch 399/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.6685 - accuracy: 0.7912 - val_loss: 0.7120 - val_accuracy: 0.7553\n",
      "Epoch 400/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6678 - accuracy: 0.7911 - val_loss: 0.7114 - val_accuracy: 0.7551\n",
      "Epoch 401/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6671 - accuracy: 0.7914 - val_loss: 0.7108 - val_accuracy: 0.7551\n",
      "Epoch 402/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6664 - accuracy: 0.7917 - val_loss: 0.7102 - val_accuracy: 0.7560\n",
      "Epoch 403/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.6657 - accuracy: 0.7917 - val_loss: 0.7096 - val_accuracy: 0.7553\n",
      "Epoch 404/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.6650 - accuracy: 0.7918 - val_loss: 0.7091 - val_accuracy: 0.7567\n",
      "Epoch 405/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.6643 - accuracy: 0.7923 - val_loss: 0.7085 - val_accuracy: 0.7560\n",
      "Epoch 406/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6636 - accuracy: 0.7922 - val_loss: 0.7079 - val_accuracy: 0.7553\n",
      "Epoch 407/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.6629 - accuracy: 0.7922 - val_loss: 0.7074 - val_accuracy: 0.7558\n",
      "Epoch 408/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6622 - accuracy: 0.7926 - val_loss: 0.7068 - val_accuracy: 0.7567\n",
      "Epoch 409/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6615 - accuracy: 0.7927 - val_loss: 0.7062 - val_accuracy: 0.7574\n",
      "Epoch 410/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6608 - accuracy: 0.7936 - val_loss: 0.7057 - val_accuracy: 0.7569\n",
      "Epoch 411/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6601 - accuracy: 0.7931 - val_loss: 0.7051 - val_accuracy: 0.7574\n",
      "Epoch 412/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.6595 - accuracy: 0.7934 - val_loss: 0.7046 - val_accuracy: 0.7569\n",
      "Epoch 413/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6588 - accuracy: 0.7931 - val_loss: 0.7040 - val_accuracy: 0.7569\n",
      "Epoch 414/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6581 - accuracy: 0.7935 - val_loss: 0.7034 - val_accuracy: 0.7574\n",
      "Epoch 415/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6574 - accuracy: 0.7941 - val_loss: 0.7028 - val_accuracy: 0.7571\n",
      "Epoch 416/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6567 - accuracy: 0.7947 - val_loss: 0.7023 - val_accuracy: 0.7569\n",
      "Epoch 417/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.6560 - accuracy: 0.7937 - val_loss: 0.7018 - val_accuracy: 0.7581\n",
      "Epoch 418/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6554 - accuracy: 0.7944 - val_loss: 0.7012 - val_accuracy: 0.7585\n",
      "Epoch 419/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6547 - accuracy: 0.7953 - val_loss: 0.7006 - val_accuracy: 0.7588\n",
      "Epoch 420/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.6540 - accuracy: 0.7952 - val_loss: 0.7001 - val_accuracy: 0.7581\n",
      "Epoch 421/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.6534 - accuracy: 0.7950 - val_loss: 0.6995 - val_accuracy: 0.7583\n",
      "Epoch 422/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6527 - accuracy: 0.7957 - val_loss: 0.6990 - val_accuracy: 0.7597\n",
      "Epoch 423/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6520 - accuracy: 0.7959 - val_loss: 0.6984 - val_accuracy: 0.7594\n",
      "Epoch 424/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6514 - accuracy: 0.7959 - val_loss: 0.6979 - val_accuracy: 0.7597\n",
      "Epoch 425/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6507 - accuracy: 0.7969 - val_loss: 0.6973 - val_accuracy: 0.7599\n",
      "Epoch 426/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6500 - accuracy: 0.7965 - val_loss: 0.6968 - val_accuracy: 0.7597\n",
      "Epoch 427/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6494 - accuracy: 0.7967 - val_loss: 0.6962 - val_accuracy: 0.7594\n",
      "Epoch 428/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6487 - accuracy: 0.7964 - val_loss: 0.6957 - val_accuracy: 0.7597\n",
      "Epoch 429/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6481 - accuracy: 0.7976 - val_loss: 0.6952 - val_accuracy: 0.7599\n",
      "Epoch 430/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6474 - accuracy: 0.7971 - val_loss: 0.6946 - val_accuracy: 0.7594\n",
      "Epoch 431/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6468 - accuracy: 0.7979 - val_loss: 0.6941 - val_accuracy: 0.7601\n",
      "Epoch 432/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6461 - accuracy: 0.7977 - val_loss: 0.6936 - val_accuracy: 0.7611\n",
      "Epoch 433/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6455 - accuracy: 0.7987 - val_loss: 0.6931 - val_accuracy: 0.7608\n",
      "Epoch 434/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6448 - accuracy: 0.7991 - val_loss: 0.6926 - val_accuracy: 0.7611\n",
      "Epoch 435/2000\n",
      "136/136 [==============================] - 1s 4ms/step - loss: 0.6442 - accuracy: 0.7989 - val_loss: 0.6920 - val_accuracy: 0.7608\n",
      "Epoch 436/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6435 - accuracy: 0.7994 - val_loss: 0.6915 - val_accuracy: 0.7615\n",
      "Epoch 437/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6429 - accuracy: 0.7996 - val_loss: 0.6910 - val_accuracy: 0.7615\n",
      "Epoch 438/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6422 - accuracy: 0.7996 - val_loss: 0.6905 - val_accuracy: 0.7618\n",
      "Epoch 439/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6416 - accuracy: 0.7993 - val_loss: 0.6900 - val_accuracy: 0.7611\n",
      "Epoch 440/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6410 - accuracy: 0.7998 - val_loss: 0.6894 - val_accuracy: 0.7618\n",
      "Epoch 441/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6403 - accuracy: 0.8000 - val_loss: 0.6889 - val_accuracy: 0.7615\n",
      "Epoch 442/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6397 - accuracy: 0.8002 - val_loss: 0.6884 - val_accuracy: 0.7611\n",
      "Epoch 443/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6390 - accuracy: 0.8000 - val_loss: 0.6879 - val_accuracy: 0.7613\n",
      "Epoch 444/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6384 - accuracy: 0.8000 - val_loss: 0.6874 - val_accuracy: 0.7618\n",
      "Epoch 445/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6378 - accuracy: 0.8009 - val_loss: 0.6869 - val_accuracy: 0.7622\n",
      "Epoch 446/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6372 - accuracy: 0.8009 - val_loss: 0.6863 - val_accuracy: 0.7634\n",
      "Epoch 447/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6365 - accuracy: 0.8013 - val_loss: 0.6858 - val_accuracy: 0.7634\n",
      "Epoch 448/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6359 - accuracy: 0.8012 - val_loss: 0.6853 - val_accuracy: 0.7631\n",
      "Epoch 449/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6353 - accuracy: 0.8022 - val_loss: 0.6848 - val_accuracy: 0.7636\n",
      "Epoch 450/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6346 - accuracy: 0.8025 - val_loss: 0.6843 - val_accuracy: 0.7629\n",
      "Epoch 451/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6340 - accuracy: 0.8026 - val_loss: 0.6839 - val_accuracy: 0.7624\n",
      "Epoch 452/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6334 - accuracy: 0.8028 - val_loss: 0.6833 - val_accuracy: 0.7629\n",
      "Epoch 453/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.8027 - val_loss: 0.6829 - val_accuracy: 0.7631\n",
      "Epoch 454/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.8030 - val_loss: 0.6823 - val_accuracy: 0.7631\n",
      "Epoch 455/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6316 - accuracy: 0.8030 - val_loss: 0.6818 - val_accuracy: 0.7634\n",
      "Epoch 456/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6310 - accuracy: 0.8030 - val_loss: 0.6813 - val_accuracy: 0.7627\n",
      "Epoch 457/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6303 - accuracy: 0.8029 - val_loss: 0.6809 - val_accuracy: 0.7629\n",
      "Epoch 458/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6297 - accuracy: 0.8035 - val_loss: 0.6804 - val_accuracy: 0.7638\n",
      "Epoch 459/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6291 - accuracy: 0.8035 - val_loss: 0.6799 - val_accuracy: 0.7641\n",
      "Epoch 460/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6285 - accuracy: 0.8039 - val_loss: 0.6795 - val_accuracy: 0.7631\n",
      "Epoch 461/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6279 - accuracy: 0.8039 - val_loss: 0.6789 - val_accuracy: 0.7641\n",
      "Epoch 462/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6273 - accuracy: 0.8043 - val_loss: 0.6785 - val_accuracy: 0.7636\n",
      "Epoch 463/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6267 - accuracy: 0.8043 - val_loss: 0.6780 - val_accuracy: 0.7641\n",
      "Epoch 464/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6261 - accuracy: 0.8043 - val_loss: 0.6775 - val_accuracy: 0.7641\n",
      "Epoch 465/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6255 - accuracy: 0.8043 - val_loss: 0.6770 - val_accuracy: 0.7645\n",
      "Epoch 466/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6249 - accuracy: 0.8042 - val_loss: 0.6766 - val_accuracy: 0.7650\n",
      "Epoch 467/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6243 - accuracy: 0.8044 - val_loss: 0.6761 - val_accuracy: 0.7647\n",
      "Epoch 468/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6237 - accuracy: 0.8044 - val_loss: 0.6756 - val_accuracy: 0.7652\n",
      "Epoch 469/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6232 - accuracy: 0.8046 - val_loss: 0.6752 - val_accuracy: 0.7652\n",
      "Epoch 470/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.6226 - accuracy: 0.8046 - val_loss: 0.6747 - val_accuracy: 0.7641\n",
      "Epoch 471/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.6220 - accuracy: 0.8048 - val_loss: 0.6743 - val_accuracy: 0.7659\n",
      "Epoch 472/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6214 - accuracy: 0.8047 - val_loss: 0.6738 - val_accuracy: 0.7654\n",
      "Epoch 473/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6208 - accuracy: 0.8048 - val_loss: 0.6734 - val_accuracy: 0.7659\n",
      "Epoch 474/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6202 - accuracy: 0.8052 - val_loss: 0.6729 - val_accuracy: 0.7647\n",
      "Epoch 475/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6197 - accuracy: 0.8055 - val_loss: 0.6725 - val_accuracy: 0.7643\n",
      "Epoch 476/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6191 - accuracy: 0.8051 - val_loss: 0.6720 - val_accuracy: 0.7645\n",
      "Epoch 477/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6185 - accuracy: 0.8054 - val_loss: 0.6715 - val_accuracy: 0.7654\n",
      "Epoch 478/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6179 - accuracy: 0.8059 - val_loss: 0.6711 - val_accuracy: 0.7652\n",
      "Epoch 479/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6174 - accuracy: 0.8064 - val_loss: 0.6707 - val_accuracy: 0.7647\n",
      "Epoch 480/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6168 - accuracy: 0.8061 - val_loss: 0.6702 - val_accuracy: 0.7664\n",
      "Epoch 481/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6162 - accuracy: 0.8067 - val_loss: 0.6697 - val_accuracy: 0.7666\n",
      "Epoch 482/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6157 - accuracy: 0.8067 - val_loss: 0.6693 - val_accuracy: 0.7654\n",
      "Epoch 483/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6151 - accuracy: 0.8069 - val_loss: 0.6688 - val_accuracy: 0.7661\n",
      "Epoch 484/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6146 - accuracy: 0.8071 - val_loss: 0.6685 - val_accuracy: 0.7666\n",
      "Epoch 485/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.6140 - accuracy: 0.8073 - val_loss: 0.6680 - val_accuracy: 0.7664\n",
      "Epoch 486/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6134 - accuracy: 0.8071 - val_loss: 0.6675 - val_accuracy: 0.7661\n",
      "Epoch 487/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6129 - accuracy: 0.8071 - val_loss: 0.6671 - val_accuracy: 0.7657\n",
      "Epoch 488/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6123 - accuracy: 0.8073 - val_loss: 0.6667 - val_accuracy: 0.7666\n",
      "Epoch 489/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6118 - accuracy: 0.8073 - val_loss: 0.6662 - val_accuracy: 0.7664\n",
      "Epoch 490/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6112 - accuracy: 0.8082 - val_loss: 0.6658 - val_accuracy: 0.7666\n",
      "Epoch 491/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6107 - accuracy: 0.8079 - val_loss: 0.6654 - val_accuracy: 0.7666\n",
      "Epoch 492/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6101 - accuracy: 0.8078 - val_loss: 0.6650 - val_accuracy: 0.7673\n",
      "Epoch 493/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6096 - accuracy: 0.8082 - val_loss: 0.6645 - val_accuracy: 0.7673\n",
      "Epoch 494/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6091 - accuracy: 0.8083 - val_loss: 0.6641 - val_accuracy: 0.7668\n",
      "Epoch 495/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6085 - accuracy: 0.8089 - val_loss: 0.6637 - val_accuracy: 0.7673\n",
      "Epoch 496/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6080 - accuracy: 0.8089 - val_loss: 0.6633 - val_accuracy: 0.7680\n",
      "Epoch 497/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6074 - accuracy: 0.8088 - val_loss: 0.6629 - val_accuracy: 0.7675\n",
      "Epoch 498/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6069 - accuracy: 0.8088 - val_loss: 0.6625 - val_accuracy: 0.7682\n",
      "Epoch 499/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.6064 - accuracy: 0.8089 - val_loss: 0.6620 - val_accuracy: 0.7682\n",
      "Epoch 500/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6058 - accuracy: 0.8092 - val_loss: 0.6616 - val_accuracy: 0.7682\n",
      "Epoch 501/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6053 - accuracy: 0.8089 - val_loss: 0.6612 - val_accuracy: 0.7677\n",
      "Epoch 502/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6048 - accuracy: 0.8094 - val_loss: 0.6608 - val_accuracy: 0.7682\n",
      "Epoch 503/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6042 - accuracy: 0.8092 - val_loss: 0.6604 - val_accuracy: 0.7682\n",
      "Epoch 504/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.6037 - accuracy: 0.8094 - val_loss: 0.6600 - val_accuracy: 0.7684\n",
      "Epoch 505/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6032 - accuracy: 0.8095 - val_loss: 0.6596 - val_accuracy: 0.7691\n",
      "Epoch 506/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6026 - accuracy: 0.8094 - val_loss: 0.6592 - val_accuracy: 0.7682\n",
      "Epoch 507/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6021 - accuracy: 0.8096 - val_loss: 0.6588 - val_accuracy: 0.7687\n",
      "Epoch 508/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6016 - accuracy: 0.8099 - val_loss: 0.6583 - val_accuracy: 0.7691\n",
      "Epoch 509/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6011 - accuracy: 0.8096 - val_loss: 0.6580 - val_accuracy: 0.7691\n",
      "Epoch 510/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.6006 - accuracy: 0.8100 - val_loss: 0.6576 - val_accuracy: 0.7680\n",
      "Epoch 511/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.6001 - accuracy: 0.8101 - val_loss: 0.6572 - val_accuracy: 0.7675\n",
      "Epoch 512/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.5995 - accuracy: 0.8103 - val_loss: 0.6568 - val_accuracy: 0.7680\n",
      "Epoch 513/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5990 - accuracy: 0.8101 - val_loss: 0.6565 - val_accuracy: 0.7682\n",
      "Epoch 514/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5985 - accuracy: 0.8101 - val_loss: 0.6560 - val_accuracy: 0.7687\n",
      "Epoch 515/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5980 - accuracy: 0.8103 - val_loss: 0.6556 - val_accuracy: 0.7689\n",
      "Epoch 516/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5975 - accuracy: 0.8103 - val_loss: 0.6553 - val_accuracy: 0.7689\n",
      "Epoch 517/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5970 - accuracy: 0.8104 - val_loss: 0.6549 - val_accuracy: 0.7687\n",
      "Epoch 518/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5965 - accuracy: 0.8107 - val_loss: 0.6545 - val_accuracy: 0.7698\n",
      "Epoch 519/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5960 - accuracy: 0.8104 - val_loss: 0.6541 - val_accuracy: 0.7696\n",
      "Epoch 520/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5955 - accuracy: 0.8105 - val_loss: 0.6538 - val_accuracy: 0.7703\n",
      "Epoch 521/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5950 - accuracy: 0.8112 - val_loss: 0.6535 - val_accuracy: 0.7694\n",
      "Epoch 522/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5945 - accuracy: 0.8112 - val_loss: 0.6531 - val_accuracy: 0.7698\n",
      "Epoch 523/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5940 - accuracy: 0.8109 - val_loss: 0.6527 - val_accuracy: 0.7698\n",
      "Epoch 524/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5935 - accuracy: 0.8112 - val_loss: 0.6523 - val_accuracy: 0.7700\n",
      "Epoch 525/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5931 - accuracy: 0.8113 - val_loss: 0.6519 - val_accuracy: 0.7703\n",
      "Epoch 526/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5926 - accuracy: 0.8113 - val_loss: 0.6516 - val_accuracy: 0.7703\n",
      "Epoch 527/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5921 - accuracy: 0.8112 - val_loss: 0.6512 - val_accuracy: 0.7707\n",
      "Epoch 528/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5916 - accuracy: 0.8111 - val_loss: 0.6508 - val_accuracy: 0.7703\n",
      "Epoch 529/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5911 - accuracy: 0.8116 - val_loss: 0.6505 - val_accuracy: 0.7700\n",
      "Epoch 530/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5906 - accuracy: 0.8113 - val_loss: 0.6501 - val_accuracy: 0.7707\n",
      "Epoch 531/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5902 - accuracy: 0.8115 - val_loss: 0.6498 - val_accuracy: 0.7705\n",
      "Epoch 532/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5897 - accuracy: 0.8113 - val_loss: 0.6494 - val_accuracy: 0.7705\n",
      "Epoch 533/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5892 - accuracy: 0.8117 - val_loss: 0.6490 - val_accuracy: 0.7700\n",
      "Epoch 534/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5888 - accuracy: 0.8118 - val_loss: 0.6487 - val_accuracy: 0.7705\n",
      "Epoch 535/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5883 - accuracy: 0.8118 - val_loss: 0.6483 - val_accuracy: 0.7705\n",
      "Epoch 536/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5878 - accuracy: 0.8116 - val_loss: 0.6480 - val_accuracy: 0.7705\n",
      "Epoch 537/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5874 - accuracy: 0.8119 - val_loss: 0.6476 - val_accuracy: 0.7705\n",
      "Epoch 538/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5869 - accuracy: 0.8120 - val_loss: 0.6473 - val_accuracy: 0.7705\n",
      "Epoch 539/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.5864 - accuracy: 0.8118 - val_loss: 0.6470 - val_accuracy: 0.7703\n",
      "Epoch 540/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5860 - accuracy: 0.8120 - val_loss: 0.6466 - val_accuracy: 0.7703\n",
      "Epoch 541/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5855 - accuracy: 0.8119 - val_loss: 0.6463 - val_accuracy: 0.7698\n",
      "Epoch 542/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5851 - accuracy: 0.8118 - val_loss: 0.6460 - val_accuracy: 0.7707\n",
      "Epoch 543/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5846 - accuracy: 0.8124 - val_loss: 0.6456 - val_accuracy: 0.7703\n",
      "Epoch 544/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.5841 - accuracy: 0.8124 - val_loss: 0.6452 - val_accuracy: 0.7703\n",
      "Epoch 545/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5837 - accuracy: 0.8124 - val_loss: 0.6450 - val_accuracy: 0.7700\n",
      "Epoch 546/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5832 - accuracy: 0.8127 - val_loss: 0.6446 - val_accuracy: 0.7703\n",
      "Epoch 547/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5828 - accuracy: 0.8126 - val_loss: 0.6443 - val_accuracy: 0.7703\n",
      "Epoch 548/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5824 - accuracy: 0.8128 - val_loss: 0.6439 - val_accuracy: 0.7707\n",
      "Epoch 549/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5819 - accuracy: 0.8128 - val_loss: 0.6436 - val_accuracy: 0.7707\n",
      "Epoch 550/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5815 - accuracy: 0.8131 - val_loss: 0.6433 - val_accuracy: 0.7710\n",
      "Epoch 551/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5810 - accuracy: 0.8130 - val_loss: 0.6430 - val_accuracy: 0.7710\n",
      "Epoch 552/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.5806 - accuracy: 0.8127 - val_loss: 0.6427 - val_accuracy: 0.7712\n",
      "Epoch 553/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5802 - accuracy: 0.8130 - val_loss: 0.6424 - val_accuracy: 0.7712\n",
      "Epoch 554/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5797 - accuracy: 0.8128 - val_loss: 0.6421 - val_accuracy: 0.7712\n",
      "Epoch 555/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5793 - accuracy: 0.8133 - val_loss: 0.6417 - val_accuracy: 0.7710\n",
      "Epoch 556/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5789 - accuracy: 0.8131 - val_loss: 0.6414 - val_accuracy: 0.7710\n",
      "Epoch 557/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5784 - accuracy: 0.8131 - val_loss: 0.6411 - val_accuracy: 0.7707\n",
      "Epoch 558/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5780 - accuracy: 0.8136 - val_loss: 0.6408 - val_accuracy: 0.7710\n",
      "Epoch 559/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5776 - accuracy: 0.8134 - val_loss: 0.6405 - val_accuracy: 0.7707\n",
      "Epoch 560/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5772 - accuracy: 0.8134 - val_loss: 0.6402 - val_accuracy: 0.7707\n",
      "Epoch 561/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5767 - accuracy: 0.8131 - val_loss: 0.6398 - val_accuracy: 0.7707\n",
      "Epoch 562/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5763 - accuracy: 0.8138 - val_loss: 0.6396 - val_accuracy: 0.7712\n",
      "Epoch 563/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.5759 - accuracy: 0.8135 - val_loss: 0.6392 - val_accuracy: 0.7710\n",
      "Epoch 564/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5755 - accuracy: 0.8138 - val_loss: 0.6389 - val_accuracy: 0.7705\n",
      "Epoch 565/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5751 - accuracy: 0.8141 - val_loss: 0.6386 - val_accuracy: 0.7707\n",
      "Epoch 566/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5747 - accuracy: 0.8141 - val_loss: 0.6383 - val_accuracy: 0.7707\n",
      "Epoch 567/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5743 - accuracy: 0.8139 - val_loss: 0.6380 - val_accuracy: 0.7705\n",
      "Epoch 568/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5738 - accuracy: 0.8142 - val_loss: 0.6378 - val_accuracy: 0.7707\n",
      "Epoch 569/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5735 - accuracy: 0.8142 - val_loss: 0.6374 - val_accuracy: 0.7710\n",
      "Epoch 570/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5730 - accuracy: 0.8140 - val_loss: 0.6371 - val_accuracy: 0.7717\n",
      "Epoch 571/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5726 - accuracy: 0.8140 - val_loss: 0.6369 - val_accuracy: 0.7712\n",
      "Epoch 572/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5722 - accuracy: 0.8143 - val_loss: 0.6366 - val_accuracy: 0.7714\n",
      "Epoch 573/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5718 - accuracy: 0.8140 - val_loss: 0.6363 - val_accuracy: 0.7719\n",
      "Epoch 574/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5714 - accuracy: 0.8143 - val_loss: 0.6360 - val_accuracy: 0.7712\n",
      "Epoch 575/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5710 - accuracy: 0.8143 - val_loss: 0.6357 - val_accuracy: 0.7721\n",
      "Epoch 576/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5706 - accuracy: 0.8141 - val_loss: 0.6355 - val_accuracy: 0.7724\n",
      "Epoch 577/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5702 - accuracy: 0.8143 - val_loss: 0.6352 - val_accuracy: 0.7719\n",
      "Epoch 578/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.5699 - accuracy: 0.8147 - val_loss: 0.6349 - val_accuracy: 0.7719\n",
      "Epoch 579/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5695 - accuracy: 0.8149 - val_loss: 0.6346 - val_accuracy: 0.7721\n",
      "Epoch 580/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5691 - accuracy: 0.8150 - val_loss: 0.6344 - val_accuracy: 0.7726\n",
      "Epoch 581/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5687 - accuracy: 0.8151 - val_loss: 0.6341 - val_accuracy: 0.7717\n",
      "Epoch 582/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5683 - accuracy: 0.8147 - val_loss: 0.6339 - val_accuracy: 0.7724\n",
      "Epoch 583/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5679 - accuracy: 0.8147 - val_loss: 0.6336 - val_accuracy: 0.7724\n",
      "Epoch 584/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5675 - accuracy: 0.8150 - val_loss: 0.6333 - val_accuracy: 0.7724\n",
      "Epoch 585/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.5672 - accuracy: 0.8149 - val_loss: 0.6331 - val_accuracy: 0.7721\n",
      "Epoch 586/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5668 - accuracy: 0.8156 - val_loss: 0.6328 - val_accuracy: 0.7721\n",
      "Epoch 587/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5664 - accuracy: 0.8152 - val_loss: 0.6325 - val_accuracy: 0.7721\n",
      "Epoch 588/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5660 - accuracy: 0.8152 - val_loss: 0.6323 - val_accuracy: 0.7719\n",
      "Epoch 589/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5657 - accuracy: 0.8156 - val_loss: 0.6320 - val_accuracy: 0.7724\n",
      "Epoch 590/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5653 - accuracy: 0.8153 - val_loss: 0.6317 - val_accuracy: 0.7721\n",
      "Epoch 591/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5649 - accuracy: 0.8153 - val_loss: 0.6316 - val_accuracy: 0.7712\n",
      "Epoch 592/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5646 - accuracy: 0.8158 - val_loss: 0.6313 - val_accuracy: 0.7712\n",
      "Epoch 593/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5642 - accuracy: 0.8158 - val_loss: 0.6310 - val_accuracy: 0.7717\n",
      "Epoch 594/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5639 - accuracy: 0.8162 - val_loss: 0.6308 - val_accuracy: 0.7714\n",
      "Epoch 595/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5635 - accuracy: 0.8156 - val_loss: 0.6305 - val_accuracy: 0.7712\n",
      "Epoch 596/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5631 - accuracy: 0.8160 - val_loss: 0.6302 - val_accuracy: 0.7724\n",
      "Epoch 597/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5628 - accuracy: 0.8158 - val_loss: 0.6300 - val_accuracy: 0.7721\n",
      "Epoch 598/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5624 - accuracy: 0.8162 - val_loss: 0.6298 - val_accuracy: 0.7721\n",
      "Epoch 599/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5621 - accuracy: 0.8162 - val_loss: 0.6295 - val_accuracy: 0.7724\n",
      "Epoch 600/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5617 - accuracy: 0.8158 - val_loss: 0.6293 - val_accuracy: 0.7726\n",
      "Epoch 601/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5614 - accuracy: 0.8162 - val_loss: 0.6291 - val_accuracy: 0.7717\n",
      "Epoch 602/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5610 - accuracy: 0.8163 - val_loss: 0.6288 - val_accuracy: 0.7728\n",
      "Epoch 603/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5607 - accuracy: 0.8161 - val_loss: 0.6286 - val_accuracy: 0.7728\n",
      "Epoch 604/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5603 - accuracy: 0.8165 - val_loss: 0.6284 - val_accuracy: 0.7724\n",
      "Epoch 605/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5600 - accuracy: 0.8163 - val_loss: 0.6281 - val_accuracy: 0.7726\n",
      "Epoch 606/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5597 - accuracy: 0.8168 - val_loss: 0.6279 - val_accuracy: 0.7730\n",
      "Epoch 607/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5593 - accuracy: 0.8168 - val_loss: 0.6277 - val_accuracy: 0.7721\n",
      "Epoch 608/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5590 - accuracy: 0.8164 - val_loss: 0.6274 - val_accuracy: 0.7726\n",
      "Epoch 609/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5586 - accuracy: 0.8165 - val_loss: 0.6272 - val_accuracy: 0.7730\n",
      "Epoch 610/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.5583 - accuracy: 0.8161 - val_loss: 0.6270 - val_accuracy: 0.7726\n",
      "Epoch 611/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5580 - accuracy: 0.8162 - val_loss: 0.6268 - val_accuracy: 0.7728\n",
      "Epoch 612/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5576 - accuracy: 0.8166 - val_loss: 0.6266 - val_accuracy: 0.7721\n",
      "Epoch 613/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5573 - accuracy: 0.8165 - val_loss: 0.6263 - val_accuracy: 0.7714\n",
      "Epoch 614/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5570 - accuracy: 0.8164 - val_loss: 0.6262 - val_accuracy: 0.7719\n",
      "Epoch 615/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5567 - accuracy: 0.8169 - val_loss: 0.6260 - val_accuracy: 0.7717\n",
      "Epoch 616/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5563 - accuracy: 0.8169 - val_loss: 0.6257 - val_accuracy: 0.7717\n",
      "Epoch 617/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5560 - accuracy: 0.8165 - val_loss: 0.6255 - val_accuracy: 0.7719\n",
      "Epoch 618/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5557 - accuracy: 0.8168 - val_loss: 0.6253 - val_accuracy: 0.7717\n",
      "Epoch 619/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5553 - accuracy: 0.8170 - val_loss: 0.6251 - val_accuracy: 0.7719\n",
      "Epoch 620/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5550 - accuracy: 0.8172 - val_loss: 0.6249 - val_accuracy: 0.7714\n",
      "Epoch 621/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5547 - accuracy: 0.8174 - val_loss: 0.6246 - val_accuracy: 0.7712\n",
      "Epoch 622/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5544 - accuracy: 0.8169 - val_loss: 0.6244 - val_accuracy: 0.7717\n",
      "Epoch 623/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5541 - accuracy: 0.8171 - val_loss: 0.6243 - val_accuracy: 0.7717\n",
      "Epoch 624/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5538 - accuracy: 0.8173 - val_loss: 0.6241 - val_accuracy: 0.7714\n",
      "Epoch 625/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5534 - accuracy: 0.8173 - val_loss: 0.6238 - val_accuracy: 0.7714\n",
      "Epoch 626/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5531 - accuracy: 0.8171 - val_loss: 0.6237 - val_accuracy: 0.7710\n",
      "Epoch 627/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5528 - accuracy: 0.8175 - val_loss: 0.6234 - val_accuracy: 0.7721\n",
      "Epoch 628/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5525 - accuracy: 0.8175 - val_loss: 0.6233 - val_accuracy: 0.7714\n",
      "Epoch 629/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5522 - accuracy: 0.8172 - val_loss: 0.6230 - val_accuracy: 0.7721\n",
      "Epoch 630/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5519 - accuracy: 0.8179 - val_loss: 0.6229 - val_accuracy: 0.7719\n",
      "Epoch 631/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5516 - accuracy: 0.8179 - val_loss: 0.6227 - val_accuracy: 0.7721\n",
      "Epoch 632/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5513 - accuracy: 0.8176 - val_loss: 0.6225 - val_accuracy: 0.7721\n",
      "Epoch 633/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5510 - accuracy: 0.8175 - val_loss: 0.6223 - val_accuracy: 0.7721\n",
      "Epoch 634/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5507 - accuracy: 0.8175 - val_loss: 0.6221 - val_accuracy: 0.7728\n",
      "Epoch 635/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5504 - accuracy: 0.8177 - val_loss: 0.6219 - val_accuracy: 0.7730\n",
      "Epoch 636/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5501 - accuracy: 0.8179 - val_loss: 0.6217 - val_accuracy: 0.7730\n",
      "Epoch 637/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5498 - accuracy: 0.8180 - val_loss: 0.6216 - val_accuracy: 0.7730\n",
      "Epoch 638/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5495 - accuracy: 0.8183 - val_loss: 0.6214 - val_accuracy: 0.7728\n",
      "Epoch 639/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5492 - accuracy: 0.8183 - val_loss: 0.6212 - val_accuracy: 0.7733\n",
      "Epoch 640/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5489 - accuracy: 0.8181 - val_loss: 0.6210 - val_accuracy: 0.7733\n",
      "Epoch 641/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5487 - accuracy: 0.8185 - val_loss: 0.6208 - val_accuracy: 0.7735\n",
      "Epoch 642/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5484 - accuracy: 0.8183 - val_loss: 0.6207 - val_accuracy: 0.7733\n",
      "Epoch 643/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5481 - accuracy: 0.8183 - val_loss: 0.6204 - val_accuracy: 0.7733\n",
      "Epoch 644/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5478 - accuracy: 0.8185 - val_loss: 0.6203 - val_accuracy: 0.7730\n",
      "Epoch 645/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5475 - accuracy: 0.8186 - val_loss: 0.6201 - val_accuracy: 0.7733\n",
      "Epoch 646/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5472 - accuracy: 0.8183 - val_loss: 0.6199 - val_accuracy: 0.7735\n",
      "Epoch 647/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5470 - accuracy: 0.8181 - val_loss: 0.6197 - val_accuracy: 0.7733\n",
      "Epoch 648/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5467 - accuracy: 0.8187 - val_loss: 0.6196 - val_accuracy: 0.7735\n",
      "Epoch 649/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5464 - accuracy: 0.8185 - val_loss: 0.6194 - val_accuracy: 0.7735\n",
      "Epoch 650/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5462 - accuracy: 0.8189 - val_loss: 0.6192 - val_accuracy: 0.7733\n",
      "Epoch 651/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5459 - accuracy: 0.8185 - val_loss: 0.6191 - val_accuracy: 0.7737\n",
      "Epoch 652/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.5456 - accuracy: 0.8185 - val_loss: 0.6189 - val_accuracy: 0.7733\n",
      "Epoch 653/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.5453 - accuracy: 0.8185 - val_loss: 0.6188 - val_accuracy: 0.7733\n",
      "Epoch 654/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5451 - accuracy: 0.8187 - val_loss: 0.6186 - val_accuracy: 0.7740\n",
      "Epoch 655/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5448 - accuracy: 0.8184 - val_loss: 0.6183 - val_accuracy: 0.7742\n",
      "Epoch 656/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5445 - accuracy: 0.8186 - val_loss: 0.6182 - val_accuracy: 0.7735\n",
      "Epoch 657/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5443 - accuracy: 0.8190 - val_loss: 0.6181 - val_accuracy: 0.7737\n",
      "Epoch 658/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5440 - accuracy: 0.8186 - val_loss: 0.6179 - val_accuracy: 0.7730\n",
      "Epoch 659/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5438 - accuracy: 0.8197 - val_loss: 0.6177 - val_accuracy: 0.7737\n",
      "Epoch 660/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5435 - accuracy: 0.8188 - val_loss: 0.6176 - val_accuracy: 0.7735\n",
      "Epoch 661/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5432 - accuracy: 0.8191 - val_loss: 0.6175 - val_accuracy: 0.7724\n",
      "Epoch 662/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5430 - accuracy: 0.8192 - val_loss: 0.6173 - val_accuracy: 0.7726\n",
      "Epoch 663/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5427 - accuracy: 0.8193 - val_loss: 0.6171 - val_accuracy: 0.7728\n",
      "Epoch 664/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5425 - accuracy: 0.8198 - val_loss: 0.6170 - val_accuracy: 0.7726\n",
      "Epoch 665/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5422 - accuracy: 0.8196 - val_loss: 0.6169 - val_accuracy: 0.7728\n",
      "Epoch 666/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5420 - accuracy: 0.8192 - val_loss: 0.6167 - val_accuracy: 0.7728\n",
      "Epoch 667/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5417 - accuracy: 0.8198 - val_loss: 0.6166 - val_accuracy: 0.7728\n",
      "Epoch 668/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5415 - accuracy: 0.8201 - val_loss: 0.6164 - val_accuracy: 0.7726\n",
      "Epoch 669/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5412 - accuracy: 0.8197 - val_loss: 0.6163 - val_accuracy: 0.7728\n",
      "Epoch 670/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5410 - accuracy: 0.8199 - val_loss: 0.6161 - val_accuracy: 0.7728\n",
      "Epoch 671/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5407 - accuracy: 0.8197 - val_loss: 0.6159 - val_accuracy: 0.7733\n",
      "Epoch 672/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5405 - accuracy: 0.8198 - val_loss: 0.6159 - val_accuracy: 0.7728\n",
      "Epoch 673/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5402 - accuracy: 0.8201 - val_loss: 0.6157 - val_accuracy: 0.7730\n",
      "Epoch 674/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5400 - accuracy: 0.8200 - val_loss: 0.6156 - val_accuracy: 0.7728\n",
      "Epoch 675/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5398 - accuracy: 0.8201 - val_loss: 0.6154 - val_accuracy: 0.7730\n",
      "Epoch 676/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5395 - accuracy: 0.8198 - val_loss: 0.6153 - val_accuracy: 0.7733\n",
      "Epoch 677/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5393 - accuracy: 0.8199 - val_loss: 0.6152 - val_accuracy: 0.7726\n",
      "Epoch 678/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5390 - accuracy: 0.8202 - val_loss: 0.6150 - val_accuracy: 0.7733\n",
      "Epoch 679/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5388 - accuracy: 0.8198 - val_loss: 0.6149 - val_accuracy: 0.7735\n",
      "Epoch 680/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5386 - accuracy: 0.8202 - val_loss: 0.6148 - val_accuracy: 0.7737\n",
      "Epoch 681/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5383 - accuracy: 0.8202 - val_loss: 0.6146 - val_accuracy: 0.7733\n",
      "Epoch 682/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5381 - accuracy: 0.8204 - val_loss: 0.6145 - val_accuracy: 0.7740\n",
      "Epoch 683/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5379 - accuracy: 0.8200 - val_loss: 0.6144 - val_accuracy: 0.7737\n",
      "Epoch 684/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5376 - accuracy: 0.8204 - val_loss: 0.6142 - val_accuracy: 0.7733\n",
      "Epoch 685/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5374 - accuracy: 0.8203 - val_loss: 0.6141 - val_accuracy: 0.7733\n",
      "Epoch 686/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5371 - accuracy: 0.8202 - val_loss: 0.6140 - val_accuracy: 0.7735\n",
      "Epoch 687/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5369 - accuracy: 0.8202 - val_loss: 0.6139 - val_accuracy: 0.7733\n",
      "Epoch 688/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5367 - accuracy: 0.8205 - val_loss: 0.6137 - val_accuracy: 0.7735\n",
      "Epoch 689/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5365 - accuracy: 0.8206 - val_loss: 0.6136 - val_accuracy: 0.7744\n",
      "Epoch 690/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5362 - accuracy: 0.8206 - val_loss: 0.6135 - val_accuracy: 0.7740\n",
      "Epoch 691/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5360 - accuracy: 0.8203 - val_loss: 0.6133 - val_accuracy: 0.7735\n",
      "Epoch 692/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5358 - accuracy: 0.8206 - val_loss: 0.6132 - val_accuracy: 0.7744\n",
      "Epoch 693/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5356 - accuracy: 0.8208 - val_loss: 0.6130 - val_accuracy: 0.7735\n",
      "Epoch 694/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5354 - accuracy: 0.8206 - val_loss: 0.6130 - val_accuracy: 0.7735\n",
      "Epoch 695/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5351 - accuracy: 0.8203 - val_loss: 0.6129 - val_accuracy: 0.7740\n",
      "Epoch 696/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5349 - accuracy: 0.8206 - val_loss: 0.6127 - val_accuracy: 0.7740\n",
      "Epoch 697/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.5347 - accuracy: 0.8206 - val_loss: 0.6126 - val_accuracy: 0.7742\n",
      "Epoch 698/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5345 - accuracy: 0.8209 - val_loss: 0.6124 - val_accuracy: 0.7740\n",
      "Epoch 699/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5343 - accuracy: 0.8206 - val_loss: 0.6123 - val_accuracy: 0.7742\n",
      "Epoch 700/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.5340 - accuracy: 0.8210 - val_loss: 0.6122 - val_accuracy: 0.7742\n",
      "Epoch 701/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5338 - accuracy: 0.8210 - val_loss: 0.6121 - val_accuracy: 0.7742\n",
      "Epoch 702/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5336 - accuracy: 0.8210 - val_loss: 0.6120 - val_accuracy: 0.7742\n",
      "Epoch 703/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5334 - accuracy: 0.8211 - val_loss: 0.6119 - val_accuracy: 0.7744\n",
      "Epoch 704/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5332 - accuracy: 0.8207 - val_loss: 0.6117 - val_accuracy: 0.7744\n",
      "Epoch 705/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.5330 - accuracy: 0.8209 - val_loss: 0.6117 - val_accuracy: 0.7742\n",
      "Epoch 706/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5328 - accuracy: 0.8211 - val_loss: 0.6115 - val_accuracy: 0.7747\n",
      "Epoch 707/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5326 - accuracy: 0.8213 - val_loss: 0.6114 - val_accuracy: 0.7747\n",
      "Epoch 708/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5324 - accuracy: 0.8208 - val_loss: 0.6112 - val_accuracy: 0.7747\n",
      "Epoch 709/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.5322 - accuracy: 0.8213 - val_loss: 0.6112 - val_accuracy: 0.7747\n",
      "Epoch 710/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.5320 - accuracy: 0.8215 - val_loss: 0.6111 - val_accuracy: 0.7751\n",
      "Epoch 711/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.5318 - accuracy: 0.8213 - val_loss: 0.6110 - val_accuracy: 0.7749\n",
      "Epoch 712/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5316 - accuracy: 0.8215 - val_loss: 0.6108 - val_accuracy: 0.7749\n",
      "Epoch 713/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5314 - accuracy: 0.8214 - val_loss: 0.6107 - val_accuracy: 0.7753\n",
      "Epoch 714/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5311 - accuracy: 0.8217 - val_loss: 0.6106 - val_accuracy: 0.7756\n",
      "Epoch 715/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.5309 - accuracy: 0.8215 - val_loss: 0.6105 - val_accuracy: 0.7753\n",
      "Epoch 716/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5307 - accuracy: 0.8215 - val_loss: 0.6104 - val_accuracy: 0.7753\n",
      "Epoch 717/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5306 - accuracy: 0.8218 - val_loss: 0.6103 - val_accuracy: 0.7756\n",
      "Epoch 718/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5304 - accuracy: 0.8221 - val_loss: 0.6102 - val_accuracy: 0.7760\n",
      "Epoch 719/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5302 - accuracy: 0.8217 - val_loss: 0.6101 - val_accuracy: 0.7753\n",
      "Epoch 720/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5300 - accuracy: 0.8216 - val_loss: 0.6100 - val_accuracy: 0.7758\n",
      "Epoch 721/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5298 - accuracy: 0.8217 - val_loss: 0.6099 - val_accuracy: 0.7758\n",
      "Epoch 722/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5296 - accuracy: 0.8220 - val_loss: 0.6098 - val_accuracy: 0.7763\n",
      "Epoch 723/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5294 - accuracy: 0.8222 - val_loss: 0.6097 - val_accuracy: 0.7758\n",
      "Epoch 724/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5292 - accuracy: 0.8219 - val_loss: 0.6096 - val_accuracy: 0.7758\n",
      "Epoch 725/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5290 - accuracy: 0.8221 - val_loss: 0.6094 - val_accuracy: 0.7763\n",
      "Epoch 726/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5288 - accuracy: 0.8222 - val_loss: 0.6093 - val_accuracy: 0.7765\n",
      "Epoch 727/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5286 - accuracy: 0.8224 - val_loss: 0.6092 - val_accuracy: 0.7763\n",
      "Epoch 728/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5284 - accuracy: 0.8220 - val_loss: 0.6092 - val_accuracy: 0.7763\n",
      "Epoch 729/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5283 - accuracy: 0.8222 - val_loss: 0.6092 - val_accuracy: 0.7767\n",
      "Epoch 730/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5281 - accuracy: 0.8226 - val_loss: 0.6090 - val_accuracy: 0.7767\n",
      "Epoch 731/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5279 - accuracy: 0.8223 - val_loss: 0.6090 - val_accuracy: 0.7767\n",
      "Epoch 732/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5277 - accuracy: 0.8224 - val_loss: 0.6089 - val_accuracy: 0.7767\n",
      "Epoch 733/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5275 - accuracy: 0.8225 - val_loss: 0.6088 - val_accuracy: 0.7767\n",
      "Epoch 734/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5273 - accuracy: 0.8221 - val_loss: 0.6088 - val_accuracy: 0.7767\n",
      "Epoch 735/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5272 - accuracy: 0.8222 - val_loss: 0.6087 - val_accuracy: 0.7763\n",
      "Epoch 736/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5270 - accuracy: 0.8224 - val_loss: 0.6086 - val_accuracy: 0.7767\n",
      "Epoch 737/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5268 - accuracy: 0.8222 - val_loss: 0.6085 - val_accuracy: 0.7765\n",
      "Epoch 738/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5266 - accuracy: 0.8222 - val_loss: 0.6084 - val_accuracy: 0.7760\n",
      "Epoch 739/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5264 - accuracy: 0.8220 - val_loss: 0.6083 - val_accuracy: 0.7765\n",
      "Epoch 740/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5262 - accuracy: 0.8221 - val_loss: 0.6082 - val_accuracy: 0.7765\n",
      "Epoch 741/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5261 - accuracy: 0.8224 - val_loss: 0.6081 - val_accuracy: 0.7763\n",
      "Epoch 742/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5259 - accuracy: 0.8223 - val_loss: 0.6080 - val_accuracy: 0.7763\n",
      "Epoch 743/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5257 - accuracy: 0.8220 - val_loss: 0.6079 - val_accuracy: 0.7758\n",
      "Epoch 744/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5255 - accuracy: 0.8220 - val_loss: 0.6078 - val_accuracy: 0.7763\n",
      "Epoch 745/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5254 - accuracy: 0.8223 - val_loss: 0.6079 - val_accuracy: 0.7765\n",
      "Epoch 746/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5252 - accuracy: 0.8226 - val_loss: 0.6077 - val_accuracy: 0.7765\n",
      "Epoch 747/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5250 - accuracy: 0.8222 - val_loss: 0.6076 - val_accuracy: 0.7763\n",
      "Epoch 748/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5249 - accuracy: 0.8222 - val_loss: 0.6076 - val_accuracy: 0.7756\n",
      "Epoch 749/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5247 - accuracy: 0.8224 - val_loss: 0.6074 - val_accuracy: 0.7758\n",
      "Epoch 750/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5245 - accuracy: 0.8226 - val_loss: 0.6074 - val_accuracy: 0.7760\n",
      "Epoch 751/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5244 - accuracy: 0.8224 - val_loss: 0.6072 - val_accuracy: 0.7765\n",
      "Epoch 752/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5242 - accuracy: 0.8227 - val_loss: 0.6072 - val_accuracy: 0.7770\n",
      "Epoch 753/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5240 - accuracy: 0.8223 - val_loss: 0.6072 - val_accuracy: 0.7765\n",
      "Epoch 754/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5239 - accuracy: 0.8228 - val_loss: 0.6071 - val_accuracy: 0.7765\n",
      "Epoch 755/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5237 - accuracy: 0.8226 - val_loss: 0.6069 - val_accuracy: 0.7767\n",
      "Epoch 756/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5235 - accuracy: 0.8230 - val_loss: 0.6068 - val_accuracy: 0.7770\n",
      "Epoch 757/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5234 - accuracy: 0.8228 - val_loss: 0.6067 - val_accuracy: 0.7770\n",
      "Epoch 758/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5232 - accuracy: 0.8227 - val_loss: 0.6067 - val_accuracy: 0.7770\n",
      "Epoch 759/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5230 - accuracy: 0.8227 - val_loss: 0.6067 - val_accuracy: 0.7770\n",
      "Epoch 760/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5229 - accuracy: 0.8230 - val_loss: 0.6066 - val_accuracy: 0.7774\n",
      "Epoch 761/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5227 - accuracy: 0.8230 - val_loss: 0.6065 - val_accuracy: 0.7772\n",
      "Epoch 762/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5226 - accuracy: 0.8228 - val_loss: 0.6064 - val_accuracy: 0.7774\n",
      "Epoch 763/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5224 - accuracy: 0.8229 - val_loss: 0.6063 - val_accuracy: 0.7774\n",
      "Epoch 764/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5222 - accuracy: 0.8230 - val_loss: 0.6063 - val_accuracy: 0.7770\n",
      "Epoch 765/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5221 - accuracy: 0.8228 - val_loss: 0.6062 - val_accuracy: 0.7772\n",
      "Epoch 766/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5219 - accuracy: 0.8233 - val_loss: 0.6062 - val_accuracy: 0.7770\n",
      "Epoch 767/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5218 - accuracy: 0.8231 - val_loss: 0.6061 - val_accuracy: 0.7770\n",
      "Epoch 768/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5216 - accuracy: 0.8230 - val_loss: 0.6060 - val_accuracy: 0.7767\n",
      "Epoch 769/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5214 - accuracy: 0.8234 - val_loss: 0.6060 - val_accuracy: 0.7772\n",
      "Epoch 770/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5213 - accuracy: 0.8232 - val_loss: 0.6059 - val_accuracy: 0.7763\n",
      "Epoch 771/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5212 - accuracy: 0.8232 - val_loss: 0.6058 - val_accuracy: 0.7772\n",
      "Epoch 772/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5210 - accuracy: 0.8232 - val_loss: 0.6058 - val_accuracy: 0.7767\n",
      "Epoch 773/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5208 - accuracy: 0.8237 - val_loss: 0.6057 - val_accuracy: 0.7772\n",
      "Epoch 774/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5207 - accuracy: 0.8229 - val_loss: 0.6056 - val_accuracy: 0.7765\n",
      "Epoch 775/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5206 - accuracy: 0.8230 - val_loss: 0.6055 - val_accuracy: 0.7767\n",
      "Epoch 776/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5204 - accuracy: 0.8236 - val_loss: 0.6055 - val_accuracy: 0.7772\n",
      "Epoch 777/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5202 - accuracy: 0.8237 - val_loss: 0.6055 - val_accuracy: 0.7765\n",
      "Epoch 778/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5201 - accuracy: 0.8232 - val_loss: 0.6054 - val_accuracy: 0.7765\n",
      "Epoch 779/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5199 - accuracy: 0.8236 - val_loss: 0.6053 - val_accuracy: 0.7767\n",
      "Epoch 780/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5198 - accuracy: 0.8236 - val_loss: 0.6052 - val_accuracy: 0.7772\n",
      "Epoch 781/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5196 - accuracy: 0.8233 - val_loss: 0.6051 - val_accuracy: 0.7763\n",
      "Epoch 782/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5195 - accuracy: 0.8234 - val_loss: 0.6051 - val_accuracy: 0.7765\n",
      "Epoch 783/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5194 - accuracy: 0.8235 - val_loss: 0.6051 - val_accuracy: 0.7767\n",
      "Epoch 784/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5192 - accuracy: 0.8239 - val_loss: 0.6050 - val_accuracy: 0.7760\n",
      "Epoch 785/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5191 - accuracy: 0.8237 - val_loss: 0.6049 - val_accuracy: 0.7765\n",
      "Epoch 786/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5189 - accuracy: 0.8238 - val_loss: 0.6048 - val_accuracy: 0.7770\n",
      "Epoch 787/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5188 - accuracy: 0.8235 - val_loss: 0.6048 - val_accuracy: 0.7774\n",
      "Epoch 788/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5186 - accuracy: 0.8237 - val_loss: 0.6047 - val_accuracy: 0.7770\n",
      "Epoch 789/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5185 - accuracy: 0.8239 - val_loss: 0.6047 - val_accuracy: 0.7770\n",
      "Epoch 790/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5183 - accuracy: 0.8240 - val_loss: 0.6046 - val_accuracy: 0.7770\n",
      "Epoch 791/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5182 - accuracy: 0.8237 - val_loss: 0.6045 - val_accuracy: 0.7770\n",
      "Epoch 792/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5181 - accuracy: 0.8238 - val_loss: 0.6045 - val_accuracy: 0.7772\n",
      "Epoch 793/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5179 - accuracy: 0.8240 - val_loss: 0.6044 - val_accuracy: 0.7772\n",
      "Epoch 794/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5178 - accuracy: 0.8241 - val_loss: 0.6044 - val_accuracy: 0.7770\n",
      "Epoch 795/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5177 - accuracy: 0.8241 - val_loss: 0.6043 - val_accuracy: 0.7774\n",
      "Epoch 796/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5175 - accuracy: 0.8239 - val_loss: 0.6043 - val_accuracy: 0.7767\n",
      "Epoch 797/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.8241 - val_loss: 0.6042 - val_accuracy: 0.7767\n",
      "Epoch 798/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.8237 - val_loss: 0.6041 - val_accuracy: 0.7765\n",
      "Epoch 799/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5171 - accuracy: 0.8243 - val_loss: 0.6041 - val_accuracy: 0.7770\n",
      "Epoch 800/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.8243 - val_loss: 0.6040 - val_accuracy: 0.7767\n",
      "Epoch 801/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.8241 - val_loss: 0.6040 - val_accuracy: 0.7770\n",
      "Epoch 802/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5167 - accuracy: 0.8240 - val_loss: 0.6040 - val_accuracy: 0.7770\n",
      "Epoch 803/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5166 - accuracy: 0.8244 - val_loss: 0.6039 - val_accuracy: 0.7772\n",
      "Epoch 804/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5164 - accuracy: 0.8242 - val_loss: 0.6038 - val_accuracy: 0.7763\n",
      "Epoch 805/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5163 - accuracy: 0.8242 - val_loss: 0.6038 - val_accuracy: 0.7772\n",
      "Epoch 806/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.8241 - val_loss: 0.6038 - val_accuracy: 0.7772\n",
      "Epoch 807/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5160 - accuracy: 0.8246 - val_loss: 0.6037 - val_accuracy: 0.7765\n",
      "Epoch 808/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5159 - accuracy: 0.8247 - val_loss: 0.6037 - val_accuracy: 0.7765\n",
      "Epoch 809/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.8246 - val_loss: 0.6035 - val_accuracy: 0.7767\n",
      "Epoch 810/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.8247 - val_loss: 0.6035 - val_accuracy: 0.7763\n",
      "Epoch 811/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5155 - accuracy: 0.8247 - val_loss: 0.6034 - val_accuracy: 0.7765\n",
      "Epoch 812/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5154 - accuracy: 0.8248 - val_loss: 0.6035 - val_accuracy: 0.7765\n",
      "Epoch 813/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5152 - accuracy: 0.8245 - val_loss: 0.6033 - val_accuracy: 0.7765\n",
      "Epoch 814/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5151 - accuracy: 0.8245 - val_loss: 0.6033 - val_accuracy: 0.7763\n",
      "Epoch 815/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5150 - accuracy: 0.8245 - val_loss: 0.6033 - val_accuracy: 0.7763\n",
      "Epoch 816/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5149 - accuracy: 0.8247 - val_loss: 0.6032 - val_accuracy: 0.7765\n",
      "Epoch 817/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5147 - accuracy: 0.8250 - val_loss: 0.6032 - val_accuracy: 0.7763\n",
      "Epoch 818/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5146 - accuracy: 0.8247 - val_loss: 0.6030 - val_accuracy: 0.7763\n",
      "Epoch 819/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5145 - accuracy: 0.8247 - val_loss: 0.6031 - val_accuracy: 0.7770\n",
      "Epoch 820/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.8245 - val_loss: 0.6030 - val_accuracy: 0.7765\n",
      "Epoch 821/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5142 - accuracy: 0.8249 - val_loss: 0.6029 - val_accuracy: 0.7765\n",
      "Epoch 822/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5141 - accuracy: 0.8251 - val_loss: 0.6029 - val_accuracy: 0.7763\n",
      "Epoch 823/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5140 - accuracy: 0.8250 - val_loss: 0.6029 - val_accuracy: 0.7770\n",
      "Epoch 824/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5139 - accuracy: 0.8251 - val_loss: 0.6029 - val_accuracy: 0.7765\n",
      "Epoch 825/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.8252 - val_loss: 0.6028 - val_accuracy: 0.7765\n",
      "Epoch 826/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5136 - accuracy: 0.8251 - val_loss: 0.6028 - val_accuracy: 0.7767\n",
      "Epoch 827/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5135 - accuracy: 0.8251 - val_loss: 0.6027 - val_accuracy: 0.7767\n",
      "Epoch 828/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5134 - accuracy: 0.8256 - val_loss: 0.6027 - val_accuracy: 0.7763\n",
      "Epoch 829/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5133 - accuracy: 0.8255 - val_loss: 0.6027 - val_accuracy: 0.7765\n",
      "Epoch 830/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5132 - accuracy: 0.8253 - val_loss: 0.6025 - val_accuracy: 0.7765\n",
      "Epoch 831/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.8253 - val_loss: 0.6025 - val_accuracy: 0.7767\n",
      "Epoch 832/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5129 - accuracy: 0.8252 - val_loss: 0.6025 - val_accuracy: 0.7770\n",
      "Epoch 833/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.8251 - val_loss: 0.6025 - val_accuracy: 0.7765\n",
      "Epoch 834/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5127 - accuracy: 0.8257 - val_loss: 0.6024 - val_accuracy: 0.7767\n",
      "Epoch 835/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5125 - accuracy: 0.8256 - val_loss: 0.6024 - val_accuracy: 0.7770\n",
      "Epoch 836/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5124 - accuracy: 0.8253 - val_loss: 0.6023 - val_accuracy: 0.7772\n",
      "Epoch 837/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5123 - accuracy: 0.8256 - val_loss: 0.6023 - val_accuracy: 0.7772\n",
      "Epoch 838/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.8252 - val_loss: 0.6022 - val_accuracy: 0.7765\n",
      "Epoch 839/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5121 - accuracy: 0.8253 - val_loss: 0.6022 - val_accuracy: 0.7772\n",
      "Epoch 840/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5120 - accuracy: 0.8258 - val_loss: 0.6021 - val_accuracy: 0.7772\n",
      "Epoch 841/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5119 - accuracy: 0.8252 - val_loss: 0.6021 - val_accuracy: 0.7767\n",
      "Epoch 842/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5117 - accuracy: 0.8253 - val_loss: 0.6021 - val_accuracy: 0.7772\n",
      "Epoch 843/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.8258 - val_loss: 0.6020 - val_accuracy: 0.7770\n",
      "Epoch 844/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.8256 - val_loss: 0.6020 - val_accuracy: 0.7772\n",
      "Epoch 845/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5114 - accuracy: 0.8257 - val_loss: 0.6020 - val_accuracy: 0.7772\n",
      "Epoch 846/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5113 - accuracy: 0.8255 - val_loss: 0.6019 - val_accuracy: 0.7772\n",
      "Epoch 847/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5112 - accuracy: 0.8259 - val_loss: 0.6019 - val_accuracy: 0.7772\n",
      "Epoch 848/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.8263 - val_loss: 0.6019 - val_accuracy: 0.7772\n",
      "Epoch 849/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.8259 - val_loss: 0.6018 - val_accuracy: 0.7772\n",
      "Epoch 850/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5108 - accuracy: 0.8258 - val_loss: 0.6018 - val_accuracy: 0.7772\n",
      "Epoch 851/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5107 - accuracy: 0.8258 - val_loss: 0.6017 - val_accuracy: 0.7772\n",
      "Epoch 852/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.8260 - val_loss: 0.6017 - val_accuracy: 0.7772\n",
      "Epoch 853/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.8260 - val_loss: 0.6017 - val_accuracy: 0.7772\n",
      "Epoch 854/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5104 - accuracy: 0.8259 - val_loss: 0.6016 - val_accuracy: 0.7770\n",
      "Epoch 855/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.8259 - val_loss: 0.6016 - val_accuracy: 0.7767\n",
      "Epoch 856/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5102 - accuracy: 0.8259 - val_loss: 0.6016 - val_accuracy: 0.7770\n",
      "Epoch 857/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5101 - accuracy: 0.8262 - val_loss: 0.6016 - val_accuracy: 0.7767\n",
      "Epoch 858/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.8265 - val_loss: 0.6015 - val_accuracy: 0.7770\n",
      "Epoch 859/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.8257 - val_loss: 0.6015 - val_accuracy: 0.7765\n",
      "Epoch 860/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.8262 - val_loss: 0.6014 - val_accuracy: 0.7767\n",
      "Epoch 861/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.8266 - val_loss: 0.6014 - val_accuracy: 0.7763\n",
      "Epoch 862/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.8265 - val_loss: 0.6013 - val_accuracy: 0.7772\n",
      "Epoch 863/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.8260 - val_loss: 0.6013 - val_accuracy: 0.7770\n",
      "Epoch 864/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.8260 - val_loss: 0.6013 - val_accuracy: 0.7772\n",
      "Epoch 865/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.8267 - val_loss: 0.6014 - val_accuracy: 0.7770\n",
      "Epoch 866/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5091 - accuracy: 0.8266 - val_loss: 0.6012 - val_accuracy: 0.7770\n",
      "Epoch 867/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.8266 - val_loss: 0.6012 - val_accuracy: 0.7770\n",
      "Epoch 868/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.8265 - val_loss: 0.6012 - val_accuracy: 0.7776\n",
      "Epoch 869/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.8266 - val_loss: 0.6011 - val_accuracy: 0.7774\n",
      "Epoch 870/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.8266 - val_loss: 0.6012 - val_accuracy: 0.7770\n",
      "Epoch 871/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.8270 - val_loss: 0.6012 - val_accuracy: 0.7770\n",
      "Epoch 872/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.8266 - val_loss: 0.6011 - val_accuracy: 0.7765\n",
      "Epoch 873/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.8264 - val_loss: 0.6010 - val_accuracy: 0.7770\n",
      "Epoch 874/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.8267 - val_loss: 0.6010 - val_accuracy: 0.7774\n",
      "Epoch 875/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5082 - accuracy: 0.8268 - val_loss: 0.6010 - val_accuracy: 0.7774\n",
      "Epoch 876/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.8264 - val_loss: 0.6010 - val_accuracy: 0.7776\n",
      "Epoch 877/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.8268 - val_loss: 0.6010 - val_accuracy: 0.7767\n",
      "Epoch 878/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.8265 - val_loss: 0.6008 - val_accuracy: 0.7776\n",
      "Epoch 879/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.8271 - val_loss: 0.6009 - val_accuracy: 0.7781\n",
      "Epoch 880/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.8266 - val_loss: 0.6008 - val_accuracy: 0.7779\n",
      "Epoch 881/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.8270 - val_loss: 0.6008 - val_accuracy: 0.7774\n",
      "Epoch 882/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.8267 - val_loss: 0.6008 - val_accuracy: 0.7772\n",
      "Epoch 883/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.8268 - val_loss: 0.6007 - val_accuracy: 0.7772\n",
      "Epoch 884/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.8267 - val_loss: 0.6007 - val_accuracy: 0.7767\n",
      "Epoch 885/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.8270 - val_loss: 0.6007 - val_accuracy: 0.7770\n",
      "Epoch 886/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.8269 - val_loss: 0.6006 - val_accuracy: 0.7772\n",
      "Epoch 887/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.8273 - val_loss: 0.6006 - val_accuracy: 0.7774\n",
      "Epoch 888/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.8271 - val_loss: 0.6006 - val_accuracy: 0.7774\n",
      "Epoch 889/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.8270 - val_loss: 0.6006 - val_accuracy: 0.7776\n",
      "Epoch 890/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.8274 - val_loss: 0.6006 - val_accuracy: 0.7774\n",
      "Epoch 891/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.8275 - val_loss: 0.6005 - val_accuracy: 0.7776\n",
      "Epoch 892/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.8271 - val_loss: 0.6005 - val_accuracy: 0.7776\n",
      "Epoch 893/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.8269 - val_loss: 0.6005 - val_accuracy: 0.7774\n",
      "Epoch 894/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.8271 - val_loss: 0.6004 - val_accuracy: 0.7774\n",
      "Epoch 895/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.8273 - val_loss: 0.6004 - val_accuracy: 0.7772\n",
      "Epoch 896/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.8276 - val_loss: 0.6004 - val_accuracy: 0.7776\n",
      "Epoch 897/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.8275 - val_loss: 0.6004 - val_accuracy: 0.7776\n",
      "Epoch 898/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.8269 - val_loss: 0.6003 - val_accuracy: 0.7776\n",
      "Epoch 899/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.8275 - val_loss: 0.6003 - val_accuracy: 0.7774\n",
      "Epoch 900/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.8275 - val_loss: 0.6003 - val_accuracy: 0.7776\n",
      "Epoch 901/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.8277 - val_loss: 0.6003 - val_accuracy: 0.7776\n",
      "Epoch 902/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.8275 - val_loss: 0.6002 - val_accuracy: 0.7781\n",
      "Epoch 903/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.8274 - val_loss: 0.6002 - val_accuracy: 0.7781\n",
      "Epoch 904/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.8274 - val_loss: 0.6002 - val_accuracy: 0.7783\n",
      "Epoch 905/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.8276 - val_loss: 0.6001 - val_accuracy: 0.7781\n",
      "Epoch 906/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.8276 - val_loss: 0.6001 - val_accuracy: 0.7781\n",
      "Epoch 907/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.8273 - val_loss: 0.6001 - val_accuracy: 0.7781\n",
      "Epoch 908/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.8279 - val_loss: 0.6001 - val_accuracy: 0.7779\n",
      "Epoch 909/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.8276 - val_loss: 0.6000 - val_accuracy: 0.7779\n",
      "Epoch 910/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.8274 - val_loss: 0.6000 - val_accuracy: 0.7779\n",
      "Epoch 911/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.8275 - val_loss: 0.5999 - val_accuracy: 0.7781\n",
      "Epoch 912/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.8275 - val_loss: 0.6000 - val_accuracy: 0.7779\n",
      "Epoch 913/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.8273 - val_loss: 0.5999 - val_accuracy: 0.7781\n",
      "Epoch 914/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.8278 - val_loss: 0.5999 - val_accuracy: 0.7779\n",
      "Epoch 915/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.8274 - val_loss: 0.5999 - val_accuracy: 0.7781\n",
      "Epoch 916/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.8275 - val_loss: 0.5999 - val_accuracy: 0.7776\n",
      "Epoch 917/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.8274 - val_loss: 0.5999 - val_accuracy: 0.7774\n",
      "Epoch 918/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.8282 - val_loss: 0.5999 - val_accuracy: 0.7776\n",
      "Epoch 919/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.8273 - val_loss: 0.5998 - val_accuracy: 0.7781\n",
      "Epoch 920/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.8279 - val_loss: 0.5998 - val_accuracy: 0.7781\n",
      "Epoch 921/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.8282 - val_loss: 0.5998 - val_accuracy: 0.7786\n",
      "Epoch 922/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.8276 - val_loss: 0.5998 - val_accuracy: 0.7774\n",
      "Epoch 923/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.8276 - val_loss: 0.5997 - val_accuracy: 0.7786\n",
      "Epoch 924/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5037 - accuracy: 0.8276 - val_loss: 0.5998 - val_accuracy: 0.7774\n",
      "Epoch 925/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5036 - accuracy: 0.8279 - val_loss: 0.5998 - val_accuracy: 0.7776\n",
      "Epoch 926/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5035 - accuracy: 0.8275 - val_loss: 0.5997 - val_accuracy: 0.7783\n",
      "Epoch 927/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5034 - accuracy: 0.8278 - val_loss: 0.5996 - val_accuracy: 0.7783\n",
      "Epoch 928/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5033 - accuracy: 0.8277 - val_loss: 0.5996 - val_accuracy: 0.7786\n",
      "Epoch 929/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5033 - accuracy: 0.8278 - val_loss: 0.5996 - val_accuracy: 0.7783\n",
      "Epoch 930/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5032 - accuracy: 0.8279 - val_loss: 0.5996 - val_accuracy: 0.7788\n",
      "Epoch 931/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5031 - accuracy: 0.8283 - val_loss: 0.5995 - val_accuracy: 0.7790\n",
      "Epoch 932/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5030 - accuracy: 0.8275 - val_loss: 0.5995 - val_accuracy: 0.7781\n",
      "Epoch 933/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5029 - accuracy: 0.8278 - val_loss: 0.5994 - val_accuracy: 0.7781\n",
      "Epoch 934/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5028 - accuracy: 0.8281 - val_loss: 0.5995 - val_accuracy: 0.7783\n",
      "Epoch 935/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.8279 - val_loss: 0.5995 - val_accuracy: 0.7781\n",
      "Epoch 936/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5026 - accuracy: 0.8276 - val_loss: 0.5995 - val_accuracy: 0.7781\n",
      "Epoch 937/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5026 - accuracy: 0.8276 - val_loss: 0.5995 - val_accuracy: 0.7776\n",
      "Epoch 938/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5025 - accuracy: 0.8279 - val_loss: 0.5994 - val_accuracy: 0.7781\n",
      "Epoch 939/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5024 - accuracy: 0.8281 - val_loss: 0.5994 - val_accuracy: 0.7781\n",
      "Epoch 940/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5023 - accuracy: 0.8276 - val_loss: 0.5994 - val_accuracy: 0.7783\n",
      "Epoch 941/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5022 - accuracy: 0.8276 - val_loss: 0.5994 - val_accuracy: 0.7783\n",
      "Epoch 942/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5022 - accuracy: 0.8276 - val_loss: 0.5994 - val_accuracy: 0.7779\n",
      "Epoch 943/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5021 - accuracy: 0.8276 - val_loss: 0.5994 - val_accuracy: 0.7776\n",
      "Epoch 944/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5020 - accuracy: 0.8276 - val_loss: 0.5993 - val_accuracy: 0.7786\n",
      "Epoch 945/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5019 - accuracy: 0.8275 - val_loss: 0.5993 - val_accuracy: 0.7786\n",
      "Epoch 946/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5018 - accuracy: 0.8279 - val_loss: 0.5993 - val_accuracy: 0.7783\n",
      "Epoch 947/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5018 - accuracy: 0.8274 - val_loss: 0.5993 - val_accuracy: 0.7776\n",
      "Epoch 948/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.5017 - accuracy: 0.8281 - val_loss: 0.5992 - val_accuracy: 0.7772\n",
      "Epoch 949/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5016 - accuracy: 0.8278 - val_loss: 0.5993 - val_accuracy: 0.7781\n",
      "Epoch 950/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5015 - accuracy: 0.8278 - val_loss: 0.5992 - val_accuracy: 0.7783\n",
      "Epoch 951/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5014 - accuracy: 0.8281 - val_loss: 0.5992 - val_accuracy: 0.7788\n",
      "Epoch 952/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5013 - accuracy: 0.8277 - val_loss: 0.5992 - val_accuracy: 0.7781\n",
      "Epoch 953/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5013 - accuracy: 0.8279 - val_loss: 0.5991 - val_accuracy: 0.7783\n",
      "Epoch 954/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5012 - accuracy: 0.8275 - val_loss: 0.5991 - val_accuracy: 0.7783\n",
      "Epoch 955/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5011 - accuracy: 0.8281 - val_loss: 0.5991 - val_accuracy: 0.7783\n",
      "Epoch 956/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5010 - accuracy: 0.8275 - val_loss: 0.5991 - val_accuracy: 0.7783\n",
      "Epoch 957/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5010 - accuracy: 0.8276 - val_loss: 0.5991 - val_accuracy: 0.7783\n",
      "Epoch 958/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5009 - accuracy: 0.8282 - val_loss: 0.5990 - val_accuracy: 0.7783\n",
      "Epoch 959/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5008 - accuracy: 0.8283 - val_loss: 0.5990 - val_accuracy: 0.7781\n",
      "Epoch 960/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5007 - accuracy: 0.8283 - val_loss: 0.5989 - val_accuracy: 0.7788\n",
      "Epoch 961/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5006 - accuracy: 0.8276 - val_loss: 0.5991 - val_accuracy: 0.7763\n",
      "Epoch 962/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5006 - accuracy: 0.8284 - val_loss: 0.5990 - val_accuracy: 0.7781\n",
      "Epoch 963/2000\n",
      "136/136 [==============================] - 1s 4ms/step - loss: 0.5005 - accuracy: 0.8279 - val_loss: 0.5990 - val_accuracy: 0.7786\n",
      "Epoch 964/2000\n",
      "136/136 [==============================] - 1s 4ms/step - loss: 0.5004 - accuracy: 0.8282 - val_loss: 0.5990 - val_accuracy: 0.7779\n",
      "Epoch 965/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5003 - accuracy: 0.8282 - val_loss: 0.5989 - val_accuracy: 0.7781\n",
      "Epoch 966/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5003 - accuracy: 0.8279 - val_loss: 0.5989 - val_accuracy: 0.7788\n",
      "Epoch 967/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5002 - accuracy: 0.8282 - val_loss: 0.5988 - val_accuracy: 0.7788\n",
      "Epoch 968/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5001 - accuracy: 0.8278 - val_loss: 0.5988 - val_accuracy: 0.7783\n",
      "Epoch 969/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.8283 - val_loss: 0.5989 - val_accuracy: 0.7781\n",
      "Epoch 970/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.8286 - val_loss: 0.5989 - val_accuracy: 0.7779\n",
      "Epoch 971/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.8279 - val_loss: 0.5988 - val_accuracy: 0.7783\n",
      "Epoch 972/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4998 - accuracy: 0.8282 - val_loss: 0.5988 - val_accuracy: 0.7781\n",
      "Epoch 973/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4998 - accuracy: 0.8279 - val_loss: 0.5988 - val_accuracy: 0.7779\n",
      "Epoch 974/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4997 - accuracy: 0.8285 - val_loss: 0.5988 - val_accuracy: 0.7786\n",
      "Epoch 975/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4996 - accuracy: 0.8285 - val_loss: 0.5988 - val_accuracy: 0.7781\n",
      "Epoch 976/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4995 - accuracy: 0.8281 - val_loss: 0.5988 - val_accuracy: 0.7779\n",
      "Epoch 977/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4995 - accuracy: 0.8283 - val_loss: 0.5989 - val_accuracy: 0.7765\n",
      "Epoch 978/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4994 - accuracy: 0.8286 - val_loss: 0.5987 - val_accuracy: 0.7772\n",
      "Epoch 979/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4993 - accuracy: 0.8288 - val_loss: 0.5988 - val_accuracy: 0.7776\n",
      "Epoch 980/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4992 - accuracy: 0.8285 - val_loss: 0.5987 - val_accuracy: 0.7776\n",
      "Epoch 981/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4991 - accuracy: 0.8285 - val_loss: 0.5988 - val_accuracy: 0.7774\n",
      "Epoch 982/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.8283 - val_loss: 0.5987 - val_accuracy: 0.7779\n",
      "Epoch 983/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4990 - accuracy: 0.8283 - val_loss: 0.5986 - val_accuracy: 0.7776\n",
      "Epoch 984/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4989 - accuracy: 0.8286 - val_loss: 0.5987 - val_accuracy: 0.7776\n",
      "Epoch 985/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4989 - accuracy: 0.8286 - val_loss: 0.5986 - val_accuracy: 0.7774\n",
      "Epoch 986/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4988 - accuracy: 0.8284 - val_loss: 0.5987 - val_accuracy: 0.7772\n",
      "Epoch 987/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4987 - accuracy: 0.8289 - val_loss: 0.5986 - val_accuracy: 0.7772\n",
      "Epoch 988/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4986 - accuracy: 0.8289 - val_loss: 0.5985 - val_accuracy: 0.7781\n",
      "Epoch 989/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4986 - accuracy: 0.8284 - val_loss: 0.5986 - val_accuracy: 0.7772\n",
      "Epoch 990/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4985 - accuracy: 0.8283 - val_loss: 0.5986 - val_accuracy: 0.7770\n",
      "Epoch 991/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4984 - accuracy: 0.8281 - val_loss: 0.5986 - val_accuracy: 0.7772\n",
      "Epoch 992/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4984 - accuracy: 0.8289 - val_loss: 0.5986 - val_accuracy: 0.7760\n",
      "Epoch 993/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4983 - accuracy: 0.8286 - val_loss: 0.5985 - val_accuracy: 0.7760\n",
      "Epoch 994/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4982 - accuracy: 0.8287 - val_loss: 0.5985 - val_accuracy: 0.7763\n",
      "Epoch 995/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4982 - accuracy: 0.8290 - val_loss: 0.5985 - val_accuracy: 0.7770\n",
      "Epoch 996/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4981 - accuracy: 0.8283 - val_loss: 0.5985 - val_accuracy: 0.7756\n",
      "Epoch 997/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4980 - accuracy: 0.8289 - val_loss: 0.5985 - val_accuracy: 0.7765\n",
      "Epoch 998/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4980 - accuracy: 0.8287 - val_loss: 0.5986 - val_accuracy: 0.7756\n",
      "Epoch 999/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4979 - accuracy: 0.8287 - val_loss: 0.5985 - val_accuracy: 0.7765\n",
      "Epoch 1000/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4978 - accuracy: 0.8290 - val_loss: 0.5985 - val_accuracy: 0.7763\n",
      "Epoch 1001/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4977 - accuracy: 0.8288 - val_loss: 0.5985 - val_accuracy: 0.7763\n",
      "Epoch 1002/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4977 - accuracy: 0.8286 - val_loss: 0.5985 - val_accuracy: 0.7760\n",
      "Epoch 1003/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4976 - accuracy: 0.8289 - val_loss: 0.5984 - val_accuracy: 0.7765\n",
      "Epoch 1004/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4975 - accuracy: 0.8288 - val_loss: 0.5984 - val_accuracy: 0.7765\n",
      "Epoch 1005/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4975 - accuracy: 0.8288 - val_loss: 0.5984 - val_accuracy: 0.7765\n",
      "Epoch 1006/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4974 - accuracy: 0.8294 - val_loss: 0.5985 - val_accuracy: 0.7760\n",
      "Epoch 1007/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4973 - accuracy: 0.8291 - val_loss: 0.5985 - val_accuracy: 0.7760\n",
      "Epoch 1008/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4973 - accuracy: 0.8292 - val_loss: 0.5984 - val_accuracy: 0.7765\n",
      "Epoch 1009/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4972 - accuracy: 0.8294 - val_loss: 0.5984 - val_accuracy: 0.7758\n",
      "Epoch 1010/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4971 - accuracy: 0.8294 - val_loss: 0.5984 - val_accuracy: 0.7760\n",
      "Epoch 1011/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4970 - accuracy: 0.8291 - val_loss: 0.5983 - val_accuracy: 0.7760\n",
      "Epoch 1012/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4970 - accuracy: 0.8291 - val_loss: 0.5983 - val_accuracy: 0.7756\n",
      "Epoch 1013/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4970 - accuracy: 0.8292 - val_loss: 0.5983 - val_accuracy: 0.7758\n",
      "Epoch 1014/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4969 - accuracy: 0.8294 - val_loss: 0.5984 - val_accuracy: 0.7760\n",
      "Epoch 1015/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4968 - accuracy: 0.8288 - val_loss: 0.5984 - val_accuracy: 0.7751\n",
      "Epoch 1016/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4967 - accuracy: 0.8293 - val_loss: 0.5983 - val_accuracy: 0.7756\n",
      "Epoch 1017/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4967 - accuracy: 0.8290 - val_loss: 0.5983 - val_accuracy: 0.7753\n",
      "Epoch 1018/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4966 - accuracy: 0.8290 - val_loss: 0.5983 - val_accuracy: 0.7763\n",
      "Epoch 1019/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4965 - accuracy: 0.8289 - val_loss: 0.5983 - val_accuracy: 0.7758\n",
      "Epoch 1020/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4965 - accuracy: 0.8295 - val_loss: 0.5983 - val_accuracy: 0.7758\n",
      "Epoch 1021/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4964 - accuracy: 0.8293 - val_loss: 0.5983 - val_accuracy: 0.7756\n",
      "Epoch 1022/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4964 - accuracy: 0.8290 - val_loss: 0.5982 - val_accuracy: 0.7758\n",
      "Epoch 1023/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4963 - accuracy: 0.8294 - val_loss: 0.5982 - val_accuracy: 0.7763\n",
      "Epoch 1024/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4962 - accuracy: 0.8295 - val_loss: 0.5982 - val_accuracy: 0.7760\n",
      "Epoch 1025/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4961 - accuracy: 0.8293 - val_loss: 0.5983 - val_accuracy: 0.7758\n",
      "Epoch 1026/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.8292 - val_loss: 0.5982 - val_accuracy: 0.7756\n",
      "Epoch 1027/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4960 - accuracy: 0.8290 - val_loss: 0.5982 - val_accuracy: 0.7767\n",
      "Epoch 1028/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4960 - accuracy: 0.8290 - val_loss: 0.5981 - val_accuracy: 0.7763\n",
      "Epoch 1029/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4959 - accuracy: 0.8289 - val_loss: 0.5982 - val_accuracy: 0.7760\n",
      "Epoch 1030/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4958 - accuracy: 0.8291 - val_loss: 0.5982 - val_accuracy: 0.7758\n",
      "Epoch 1031/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4958 - accuracy: 0.8293 - val_loss: 0.5982 - val_accuracy: 0.7756\n",
      "Epoch 1032/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4957 - accuracy: 0.8293 - val_loss: 0.5981 - val_accuracy: 0.7765\n",
      "Epoch 1033/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4956 - accuracy: 0.8291 - val_loss: 0.5982 - val_accuracy: 0.7763\n",
      "Epoch 1034/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4956 - accuracy: 0.8291 - val_loss: 0.5982 - val_accuracy: 0.7753\n",
      "Epoch 1035/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4955 - accuracy: 0.8291 - val_loss: 0.5981 - val_accuracy: 0.7760\n",
      "Epoch 1036/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4955 - accuracy: 0.8294 - val_loss: 0.5980 - val_accuracy: 0.7760\n",
      "Epoch 1037/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4954 - accuracy: 0.8295 - val_loss: 0.5981 - val_accuracy: 0.7760\n",
      "Epoch 1038/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4953 - accuracy: 0.8295 - val_loss: 0.5980 - val_accuracy: 0.7751\n",
      "Epoch 1039/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4952 - accuracy: 0.8294 - val_loss: 0.5980 - val_accuracy: 0.7763\n",
      "Epoch 1040/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4952 - accuracy: 0.8295 - val_loss: 0.5980 - val_accuracy: 0.7758\n",
      "Epoch 1041/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.8298 - val_loss: 0.5979 - val_accuracy: 0.7765\n",
      "Epoch 1042/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4951 - accuracy: 0.8298 - val_loss: 0.5980 - val_accuracy: 0.7763\n",
      "Epoch 1043/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4950 - accuracy: 0.8290 - val_loss: 0.5979 - val_accuracy: 0.7763\n",
      "Epoch 1044/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4949 - accuracy: 0.8296 - val_loss: 0.5980 - val_accuracy: 0.7760\n",
      "Epoch 1045/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4949 - accuracy: 0.8290 - val_loss: 0.5980 - val_accuracy: 0.7751\n",
      "Epoch 1046/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4948 - accuracy: 0.8296 - val_loss: 0.5980 - val_accuracy: 0.7756\n",
      "Epoch 1047/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4948 - accuracy: 0.8294 - val_loss: 0.5980 - val_accuracy: 0.7758\n",
      "Epoch 1048/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4947 - accuracy: 0.8293 - val_loss: 0.5980 - val_accuracy: 0.7749\n",
      "Epoch 1049/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4946 - accuracy: 0.8294 - val_loss: 0.5979 - val_accuracy: 0.7767\n",
      "Epoch 1050/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4946 - accuracy: 0.8293 - val_loss: 0.5980 - val_accuracy: 0.7758\n",
      "Epoch 1051/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4945 - accuracy: 0.8297 - val_loss: 0.5979 - val_accuracy: 0.7763\n",
      "Epoch 1052/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4944 - accuracy: 0.8294 - val_loss: 0.5980 - val_accuracy: 0.7765\n",
      "Epoch 1053/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4944 - accuracy: 0.8293 - val_loss: 0.5979 - val_accuracy: 0.7758\n",
      "Epoch 1054/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4944 - accuracy: 0.8294 - val_loss: 0.5980 - val_accuracy: 0.7760\n",
      "Epoch 1055/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4943 - accuracy: 0.8294 - val_loss: 0.5980 - val_accuracy: 0.7751\n",
      "Epoch 1056/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4942 - accuracy: 0.8291 - val_loss: 0.5980 - val_accuracy: 0.7742\n",
      "Epoch 1057/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4941 - accuracy: 0.8295 - val_loss: 0.5979 - val_accuracy: 0.7751\n",
      "Epoch 1058/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4941 - accuracy: 0.8294 - val_loss: 0.5979 - val_accuracy: 0.7767\n",
      "Epoch 1059/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4940 - accuracy: 0.8294 - val_loss: 0.5979 - val_accuracy: 0.7763\n",
      "Epoch 1060/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4940 - accuracy: 0.8297 - val_loss: 0.5978 - val_accuracy: 0.7758\n",
      "Epoch 1061/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4939 - accuracy: 0.8294 - val_loss: 0.5978 - val_accuracy: 0.7760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1062/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4939 - accuracy: 0.8291 - val_loss: 0.5979 - val_accuracy: 0.7751\n",
      "Epoch 1063/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4938 - accuracy: 0.8301 - val_loss: 0.5979 - val_accuracy: 0.7747\n",
      "Epoch 1064/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4937 - accuracy: 0.8295 - val_loss: 0.5978 - val_accuracy: 0.7756\n",
      "Epoch 1065/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4937 - accuracy: 0.8294 - val_loss: 0.5979 - val_accuracy: 0.7749\n",
      "Epoch 1066/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4936 - accuracy: 0.8292 - val_loss: 0.5977 - val_accuracy: 0.7767\n",
      "Epoch 1067/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4935 - accuracy: 0.8290 - val_loss: 0.5979 - val_accuracy: 0.7753\n",
      "Epoch 1068/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4935 - accuracy: 0.8291 - val_loss: 0.5978 - val_accuracy: 0.7747\n",
      "Epoch 1069/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4934 - accuracy: 0.8294 - val_loss: 0.5979 - val_accuracy: 0.7749\n",
      "Epoch 1070/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4933 - accuracy: 0.8296 - val_loss: 0.5978 - val_accuracy: 0.7765\n",
      "Epoch 1071/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4934 - accuracy: 0.8294 - val_loss: 0.5978 - val_accuracy: 0.7749\n",
      "Epoch 1072/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4933 - accuracy: 0.8293 - val_loss: 0.5978 - val_accuracy: 0.7756\n",
      "Epoch 1073/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4932 - accuracy: 0.8297 - val_loss: 0.5978 - val_accuracy: 0.7758\n",
      "Epoch 1074/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4932 - accuracy: 0.8295 - val_loss: 0.5978 - val_accuracy: 0.7744\n",
      "Epoch 1075/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4931 - accuracy: 0.8296 - val_loss: 0.5978 - val_accuracy: 0.7756\n",
      "Epoch 1076/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4930 - accuracy: 0.8294 - val_loss: 0.5977 - val_accuracy: 0.7753\n",
      "Epoch 1077/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4930 - accuracy: 0.8291 - val_loss: 0.5978 - val_accuracy: 0.7744\n",
      "Epoch 1078/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.8297 - val_loss: 0.5978 - val_accuracy: 0.7749\n",
      "Epoch 1079/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4929 - accuracy: 0.8293 - val_loss: 0.5978 - val_accuracy: 0.7742\n",
      "Epoch 1080/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4928 - accuracy: 0.8295 - val_loss: 0.5978 - val_accuracy: 0.7737\n",
      "Epoch 1081/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4928 - accuracy: 0.8292 - val_loss: 0.5978 - val_accuracy: 0.7742\n",
      "Epoch 1082/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4927 - accuracy: 0.8294 - val_loss: 0.5977 - val_accuracy: 0.7747\n",
      "Epoch 1083/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4927 - accuracy: 0.8290 - val_loss: 0.5977 - val_accuracy: 0.7758\n",
      "Epoch 1084/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4926 - accuracy: 0.8297 - val_loss: 0.5977 - val_accuracy: 0.7747\n",
      "Epoch 1085/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4925 - accuracy: 0.8297 - val_loss: 0.5977 - val_accuracy: 0.7753\n",
      "Epoch 1086/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4925 - accuracy: 0.8301 - val_loss: 0.5976 - val_accuracy: 0.7760\n",
      "Epoch 1087/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4924 - accuracy: 0.8293 - val_loss: 0.5977 - val_accuracy: 0.7753\n",
      "Epoch 1088/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4923 - accuracy: 0.8292 - val_loss: 0.5976 - val_accuracy: 0.7751\n",
      "Epoch 1089/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.8292 - val_loss: 0.5976 - val_accuracy: 0.7751\n",
      "Epoch 1090/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.8296 - val_loss: 0.5977 - val_accuracy: 0.7740\n",
      "Epoch 1091/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4922 - accuracy: 0.8294 - val_loss: 0.5976 - val_accuracy: 0.7747\n",
      "Epoch 1092/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4921 - accuracy: 0.8293 - val_loss: 0.5976 - val_accuracy: 0.7756\n",
      "Epoch 1093/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4921 - accuracy: 0.8297 - val_loss: 0.5976 - val_accuracy: 0.7751\n",
      "Epoch 1094/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4921 - accuracy: 0.8293 - val_loss: 0.5976 - val_accuracy: 0.7751\n",
      "Epoch 1095/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4920 - accuracy: 0.8294 - val_loss: 0.5976 - val_accuracy: 0.7742\n",
      "Epoch 1096/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4919 - accuracy: 0.8298 - val_loss: 0.5976 - val_accuracy: 0.7737\n",
      "Epoch 1097/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4919 - accuracy: 0.8298 - val_loss: 0.5976 - val_accuracy: 0.7747\n",
      "Epoch 1098/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4918 - accuracy: 0.8297 - val_loss: 0.5976 - val_accuracy: 0.7749\n",
      "Epoch 1099/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4918 - accuracy: 0.8299 - val_loss: 0.5976 - val_accuracy: 0.7744\n",
      "Epoch 1100/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4917 - accuracy: 0.8298 - val_loss: 0.5976 - val_accuracy: 0.7747\n",
      "Epoch 1101/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4917 - accuracy: 0.8295 - val_loss: 0.5976 - val_accuracy: 0.7744\n",
      "Epoch 1102/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4916 - accuracy: 0.8293 - val_loss: 0.5975 - val_accuracy: 0.7749\n",
      "Epoch 1103/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4915 - accuracy: 0.8294 - val_loss: 0.5976 - val_accuracy: 0.7737\n",
      "Epoch 1104/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4915 - accuracy: 0.8291 - val_loss: 0.5976 - val_accuracy: 0.7742\n",
      "Epoch 1105/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4914 - accuracy: 0.8296 - val_loss: 0.5976 - val_accuracy: 0.7737\n",
      "Epoch 1106/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4914 - accuracy: 0.8300 - val_loss: 0.5975 - val_accuracy: 0.7751\n",
      "Epoch 1107/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4914 - accuracy: 0.8299 - val_loss: 0.5974 - val_accuracy: 0.7742\n",
      "Epoch 1108/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4913 - accuracy: 0.8296 - val_loss: 0.5975 - val_accuracy: 0.7742\n",
      "Epoch 1109/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4912 - accuracy: 0.8290 - val_loss: 0.5975 - val_accuracy: 0.7744\n",
      "Epoch 1110/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4912 - accuracy: 0.8292 - val_loss: 0.5976 - val_accuracy: 0.7735\n",
      "Epoch 1111/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4911 - accuracy: 0.8296 - val_loss: 0.5975 - val_accuracy: 0.7742\n",
      "Epoch 1112/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4911 - accuracy: 0.8294 - val_loss: 0.5975 - val_accuracy: 0.7744\n",
      "Epoch 1113/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4910 - accuracy: 0.8300 - val_loss: 0.5974 - val_accuracy: 0.7742\n",
      "Epoch 1114/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4910 - accuracy: 0.8296 - val_loss: 0.5974 - val_accuracy: 0.7753\n",
      "Epoch 1115/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.8294 - val_loss: 0.5975 - val_accuracy: 0.7751\n",
      "Epoch 1116/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4909 - accuracy: 0.8294 - val_loss: 0.5974 - val_accuracy: 0.7749\n",
      "Epoch 1117/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4908 - accuracy: 0.8294 - val_loss: 0.5975 - val_accuracy: 0.7742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1118/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4908 - accuracy: 0.8296 - val_loss: 0.5975 - val_accuracy: 0.7742\n",
      "Epoch 1119/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4907 - accuracy: 0.8298 - val_loss: 0.5973 - val_accuracy: 0.7747\n",
      "Epoch 1120/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4907 - accuracy: 0.8293 - val_loss: 0.5974 - val_accuracy: 0.7744\n",
      "Epoch 1121/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4906 - accuracy: 0.8303 - val_loss: 0.5974 - val_accuracy: 0.7749\n",
      "Epoch 1122/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4906 - accuracy: 0.8299 - val_loss: 0.5974 - val_accuracy: 0.7728\n",
      "Epoch 1123/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4905 - accuracy: 0.8297 - val_loss: 0.5973 - val_accuracy: 0.7756\n",
      "Epoch 1124/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4905 - accuracy: 0.8294 - val_loss: 0.5974 - val_accuracy: 0.7747\n",
      "Epoch 1125/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4904 - accuracy: 0.8294 - val_loss: 0.5973 - val_accuracy: 0.7751\n",
      "Epoch 1126/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.8296 - val_loss: 0.5974 - val_accuracy: 0.7740\n",
      "Epoch 1127/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4903 - accuracy: 0.8298 - val_loss: 0.5974 - val_accuracy: 0.7744\n",
      "Epoch 1128/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4903 - accuracy: 0.8294 - val_loss: 0.5973 - val_accuracy: 0.7740\n",
      "Epoch 1129/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4902 - accuracy: 0.8298 - val_loss: 0.5974 - val_accuracy: 0.7740\n",
      "Epoch 1130/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4902 - accuracy: 0.8299 - val_loss: 0.5973 - val_accuracy: 0.7740\n",
      "Epoch 1131/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4901 - accuracy: 0.8297 - val_loss: 0.5973 - val_accuracy: 0.7744\n",
      "Epoch 1132/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.8300 - val_loss: 0.5973 - val_accuracy: 0.7747\n",
      "Epoch 1133/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.8294 - val_loss: 0.5974 - val_accuracy: 0.7749\n",
      "Epoch 1134/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4900 - accuracy: 0.8293 - val_loss: 0.5973 - val_accuracy: 0.7735\n",
      "Epoch 1135/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4899 - accuracy: 0.8298 - val_loss: 0.5973 - val_accuracy: 0.7742\n",
      "Epoch 1136/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4898 - accuracy: 0.8299 - val_loss: 0.5973 - val_accuracy: 0.7740\n",
      "Epoch 1137/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4898 - accuracy: 0.8297 - val_loss: 0.5972 - val_accuracy: 0.7742\n",
      "Epoch 1138/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4897 - accuracy: 0.8296 - val_loss: 0.5973 - val_accuracy: 0.7737\n",
      "Epoch 1139/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4897 - accuracy: 0.8299 - val_loss: 0.5973 - val_accuracy: 0.7730\n",
      "Epoch 1140/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4896 - accuracy: 0.8305 - val_loss: 0.5972 - val_accuracy: 0.7747\n",
      "Epoch 1141/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4896 - accuracy: 0.8298 - val_loss: 0.5972 - val_accuracy: 0.7742\n",
      "Epoch 1142/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4895 - accuracy: 0.8298 - val_loss: 0.5972 - val_accuracy: 0.7744\n",
      "Epoch 1143/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4895 - accuracy: 0.8293 - val_loss: 0.5973 - val_accuracy: 0.7735\n",
      "Epoch 1144/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4894 - accuracy: 0.8302 - val_loss: 0.5972 - val_accuracy: 0.7742\n",
      "Epoch 1145/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4893 - accuracy: 0.8295 - val_loss: 0.5973 - val_accuracy: 0.7735\n",
      "Epoch 1146/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4893 - accuracy: 0.8297 - val_loss: 0.5973 - val_accuracy: 0.7737\n",
      "Epoch 1147/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4893 - accuracy: 0.8300 - val_loss: 0.5972 - val_accuracy: 0.7735\n",
      "Epoch 1148/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4892 - accuracy: 0.8293 - val_loss: 0.5972 - val_accuracy: 0.7740\n",
      "Epoch 1149/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4892 - accuracy: 0.8296 - val_loss: 0.5973 - val_accuracy: 0.7730\n",
      "Epoch 1150/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4891 - accuracy: 0.8302 - val_loss: 0.5972 - val_accuracy: 0.7737\n",
      "Epoch 1151/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4891 - accuracy: 0.8294 - val_loss: 0.5972 - val_accuracy: 0.7740\n",
      "Epoch 1152/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4890 - accuracy: 0.8299 - val_loss: 0.5972 - val_accuracy: 0.7737\n",
      "Epoch 1153/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4890 - accuracy: 0.8293 - val_loss: 0.5971 - val_accuracy: 0.7742\n",
      "Epoch 1154/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4889 - accuracy: 0.8295 - val_loss: 0.5971 - val_accuracy: 0.7735\n",
      "Epoch 1155/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4888 - accuracy: 0.8300 - val_loss: 0.5972 - val_accuracy: 0.7740\n",
      "Epoch 1156/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4888 - accuracy: 0.8296 - val_loss: 0.5972 - val_accuracy: 0.7737\n",
      "Epoch 1157/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4887 - accuracy: 0.8296 - val_loss: 0.5971 - val_accuracy: 0.7740\n",
      "Epoch 1158/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4887 - accuracy: 0.8296 - val_loss: 0.5972 - val_accuracy: 0.7733\n",
      "Epoch 1159/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4887 - accuracy: 0.8297 - val_loss: 0.5972 - val_accuracy: 0.7733\n",
      "Epoch 1160/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4886 - accuracy: 0.8294 - val_loss: 0.5972 - val_accuracy: 0.7733\n",
      "Epoch 1161/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4886 - accuracy: 0.8293 - val_loss: 0.5972 - val_accuracy: 0.7733\n",
      "Epoch 1162/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.8303 - val_loss: 0.5971 - val_accuracy: 0.7742\n",
      "Epoch 1163/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.8297 - val_loss: 0.5971 - val_accuracy: 0.7737\n",
      "Epoch 1164/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4884 - accuracy: 0.8295 - val_loss: 0.5972 - val_accuracy: 0.7730\n",
      "Epoch 1165/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4884 - accuracy: 0.8297 - val_loss: 0.5971 - val_accuracy: 0.7740\n",
      "Epoch 1166/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4884 - accuracy: 0.8298 - val_loss: 0.5972 - val_accuracy: 0.7737\n",
      "Epoch 1167/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4883 - accuracy: 0.8300 - val_loss: 0.5971 - val_accuracy: 0.7742\n",
      "Epoch 1168/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4882 - accuracy: 0.8297 - val_loss: 0.5971 - val_accuracy: 0.7740\n",
      "Epoch 1169/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4882 - accuracy: 0.8296 - val_loss: 0.5970 - val_accuracy: 0.7737\n",
      "Epoch 1170/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4881 - accuracy: 0.8296 - val_loss: 0.5970 - val_accuracy: 0.7737\n",
      "Epoch 1171/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4881 - accuracy: 0.8296 - val_loss: 0.5970 - val_accuracy: 0.7740\n",
      "Epoch 1172/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4880 - accuracy: 0.8295 - val_loss: 0.5970 - val_accuracy: 0.7742\n",
      "Epoch 1173/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4880 - accuracy: 0.8300 - val_loss: 0.5970 - val_accuracy: 0.7735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1174/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4879 - accuracy: 0.8294 - val_loss: 0.5970 - val_accuracy: 0.7740\n",
      "Epoch 1175/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4879 - accuracy: 0.8300 - val_loss: 0.5971 - val_accuracy: 0.7737\n",
      "Epoch 1176/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4878 - accuracy: 0.8301 - val_loss: 0.5970 - val_accuracy: 0.7740\n",
      "Epoch 1177/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4878 - accuracy: 0.8297 - val_loss: 0.5970 - val_accuracy: 0.7740\n",
      "Epoch 1178/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4878 - accuracy: 0.8295 - val_loss: 0.5970 - val_accuracy: 0.7744\n",
      "Epoch 1179/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4877 - accuracy: 0.8294 - val_loss: 0.5971 - val_accuracy: 0.7742\n",
      "Epoch 1180/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4877 - accuracy: 0.8298 - val_loss: 0.5971 - val_accuracy: 0.7724\n",
      "Epoch 1181/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4876 - accuracy: 0.8297 - val_loss: 0.5970 - val_accuracy: 0.7740\n",
      "Epoch 1182/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4876 - accuracy: 0.8298 - val_loss: 0.5970 - val_accuracy: 0.7742\n",
      "Epoch 1183/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4875 - accuracy: 0.8291 - val_loss: 0.5971 - val_accuracy: 0.7733\n",
      "Epoch 1184/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4875 - accuracy: 0.8304 - val_loss: 0.5970 - val_accuracy: 0.7740\n",
      "Epoch 1185/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4874 - accuracy: 0.8297 - val_loss: 0.5970 - val_accuracy: 0.7740\n",
      "Epoch 1186/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4874 - accuracy: 0.8301 - val_loss: 0.5969 - val_accuracy: 0.7737\n",
      "Epoch 1187/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4873 - accuracy: 0.8296 - val_loss: 0.5969 - val_accuracy: 0.7740\n",
      "Epoch 1188/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4873 - accuracy: 0.8297 - val_loss: 0.5969 - val_accuracy: 0.7742\n",
      "Epoch 1189/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4872 - accuracy: 0.8296 - val_loss: 0.5969 - val_accuracy: 0.7744\n",
      "Epoch 1190/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4872 - accuracy: 0.8292 - val_loss: 0.5969 - val_accuracy: 0.7742\n",
      "Epoch 1191/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4872 - accuracy: 0.8298 - val_loss: 0.5969 - val_accuracy: 0.7740\n",
      "Epoch 1192/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4871 - accuracy: 0.8294 - val_loss: 0.5969 - val_accuracy: 0.7742\n",
      "Epoch 1193/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4871 - accuracy: 0.8300 - val_loss: 0.5969 - val_accuracy: 0.7744\n",
      "Epoch 1194/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4870 - accuracy: 0.8300 - val_loss: 0.5969 - val_accuracy: 0.7742\n",
      "Epoch 1195/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4870 - accuracy: 0.8302 - val_loss: 0.5969 - val_accuracy: 0.7744\n",
      "Epoch 1196/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4869 - accuracy: 0.8298 - val_loss: 0.5969 - val_accuracy: 0.7740\n",
      "Epoch 1197/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4869 - accuracy: 0.8299 - val_loss: 0.5968 - val_accuracy: 0.7742\n",
      "Epoch 1198/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.8296 - val_loss: 0.5969 - val_accuracy: 0.7740\n",
      "Epoch 1199/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4868 - accuracy: 0.8293 - val_loss: 0.5969 - val_accuracy: 0.7742\n",
      "Epoch 1200/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.8302 - val_loss: 0.5969 - val_accuracy: 0.7740\n",
      "Epoch 1201/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4867 - accuracy: 0.8298 - val_loss: 0.5968 - val_accuracy: 0.7735\n",
      "Epoch 1202/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4867 - accuracy: 0.8298 - val_loss: 0.5969 - val_accuracy: 0.7742\n",
      "Epoch 1203/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4866 - accuracy: 0.8303 - val_loss: 0.5969 - val_accuracy: 0.7733\n",
      "Epoch 1204/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4866 - accuracy: 0.8300 - val_loss: 0.5969 - val_accuracy: 0.7749\n",
      "Epoch 1205/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4865 - accuracy: 0.8304 - val_loss: 0.5968 - val_accuracy: 0.7740\n",
      "Epoch 1206/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4865 - accuracy: 0.8301 - val_loss: 0.5969 - val_accuracy: 0.7740\n",
      "Epoch 1207/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4865 - accuracy: 0.8295 - val_loss: 0.5968 - val_accuracy: 0.7737\n",
      "Epoch 1208/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4864 - accuracy: 0.8296 - val_loss: 0.5969 - val_accuracy: 0.7737\n",
      "Epoch 1209/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4864 - accuracy: 0.8302 - val_loss: 0.5968 - val_accuracy: 0.7735\n",
      "Epoch 1210/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4863 - accuracy: 0.8300 - val_loss: 0.5968 - val_accuracy: 0.7740\n",
      "Epoch 1211/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4863 - accuracy: 0.8300 - val_loss: 0.5969 - val_accuracy: 0.7728\n",
      "Epoch 1212/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4863 - accuracy: 0.8304 - val_loss: 0.5969 - val_accuracy: 0.7737\n",
      "Epoch 1213/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4862 - accuracy: 0.8302 - val_loss: 0.5968 - val_accuracy: 0.7744\n",
      "Epoch 1214/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4862 - accuracy: 0.8301 - val_loss: 0.5968 - val_accuracy: 0.7735\n",
      "Epoch 1215/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.8297 - val_loss: 0.5968 - val_accuracy: 0.7730\n",
      "Epoch 1216/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4861 - accuracy: 0.8302 - val_loss: 0.5968 - val_accuracy: 0.7740\n",
      "Epoch 1217/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4860 - accuracy: 0.8296 - val_loss: 0.5968 - val_accuracy: 0.7740\n",
      "Epoch 1218/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4860 - accuracy: 0.8298 - val_loss: 0.5968 - val_accuracy: 0.7730\n",
      "Epoch 1219/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4859 - accuracy: 0.8298 - val_loss: 0.5968 - val_accuracy: 0.7733\n",
      "Epoch 1220/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4859 - accuracy: 0.8300 - val_loss: 0.5968 - val_accuracy: 0.7737\n",
      "Epoch 1221/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4859 - accuracy: 0.8302 - val_loss: 0.5968 - val_accuracy: 0.7735\n",
      "Epoch 1222/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4858 - accuracy: 0.8299 - val_loss: 0.5968 - val_accuracy: 0.7740\n",
      "Epoch 1223/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4858 - accuracy: 0.8301 - val_loss: 0.5968 - val_accuracy: 0.7730\n",
      "Epoch 1224/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4857 - accuracy: 0.8299 - val_loss: 0.5968 - val_accuracy: 0.7733\n",
      "Epoch 1225/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4857 - accuracy: 0.8296 - val_loss: 0.5968 - val_accuracy: 0.7735\n",
      "Epoch 1226/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4857 - accuracy: 0.8302 - val_loss: 0.5968 - val_accuracy: 0.7724\n",
      "Epoch 1227/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4856 - accuracy: 0.8303 - val_loss: 0.5967 - val_accuracy: 0.7747\n",
      "Epoch 1228/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4856 - accuracy: 0.8301 - val_loss: 0.5967 - val_accuracy: 0.7737\n",
      "Epoch 1229/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4855 - accuracy: 0.8298 - val_loss: 0.5967 - val_accuracy: 0.7737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1230/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4855 - accuracy: 0.8300 - val_loss: 0.5967 - val_accuracy: 0.7740\n",
      "Epoch 1231/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4855 - accuracy: 0.8297 - val_loss: 0.5968 - val_accuracy: 0.7726\n",
      "Epoch 1232/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4854 - accuracy: 0.8304 - val_loss: 0.5967 - val_accuracy: 0.7740\n",
      "Epoch 1233/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4854 - accuracy: 0.8303 - val_loss: 0.5967 - val_accuracy: 0.7742\n",
      "Epoch 1234/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4853 - accuracy: 0.8300 - val_loss: 0.5967 - val_accuracy: 0.7747\n",
      "Epoch 1235/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4853 - accuracy: 0.8301 - val_loss: 0.5968 - val_accuracy: 0.7735\n",
      "Epoch 1236/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.8302 - val_loss: 0.5967 - val_accuracy: 0.7747\n",
      "Epoch 1237/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4852 - accuracy: 0.8301 - val_loss: 0.5969 - val_accuracy: 0.7733\n",
      "Epoch 1238/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4852 - accuracy: 0.8300 - val_loss: 0.5968 - val_accuracy: 0.7740\n",
      "Epoch 1239/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4851 - accuracy: 0.8304 - val_loss: 0.5968 - val_accuracy: 0.7726\n",
      "Epoch 1240/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4851 - accuracy: 0.8303 - val_loss: 0.5967 - val_accuracy: 0.7737\n",
      "Epoch 1241/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4850 - accuracy: 0.8302 - val_loss: 0.5967 - val_accuracy: 0.7744\n",
      "Epoch 1242/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4850 - accuracy: 0.8305 - val_loss: 0.5967 - val_accuracy: 0.7740\n",
      "Epoch 1243/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.8307 - val_loss: 0.5968 - val_accuracy: 0.7728\n",
      "Epoch 1244/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4849 - accuracy: 0.8301 - val_loss: 0.5967 - val_accuracy: 0.7735\n",
      "Epoch 1245/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4849 - accuracy: 0.8306 - val_loss: 0.5967 - val_accuracy: 0.7747\n",
      "Epoch 1246/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4849 - accuracy: 0.8304 - val_loss: 0.5966 - val_accuracy: 0.7749\n",
      "Epoch 1247/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4848 - accuracy: 0.8304 - val_loss: 0.5967 - val_accuracy: 0.7737\n",
      "Epoch 1248/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4848 - accuracy: 0.8306 - val_loss: 0.5968 - val_accuracy: 0.7742\n",
      "Epoch 1249/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4847 - accuracy: 0.8305 - val_loss: 0.5967 - val_accuracy: 0.7751\n",
      "Epoch 1250/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4847 - accuracy: 0.8301 - val_loss: 0.5967 - val_accuracy: 0.7740\n",
      "Epoch 1251/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4846 - accuracy: 0.8303 - val_loss: 0.5968 - val_accuracy: 0.7742\n",
      "Epoch 1252/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4846 - accuracy: 0.8302 - val_loss: 0.5967 - val_accuracy: 0.7751\n",
      "Epoch 1253/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4846 - accuracy: 0.8302 - val_loss: 0.5968 - val_accuracy: 0.7749\n",
      "Epoch 1254/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4845 - accuracy: 0.8304 - val_loss: 0.5966 - val_accuracy: 0.7749\n",
      "Epoch 1255/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4845 - accuracy: 0.8300 - val_loss: 0.5967 - val_accuracy: 0.7747\n",
      "Epoch 1256/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4845 - accuracy: 0.8302 - val_loss: 0.5968 - val_accuracy: 0.7737\n",
      "Epoch 1257/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4844 - accuracy: 0.8304 - val_loss: 0.5967 - val_accuracy: 0.7740\n",
      "Epoch 1258/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4844 - accuracy: 0.8303 - val_loss: 0.5967 - val_accuracy: 0.7753\n",
      "Epoch 1259/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4843 - accuracy: 0.8302 - val_loss: 0.5967 - val_accuracy: 0.7749\n",
      "Epoch 1260/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4843 - accuracy: 0.8305 - val_loss: 0.5967 - val_accuracy: 0.7737\n",
      "Epoch 1261/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4842 - accuracy: 0.8305 - val_loss: 0.5968 - val_accuracy: 0.7737\n",
      "Epoch 1262/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4842 - accuracy: 0.8308 - val_loss: 0.5967 - val_accuracy: 0.7747\n",
      "Epoch 1263/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4842 - accuracy: 0.8296 - val_loss: 0.5967 - val_accuracy: 0.7742\n",
      "Epoch 1264/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4841 - accuracy: 0.8303 - val_loss: 0.5967 - val_accuracy: 0.7744\n",
      "Epoch 1265/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4841 - accuracy: 0.8306 - val_loss: 0.5967 - val_accuracy: 0.7749\n",
      "Epoch 1266/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4841 - accuracy: 0.8302 - val_loss: 0.5967 - val_accuracy: 0.7751\n",
      "Epoch 1267/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.8306 - val_loss: 0.5966 - val_accuracy: 0.7758\n",
      "Epoch 1268/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4840 - accuracy: 0.8301 - val_loss: 0.5967 - val_accuracy: 0.7744\n",
      "Epoch 1269/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4839 - accuracy: 0.8306 - val_loss: 0.5967 - val_accuracy: 0.7749\n",
      "Epoch 1270/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4839 - accuracy: 0.8306 - val_loss: 0.5966 - val_accuracy: 0.7756\n",
      "Epoch 1271/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4839 - accuracy: 0.8310 - val_loss: 0.5967 - val_accuracy: 0.7744\n",
      "Epoch 1272/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4838 - accuracy: 0.8306 - val_loss: 0.5967 - val_accuracy: 0.7737\n",
      "Epoch 1273/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.8305 - val_loss: 0.5967 - val_accuracy: 0.7740\n",
      "Epoch 1274/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4837 - accuracy: 0.8307 - val_loss: 0.5966 - val_accuracy: 0.7744\n",
      "Epoch 1275/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4837 - accuracy: 0.8306 - val_loss: 0.5967 - val_accuracy: 0.7740\n",
      "Epoch 1276/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4837 - accuracy: 0.8309 - val_loss: 0.5967 - val_accuracy: 0.7740\n",
      "Epoch 1277/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4837 - accuracy: 0.8310 - val_loss: 0.5966 - val_accuracy: 0.7756\n",
      "Epoch 1278/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4836 - accuracy: 0.8308 - val_loss: 0.5967 - val_accuracy: 0.7742\n",
      "Epoch 1279/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4836 - accuracy: 0.8303 - val_loss: 0.5967 - val_accuracy: 0.7749\n",
      "Epoch 1280/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4835 - accuracy: 0.8306 - val_loss: 0.5967 - val_accuracy: 0.7742\n",
      "Epoch 1281/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4835 - accuracy: 0.8302 - val_loss: 0.5967 - val_accuracy: 0.7744\n",
      "Epoch 1282/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4834 - accuracy: 0.8303 - val_loss: 0.5967 - val_accuracy: 0.7733\n",
      "Epoch 1283/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4834 - accuracy: 0.8308 - val_loss: 0.5967 - val_accuracy: 0.7733\n",
      "Epoch 1284/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4834 - accuracy: 0.8304 - val_loss: 0.5967 - val_accuracy: 0.7737\n",
      "Epoch 1285/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4834 - accuracy: 0.8306 - val_loss: 0.5966 - val_accuracy: 0.7747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1286/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4833 - accuracy: 0.8306 - val_loss: 0.5967 - val_accuracy: 0.7744\n",
      "Epoch 1287/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4833 - accuracy: 0.8308 - val_loss: 0.5967 - val_accuracy: 0.7749\n",
      "Epoch 1288/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4832 - accuracy: 0.8305 - val_loss: 0.5967 - val_accuracy: 0.7749\n",
      "Epoch 1289/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4832 - accuracy: 0.8303 - val_loss: 0.5966 - val_accuracy: 0.7744\n",
      "Epoch 1290/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4832 - accuracy: 0.8306 - val_loss: 0.5966 - val_accuracy: 0.7749\n",
      "Epoch 1291/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4831 - accuracy: 0.8305 - val_loss: 0.5966 - val_accuracy: 0.7751\n",
      "Epoch 1292/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4831 - accuracy: 0.8308 - val_loss: 0.5967 - val_accuracy: 0.7747\n",
      "Epoch 1293/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4830 - accuracy: 0.8307 - val_loss: 0.5966 - val_accuracy: 0.7747\n",
      "Epoch 1294/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4830 - accuracy: 0.8304 - val_loss: 0.5967 - val_accuracy: 0.7742\n",
      "Epoch 1295/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4830 - accuracy: 0.8308 - val_loss: 0.5967 - val_accuracy: 0.7744\n",
      "Epoch 1296/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4829 - accuracy: 0.8306 - val_loss: 0.5967 - val_accuracy: 0.7749\n",
      "Epoch 1297/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4829 - accuracy: 0.8305 - val_loss: 0.5966 - val_accuracy: 0.7744\n",
      "Epoch 1298/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4828 - accuracy: 0.8310 - val_loss: 0.5966 - val_accuracy: 0.7749\n",
      "Epoch 1299/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4828 - accuracy: 0.8304 - val_loss: 0.5966 - val_accuracy: 0.7749\n",
      "Epoch 1300/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4828 - accuracy: 0.8308 - val_loss: 0.5966 - val_accuracy: 0.7742\n",
      "Epoch 1301/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4827 - accuracy: 0.8308 - val_loss: 0.5967 - val_accuracy: 0.7742\n",
      "Epoch 1302/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4827 - accuracy: 0.8310 - val_loss: 0.5967 - val_accuracy: 0.7749\n",
      "Epoch 1303/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.8306 - val_loss: 0.5967 - val_accuracy: 0.7751\n",
      "Epoch 1304/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4826 - accuracy: 0.8309 - val_loss: 0.5966 - val_accuracy: 0.7749\n",
      "Epoch 1305/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4826 - accuracy: 0.8305 - val_loss: 0.5966 - val_accuracy: 0.7742\n",
      "Epoch 1306/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4826 - accuracy: 0.8307 - val_loss: 0.5967 - val_accuracy: 0.7733\n",
      "Epoch 1307/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4825 - accuracy: 0.8312 - val_loss: 0.5966 - val_accuracy: 0.7740\n",
      "Epoch 1308/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4825 - accuracy: 0.8310 - val_loss: 0.5966 - val_accuracy: 0.7742\n",
      "Epoch 1309/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4824 - accuracy: 0.8306 - val_loss: 0.5966 - val_accuracy: 0.7751\n",
      "Epoch 1310/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4824 - accuracy: 0.8308 - val_loss: 0.5966 - val_accuracy: 0.7751\n",
      "Epoch 1311/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4824 - accuracy: 0.8306 - val_loss: 0.5967 - val_accuracy: 0.7751\n",
      "Epoch 1312/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.8300 - val_loss: 0.5966 - val_accuracy: 0.7742\n",
      "Epoch 1313/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4823 - accuracy: 0.8306 - val_loss: 0.5967 - val_accuracy: 0.7744\n",
      "Epoch 1314/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4823 - accuracy: 0.8306 - val_loss: 0.5966 - val_accuracy: 0.7740\n",
      "Epoch 1315/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4822 - accuracy: 0.8310 - val_loss: 0.5965 - val_accuracy: 0.7744\n",
      "Epoch 1316/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4822 - accuracy: 0.8304 - val_loss: 0.5965 - val_accuracy: 0.7744\n",
      "Epoch 1317/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4822 - accuracy: 0.8308 - val_loss: 0.5966 - val_accuracy: 0.7740\n",
      "Epoch 1318/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.8304 - val_loss: 0.5966 - val_accuracy: 0.7742\n",
      "Epoch 1319/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.8307 - val_loss: 0.5966 - val_accuracy: 0.7737\n",
      "Epoch 1320/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4820 - accuracy: 0.8309 - val_loss: 0.5966 - val_accuracy: 0.7740\n",
      "Epoch 1321/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4820 - accuracy: 0.8310 - val_loss: 0.5965 - val_accuracy: 0.7742\n",
      "Epoch 1322/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4820 - accuracy: 0.8308 - val_loss: 0.5966 - val_accuracy: 0.7740\n",
      "Epoch 1323/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4820 - accuracy: 0.8305 - val_loss: 0.5966 - val_accuracy: 0.7740\n",
      "Epoch 1324/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4819 - accuracy: 0.8308 - val_loss: 0.5967 - val_accuracy: 0.7740\n",
      "Epoch 1325/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4819 - accuracy: 0.8310 - val_loss: 0.5966 - val_accuracy: 0.7742\n",
      "Epoch 1326/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4818 - accuracy: 0.8311 - val_loss: 0.5967 - val_accuracy: 0.7737\n",
      "Epoch 1327/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4818 - accuracy: 0.8310 - val_loss: 0.5965 - val_accuracy: 0.7735\n",
      "Epoch 1328/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4818 - accuracy: 0.8310 - val_loss: 0.5965 - val_accuracy: 0.7744\n",
      "Epoch 1329/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4817 - accuracy: 0.8310 - val_loss: 0.5966 - val_accuracy: 0.7737\n",
      "Epoch 1330/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4817 - accuracy: 0.8311 - val_loss: 0.5965 - val_accuracy: 0.7735\n",
      "Epoch 1331/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4817 - accuracy: 0.8309 - val_loss: 0.5966 - val_accuracy: 0.7744\n",
      "Epoch 1332/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4816 - accuracy: 0.8309 - val_loss: 0.5966 - val_accuracy: 0.7740\n",
      "Epoch 1333/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.8312 - val_loss: 0.5966 - val_accuracy: 0.7749\n",
      "Epoch 1334/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4816 - accuracy: 0.8314 - val_loss: 0.5966 - val_accuracy: 0.7740\n",
      "Epoch 1335/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4816 - accuracy: 0.8315 - val_loss: 0.5967 - val_accuracy: 0.7737\n",
      "Epoch 1336/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.8307 - val_loss: 0.5965 - val_accuracy: 0.7737\n",
      "Epoch 1337/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.8310 - val_loss: 0.5967 - val_accuracy: 0.7740\n",
      "Epoch 1338/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4814 - accuracy: 0.8313 - val_loss: 0.5966 - val_accuracy: 0.7747\n",
      "Epoch 1339/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4814 - accuracy: 0.8308 - val_loss: 0.5965 - val_accuracy: 0.7749\n",
      "Epoch 1340/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.8309 - val_loss: 0.5966 - val_accuracy: 0.7740\n",
      "Epoch 1341/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.8316 - val_loss: 0.5967 - val_accuracy: 0.7737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1342/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.8315 - val_loss: 0.5966 - val_accuracy: 0.7740\n",
      "Epoch 1343/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4812 - accuracy: 0.8309 - val_loss: 0.5966 - val_accuracy: 0.7737\n",
      "Epoch 1344/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4812 - accuracy: 0.8312 - val_loss: 0.5966 - val_accuracy: 0.7737\n",
      "Epoch 1345/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4812 - accuracy: 0.8313 - val_loss: 0.5966 - val_accuracy: 0.7733\n",
      "Epoch 1346/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4812 - accuracy: 0.8312 - val_loss: 0.5966 - val_accuracy: 0.7735\n",
      "Epoch 1347/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4811 - accuracy: 0.8312 - val_loss: 0.5966 - val_accuracy: 0.7737\n",
      "Epoch 1348/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4811 - accuracy: 0.8310 - val_loss: 0.5965 - val_accuracy: 0.7740\n",
      "Epoch 1349/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4811 - accuracy: 0.8309 - val_loss: 0.5966 - val_accuracy: 0.7742\n",
      "Epoch 1350/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4810 - accuracy: 0.8310 - val_loss: 0.5967 - val_accuracy: 0.7735\n",
      "Epoch 1351/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4810 - accuracy: 0.8312 - val_loss: 0.5966 - val_accuracy: 0.7742\n",
      "Epoch 1352/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4810 - accuracy: 0.8315 - val_loss: 0.5965 - val_accuracy: 0.7735\n",
      "Epoch 1353/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4809 - accuracy: 0.8313 - val_loss: 0.5966 - val_accuracy: 0.7742\n",
      "Epoch 1354/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4809 - accuracy: 0.8308 - val_loss: 0.5966 - val_accuracy: 0.7735\n",
      "Epoch 1355/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4809 - accuracy: 0.8316 - val_loss: 0.5966 - val_accuracy: 0.7751\n",
      "Epoch 1356/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4808 - accuracy: 0.8313 - val_loss: 0.5966 - val_accuracy: 0.7742\n",
      "Epoch 1357/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4808 - accuracy: 0.8312 - val_loss: 0.5966 - val_accuracy: 0.7747\n",
      "Epoch 1358/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4808 - accuracy: 0.8313 - val_loss: 0.5966 - val_accuracy: 0.7744\n",
      "Epoch 1359/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4807 - accuracy: 0.8316 - val_loss: 0.5966 - val_accuracy: 0.7737\n",
      "Epoch 1360/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4807 - accuracy: 0.8314 - val_loss: 0.5966 - val_accuracy: 0.7737\n",
      "Epoch 1361/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4807 - accuracy: 0.8313 - val_loss: 0.5967 - val_accuracy: 0.7737\n",
      "Epoch 1362/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4806 - accuracy: 0.8316 - val_loss: 0.5966 - val_accuracy: 0.7742\n",
      "Epoch 1363/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4806 - accuracy: 0.8313 - val_loss: 0.5966 - val_accuracy: 0.7744\n",
      "Epoch 1364/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4805 - accuracy: 0.8314 - val_loss: 0.5967 - val_accuracy: 0.7737\n",
      "Epoch 1365/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4806 - accuracy: 0.8311 - val_loss: 0.5965 - val_accuracy: 0.7737\n",
      "Epoch 1366/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4805 - accuracy: 0.8315 - val_loss: 0.5966 - val_accuracy: 0.7730\n",
      "Epoch 1367/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4804 - accuracy: 0.8317 - val_loss: 0.5965 - val_accuracy: 0.7747\n",
      "Epoch 1368/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4804 - accuracy: 0.8310 - val_loss: 0.5965 - val_accuracy: 0.7747\n",
      "Epoch 1369/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4804 - accuracy: 0.8317 - val_loss: 0.5966 - val_accuracy: 0.7742\n",
      "Epoch 1370/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4803 - accuracy: 0.8312 - val_loss: 0.5966 - val_accuracy: 0.7744\n",
      "Epoch 1371/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4803 - accuracy: 0.8313 - val_loss: 0.5966 - val_accuracy: 0.7751\n",
      "Epoch 1372/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4803 - accuracy: 0.8314 - val_loss: 0.5966 - val_accuracy: 0.7747\n",
      "Epoch 1373/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4803 - accuracy: 0.8318 - val_loss: 0.5965 - val_accuracy: 0.7737\n",
      "Epoch 1374/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4802 - accuracy: 0.8310 - val_loss: 0.5966 - val_accuracy: 0.7740\n",
      "Epoch 1375/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4802 - accuracy: 0.8318 - val_loss: 0.5966 - val_accuracy: 0.7740\n",
      "Epoch 1376/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4802 - accuracy: 0.8311 - val_loss: 0.5966 - val_accuracy: 0.7742\n",
      "Epoch 1377/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4801 - accuracy: 0.8315 - val_loss: 0.5966 - val_accuracy: 0.7737\n",
      "Epoch 1378/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4801 - accuracy: 0.8316 - val_loss: 0.5966 - val_accuracy: 0.7742\n",
      "Epoch 1379/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4800 - accuracy: 0.8312 - val_loss: 0.5966 - val_accuracy: 0.7744\n",
      "Epoch 1380/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.8316 - val_loss: 0.5965 - val_accuracy: 0.7742\n",
      "Epoch 1381/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4800 - accuracy: 0.8315 - val_loss: 0.5965 - val_accuracy: 0.7742\n",
      "Epoch 1382/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4799 - accuracy: 0.8317 - val_loss: 0.5965 - val_accuracy: 0.7737\n",
      "Epoch 1383/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.8317 - val_loss: 0.5966 - val_accuracy: 0.7730\n",
      "Epoch 1384/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4799 - accuracy: 0.8315 - val_loss: 0.5966 - val_accuracy: 0.7740\n",
      "Epoch 1385/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4798 - accuracy: 0.8315 - val_loss: 0.5966 - val_accuracy: 0.7737\n",
      "Epoch 1386/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4799 - accuracy: 0.8312 - val_loss: 0.5966 - val_accuracy: 0.7740\n",
      "Epoch 1387/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4798 - accuracy: 0.8316 - val_loss: 0.5966 - val_accuracy: 0.7740\n",
      "Epoch 1388/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4798 - accuracy: 0.8316 - val_loss: 0.5966 - val_accuracy: 0.7740\n",
      "Epoch 1389/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4797 - accuracy: 0.8321 - val_loss: 0.5965 - val_accuracy: 0.7735\n",
      "Epoch 1390/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4797 - accuracy: 0.8313 - val_loss: 0.5966 - val_accuracy: 0.7740\n",
      "Epoch 1391/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4797 - accuracy: 0.8317 - val_loss: 0.5965 - val_accuracy: 0.7740\n",
      "Epoch 1392/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4796 - accuracy: 0.8313 - val_loss: 0.5965 - val_accuracy: 0.7740\n",
      "Epoch 1393/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4796 - accuracy: 0.8312 - val_loss: 0.5965 - val_accuracy: 0.7740\n",
      "Epoch 1394/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4796 - accuracy: 0.8316 - val_loss: 0.5965 - val_accuracy: 0.7740\n",
      "Epoch 1395/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4796 - accuracy: 0.8318 - val_loss: 0.5965 - val_accuracy: 0.7737\n",
      "Epoch 1396/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4795 - accuracy: 0.8317 - val_loss: 0.5965 - val_accuracy: 0.7735\n",
      "Epoch 1397/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4795 - accuracy: 0.8314 - val_loss: 0.5966 - val_accuracy: 0.7740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1398/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.8319 - val_loss: 0.5965 - val_accuracy: 0.7735\n",
      "Epoch 1399/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.8316 - val_loss: 0.5965 - val_accuracy: 0.7737\n",
      "Epoch 1400/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4794 - accuracy: 0.8315 - val_loss: 0.5964 - val_accuracy: 0.7737\n",
      "Epoch 1401/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4794 - accuracy: 0.8316 - val_loss: 0.5964 - val_accuracy: 0.7735\n",
      "Epoch 1402/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.8319 - val_loss: 0.5964 - val_accuracy: 0.7735\n",
      "Epoch 1403/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.8313 - val_loss: 0.5964 - val_accuracy: 0.7737\n",
      "Epoch 1404/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4793 - accuracy: 0.8316 - val_loss: 0.5964 - val_accuracy: 0.7730\n",
      "Epoch 1405/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4792 - accuracy: 0.8316 - val_loss: 0.5964 - val_accuracy: 0.7737\n",
      "Epoch 1406/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4792 - accuracy: 0.8312 - val_loss: 0.5964 - val_accuracy: 0.7742\n",
      "Epoch 1407/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4792 - accuracy: 0.8313 - val_loss: 0.5964 - val_accuracy: 0.7737\n",
      "Epoch 1408/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4792 - accuracy: 0.8319 - val_loss: 0.5964 - val_accuracy: 0.7737\n",
      "Epoch 1409/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4791 - accuracy: 0.8313 - val_loss: 0.5965 - val_accuracy: 0.7737\n",
      "Epoch 1410/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4791 - accuracy: 0.8315 - val_loss: 0.5965 - val_accuracy: 0.7735\n",
      "Epoch 1411/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4790 - accuracy: 0.8318 - val_loss: 0.5964 - val_accuracy: 0.7737\n",
      "Epoch 1412/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4790 - accuracy: 0.8311 - val_loss: 0.5965 - val_accuracy: 0.7740\n",
      "Epoch 1413/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4790 - accuracy: 0.8321 - val_loss: 0.5964 - val_accuracy: 0.7742\n",
      "Epoch 1414/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4789 - accuracy: 0.8317 - val_loss: 0.5965 - val_accuracy: 0.7737\n",
      "Epoch 1415/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.8320 - val_loss: 0.5964 - val_accuracy: 0.7742\n",
      "Epoch 1416/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4789 - accuracy: 0.8321 - val_loss: 0.5964 - val_accuracy: 0.7742\n",
      "Epoch 1417/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4788 - accuracy: 0.8317 - val_loss: 0.5965 - val_accuracy: 0.7740\n",
      "Epoch 1418/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4788 - accuracy: 0.8314 - val_loss: 0.5965 - val_accuracy: 0.7742\n",
      "Epoch 1419/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4788 - accuracy: 0.8319 - val_loss: 0.5965 - val_accuracy: 0.7744\n",
      "Epoch 1420/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4788 - accuracy: 0.8317 - val_loss: 0.5964 - val_accuracy: 0.7737\n",
      "Epoch 1421/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4787 - accuracy: 0.8318 - val_loss: 0.5965 - val_accuracy: 0.7737\n",
      "Epoch 1422/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4787 - accuracy: 0.8320 - val_loss: 0.5965 - val_accuracy: 0.7740\n",
      "Epoch 1423/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4787 - accuracy: 0.8313 - val_loss: 0.5964 - val_accuracy: 0.7742\n",
      "Epoch 1424/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4787 - accuracy: 0.8312 - val_loss: 0.5965 - val_accuracy: 0.7737\n",
      "Epoch 1425/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4786 - accuracy: 0.8321 - val_loss: 0.5965 - val_accuracy: 0.7744\n",
      "Epoch 1426/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4786 - accuracy: 0.8316 - val_loss: 0.5965 - val_accuracy: 0.7742\n",
      "Epoch 1427/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4786 - accuracy: 0.8319 - val_loss: 0.5965 - val_accuracy: 0.7737\n",
      "Epoch 1428/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4786 - accuracy: 0.8319 - val_loss: 0.5965 - val_accuracy: 0.7742\n",
      "Epoch 1429/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4785 - accuracy: 0.8316 - val_loss: 0.5966 - val_accuracy: 0.7735\n",
      "Epoch 1430/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4785 - accuracy: 0.8316 - val_loss: 0.5966 - val_accuracy: 0.7735\n",
      "Epoch 1431/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4785 - accuracy: 0.8317 - val_loss: 0.5965 - val_accuracy: 0.7733\n",
      "Epoch 1432/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4784 - accuracy: 0.8319 - val_loss: 0.5965 - val_accuracy: 0.7742\n",
      "Epoch 1433/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4784 - accuracy: 0.8316 - val_loss: 0.5964 - val_accuracy: 0.7740\n",
      "Epoch 1434/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4783 - accuracy: 0.8318 - val_loss: 0.5965 - val_accuracy: 0.7737\n",
      "Epoch 1435/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4783 - accuracy: 0.8317 - val_loss: 0.5965 - val_accuracy: 0.7737\n",
      "Epoch 1436/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4783 - accuracy: 0.8312 - val_loss: 0.5965 - val_accuracy: 0.7737\n",
      "Epoch 1437/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4783 - accuracy: 0.8315 - val_loss: 0.5965 - val_accuracy: 0.7742\n",
      "Epoch 1438/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4783 - accuracy: 0.8321 - val_loss: 0.5965 - val_accuracy: 0.7749\n",
      "Epoch 1439/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4782 - accuracy: 0.8319 - val_loss: 0.5964 - val_accuracy: 0.7740\n",
      "Epoch 1440/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4782 - accuracy: 0.8312 - val_loss: 0.5965 - val_accuracy: 0.7740\n",
      "Epoch 1441/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4782 - accuracy: 0.8317 - val_loss: 0.5965 - val_accuracy: 0.7737\n",
      "Epoch 1442/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4781 - accuracy: 0.8321 - val_loss: 0.5965 - val_accuracy: 0.7740\n",
      "Epoch 1443/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4781 - accuracy: 0.8315 - val_loss: 0.5965 - val_accuracy: 0.7749\n",
      "Epoch 1444/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4781 - accuracy: 0.8321 - val_loss: 0.5965 - val_accuracy: 0.7744\n",
      "Epoch 1445/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4780 - accuracy: 0.8320 - val_loss: 0.5966 - val_accuracy: 0.7740\n",
      "Epoch 1446/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.8316 - val_loss: 0.5965 - val_accuracy: 0.7747\n",
      "Epoch 1447/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4780 - accuracy: 0.8322 - val_loss: 0.5965 - val_accuracy: 0.7740\n",
      "Epoch 1448/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4780 - accuracy: 0.8316 - val_loss: 0.5965 - val_accuracy: 0.7742\n",
      "Epoch 1449/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.8314 - val_loss: 0.5965 - val_accuracy: 0.7737\n",
      "Epoch 1450/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.8315 - val_loss: 0.5965 - val_accuracy: 0.7742\n",
      "Epoch 1451/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.8315 - val_loss: 0.5967 - val_accuracy: 0.7740\n",
      "Epoch 1452/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4778 - accuracy: 0.8321 - val_loss: 0.5965 - val_accuracy: 0.7735\n",
      "Epoch 1453/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.8316 - val_loss: 0.5965 - val_accuracy: 0.7742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1454/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4777 - accuracy: 0.8316 - val_loss: 0.5965 - val_accuracy: 0.7740\n",
      "Epoch 1455/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4777 - accuracy: 0.8315 - val_loss: 0.5965 - val_accuracy: 0.7742\n",
      "Epoch 1456/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4777 - accuracy: 0.8316 - val_loss: 0.5965 - val_accuracy: 0.7740\n",
      "Epoch 1457/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4777 - accuracy: 0.8316 - val_loss: 0.5964 - val_accuracy: 0.7742\n",
      "Epoch 1458/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.8316 - val_loss: 0.5966 - val_accuracy: 0.7742\n",
      "Epoch 1459/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4776 - accuracy: 0.8315 - val_loss: 0.5966 - val_accuracy: 0.7737\n",
      "Epoch 1460/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4776 - accuracy: 0.8320 - val_loss: 0.5965 - val_accuracy: 0.7740\n",
      "Epoch 1461/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4775 - accuracy: 0.8315 - val_loss: 0.5966 - val_accuracy: 0.7737\n",
      "Epoch 1462/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4775 - accuracy: 0.8315 - val_loss: 0.5966 - val_accuracy: 0.7740\n",
      "Epoch 1463/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4775 - accuracy: 0.8312 - val_loss: 0.5966 - val_accuracy: 0.7740\n",
      "Epoch 1464/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4775 - accuracy: 0.8322 - val_loss: 0.5966 - val_accuracy: 0.7740\n",
      "Epoch 1465/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4775 - accuracy: 0.8319 - val_loss: 0.5965 - val_accuracy: 0.7740\n",
      "Epoch 1466/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.8315 - val_loss: 0.5965 - val_accuracy: 0.7737\n",
      "Epoch 1467/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.8312 - val_loss: 0.5966 - val_accuracy: 0.7742\n",
      "Epoch 1468/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4774 - accuracy: 0.8323 - val_loss: 0.5965 - val_accuracy: 0.7733\n",
      "Epoch 1469/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4773 - accuracy: 0.8312 - val_loss: 0.5966 - val_accuracy: 0.7737\n",
      "Epoch 1470/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4773 - accuracy: 0.8315 - val_loss: 0.5966 - val_accuracy: 0.7740\n",
      "Epoch 1471/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4773 - accuracy: 0.8318 - val_loss: 0.5964 - val_accuracy: 0.7728\n",
      "Epoch 1472/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.8313 - val_loss: 0.5966 - val_accuracy: 0.7737\n",
      "Epoch 1473/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.8320 - val_loss: 0.5966 - val_accuracy: 0.7735\n",
      "Epoch 1474/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4772 - accuracy: 0.8319 - val_loss: 0.5967 - val_accuracy: 0.7737\n",
      "Epoch 1475/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4772 - accuracy: 0.8319 - val_loss: 0.5966 - val_accuracy: 0.7737\n",
      "Epoch 1476/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4771 - accuracy: 0.8318 - val_loss: 0.5965 - val_accuracy: 0.7737\n",
      "Epoch 1477/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4771 - accuracy: 0.8316 - val_loss: 0.5965 - val_accuracy: 0.7740\n",
      "Epoch 1478/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4770 - accuracy: 0.8319 - val_loss: 0.5965 - val_accuracy: 0.7737\n",
      "Epoch 1479/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.8317 - val_loss: 0.5966 - val_accuracy: 0.7735\n",
      "Epoch 1480/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4770 - accuracy: 0.8315 - val_loss: 0.5966 - val_accuracy: 0.7735\n",
      "Epoch 1481/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4770 - accuracy: 0.8323 - val_loss: 0.5966 - val_accuracy: 0.7735\n",
      "Epoch 1482/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4770 - accuracy: 0.8315 - val_loss: 0.5965 - val_accuracy: 0.7735\n",
      "Epoch 1483/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4769 - accuracy: 0.8313 - val_loss: 0.5965 - val_accuracy: 0.7737\n",
      "Epoch 1484/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4769 - accuracy: 0.8317 - val_loss: 0.5966 - val_accuracy: 0.7733\n",
      "Epoch 1485/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4769 - accuracy: 0.8321 - val_loss: 0.5965 - val_accuracy: 0.7737\n",
      "Epoch 1486/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4768 - accuracy: 0.8317 - val_loss: 0.5965 - val_accuracy: 0.7728\n",
      "Epoch 1487/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4768 - accuracy: 0.8319 - val_loss: 0.5965 - val_accuracy: 0.7735\n",
      "Epoch 1488/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4768 - accuracy: 0.8315 - val_loss: 0.5966 - val_accuracy: 0.7735\n",
      "Epoch 1489/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4768 - accuracy: 0.8316 - val_loss: 0.5967 - val_accuracy: 0.7733\n",
      "Epoch 1490/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4767 - accuracy: 0.8310 - val_loss: 0.5966 - val_accuracy: 0.7733\n",
      "Epoch 1491/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.8318 - val_loss: 0.5966 - val_accuracy: 0.7735\n",
      "Epoch 1492/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.8315 - val_loss: 0.5966 - val_accuracy: 0.7730\n",
      "Epoch 1493/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4767 - accuracy: 0.8318 - val_loss: 0.5966 - val_accuracy: 0.7733\n",
      "Epoch 1494/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4766 - accuracy: 0.8317 - val_loss: 0.5966 - val_accuracy: 0.7733\n",
      "Epoch 1495/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4766 - accuracy: 0.8319 - val_loss: 0.5965 - val_accuracy: 0.7726\n",
      "Epoch 1496/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4766 - accuracy: 0.8317 - val_loss: 0.5965 - val_accuracy: 0.7726\n",
      "Epoch 1497/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4765 - accuracy: 0.8313 - val_loss: 0.5965 - val_accuracy: 0.7735\n",
      "Epoch 1498/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.8313 - val_loss: 0.5966 - val_accuracy: 0.7730\n",
      "Epoch 1499/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.8315 - val_loss: 0.5966 - val_accuracy: 0.7721\n",
      "Epoch 1500/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4765 - accuracy: 0.8316 - val_loss: 0.5965 - val_accuracy: 0.7730\n",
      "Epoch 1501/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4764 - accuracy: 0.8317 - val_loss: 0.5965 - val_accuracy: 0.7733\n",
      "Epoch 1502/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4764 - accuracy: 0.8316 - val_loss: 0.5966 - val_accuracy: 0.7726\n",
      "Epoch 1503/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4764 - accuracy: 0.8319 - val_loss: 0.5965 - val_accuracy: 0.7721\n",
      "Epoch 1504/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.8321 - val_loss: 0.5965 - val_accuracy: 0.7728\n",
      "Epoch 1505/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4763 - accuracy: 0.8316 - val_loss: 0.5966 - val_accuracy: 0.7728\n",
      "Epoch 1506/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4763 - accuracy: 0.8321 - val_loss: 0.5966 - val_accuracy: 0.7730\n",
      "Epoch 1507/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4763 - accuracy: 0.8320 - val_loss: 0.5965 - val_accuracy: 0.7735\n",
      "Epoch 1508/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4763 - accuracy: 0.8313 - val_loss: 0.5966 - val_accuracy: 0.7728\n",
      "Epoch 1509/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4762 - accuracy: 0.8315 - val_loss: 0.5965 - val_accuracy: 0.7724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1510/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.8312 - val_loss: 0.5965 - val_accuracy: 0.7733\n",
      "Epoch 1511/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.8320 - val_loss: 0.5965 - val_accuracy: 0.7733\n",
      "Epoch 1512/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.8323 - val_loss: 0.5967 - val_accuracy: 0.7728\n",
      "Epoch 1513/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.8319 - val_loss: 0.5965 - val_accuracy: 0.7726\n",
      "Epoch 1514/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4761 - accuracy: 0.8317 - val_loss: 0.5966 - val_accuracy: 0.7733\n",
      "Epoch 1515/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.8324 - val_loss: 0.5965 - val_accuracy: 0.7726\n",
      "Epoch 1516/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.8315 - val_loss: 0.5965 - val_accuracy: 0.7733\n",
      "Epoch 1517/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.8321 - val_loss: 0.5965 - val_accuracy: 0.7726\n",
      "Epoch 1518/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4760 - accuracy: 0.8316 - val_loss: 0.5965 - val_accuracy: 0.7724\n",
      "Epoch 1519/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4759 - accuracy: 0.8315 - val_loss: 0.5966 - val_accuracy: 0.7726\n",
      "Epoch 1520/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4759 - accuracy: 0.8317 - val_loss: 0.5966 - val_accuracy: 0.7733\n",
      "Epoch 1521/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4759 - accuracy: 0.8320 - val_loss: 0.5965 - val_accuracy: 0.7728\n",
      "Epoch 1522/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4759 - accuracy: 0.8317 - val_loss: 0.5967 - val_accuracy: 0.7726\n",
      "Epoch 1523/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4758 - accuracy: 0.8319 - val_loss: 0.5964 - val_accuracy: 0.7735\n",
      "Epoch 1524/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4758 - accuracy: 0.8318 - val_loss: 0.5966 - val_accuracy: 0.7728\n",
      "Epoch 1525/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4758 - accuracy: 0.8317 - val_loss: 0.5966 - val_accuracy: 0.7721\n",
      "Epoch 1526/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4758 - accuracy: 0.8317 - val_loss: 0.5966 - val_accuracy: 0.7726\n",
      "Epoch 1527/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4757 - accuracy: 0.8315 - val_loss: 0.5965 - val_accuracy: 0.7726\n",
      "Epoch 1528/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4757 - accuracy: 0.8320 - val_loss: 0.5965 - val_accuracy: 0.7724\n",
      "Epoch 1529/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4757 - accuracy: 0.8315 - val_loss: 0.5965 - val_accuracy: 0.7735\n",
      "Epoch 1530/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4757 - accuracy: 0.8321 - val_loss: 0.5966 - val_accuracy: 0.7728\n",
      "Epoch 1531/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.8315 - val_loss: 0.5966 - val_accuracy: 0.7735\n",
      "Epoch 1532/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4756 - accuracy: 0.8313 - val_loss: 0.5966 - val_accuracy: 0.7733\n",
      "Epoch 1533/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.8320 - val_loss: 0.5967 - val_accuracy: 0.7728\n",
      "Epoch 1534/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.8312 - val_loss: 0.5967 - val_accuracy: 0.7730\n",
      "Epoch 1535/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.8321 - val_loss: 0.5966 - val_accuracy: 0.7728\n",
      "Epoch 1536/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4755 - accuracy: 0.8313 - val_loss: 0.5966 - val_accuracy: 0.7728\n",
      "Epoch 1537/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4755 - accuracy: 0.8317 - val_loss: 0.5967 - val_accuracy: 0.7726\n",
      "Epoch 1538/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4755 - accuracy: 0.8319 - val_loss: 0.5965 - val_accuracy: 0.7726\n",
      "Epoch 1539/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4754 - accuracy: 0.8318 - val_loss: 0.5965 - val_accuracy: 0.7726\n",
      "Epoch 1540/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4754 - accuracy: 0.8321 - val_loss: 0.5966 - val_accuracy: 0.7726\n",
      "Epoch 1541/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4754 - accuracy: 0.8319 - val_loss: 0.5965 - val_accuracy: 0.7730\n",
      "Epoch 1542/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4753 - accuracy: 0.8316 - val_loss: 0.5965 - val_accuracy: 0.7730\n",
      "Epoch 1543/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4753 - accuracy: 0.8318 - val_loss: 0.5965 - val_accuracy: 0.7735\n",
      "Epoch 1544/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4753 - accuracy: 0.8319 - val_loss: 0.5965 - val_accuracy: 0.7721\n",
      "Epoch 1545/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.8315 - val_loss: 0.5966 - val_accuracy: 0.7721\n",
      "Epoch 1546/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4753 - accuracy: 0.8321 - val_loss: 0.5965 - val_accuracy: 0.7728\n",
      "Epoch 1547/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4752 - accuracy: 0.8319 - val_loss: 0.5965 - val_accuracy: 0.7730\n",
      "Epoch 1548/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4752 - accuracy: 0.8323 - val_loss: 0.5966 - val_accuracy: 0.7728\n",
      "Epoch 1549/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4752 - accuracy: 0.8321 - val_loss: 0.5966 - val_accuracy: 0.7726\n",
      "Epoch 1550/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4751 - accuracy: 0.8320 - val_loss: 0.5967 - val_accuracy: 0.7724\n",
      "Epoch 1551/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4751 - accuracy: 0.8321 - val_loss: 0.5966 - val_accuracy: 0.7728\n",
      "Epoch 1552/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4751 - accuracy: 0.8321 - val_loss: 0.5966 - val_accuracy: 0.7726\n",
      "Epoch 1553/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4751 - accuracy: 0.8325 - val_loss: 0.5965 - val_accuracy: 0.7721\n",
      "Epoch 1554/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4750 - accuracy: 0.8317 - val_loss: 0.5966 - val_accuracy: 0.7726\n",
      "Epoch 1555/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4750 - accuracy: 0.8318 - val_loss: 0.5966 - val_accuracy: 0.7726\n",
      "Epoch 1556/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4750 - accuracy: 0.8319 - val_loss: 0.5966 - val_accuracy: 0.7728\n",
      "Epoch 1557/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4750 - accuracy: 0.8317 - val_loss: 0.5967 - val_accuracy: 0.7735\n",
      "Epoch 1558/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4749 - accuracy: 0.8325 - val_loss: 0.5966 - val_accuracy: 0.7726\n",
      "Epoch 1559/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4749 - accuracy: 0.8321 - val_loss: 0.5966 - val_accuracy: 0.7733\n",
      "Epoch 1560/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.8321 - val_loss: 0.5967 - val_accuracy: 0.7728\n",
      "Epoch 1561/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4749 - accuracy: 0.8320 - val_loss: 0.5966 - val_accuracy: 0.7724\n",
      "Epoch 1562/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4749 - accuracy: 0.8318 - val_loss: 0.5967 - val_accuracy: 0.7728\n",
      "Epoch 1563/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.8322 - val_loss: 0.5967 - val_accuracy: 0.7728\n",
      "Epoch 1564/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4748 - accuracy: 0.8325 - val_loss: 0.5966 - val_accuracy: 0.7730\n",
      "Epoch 1565/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4748 - accuracy: 0.8321 - val_loss: 0.5966 - val_accuracy: 0.7726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1566/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4748 - accuracy: 0.8323 - val_loss: 0.5966 - val_accuracy: 0.7726\n",
      "Epoch 1567/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4747 - accuracy: 0.8319 - val_loss: 0.5966 - val_accuracy: 0.7735\n",
      "Epoch 1568/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4747 - accuracy: 0.8320 - val_loss: 0.5966 - val_accuracy: 0.7728\n",
      "Epoch 1569/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4747 - accuracy: 0.8325 - val_loss: 0.5966 - val_accuracy: 0.7724\n",
      "Epoch 1570/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4746 - accuracy: 0.8316 - val_loss: 0.5967 - val_accuracy: 0.7726\n",
      "Epoch 1571/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4746 - accuracy: 0.8325 - val_loss: 0.5966 - val_accuracy: 0.7726\n",
      "Epoch 1572/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4746 - accuracy: 0.8324 - val_loss: 0.5966 - val_accuracy: 0.7724\n",
      "Epoch 1573/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.8321 - val_loss: 0.5966 - val_accuracy: 0.7724\n",
      "Epoch 1574/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4745 - accuracy: 0.8323 - val_loss: 0.5966 - val_accuracy: 0.7730\n",
      "Epoch 1575/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4745 - accuracy: 0.8327 - val_loss: 0.5966 - val_accuracy: 0.7721\n",
      "Epoch 1576/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4745 - accuracy: 0.8325 - val_loss: 0.5965 - val_accuracy: 0.7728\n",
      "Epoch 1577/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4745 - accuracy: 0.8322 - val_loss: 0.5966 - val_accuracy: 0.7726\n",
      "Epoch 1578/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4744 - accuracy: 0.8321 - val_loss: 0.5966 - val_accuracy: 0.7719\n",
      "Epoch 1579/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4744 - accuracy: 0.8322 - val_loss: 0.5965 - val_accuracy: 0.7724\n",
      "Epoch 1580/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4744 - accuracy: 0.8319 - val_loss: 0.5965 - val_accuracy: 0.7724\n",
      "Epoch 1581/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4744 - accuracy: 0.8323 - val_loss: 0.5966 - val_accuracy: 0.7733\n",
      "Epoch 1582/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.8324 - val_loss: 0.5966 - val_accuracy: 0.7728\n",
      "Epoch 1583/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4743 - accuracy: 0.8323 - val_loss: 0.5965 - val_accuracy: 0.7730\n",
      "Epoch 1584/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4743 - accuracy: 0.8323 - val_loss: 0.5966 - val_accuracy: 0.7721\n",
      "Epoch 1585/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.8325 - val_loss: 0.5967 - val_accuracy: 0.7726\n",
      "Epoch 1586/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.8325 - val_loss: 0.5966 - val_accuracy: 0.7719\n",
      "Epoch 1587/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4742 - accuracy: 0.8323 - val_loss: 0.5966 - val_accuracy: 0.7726\n",
      "Epoch 1588/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.8323 - val_loss: 0.5966 - val_accuracy: 0.7728\n",
      "Epoch 1589/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4742 - accuracy: 0.8327 - val_loss: 0.5965 - val_accuracy: 0.7733\n",
      "Epoch 1590/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4742 - accuracy: 0.8326 - val_loss: 0.5965 - val_accuracy: 0.7733\n",
      "Epoch 1591/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4741 - accuracy: 0.8324 - val_loss: 0.5965 - val_accuracy: 0.7726\n",
      "Epoch 1592/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4741 - accuracy: 0.8321 - val_loss: 0.5966 - val_accuracy: 0.7730\n",
      "Epoch 1593/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.8323 - val_loss: 0.5966 - val_accuracy: 0.7726\n",
      "Epoch 1594/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4740 - accuracy: 0.8323 - val_loss: 0.5967 - val_accuracy: 0.7733\n",
      "Epoch 1595/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4740 - accuracy: 0.8321 - val_loss: 0.5966 - val_accuracy: 0.7733\n",
      "Epoch 1596/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4740 - accuracy: 0.8325 - val_loss: 0.5965 - val_accuracy: 0.7728\n",
      "Epoch 1597/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4740 - accuracy: 0.8323 - val_loss: 0.5966 - val_accuracy: 0.7730\n",
      "Epoch 1598/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4739 - accuracy: 0.8324 - val_loss: 0.5966 - val_accuracy: 0.7726\n",
      "Epoch 1599/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4739 - accuracy: 0.8325 - val_loss: 0.5966 - val_accuracy: 0.7733\n",
      "Epoch 1600/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4739 - accuracy: 0.8323 - val_loss: 0.5967 - val_accuracy: 0.7726\n",
      "Epoch 1601/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4739 - accuracy: 0.8325 - val_loss: 0.5967 - val_accuracy: 0.7726\n",
      "Epoch 1602/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4739 - accuracy: 0.8324 - val_loss: 0.5967 - val_accuracy: 0.7728\n",
      "Epoch 1603/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4738 - accuracy: 0.8324 - val_loss: 0.5967 - val_accuracy: 0.7728\n",
      "Epoch 1604/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4738 - accuracy: 0.8324 - val_loss: 0.5966 - val_accuracy: 0.7730\n",
      "Epoch 1605/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4738 - accuracy: 0.8325 - val_loss: 0.5966 - val_accuracy: 0.7726\n",
      "Epoch 1606/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4737 - accuracy: 0.8329 - val_loss: 0.5966 - val_accuracy: 0.7724\n",
      "Epoch 1607/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4737 - accuracy: 0.8321 - val_loss: 0.5966 - val_accuracy: 0.7735\n",
      "Epoch 1608/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4737 - accuracy: 0.8325 - val_loss: 0.5966 - val_accuracy: 0.7733\n",
      "Epoch 1609/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4737 - accuracy: 0.8326 - val_loss: 0.5966 - val_accuracy: 0.7726\n",
      "Epoch 1610/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4737 - accuracy: 0.8329 - val_loss: 0.5967 - val_accuracy: 0.7735\n",
      "Epoch 1611/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4737 - accuracy: 0.8323 - val_loss: 0.5967 - val_accuracy: 0.7735\n",
      "Epoch 1612/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4737 - accuracy: 0.8323 - val_loss: 0.5967 - val_accuracy: 0.7733\n",
      "Epoch 1613/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4736 - accuracy: 0.8319 - val_loss: 0.5966 - val_accuracy: 0.7726\n",
      "Epoch 1614/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4736 - accuracy: 0.8325 - val_loss: 0.5967 - val_accuracy: 0.7726\n",
      "Epoch 1615/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4736 - accuracy: 0.8324 - val_loss: 0.5967 - val_accuracy: 0.7730\n",
      "Epoch 1616/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4736 - accuracy: 0.8326 - val_loss: 0.5966 - val_accuracy: 0.7730\n",
      "Epoch 1617/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4735 - accuracy: 0.8321 - val_loss: 0.5966 - val_accuracy: 0.7721\n",
      "Epoch 1618/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4735 - accuracy: 0.8329 - val_loss: 0.5966 - val_accuracy: 0.7730\n",
      "Epoch 1619/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.8327 - val_loss: 0.5966 - val_accuracy: 0.7733\n",
      "Epoch 1620/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.8323 - val_loss: 0.5967 - val_accuracy: 0.7728\n",
      "Epoch 1621/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4734 - accuracy: 0.8327 - val_loss: 0.5967 - val_accuracy: 0.7733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1622/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4734 - accuracy: 0.8325 - val_loss: 0.5966 - val_accuracy: 0.7724\n",
      "Epoch 1623/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4734 - accuracy: 0.8327 - val_loss: 0.5967 - val_accuracy: 0.7728\n",
      "Epoch 1624/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4734 - accuracy: 0.8327 - val_loss: 0.5966 - val_accuracy: 0.7737\n",
      "Epoch 1625/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4733 - accuracy: 0.8328 - val_loss: 0.5967 - val_accuracy: 0.7735\n",
      "Epoch 1626/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4733 - accuracy: 0.8326 - val_loss: 0.5967 - val_accuracy: 0.7728\n",
      "Epoch 1627/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4733 - accuracy: 0.8325 - val_loss: 0.5966 - val_accuracy: 0.7730\n",
      "Epoch 1628/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4733 - accuracy: 0.8326 - val_loss: 0.5967 - val_accuracy: 0.7728\n",
      "Epoch 1629/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4732 - accuracy: 0.8326 - val_loss: 0.5967 - val_accuracy: 0.7730\n",
      "Epoch 1630/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4732 - accuracy: 0.8328 - val_loss: 0.5967 - val_accuracy: 0.7721\n",
      "Epoch 1631/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4732 - accuracy: 0.8320 - val_loss: 0.5967 - val_accuracy: 0.7730\n",
      "Epoch 1632/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4732 - accuracy: 0.8320 - val_loss: 0.5968 - val_accuracy: 0.7733\n",
      "Epoch 1633/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4731 - accuracy: 0.8324 - val_loss: 0.5967 - val_accuracy: 0.7733\n",
      "Epoch 1634/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4731 - accuracy: 0.8325 - val_loss: 0.5966 - val_accuracy: 0.7735\n",
      "Epoch 1635/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4731 - accuracy: 0.8320 - val_loss: 0.5967 - val_accuracy: 0.7737\n",
      "Epoch 1636/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4731 - accuracy: 0.8321 - val_loss: 0.5967 - val_accuracy: 0.7733\n",
      "Epoch 1637/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4731 - accuracy: 0.8324 - val_loss: 0.5967 - val_accuracy: 0.7733\n",
      "Epoch 1638/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4731 - accuracy: 0.8326 - val_loss: 0.5967 - val_accuracy: 0.7733\n",
      "Epoch 1639/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4730 - accuracy: 0.8324 - val_loss: 0.5966 - val_accuracy: 0.7737\n",
      "Epoch 1640/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4730 - accuracy: 0.8329 - val_loss: 0.5967 - val_accuracy: 0.7730\n",
      "Epoch 1641/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4730 - accuracy: 0.8328 - val_loss: 0.5968 - val_accuracy: 0.7726\n",
      "Epoch 1642/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4729 - accuracy: 0.8327 - val_loss: 0.5967 - val_accuracy: 0.7728\n",
      "Epoch 1643/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4729 - accuracy: 0.8325 - val_loss: 0.5968 - val_accuracy: 0.7726\n",
      "Epoch 1644/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4729 - accuracy: 0.8331 - val_loss: 0.5967 - val_accuracy: 0.7735\n",
      "Epoch 1645/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4729 - accuracy: 0.8327 - val_loss: 0.5967 - val_accuracy: 0.7735\n",
      "Epoch 1646/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4728 - accuracy: 0.8327 - val_loss: 0.5967 - val_accuracy: 0.7721\n",
      "Epoch 1647/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4728 - accuracy: 0.8326 - val_loss: 0.5968 - val_accuracy: 0.7724\n",
      "Epoch 1648/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4728 - accuracy: 0.8324 - val_loss: 0.5969 - val_accuracy: 0.7733\n",
      "Epoch 1649/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4728 - accuracy: 0.8325 - val_loss: 0.5967 - val_accuracy: 0.7735\n",
      "Epoch 1650/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4728 - accuracy: 0.8326 - val_loss: 0.5966 - val_accuracy: 0.7735\n",
      "Epoch 1651/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4727 - accuracy: 0.8325 - val_loss: 0.5967 - val_accuracy: 0.7726\n",
      "Epoch 1652/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4727 - accuracy: 0.8324 - val_loss: 0.5967 - val_accuracy: 0.7737\n",
      "Epoch 1653/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.8328 - val_loss: 0.5966 - val_accuracy: 0.7726\n",
      "Epoch 1654/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.8326 - val_loss: 0.5966 - val_accuracy: 0.7737\n",
      "Epoch 1655/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4726 - accuracy: 0.8325 - val_loss: 0.5967 - val_accuracy: 0.7730\n",
      "Epoch 1656/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4726 - accuracy: 0.8330 - val_loss: 0.5966 - val_accuracy: 0.7733\n",
      "Epoch 1657/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4726 - accuracy: 0.8329 - val_loss: 0.5966 - val_accuracy: 0.7737\n",
      "Epoch 1658/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4726 - accuracy: 0.8323 - val_loss: 0.5968 - val_accuracy: 0.7737\n",
      "Epoch 1659/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.8332 - val_loss: 0.5966 - val_accuracy: 0.7740\n",
      "Epoch 1660/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.8319 - val_loss: 0.5967 - val_accuracy: 0.7733\n",
      "Epoch 1661/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4725 - accuracy: 0.8325 - val_loss: 0.5968 - val_accuracy: 0.7733\n",
      "Epoch 1662/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.8326 - val_loss: 0.5967 - val_accuracy: 0.7730\n",
      "Epoch 1663/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.8328 - val_loss: 0.5966 - val_accuracy: 0.7735\n",
      "Epoch 1664/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4725 - accuracy: 0.8326 - val_loss: 0.5966 - val_accuracy: 0.7733\n",
      "Epoch 1665/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4725 - accuracy: 0.8326 - val_loss: 0.5966 - val_accuracy: 0.7730\n",
      "Epoch 1666/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4724 - accuracy: 0.8327 - val_loss: 0.5967 - val_accuracy: 0.7726\n",
      "Epoch 1667/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4724 - accuracy: 0.8329 - val_loss: 0.5967 - val_accuracy: 0.7737\n",
      "Epoch 1668/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.8328 - val_loss: 0.5967 - val_accuracy: 0.7733\n",
      "Epoch 1669/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.8327 - val_loss: 0.5967 - val_accuracy: 0.7721\n",
      "Epoch 1670/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4723 - accuracy: 0.8324 - val_loss: 0.5967 - val_accuracy: 0.7730\n",
      "Epoch 1671/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.8326 - val_loss: 0.5968 - val_accuracy: 0.7726\n",
      "Epoch 1672/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4723 - accuracy: 0.8329 - val_loss: 0.5969 - val_accuracy: 0.7728\n",
      "Epoch 1673/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.8328 - val_loss: 0.5969 - val_accuracy: 0.7728\n",
      "Epoch 1674/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4723 - accuracy: 0.8329 - val_loss: 0.5967 - val_accuracy: 0.7726\n",
      "Epoch 1675/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4722 - accuracy: 0.8328 - val_loss: 0.5966 - val_accuracy: 0.7721\n",
      "Epoch 1676/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.8325 - val_loss: 0.5967 - val_accuracy: 0.7728\n",
      "Epoch 1677/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4722 - accuracy: 0.8325 - val_loss: 0.5967 - val_accuracy: 0.7728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1678/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4722 - accuracy: 0.8328 - val_loss: 0.5967 - val_accuracy: 0.7726\n",
      "Epoch 1679/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4721 - accuracy: 0.8324 - val_loss: 0.5967 - val_accuracy: 0.7735\n",
      "Epoch 1680/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4721 - accuracy: 0.8324 - val_loss: 0.5967 - val_accuracy: 0.7721\n",
      "Epoch 1681/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4721 - accuracy: 0.8326 - val_loss: 0.5967 - val_accuracy: 0.7726\n",
      "Epoch 1682/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4721 - accuracy: 0.8330 - val_loss: 0.5967 - val_accuracy: 0.7733\n",
      "Epoch 1683/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4720 - accuracy: 0.8328 - val_loss: 0.5966 - val_accuracy: 0.7733\n",
      "Epoch 1684/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4720 - accuracy: 0.8328 - val_loss: 0.5967 - val_accuracy: 0.7735\n",
      "Epoch 1685/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4720 - accuracy: 0.8326 - val_loss: 0.5966 - val_accuracy: 0.7728\n",
      "Epoch 1686/2000\n",
      "136/136 [==============================] - 1s 4ms/step - loss: 0.4720 - accuracy: 0.8328 - val_loss: 0.5967 - val_accuracy: 0.7733\n",
      "Epoch 1687/2000\n",
      "136/136 [==============================] - 1s 4ms/step - loss: 0.4720 - accuracy: 0.8329 - val_loss: 0.5966 - val_accuracy: 0.7728\n",
      "Epoch 1688/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4719 - accuracy: 0.8321 - val_loss: 0.5967 - val_accuracy: 0.7733\n",
      "Epoch 1689/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4719 - accuracy: 0.8326 - val_loss: 0.5967 - val_accuracy: 0.7726\n",
      "Epoch 1690/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4719 - accuracy: 0.8325 - val_loss: 0.5967 - val_accuracy: 0.7724\n",
      "Epoch 1691/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4719 - accuracy: 0.8323 - val_loss: 0.5968 - val_accuracy: 0.7724\n",
      "Epoch 1692/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4719 - accuracy: 0.8324 - val_loss: 0.5967 - val_accuracy: 0.7730\n",
      "Epoch 1693/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4719 - accuracy: 0.8328 - val_loss: 0.5967 - val_accuracy: 0.7719\n",
      "Epoch 1694/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4718 - accuracy: 0.8326 - val_loss: 0.5966 - val_accuracy: 0.7726\n",
      "Epoch 1695/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4718 - accuracy: 0.8328 - val_loss: 0.5967 - val_accuracy: 0.7726\n",
      "Epoch 1696/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4718 - accuracy: 0.8327 - val_loss: 0.5967 - val_accuracy: 0.7724\n",
      "Epoch 1697/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4717 - accuracy: 0.8328 - val_loss: 0.5967 - val_accuracy: 0.7730\n",
      "Epoch 1698/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4717 - accuracy: 0.8325 - val_loss: 0.5967 - val_accuracy: 0.7728\n",
      "Epoch 1699/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4717 - accuracy: 0.8328 - val_loss: 0.5967 - val_accuracy: 0.7724\n",
      "Epoch 1700/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4717 - accuracy: 0.8324 - val_loss: 0.5968 - val_accuracy: 0.7730\n",
      "Epoch 1701/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4717 - accuracy: 0.8326 - val_loss: 0.5967 - val_accuracy: 0.7730\n",
      "Epoch 1702/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4717 - accuracy: 0.8328 - val_loss: 0.5967 - val_accuracy: 0.7726\n",
      "Epoch 1703/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4717 - accuracy: 0.8329 - val_loss: 0.5967 - val_accuracy: 0.7733\n",
      "Epoch 1704/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4716 - accuracy: 0.8325 - val_loss: 0.5969 - val_accuracy: 0.7733\n",
      "Epoch 1705/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4716 - accuracy: 0.8329 - val_loss: 0.5968 - val_accuracy: 0.7735\n",
      "Epoch 1706/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4716 - accuracy: 0.8326 - val_loss: 0.5967 - val_accuracy: 0.7726\n",
      "Epoch 1707/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4716 - accuracy: 0.8327 - val_loss: 0.5967 - val_accuracy: 0.7728\n",
      "Epoch 1708/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4715 - accuracy: 0.8329 - val_loss: 0.5967 - val_accuracy: 0.7728\n",
      "Epoch 1709/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4715 - accuracy: 0.8327 - val_loss: 0.5967 - val_accuracy: 0.7730\n",
      "Epoch 1710/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4715 - accuracy: 0.8329 - val_loss: 0.5967 - val_accuracy: 0.7728\n",
      "Epoch 1711/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4715 - accuracy: 0.8326 - val_loss: 0.5967 - val_accuracy: 0.7726\n",
      "Epoch 1712/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4714 - accuracy: 0.8327 - val_loss: 0.5967 - val_accuracy: 0.7721\n",
      "Epoch 1713/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4714 - accuracy: 0.8324 - val_loss: 0.5967 - val_accuracy: 0.7726\n",
      "Epoch 1714/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4714 - accuracy: 0.8327 - val_loss: 0.5968 - val_accuracy: 0.7724\n",
      "Epoch 1715/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4714 - accuracy: 0.8323 - val_loss: 0.5967 - val_accuracy: 0.7726\n",
      "Epoch 1716/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4714 - accuracy: 0.8325 - val_loss: 0.5967 - val_accuracy: 0.7726\n",
      "Epoch 1717/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4713 - accuracy: 0.8326 - val_loss: 0.5966 - val_accuracy: 0.7724\n",
      "Epoch 1718/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4713 - accuracy: 0.8325 - val_loss: 0.5966 - val_accuracy: 0.7726\n",
      "Epoch 1719/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4713 - accuracy: 0.8324 - val_loss: 0.5968 - val_accuracy: 0.7724\n",
      "Epoch 1720/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4713 - accuracy: 0.8331 - val_loss: 0.5968 - val_accuracy: 0.7721\n",
      "Epoch 1721/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4713 - accuracy: 0.8324 - val_loss: 0.5966 - val_accuracy: 0.7730\n",
      "Epoch 1722/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4712 - accuracy: 0.8334 - val_loss: 0.5967 - val_accuracy: 0.7728\n",
      "Epoch 1723/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4712 - accuracy: 0.8326 - val_loss: 0.5967 - val_accuracy: 0.7724\n",
      "Epoch 1724/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4712 - accuracy: 0.8325 - val_loss: 0.5967 - val_accuracy: 0.7721\n",
      "Epoch 1725/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4712 - accuracy: 0.8331 - val_loss: 0.5966 - val_accuracy: 0.7724\n",
      "Epoch 1726/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4712 - accuracy: 0.8328 - val_loss: 0.5966 - val_accuracy: 0.7719\n",
      "Epoch 1727/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4712 - accuracy: 0.8324 - val_loss: 0.5967 - val_accuracy: 0.7728\n",
      "Epoch 1728/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4711 - accuracy: 0.8329 - val_loss: 0.5967 - val_accuracy: 0.7724\n",
      "Epoch 1729/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4711 - accuracy: 0.8326 - val_loss: 0.5968 - val_accuracy: 0.7721\n",
      "Epoch 1730/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4711 - accuracy: 0.8328 - val_loss: 0.5967 - val_accuracy: 0.7726\n",
      "Epoch 1731/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4711 - accuracy: 0.8323 - val_loss: 0.5967 - val_accuracy: 0.7728\n",
      "Epoch 1732/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4711 - accuracy: 0.8332 - val_loss: 0.5966 - val_accuracy: 0.7730\n",
      "Epoch 1733/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4710 - accuracy: 0.8325 - val_loss: 0.5966 - val_accuracy: 0.7735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1734/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4711 - accuracy: 0.8329 - val_loss: 0.5965 - val_accuracy: 0.7724\n",
      "Epoch 1735/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4710 - accuracy: 0.8328 - val_loss: 0.5967 - val_accuracy: 0.7730\n",
      "Epoch 1736/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4709 - accuracy: 0.8321 - val_loss: 0.5967 - val_accuracy: 0.7728\n",
      "Epoch 1737/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4709 - accuracy: 0.8336 - val_loss: 0.5966 - val_accuracy: 0.7728\n",
      "Epoch 1738/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4709 - accuracy: 0.8331 - val_loss: 0.5966 - val_accuracy: 0.7724\n",
      "Epoch 1739/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4709 - accuracy: 0.8332 - val_loss: 0.5966 - val_accuracy: 0.7728\n",
      "Epoch 1740/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4709 - accuracy: 0.8334 - val_loss: 0.5968 - val_accuracy: 0.7730\n",
      "Epoch 1741/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4709 - accuracy: 0.8329 - val_loss: 0.5966 - val_accuracy: 0.7728\n",
      "Epoch 1742/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4708 - accuracy: 0.8331 - val_loss: 0.5966 - val_accuracy: 0.7724\n",
      "Epoch 1743/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4708 - accuracy: 0.8324 - val_loss: 0.5967 - val_accuracy: 0.7730\n",
      "Epoch 1744/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4708 - accuracy: 0.8325 - val_loss: 0.5967 - val_accuracy: 0.7721\n",
      "Epoch 1745/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4708 - accuracy: 0.8328 - val_loss: 0.5967 - val_accuracy: 0.7726\n",
      "Epoch 1746/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4707 - accuracy: 0.8332 - val_loss: 0.5967 - val_accuracy: 0.7721\n",
      "Epoch 1747/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4708 - accuracy: 0.8327 - val_loss: 0.5966 - val_accuracy: 0.7726\n",
      "Epoch 1748/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4707 - accuracy: 0.8323 - val_loss: 0.5968 - val_accuracy: 0.7728\n",
      "Epoch 1749/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4707 - accuracy: 0.8334 - val_loss: 0.5967 - val_accuracy: 0.7724\n",
      "Epoch 1750/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4707 - accuracy: 0.8328 - val_loss: 0.5968 - val_accuracy: 0.7726\n",
      "Epoch 1751/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4707 - accuracy: 0.8327 - val_loss: 0.5967 - val_accuracy: 0.7721\n",
      "Epoch 1752/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4707 - accuracy: 0.8329 - val_loss: 0.5967 - val_accuracy: 0.7724\n",
      "Epoch 1753/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4707 - accuracy: 0.8324 - val_loss: 0.5967 - val_accuracy: 0.7721\n",
      "Epoch 1754/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4706 - accuracy: 0.8328 - val_loss: 0.5967 - val_accuracy: 0.7728\n",
      "Epoch 1755/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4706 - accuracy: 0.8335 - val_loss: 0.5967 - val_accuracy: 0.7721\n",
      "Epoch 1756/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4705 - accuracy: 0.8332 - val_loss: 0.5968 - val_accuracy: 0.7726\n",
      "Epoch 1757/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4706 - accuracy: 0.8329 - val_loss: 0.5967 - val_accuracy: 0.7721\n",
      "Epoch 1758/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4705 - accuracy: 0.8327 - val_loss: 0.5968 - val_accuracy: 0.7728\n",
      "Epoch 1759/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4705 - accuracy: 0.8330 - val_loss: 0.5968 - val_accuracy: 0.7724\n",
      "Epoch 1760/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4705 - accuracy: 0.8332 - val_loss: 0.5967 - val_accuracy: 0.7721\n",
      "Epoch 1761/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4705 - accuracy: 0.8330 - val_loss: 0.5968 - val_accuracy: 0.7721\n",
      "Epoch 1762/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4704 - accuracy: 0.8327 - val_loss: 0.5968 - val_accuracy: 0.7721\n",
      "Epoch 1763/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4704 - accuracy: 0.8330 - val_loss: 0.5968 - val_accuracy: 0.7728\n",
      "Epoch 1764/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4704 - accuracy: 0.8327 - val_loss: 0.5968 - val_accuracy: 0.7726\n",
      "Epoch 1765/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4704 - accuracy: 0.8325 - val_loss: 0.5967 - val_accuracy: 0.7721\n",
      "Epoch 1766/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4704 - accuracy: 0.8334 - val_loss: 0.5968 - val_accuracy: 0.7730\n",
      "Epoch 1767/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4704 - accuracy: 0.8334 - val_loss: 0.5969 - val_accuracy: 0.7726\n",
      "Epoch 1768/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4703 - accuracy: 0.8330 - val_loss: 0.5967 - val_accuracy: 0.7719\n",
      "Epoch 1769/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4703 - accuracy: 0.8327 - val_loss: 0.5969 - val_accuracy: 0.7730\n",
      "Epoch 1770/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4703 - accuracy: 0.8336 - val_loss: 0.5967 - val_accuracy: 0.7721\n",
      "Epoch 1771/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4703 - accuracy: 0.8335 - val_loss: 0.5968 - val_accuracy: 0.7724\n",
      "Epoch 1772/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4703 - accuracy: 0.8328 - val_loss: 0.5969 - val_accuracy: 0.7733\n",
      "Epoch 1773/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4702 - accuracy: 0.8331 - val_loss: 0.5967 - val_accuracy: 0.7724\n",
      "Epoch 1774/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4702 - accuracy: 0.8331 - val_loss: 0.5968 - val_accuracy: 0.7728\n",
      "Epoch 1775/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4702 - accuracy: 0.8329 - val_loss: 0.5967 - val_accuracy: 0.7721\n",
      "Epoch 1776/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.8330 - val_loss: 0.5968 - val_accuracy: 0.7724\n",
      "Epoch 1777/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4701 - accuracy: 0.8334 - val_loss: 0.5967 - val_accuracy: 0.7721\n",
      "Epoch 1778/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4701 - accuracy: 0.8327 - val_loss: 0.5967 - val_accuracy: 0.7721\n",
      "Epoch 1779/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4702 - accuracy: 0.8335 - val_loss: 0.5968 - val_accuracy: 0.7719\n",
      "Epoch 1780/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4701 - accuracy: 0.8331 - val_loss: 0.5968 - val_accuracy: 0.7719\n",
      "Epoch 1781/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4701 - accuracy: 0.8331 - val_loss: 0.5968 - val_accuracy: 0.7721\n",
      "Epoch 1782/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4701 - accuracy: 0.8329 - val_loss: 0.5968 - val_accuracy: 0.7721\n",
      "Epoch 1783/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4700 - accuracy: 0.8331 - val_loss: 0.5966 - val_accuracy: 0.7721\n",
      "Epoch 1784/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4700 - accuracy: 0.8335 - val_loss: 0.5967 - val_accuracy: 0.7721\n",
      "Epoch 1785/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4700 - accuracy: 0.8330 - val_loss: 0.5967 - val_accuracy: 0.7719\n",
      "Epoch 1786/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4700 - accuracy: 0.8330 - val_loss: 0.5966 - val_accuracy: 0.7724\n",
      "Epoch 1787/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4700 - accuracy: 0.8327 - val_loss: 0.5967 - val_accuracy: 0.7719\n",
      "Epoch 1788/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4699 - accuracy: 0.8330 - val_loss: 0.5967 - val_accuracy: 0.7730\n",
      "Epoch 1789/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4699 - accuracy: 0.8332 - val_loss: 0.5967 - val_accuracy: 0.7726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1790/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4699 - accuracy: 0.8335 - val_loss: 0.5968 - val_accuracy: 0.7724\n",
      "Epoch 1791/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4699 - accuracy: 0.8336 - val_loss: 0.5967 - val_accuracy: 0.7719\n",
      "Epoch 1792/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4699 - accuracy: 0.8331 - val_loss: 0.5970 - val_accuracy: 0.7726\n",
      "Epoch 1793/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4699 - accuracy: 0.8332 - val_loss: 0.5969 - val_accuracy: 0.7728\n",
      "Epoch 1794/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4698 - accuracy: 0.8332 - val_loss: 0.5967 - val_accuracy: 0.7728\n",
      "Epoch 1795/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4698 - accuracy: 0.8335 - val_loss: 0.5966 - val_accuracy: 0.7717\n",
      "Epoch 1796/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4698 - accuracy: 0.8332 - val_loss: 0.5967 - val_accuracy: 0.7719\n",
      "Epoch 1797/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4698 - accuracy: 0.8333 - val_loss: 0.5966 - val_accuracy: 0.7721\n",
      "Epoch 1798/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4697 - accuracy: 0.8331 - val_loss: 0.5968 - val_accuracy: 0.7721\n",
      "Epoch 1799/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4697 - accuracy: 0.8332 - val_loss: 0.5968 - val_accuracy: 0.7721\n",
      "Epoch 1800/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4697 - accuracy: 0.8334 - val_loss: 0.5967 - val_accuracy: 0.7719\n",
      "Epoch 1801/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4697 - accuracy: 0.8334 - val_loss: 0.5968 - val_accuracy: 0.7721\n",
      "Epoch 1802/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4697 - accuracy: 0.8328 - val_loss: 0.5967 - val_accuracy: 0.7724\n",
      "Epoch 1803/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4697 - accuracy: 0.8334 - val_loss: 0.5968 - val_accuracy: 0.7721\n",
      "Epoch 1804/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4696 - accuracy: 0.8331 - val_loss: 0.5968 - val_accuracy: 0.7717\n",
      "Epoch 1805/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4696 - accuracy: 0.8334 - val_loss: 0.5967 - val_accuracy: 0.7719\n",
      "Epoch 1806/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4696 - accuracy: 0.8335 - val_loss: 0.5967 - val_accuracy: 0.7717\n",
      "Epoch 1807/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4696 - accuracy: 0.8332 - val_loss: 0.5968 - val_accuracy: 0.7726\n",
      "Epoch 1808/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4696 - accuracy: 0.8329 - val_loss: 0.5968 - val_accuracy: 0.7733\n",
      "Epoch 1809/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4695 - accuracy: 0.8332 - val_loss: 0.5968 - val_accuracy: 0.7724\n",
      "Epoch 1810/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4695 - accuracy: 0.8335 - val_loss: 0.5967 - val_accuracy: 0.7721\n",
      "Epoch 1811/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4695 - accuracy: 0.8332 - val_loss: 0.5967 - val_accuracy: 0.7717\n",
      "Epoch 1812/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4695 - accuracy: 0.8339 - val_loss: 0.5967 - val_accuracy: 0.7712\n",
      "Epoch 1813/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4695 - accuracy: 0.8332 - val_loss: 0.5967 - val_accuracy: 0.7724\n",
      "Epoch 1814/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4695 - accuracy: 0.8336 - val_loss: 0.5968 - val_accuracy: 0.7717\n",
      "Epoch 1815/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4694 - accuracy: 0.8334 - val_loss: 0.5969 - val_accuracy: 0.7730\n",
      "Epoch 1816/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4694 - accuracy: 0.8332 - val_loss: 0.5966 - val_accuracy: 0.7724\n",
      "Epoch 1817/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4694 - accuracy: 0.8333 - val_loss: 0.5968 - val_accuracy: 0.7726\n",
      "Epoch 1818/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4694 - accuracy: 0.8333 - val_loss: 0.5967 - val_accuracy: 0.7728\n",
      "Epoch 1819/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.8335 - val_loss: 0.5967 - val_accuracy: 0.7714\n",
      "Epoch 1820/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4693 - accuracy: 0.8334 - val_loss: 0.5968 - val_accuracy: 0.7730\n",
      "Epoch 1821/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4694 - accuracy: 0.8332 - val_loss: 0.5968 - val_accuracy: 0.7728\n",
      "Epoch 1822/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4693 - accuracy: 0.8336 - val_loss: 0.5966 - val_accuracy: 0.7724\n",
      "Epoch 1823/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.8327 - val_loss: 0.5968 - val_accuracy: 0.7726\n",
      "Epoch 1824/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4693 - accuracy: 0.8331 - val_loss: 0.5967 - val_accuracy: 0.7726\n",
      "Epoch 1825/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4693 - accuracy: 0.8334 - val_loss: 0.5967 - val_accuracy: 0.7714\n",
      "Epoch 1826/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4692 - accuracy: 0.8332 - val_loss: 0.5969 - val_accuracy: 0.7714\n",
      "Epoch 1827/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4692 - accuracy: 0.8330 - val_loss: 0.5967 - val_accuracy: 0.7728\n",
      "Epoch 1828/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4692 - accuracy: 0.8340 - val_loss: 0.5966 - val_accuracy: 0.7721\n",
      "Epoch 1829/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4692 - accuracy: 0.8333 - val_loss: 0.5967 - val_accuracy: 0.7721\n",
      "Epoch 1830/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.8332 - val_loss: 0.5968 - val_accuracy: 0.7730\n",
      "Epoch 1831/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4691 - accuracy: 0.8334 - val_loss: 0.5968 - val_accuracy: 0.7724\n",
      "Epoch 1832/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4691 - accuracy: 0.8328 - val_loss: 0.5968 - val_accuracy: 0.7719\n",
      "Epoch 1833/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4691 - accuracy: 0.8327 - val_loss: 0.5967 - val_accuracy: 0.7721\n",
      "Epoch 1834/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4691 - accuracy: 0.8333 - val_loss: 0.5966 - val_accuracy: 0.7721\n",
      "Epoch 1835/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4691 - accuracy: 0.8335 - val_loss: 0.5967 - val_accuracy: 0.7719\n",
      "Epoch 1836/2000\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 0.4691 - accuracy: 0.8334 - val_loss: 0.5967 - val_accuracy: 0.7721\n",
      "Epoch 1837/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4690 - accuracy: 0.8335 - val_loss: 0.5966 - val_accuracy: 0.7724\n",
      "Epoch 1838/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4690 - accuracy: 0.8332 - val_loss: 0.5968 - val_accuracy: 0.7724\n",
      "Epoch 1839/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4690 - accuracy: 0.8336 - val_loss: 0.5966 - val_accuracy: 0.7721\n",
      "Epoch 1840/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4690 - accuracy: 0.8330 - val_loss: 0.5966 - val_accuracy: 0.7724\n",
      "Epoch 1841/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4690 - accuracy: 0.8334 - val_loss: 0.5967 - val_accuracy: 0.7730\n",
      "Epoch 1842/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4690 - accuracy: 0.8333 - val_loss: 0.5968 - val_accuracy: 0.7721\n",
      "Epoch 1843/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4689 - accuracy: 0.8333 - val_loss: 0.5968 - val_accuracy: 0.7721\n",
      "Epoch 1844/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4689 - accuracy: 0.8336 - val_loss: 0.5967 - val_accuracy: 0.7728\n",
      "Epoch 1845/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4689 - accuracy: 0.8332 - val_loss: 0.5967 - val_accuracy: 0.7719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1846/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4689 - accuracy: 0.8333 - val_loss: 0.5969 - val_accuracy: 0.7724\n",
      "Epoch 1847/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.8332 - val_loss: 0.5968 - val_accuracy: 0.7735\n",
      "Epoch 1848/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4689 - accuracy: 0.8332 - val_loss: 0.5967 - val_accuracy: 0.7721\n",
      "Epoch 1849/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4688 - accuracy: 0.8336 - val_loss: 0.5967 - val_accuracy: 0.7714\n",
      "Epoch 1850/2000\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 0.4688 - accuracy: 0.8335 - val_loss: 0.5966 - val_accuracy: 0.7726\n",
      "Epoch 1851/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4688 - accuracy: 0.8332 - val_loss: 0.5967 - val_accuracy: 0.7733\n",
      "Epoch 1852/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4688 - accuracy: 0.8334 - val_loss: 0.5968 - val_accuracy: 0.7714\n",
      "Epoch 1853/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.8331 - val_loss: 0.5966 - val_accuracy: 0.7733\n",
      "Epoch 1854/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.8335 - val_loss: 0.5968 - val_accuracy: 0.7742\n",
      "Epoch 1855/2000\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 0.4687 - accuracy: 0.8335 - val_loss: 0.5967 - val_accuracy: 0.7717\n",
      "Epoch 1856/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.8332 - val_loss: 0.5968 - val_accuracy: 0.7728\n",
      "Epoch 1857/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.8332 - val_loss: 0.5968 - val_accuracy: 0.7724\n",
      "Epoch 1858/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.8333 - val_loss: 0.5967 - val_accuracy: 0.7735\n",
      "Epoch 1859/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4686 - accuracy: 0.8333 - val_loss: 0.5967 - val_accuracy: 0.7730\n",
      "Epoch 1860/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4686 - accuracy: 0.8331 - val_loss: 0.5966 - val_accuracy: 0.7728\n",
      "Epoch 1861/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4686 - accuracy: 0.8335 - val_loss: 0.5967 - val_accuracy: 0.7728\n",
      "Epoch 1862/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4686 - accuracy: 0.8335 - val_loss: 0.5967 - val_accuracy: 0.7717\n",
      "Epoch 1863/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4686 - accuracy: 0.8328 - val_loss: 0.5969 - val_accuracy: 0.7726\n",
      "Epoch 1864/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4686 - accuracy: 0.8331 - val_loss: 0.5968 - val_accuracy: 0.7728\n",
      "Epoch 1865/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4686 - accuracy: 0.8335 - val_loss: 0.5969 - val_accuracy: 0.7719\n",
      "Epoch 1866/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4685 - accuracy: 0.8334 - val_loss: 0.5968 - val_accuracy: 0.7726\n",
      "Epoch 1867/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4685 - accuracy: 0.8334 - val_loss: 0.5968 - val_accuracy: 0.7714\n",
      "Epoch 1868/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4685 - accuracy: 0.8330 - val_loss: 0.5968 - val_accuracy: 0.7710\n",
      "Epoch 1869/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4685 - accuracy: 0.8335 - val_loss: 0.5968 - val_accuracy: 0.7714\n",
      "Epoch 1870/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4685 - accuracy: 0.8334 - val_loss: 0.5967 - val_accuracy: 0.7719\n",
      "Epoch 1871/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4685 - accuracy: 0.8335 - val_loss: 0.5968 - val_accuracy: 0.7726\n",
      "Epoch 1872/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4684 - accuracy: 0.8336 - val_loss: 0.5969 - val_accuracy: 0.7714\n",
      "Epoch 1873/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4684 - accuracy: 0.8333 - val_loss: 0.5968 - val_accuracy: 0.7730\n",
      "Epoch 1874/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4684 - accuracy: 0.8331 - val_loss: 0.5967 - val_accuracy: 0.7726\n",
      "Epoch 1875/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4684 - accuracy: 0.8333 - val_loss: 0.5968 - val_accuracy: 0.7714\n",
      "Epoch 1876/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4684 - accuracy: 0.8332 - val_loss: 0.5969 - val_accuracy: 0.7724\n",
      "Epoch 1877/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4684 - accuracy: 0.8332 - val_loss: 0.5968 - val_accuracy: 0.7714\n",
      "Epoch 1878/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4683 - accuracy: 0.8335 - val_loss: 0.5967 - val_accuracy: 0.7714\n",
      "Epoch 1879/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4683 - accuracy: 0.8331 - val_loss: 0.5968 - val_accuracy: 0.7726\n",
      "Epoch 1880/2000\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.8337 - val_loss: 0.5969 - val_accuracy: 0.7719\n",
      "Epoch 1881/2000\n",
      "136/136 [==============================] - 1s 4ms/step - loss: 0.4683 - accuracy: 0.8335 - val_loss: 0.5968 - val_accuracy: 0.7712\n",
      "Epoch 1882/2000\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.8330 - val_loss: 0.5968 - val_accuracy: 0.7719\n",
      "Epoch 1883/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4682 - accuracy: 0.8338 - val_loss: 0.5969 - val_accuracy: 0.7719\n",
      "Epoch 1884/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4682 - accuracy: 0.8335 - val_loss: 0.5968 - val_accuracy: 0.7724\n",
      "Epoch 1885/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.8338 - val_loss: 0.5969 - val_accuracy: 0.7726\n",
      "Epoch 1886/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.8340 - val_loss: 0.5967 - val_accuracy: 0.7726\n",
      "Epoch 1887/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.8334 - val_loss: 0.5968 - val_accuracy: 0.7724\n",
      "Epoch 1888/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.8338 - val_loss: 0.5968 - val_accuracy: 0.7712\n",
      "Epoch 1889/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.8338 - val_loss: 0.5967 - val_accuracy: 0.7721\n",
      "Epoch 1890/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.8333 - val_loss: 0.5968 - val_accuracy: 0.7719\n",
      "Epoch 1891/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.8335 - val_loss: 0.5968 - val_accuracy: 0.7724\n",
      "Epoch 1892/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.8332 - val_loss: 0.5967 - val_accuracy: 0.7726\n",
      "Epoch 1893/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.8339 - val_loss: 0.5967 - val_accuracy: 0.7710\n",
      "Epoch 1894/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.8341 - val_loss: 0.5968 - val_accuracy: 0.7724\n",
      "Epoch 1895/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.8334 - val_loss: 0.5968 - val_accuracy: 0.7726\n",
      "Epoch 1896/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.8337 - val_loss: 0.5968 - val_accuracy: 0.7717\n",
      "Epoch 1897/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.8335 - val_loss: 0.5968 - val_accuracy: 0.7728\n",
      "Epoch 1898/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.8333 - val_loss: 0.5968 - val_accuracy: 0.7717\n",
      "Epoch 1899/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.8334 - val_loss: 0.5968 - val_accuracy: 0.7724\n",
      "Epoch 1900/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.8336 - val_loss: 0.5968 - val_accuracy: 0.7728\n",
      "Epoch 1901/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.8337 - val_loss: 0.5969 - val_accuracy: 0.7714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1902/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.8334 - val_loss: 0.5968 - val_accuracy: 0.7724\n",
      "Epoch 1903/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.8328 - val_loss: 0.5968 - val_accuracy: 0.7719\n",
      "Epoch 1904/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.8338 - val_loss: 0.5968 - val_accuracy: 0.7726\n",
      "Epoch 1905/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.8338 - val_loss: 0.5969 - val_accuracy: 0.7717\n",
      "Epoch 1906/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.8335 - val_loss: 0.5968 - val_accuracy: 0.7719\n",
      "Epoch 1907/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.8331 - val_loss: 0.5969 - val_accuracy: 0.7717\n",
      "Epoch 1908/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.8332 - val_loss: 0.5967 - val_accuracy: 0.7735\n",
      "Epoch 1909/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.8336 - val_loss: 0.5968 - val_accuracy: 0.7728\n",
      "Epoch 1910/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.8335 - val_loss: 0.5969 - val_accuracy: 0.7712\n",
      "Epoch 1911/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.8339 - val_loss: 0.5968 - val_accuracy: 0.7724\n",
      "Epoch 1912/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.8332 - val_loss: 0.5967 - val_accuracy: 0.7737\n",
      "Epoch 1913/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.8335 - val_loss: 0.5968 - val_accuracy: 0.7721\n",
      "Epoch 1914/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.8335 - val_loss: 0.5968 - val_accuracy: 0.7710\n",
      "Epoch 1915/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.8339 - val_loss: 0.5969 - val_accuracy: 0.7719\n",
      "Epoch 1916/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.8337 - val_loss: 0.5969 - val_accuracy: 0.7712\n",
      "Epoch 1917/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.8338 - val_loss: 0.5967 - val_accuracy: 0.7733\n",
      "Epoch 1918/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.8338 - val_loss: 0.5969 - val_accuracy: 0.7719\n",
      "Epoch 1919/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.8335 - val_loss: 0.5967 - val_accuracy: 0.7730\n",
      "Epoch 1920/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.8328 - val_loss: 0.5968 - val_accuracy: 0.7717\n",
      "Epoch 1921/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.8336 - val_loss: 0.5968 - val_accuracy: 0.7717\n",
      "Epoch 1922/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.8336 - val_loss: 0.5969 - val_accuracy: 0.7721\n",
      "Epoch 1923/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.8335 - val_loss: 0.5968 - val_accuracy: 0.7724\n",
      "Epoch 1924/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.8332 - val_loss: 0.5968 - val_accuracy: 0.7710\n",
      "Epoch 1925/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.8334 - val_loss: 0.5968 - val_accuracy: 0.7719\n",
      "Epoch 1926/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.8338 - val_loss: 0.5968 - val_accuracy: 0.7728\n",
      "Epoch 1927/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.8335 - val_loss: 0.5970 - val_accuracy: 0.7717\n",
      "Epoch 1928/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.8332 - val_loss: 0.5969 - val_accuracy: 0.7714\n",
      "Epoch 1929/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.8336 - val_loss: 0.5970 - val_accuracy: 0.7719\n",
      "Epoch 1930/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.8334 - val_loss: 0.5969 - val_accuracy: 0.7724\n",
      "Epoch 1931/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.8334 - val_loss: 0.5969 - val_accuracy: 0.7724\n",
      "Epoch 1932/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.8338 - val_loss: 0.5968 - val_accuracy: 0.7719\n",
      "Epoch 1933/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.8334 - val_loss: 0.5969 - val_accuracy: 0.7724\n",
      "Epoch 1934/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.8335 - val_loss: 0.5968 - val_accuracy: 0.7733\n",
      "Epoch 1935/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.8337 - val_loss: 0.5969 - val_accuracy: 0.7719\n",
      "Epoch 1936/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.8337 - val_loss: 0.5968 - val_accuracy: 0.7724\n",
      "Epoch 1937/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.8337 - val_loss: 0.5968 - val_accuracy: 0.7721\n",
      "Epoch 1938/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.8330 - val_loss: 0.5970 - val_accuracy: 0.7719\n",
      "Epoch 1939/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.8338 - val_loss: 0.5968 - val_accuracy: 0.7719\n",
      "Epoch 1940/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.8339 - val_loss: 0.5968 - val_accuracy: 0.7724\n",
      "Epoch 1941/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.8333 - val_loss: 0.5968 - val_accuracy: 0.7707\n",
      "Epoch 1942/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.8334 - val_loss: 0.5968 - val_accuracy: 0.7719\n",
      "Epoch 1943/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.8335 - val_loss: 0.5968 - val_accuracy: 0.7721\n",
      "Epoch 1944/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.8336 - val_loss: 0.5969 - val_accuracy: 0.7717\n",
      "Epoch 1945/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.8333 - val_loss: 0.5969 - val_accuracy: 0.7714\n",
      "Epoch 1946/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.8340 - val_loss: 0.5968 - val_accuracy: 0.7712\n",
      "Epoch 1947/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.8335 - val_loss: 0.5970 - val_accuracy: 0.7717\n",
      "Epoch 1948/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.8337 - val_loss: 0.5969 - val_accuracy: 0.7714\n",
      "Epoch 1949/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.8338 - val_loss: 0.5970 - val_accuracy: 0.7719\n",
      "Epoch 1950/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.8336 - val_loss: 0.5969 - val_accuracy: 0.7707\n",
      "Epoch 1951/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.8338 - val_loss: 0.5969 - val_accuracy: 0.7712\n",
      "Epoch 1952/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.8339 - val_loss: 0.5968 - val_accuracy: 0.7714\n",
      "Epoch 1953/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.8339 - val_loss: 0.5970 - val_accuracy: 0.7710\n",
      "Epoch 1954/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.8339 - val_loss: 0.5969 - val_accuracy: 0.7719\n",
      "Epoch 1955/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.8337 - val_loss: 0.5970 - val_accuracy: 0.7712\n",
      "Epoch 1956/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.8332 - val_loss: 0.5968 - val_accuracy: 0.7737\n",
      "Epoch 1957/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.8338 - val_loss: 0.5969 - val_accuracy: 0.7712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1958/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.8341 - val_loss: 0.5968 - val_accuracy: 0.7730\n",
      "Epoch 1959/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.8334 - val_loss: 0.5968 - val_accuracy: 0.7730\n",
      "Epoch 1960/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.8336 - val_loss: 0.5968 - val_accuracy: 0.7710\n",
      "Epoch 1961/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.8343 - val_loss: 0.5968 - val_accuracy: 0.7726\n",
      "Epoch 1962/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.8334 - val_loss: 0.5969 - val_accuracy: 0.7705\n",
      "Epoch 1963/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.8336 - val_loss: 0.5968 - val_accuracy: 0.7719\n",
      "Epoch 1964/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.8338 - val_loss: 0.5969 - val_accuracy: 0.7707\n",
      "Epoch 1965/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.8336 - val_loss: 0.5969 - val_accuracy: 0.7721\n",
      "Epoch 1966/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.8340 - val_loss: 0.5969 - val_accuracy: 0.7719\n",
      "Epoch 1967/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.8336 - val_loss: 0.5967 - val_accuracy: 0.7730\n",
      "Epoch 1968/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.8338 - val_loss: 0.5968 - val_accuracy: 0.7728\n",
      "Epoch 1969/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.8342 - val_loss: 0.5968 - val_accuracy: 0.7726\n",
      "Epoch 1970/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.8342 - val_loss: 0.5969 - val_accuracy: 0.7714\n",
      "Epoch 1971/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.8339 - val_loss: 0.5970 - val_accuracy: 0.7717\n",
      "Epoch 1972/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.8339 - val_loss: 0.5969 - val_accuracy: 0.7721\n",
      "Epoch 1973/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.8332 - val_loss: 0.5970 - val_accuracy: 0.7724\n",
      "Epoch 1974/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.8338 - val_loss: 0.5970 - val_accuracy: 0.7719\n",
      "Epoch 1975/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.8335 - val_loss: 0.5970 - val_accuracy: 0.7721\n",
      "Epoch 1976/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.8339 - val_loss: 0.5969 - val_accuracy: 0.7719\n",
      "Epoch 1977/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4667 - accuracy: 0.8339 - val_loss: 0.5968 - val_accuracy: 0.7726\n",
      "Epoch 1978/2000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4667 - accuracy: 0.8336 - val_loss: 0.5968 - val_accuracy: 0.7719\n",
      "Epoch 1979/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.8342 - val_loss: 0.5968 - val_accuracy: 0.7728\n",
      "Epoch 1980/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.8336 - val_loss: 0.5968 - val_accuracy: 0.7719\n",
      "Epoch 1981/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.8339 - val_loss: 0.5969 - val_accuracy: 0.7721\n",
      "Epoch 1982/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.8336 - val_loss: 0.5969 - val_accuracy: 0.7719\n",
      "Epoch 1983/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.8340 - val_loss: 0.5969 - val_accuracy: 0.7724\n",
      "Epoch 1984/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.8339 - val_loss: 0.5970 - val_accuracy: 0.7728\n",
      "Epoch 1985/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.8340 - val_loss: 0.5969 - val_accuracy: 0.7724\n",
      "Epoch 1986/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.8336 - val_loss: 0.5969 - val_accuracy: 0.7719\n",
      "Epoch 1987/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.8337 - val_loss: 0.5969 - val_accuracy: 0.7726\n",
      "Epoch 1988/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.8341 - val_loss: 0.5968 - val_accuracy: 0.7728\n",
      "Epoch 1989/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.8338 - val_loss: 0.5968 - val_accuracy: 0.7719\n",
      "Epoch 1990/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.8336 - val_loss: 0.5969 - val_accuracy: 0.7728\n",
      "Epoch 1991/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.8342 - val_loss: 0.5968 - val_accuracy: 0.7719\n",
      "Epoch 1992/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.8342 - val_loss: 0.5970 - val_accuracy: 0.7728\n",
      "Epoch 1993/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.8337 - val_loss: 0.5970 - val_accuracy: 0.7721\n",
      "Epoch 1994/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.8336 - val_loss: 0.5969 - val_accuracy: 0.7724\n",
      "Epoch 1995/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.8343 - val_loss: 0.5970 - val_accuracy: 0.7728\n",
      "Epoch 1996/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.8339 - val_loss: 0.5969 - val_accuracy: 0.7724\n",
      "Epoch 1997/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.8337 - val_loss: 0.5970 - val_accuracy: 0.7719\n",
      "Epoch 1998/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.8336 - val_loss: 0.5969 - val_accuracy: 0.7726\n",
      "Epoch 1999/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.8340 - val_loss: 0.5969 - val_accuracy: 0.7726\n",
      "Epoch 2000/2000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.8342 - val_loss: 0.5969 - val_accuracy: 0.7730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x186e0a48940>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 2000\n",
    "history=model.fit(X_train_idf.toarray(), y_train, batch_size=batch_size, epochs=epochs, shuffle=True, verbose=1,validation_split=0.2)\n",
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d00c466",
   "metadata": {},
   "source": [
    "##### 6) Finding Training and Testing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d517703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training and testing accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9dc7b678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 0s 1ms/step - loss: 0.6363 - accuracy: 0.7610\n",
      "Test Accuracy: 0.7609657049179077 and Test Loss: 0.6362605094909668\n"
     ]
    }
   ],
   "source": [
    "test_loss,test_acc=model.evaluate(X_test_idf.toarray(),y_test)\n",
    "print(f'Test Accuracy: {test_acc} and Test Loss: {test_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a47670",
   "metadata": {},
   "source": [
    "##### 7) Compute and plot the confusion matrix for the three classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7eb7ef1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 0s 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.75      0.77      1835\n",
      "     neutral       0.72      0.71      0.72      1801\n",
      "    positive       0.79      0.82      0.80      1790\n",
      "\n",
      "    accuracy                           0.76      5426\n",
      "   macro avg       0.76      0.76      0.76      5426\n",
      "weighted avg       0.76      0.76      0.76      5426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions=model.predict(X_test_idf.toarray())\n",
    "class_labels = ['negative', 'positive','neutral']\n",
    "predicted_class_labels = [class_labels[np.argmax(pred)] for pred in predictions]\n",
    "actual_class_labels=[class_labels[actual] for actual in y_test]\n",
    "print(classification_report(actual_class_labels, predicted_class_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9208658a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(actual_class_labels, predicted_class_labels, labels=class_labels)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Purples\", xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd974772",
   "metadata": {},
   "source": [
    "##### 8) Saving the final results in Excel sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0081b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision per class: [0.78029445 0.71603563 0.78594421]\n",
      "Recall per class: [0.75095368 0.71404775 0.81843575]\n"
     ]
    }
   ],
   "source": [
    "precision_per_class = precision_score(actual_class_labels, predicted_class_labels, average=None)\n",
    "recall_per_class = recall_score(actual_class_labels, predicted_class_labels, average=None)\n",
    "\n",
    "print(\"Precision per class:\", precision_per_class)\n",
    "print(\"Recall per class:\", recall_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7df0d2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1 Score: 0.7609657206044969\n",
      "Macro F1 Score: 0.7607480819780541\n"
     ]
    }
   ],
   "source": [
    "f1_micro = f1_score(actual_class_labels, predicted_class_labels, average='micro')\n",
    "f1_macro = f1_score(actual_class_labels, predicted_class_labels, average='macro')\n",
    "\n",
    "print(\"Micro F1 Score:\", f1_micro)\n",
    "print(\"Macro F1 Score:\", f1_macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7718ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>RandomDeletion_Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Training Accuracy</td>\n",
       "      <td>0.834274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Testing Accuracy</td>\n",
       "      <td>0.760966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Micro F1 Score</td>\n",
       "      <td>0.760966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Macro F1 Score</td>\n",
       "      <td>0.760748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Precision for Negative sentiment</td>\n",
       "      <td>0.780294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Precision for Positive sentiment</td>\n",
       "      <td>0.716036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Precision for Neutral sentiment</td>\n",
       "      <td>0.785944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Recall for Negative sentiment</td>\n",
       "      <td>0.750954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Recall for Positive sentiment</td>\n",
       "      <td>0.714048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Recall for Neutral sentiment</td>\n",
       "      <td>0.818436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Unnamed: 0  RandomDeletion_Dataset\n",
       "0                 Training Accuracy                0.834274\n",
       "1                  Testing Accuracy                0.760966\n",
       "2                    Micro F1 Score                0.760966\n",
       "3                    Macro F1 Score                0.760748\n",
       "4  Precision for Negative sentiment                0.780294\n",
       "5  Precision for Positive sentiment                0.716036\n",
       "6   Precision for Neutral sentiment                0.785944\n",
       "7     Recall for Negative sentiment                0.750954\n",
       "8     Recall for Positive sentiment                0.714048\n",
       "9      Recall for Neutral sentiment                0.818436"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=pd.read_csv('SimpleDNNModelResults.csv')\n",
    "result['RandomDeletion_Dataset']=[max(history.history['accuracy']),test_acc,f1_micro,f1_macro,precision_per_class[0],precision_per_class[1],precision_per_class[2],recall_per_class[0],recall_per_class[1],recall_per_class[2]]\n",
    "result[['Unnamed: 0','RandomDeletion_Dataset']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "448e60d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('SimpleDNNModelResults.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
